{"2024-12-09T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2412.06775v1","updated":"2024-12-09T18:57:57Z","published":"2024-12-09T18:57:57Z","title":"Delve into Visual Contrastive Decoding for Hallucination Mitigation of\n  Large Vision-Language Models","summary":"  While large vision-language models (LVLMs) have shown impressive capabilities\nin generating plausible responses correlated with input visual contents, they\nstill suffer from hallucinations, where the generated text inaccurately\nreflects visual contents. To address this, recent approaches apply contrastive\ndecoding to calibrate the model's response via contrasting output distributions\nwith original and visually distorted samples, demonstrating promising\nhallucination mitigation in a training-free manner. However, the potential of\nchanging information in visual inputs is not well-explored, so a deeper\ninvestigation into the behaviors of visual contrastive decoding is of great\ninterest. In this paper, we first explore various methods for contrastive\ndecoding to change visual contents, including image downsampling and editing.\nDownsampling images reduces the detailed textual information while editing\nyields new contents in images, providing new aspects as visual contrastive\nsamples. To further study benefits by using different contrastive samples, we\nanalyze probability-level metrics, including entropy and distribution distance.\nInterestingly, the effect of these samples in mitigating hallucinations varies\na lot across LVLMs and benchmarks. Based on our analysis, we propose a simple\nyet effective method to combine contrastive samples, offering a practical\nsolution for applying contrastive decoding across various scenarios. Extensive\nexperiments are conducted to validate the proposed fusion method among\ndifferent benchmarks.\n","authors":["Yi-Lun Lee","Yi-Hsuan Tsai","Wei-Chen Chiu"],"pdf_url":"https://arxiv.org/pdf/2412.06775v1.pdf","comment":"Under review. Project pages: https://github.com/YiLunLee/VCD_Analysis"},{"id":"http://arxiv.org/abs/2412.06769v1","updated":"2024-12-09T18:55:56Z","published":"2024-12-09T18:55:56Z","title":"Training Large Language Models to Reason in a Continuous Latent Space","summary":"  Large language models (LLMs) are restricted to reason in the \"language\nspace\", where they typically express the reasoning process with a\nchain-of-thought (CoT) to solve a complex reasoning problem. However, we argue\nthat language space may not always be optimal for reasoning. For example, most\nword tokens are primarily for textual coherence and not essential for\nreasoning, while some critical tokens require complex planning and pose huge\nchallenges to LLMs. To explore the potential of LLM reasoning in an\nunrestricted latent space instead of using natural language, we introduce a new\nparadigm Coconut (Chain of Continuous Thought). We utilize the last hidden\nstate of the LLM as a representation of the reasoning state (termed \"continuous\nthought\"). Rather than decoding this into a word token, we feed it back to the\nLLM as the subsequent input embedding directly in the continuous space.\nExperiments show that Coconut can effectively augment the LLM on several\nreasoning tasks. This novel latent reasoning paradigm leads to emergent\nadvanced reasoning patterns: the continuous thought can encode multiple\nalternative next reasoning steps, allowing the model to perform a breadth-first\nsearch (BFS) to solve the problem, rather than prematurely committing to a\nsingle deterministic path like CoT. Coconut outperforms CoT in certain logical\nreasoning tasks that require substantial backtracking during planning, with\nfewer thinking tokens during inference. These findings demonstrate the promise\nof latent reasoning and offer valuable insights for future research.\n","authors":["Shibo Hao","Sainbayar Sukhbaatar","DiJia Su","Xian Li","Zhiting Hu","Jason Weston","Yuandong Tian"],"pdf_url":"https://arxiv.org/pdf/2412.06769v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06748v1","updated":"2024-12-09T18:40:44Z","published":"2024-12-09T18:40:44Z","title":"Refusal Tokens: A Simple Way to Calibrate Refusals in Large Language\n  Models","summary":"  A key component of building safe and reliable language models is enabling the\nmodels to appropriately refuse to follow certain instructions or answer certain\nquestions. We may want models to output refusal messages for various categories\nof user queries, for example, ill-posed questions, instructions for committing\nillegal acts, or queries which require information past the model's knowledge\nhorizon. Engineering models that refuse to answer such questions is complicated\nby the fact that an individual may want their model to exhibit varying levels\nof sensitivity for refusing queries of various categories, and different users\nmay want different refusal rates. The current default approach involves\ntraining multiple models with varying proportions of refusal messages from each\ncategory to achieve the desired refusal rates, which is computationally\nexpensive and may require training a new model to accommodate each user's\ndesired preference over refusal rates. To address these challenges, we propose\nrefusal tokens, one such token for each refusal category or a single refusal\ntoken, which are prepended to the model's responses during training. We then\nshow how to increase or decrease the probability of generating the refusal\ntoken for each category during inference to steer the model's refusal behavior.\nRefusal tokens enable controlling a single model's refusal rates without the\nneed of any further fine-tuning, but only by selectively intervening during\ngeneration.\n","authors":["Neel Jain","Aditya Shrivastava","Chenyang Zhu","Daben Liu","Alfy Samuel","Ashwinee Panda","Anoop Kumar","Micah Goldblum","Tom Goldstein"],"pdf_url":"https://arxiv.org/pdf/2412.06748v1.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2412.06745v1","updated":"2024-12-09T18:37:14Z","published":"2024-12-09T18:37:14Z","title":"ONEBench to Test Them All: Sample-Level Benchmarking Over Open-Ended\n  Capabilities","summary":"  Traditional fixed test sets fall short in evaluating open-ended capabilities\nof foundation models. To address this, we propose ONEBench(OpeN-Ended\nBenchmarking), a new testing paradigm that consolidates individual evaluation\ndatasets into a unified, ever-expanding sample pool. ONEBench allows users to\ngenerate custom, open-ended evaluation benchmarks from this pool, corresponding\nto specific capabilities of interest. By aggregating samples across test sets,\nONEBench enables the assessment of diverse capabilities beyond those covered by\nthe original test sets, while mitigating overfitting and dataset bias. Most\nimportantly, it frames model evaluation as a collective process of selecting\nand aggregating sample-level tests.\n  The shift from task-specific benchmarks to ONEBench introduces two\nchallenges: (1)heterogeneity and (2)incompleteness. Heterogeneity refers to the\naggregation over diverse metrics, while incompleteness describes comparing\nmodels evaluated on different data subsets. To address these challenges, we\nexplore algorithms to aggregate sparse measurements into reliable model scores.\nOur aggregation algorithm ensures identifiability(asymptotically recovering\nground-truth scores) and rapid convergence, enabling accurate model ranking\nwith less data. On homogenous datasets, we show our aggregation algorithm\nprovides rankings that highly correlate with those produced by average scores.\nWe also demonstrate robustness to ~95% of measurements missing, reducing\nevaluation cost by up to 20x with little-to-no change in model rankings. We\nintroduce ONEBench-LLM for language models and ONEBench-LMM for vision-language\nmodels, unifying evaluations across these domains. Overall, we present a\ntechnique for open-ended evaluation, which can aggregate over incomplete,\nheterogeneous sample-level measurements to continually grow a benchmark\nalongside the rapidly developing foundation models.\n","authors":["Adhiraj Ghosh","Sebastian Dziadzio","Ameya Prabhu","Vishaal Udandarao","Samuel Albanie","Matthias Bethge"],"pdf_url":"https://arxiv.org/pdf/2412.06745v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.11796v4","updated":"2024-12-09T18:31:01Z","published":"2024-08-21T17:38:48Z","title":"LLM Pruning and Distillation in Practice: The Minitron Approach","summary":"  We present a comprehensive report on compressing the Llama 3.1 8B and Mistral\nNeMo 12B models to 4B and 8B parameters, respectively, using pruning and\ndistillation. We explore two distinct pruning strategies: (1) depth pruning and\n(2) joint hidden/attention/MLP (width) pruning, and evaluate the results on\ncommon benchmarks from the LM Evaluation Harness. The models are then aligned\nwith NeMo Aligner and tested in instruct-tuned versions. This approach produces\na compelling 4B model from Llama 3.1 8B and a state-of-the-art\nMistral-NeMo-Minitron-8B (MN-Minitron-8B for brevity) model from Mistral NeMo\n12B. We found that with no access to the original data, it is beneficial to\nslightly fine-tune teacher models on the distillation dataset. We open-source\nour base model weights on Hugging Face with a permissive license.\n","authors":["Sharath Turuvekere Sreenivas","Saurav Muralidharan","Raviraj Joshi","Marcin Chochowski","Ameya Sunil Mahabaleshwarkar","Gerald Shen","Jiaqi Zeng","Zijia Chen","Yoshi Suhara","Shizhe Diao","Chenhan Yu","Wei-Chun Chen","Hayley Ross","Oluwatobi Olabiyi","Ashwath Aithal","Oleksii Kuchaiev","Daniel Korzekwa","Pavlo Molchanov","Mostofa Patwary","Mohammad Shoeybi","Jan Kautz","Bryan Catanzaro"],"pdf_url":"https://arxiv.org/pdf/2408.11796v4.pdf","comment":"v4: Update author order"},{"id":"http://arxiv.org/abs/2412.03782v2","updated":"2024-12-09T18:28:06Z","published":"2024-12-05T00:05:11Z","title":"The broader spectrum of in-context learning","summary":"  The ability of language models to learn a task from a few examples in context\nhas generated substantial interest. Here, we provide a perspective that\nsituates this type of supervised few-shot learning within a much broader\nspectrum of meta-learned in-context learning. Indeed, we suggest that any\ndistribution of sequences in which context non-trivially decreases loss on\nsubsequent predictions can be interpreted as eliciting a kind of in-context\nlearning. We suggest that this perspective helps to unify the broad set of\nin-context abilities that language models exhibit $\\unicode{x2014}$ such as\nadapting to tasks from instructions or role play, or extrapolating time series.\nThis perspective also sheds light on potential roots of in-context learning in\nlower-level processing of linguistic dependencies (e.g. coreference or parallel\nstructures). Finally, taking this perspective highlights the importance of\ngeneralization, which we suggest can be studied along several dimensions: not\nonly the ability to learn something novel, but also flexibility in learning\nfrom different presentations, and in applying what is learned. We discuss\nbroader connections to past literature in meta-learning and goal-conditioned\nagents, and other perspectives on learning and adaptation. We close by\nsuggesting that research on in-context learning should consider this broader\nspectrum of in-context capabilities and types of generalization.\n","authors":["Andrew Kyle Lampinen","Stephanie C. Y. Chan","Aaditya K. Singh","Murray Shanahan"],"pdf_url":"https://arxiv.org/pdf/2412.03782v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06738v1","updated":"2024-12-09T18:27:32Z","published":"2024-12-09T18:27:32Z","title":"JAPAGEN: Efficient Few/Zero-shot Learning via Japanese Training Dataset\n  Generation with LLM","summary":"  Recently some studies have highlighted the potential of Large Language Models\n(LLMs) as effective generators of supervised training data, offering advantages\nsuch as enhanced inference efficiency and reduced costs associated with data\ncollection. However, these studies have predominantly focused on English\nlanguage tasks. In this paper, we address the fundamental research question:\nCan LLMs serve as proficient training data generators for other language tasks?\nSpecifically, we leverage LLMs to synthesize supervised training data under\nfew-shot and zero-shot learning scenarios across six diverse Japanese\ndownstream tasks. Subsequently, we utilize this synthesized data to train\ncompact models (e.g., BERT). This novel methodology is termed JAPAGEN. Our\nexperimental findings underscore that JAPAGEN achieves robust performance in\nclassification tasks that necessitate formal text inputs, demonstrating\ncompetitive results compared to conventional LLM prompting strategies.\n","authors":["Takuro Fujii","Satoru Katsumata"],"pdf_url":"https://arxiv.org/pdf/2412.06738v1.pdf","comment":"Accepted by PACLIC38 (2024)"},{"id":"http://arxiv.org/abs/2404.04850v2","updated":"2024-12-09T18:25:51Z","published":"2024-04-07T07:44:33Z","title":"How Many Languages Make Good Multilingual Instruction Tuning? A Case\n  Study on BLOOM","summary":"  Instruction tuning a large language model with multiple languages can prepare\nit for multilingual downstream tasks. Nonetheless, it is yet to be determined\nwhether having a handful of languages is sufficient, or whether the benefits\nincrease with the inclusion of more. By fine-tuning large multilingual models\non 1 to 52 languages, we present a case study on BLOOM to understand three\npertinent factors affecting performance: the number of languages, language\nexposure, and similarity between training and test languages. Overall we found\nthat 1) expanding language coverage in multilingual instruction tuning proves\nto be beneficial; 2) accuracy often significantly boots if the test language\nappears in the instruction mixture; 3) languages' genetic features correlate\nwith cross-lingual transfer more than merely the number of language but\ndifferent languages benefit to various degrees.\n","authors":["Shaoxiong Ji","Pinzhen Chen"],"pdf_url":"https://arxiv.org/pdf/2404.04850v2.pdf","comment":"COLING 2025"},{"id":"http://arxiv.org/abs/2412.06724v1","updated":"2024-12-09T18:13:27Z","published":"2024-12-09T18:13:27Z","title":"AutoDCWorkflow: LLM-based Data Cleaning Workflow Auto-Generation and\n  Benchmark","summary":"  We investigate the reasoning capabilities of large language models (LLMs) for\nautomatically generating data-cleaning workflows. To evaluate LLMs' ability to\ncomplete data-cleaning tasks, we implemented a pipeline for LLM-based Auto Data\nCleaning Workflow (AutoDCWorkflow), prompting LLMs on data cleaning operations\nto repair three types of data quality issues: duplicates, missing values, and\ninconsistent data formats. Given a dirty table and a purpose (expressed as a\nquery), this pipeline generates a minimal, clean table sufficient to address\nthe purpose and the data cleaning workflow used to produce the table. The\nplanning process involves three main LLM-driven components: (1) Select Target\nColumns: Identifies a set of target columns related to the purpose. (2) Inspect\nColumn Quality: Assesses the data quality for each target column and generates\na Data Quality Report as operation objectives. (3) Generate Operation &\nArguments: Predicts the next operation and arguments based on the data quality\nreport results. Additionally, we propose a data cleaning benchmark to evaluate\nthe capability of LLM agents to automatically generate workflows that address\ndata cleaning purposes of varying difficulty levels. The benchmark comprises\nthe annotated datasets as a collection of purpose, raw table, clean table, data\ncleaning workflow, and answer set. In our experiments, we evaluated three LLMs\nthat auto-generate purpose-driven data cleaning workflows. The results indicate\nthat LLMs perform well in planning and generating data-cleaning workflows\nwithout the need for fine-tuning.\n","authors":["Lan Li","Liri Fang","Vetle I. Torvik"],"pdf_url":"https://arxiv.org/pdf/2412.06724v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06720v1","updated":"2024-12-09T18:06:39Z","published":"2024-12-09T18:06:39Z","title":"VP-MEL: Visual Prompts Guided Multimodal Entity Linking","summary":"  Multimodal Entity Linking (MEL) is extensively utilized in the domains of\ninformation retrieval. However, existing MEL methods typically utilize mention\nwords as mentions for retrieval. This results in a significant dependence of\nMEL on mention words, thereby constraining its capacity to effectively leverage\ninformation from both images and text. In situations where mention words are\nabsent, MEL methods struggle to leverage image-text pairs for entity linking.\nTo solve these issues, we introduce a Visual Prompts guided Multimodal Entity\nLinking (VP-MEL) task. VP-MEL directly marks specific regions within the image.\nThese markers are referred to as visual prompts in VP-MEL. Without mention\nwords, VP-MEL aims to utilize marked image-text pairs to align visual prompts\nwith specific entities in the knowledge bases. A new dataset for the VP-MEL\ntask, VPWiki, is proposed in this paper. Moreover, we propose a framework named\nFBMEL, which enhances the significance of visual prompts and fully leverages\nthe information in image-text pairs. Experimental results on the VPWiki dataset\ndemonstrate that FBMEL outperforms baseline methods across multiple benchmarks\nfor the VP-MEL task.\n","authors":["Hongze Mi","Jinyuan Li","Xuying Zhang","Haoran Cheng","Jiahao Wang","Di Sun","Gang Pan"],"pdf_url":"https://arxiv.org/pdf/2412.06720v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06712v1","updated":"2024-12-09T18:01:13Z","published":"2024-12-09T18:01:13Z","title":"How to Merge Your Multimodal Models Over Time?","summary":"  Model merging combines multiple expert models - finetuned from a base\nfoundation model on diverse tasks and domains - into a single, more capable\nmodel. However, most existing model merging approaches assume that all experts\nare available simultaneously. In reality, new tasks and domains emerge\nprogressively over time, requiring strategies to integrate the knowledge of\nexpert models as they become available: a process we call temporal model\nmerging. The temporal dimension introduces unique challenges not addressed in\nprior work, raising new questions such as: when training for a new task, should\nthe expert model start from the merged past experts or from the original base\nmodel? Should we merge all models at each time step? Which merging techniques\nare best suited for temporal merging? Should different strategies be used to\ninitialize the training and deploy the model? To answer these questions, we\npropose a unified framework called TIME - Temporal Integration of Model\nExpertise - which defines temporal model merging across three axes: (1)\nInitialization Phase, (2) Deployment Phase, and (3) Merging Technique. Using\nTIME, we study temporal model merging across model sizes, compute budgets, and\nlearning horizons on the FoMo-in-Flux benchmark. Our comprehensive suite of\nexperiments across TIME allows us to uncover key insights for temporal model\nmerging, offering a better understanding of current challenges and best\npractices for effective temporal model merging.\n","authors":["Sebastian Dziadzio","Vishaal Udandarao","Karsten Roth","Ameya Prabhu","Zeynep Akata","Samuel Albanie","Matthias Bethge"],"pdf_url":"https://arxiv.org/pdf/2412.06712v1.pdf","comment":"Technical Report. Code at\n  https://github.com/ExplainableML/fomo_in_flux"},{"id":"http://arxiv.org/abs/2412.06693v1","updated":"2024-12-09T17:39:43Z","published":"2024-12-09T17:39:43Z","title":"OmniEvalKit: A Modular, Lightweight Toolbox for Evaluating Large\n  Language Model and its Omni-Extensions","summary":"  The rapid advancements in Large Language Models (LLMs) have significantly\nexpanded their applications, ranging from multilingual support to\ndomain-specific tasks and multimodal integration. In this paper, we present\nOmniEvalKit, a novel benchmarking toolbox designed to evaluate LLMs and their\nomni-extensions across multilingual, multidomain, and multimodal capabilities.\nUnlike existing benchmarks that often focus on a single aspect, OmniEvalKit\nprovides a modular, lightweight, and automated evaluation system. It is\nstructured with a modular architecture comprising a Static Builder and Dynamic\nData Flow, promoting the seamless integration of new models and datasets.\nOmniEvalKit supports over 100 LLMs and 50 evaluation datasets, covering\ncomprehensive evaluations across thousands of model-dataset combinations.\nOmniEvalKit is dedicated to creating an ultra-lightweight and fast-deployable\nevaluation framework, making downstream applications more convenient and\nversatile for the AI community.\n","authors":["Yi-Kai Zhang","Xu-Xiang Zhong","Shiyin Lu","Qing-Guo Chen","De-Chuan Zhan","Han-Jia Ye"],"pdf_url":"https://arxiv.org/pdf/2412.06693v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06676v1","updated":"2024-12-09T17:13:20Z","published":"2024-12-09T17:13:20Z","title":"I Don't Know: Explicit Modeling of Uncertainty with an [IDK] Token","summary":"  Large Language Models are known to capture real-world knowledge, allowing\nthem to excel in many downstream tasks. Despite recent advances, these models\nare still prone to what are commonly known as hallucinations, causing them to\nemit unwanted and factually incorrect text. In this work, we propose a novel\ncalibration method that can be used to combat hallucinations. We add a special\n[IDK] (\"I don't know\") token to the model's vocabulary and introduce an\nobjective function that shifts probability mass to the [IDK] token for\nincorrect predictions. This approach allows the model to express uncertainty in\nits output explicitly. We evaluate our proposed method across multiple model\narchitectures and factual downstream tasks. We find that models trained with\nour method are able to express uncertainty in places where they would\npreviously make mistakes while suffering only a small loss of encoded\nknowledge. We further perform extensive ablation studies of multiple variations\nof our approach and provide a detailed analysis of the precision-recall\ntradeoff of our method.\n","authors":["Roi Cohen","Konstantin Dobler","Eden Biran","Gerard de Melo"],"pdf_url":"https://arxiv.org/pdf/2412.06676v1.pdf","comment":"Published at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2412.06654v1","updated":"2024-12-09T16:54:54Z","published":"2024-12-09T16:54:54Z","title":"GEAR: A Simple GENERATE, EMBED, AVERAGE AND RANK Approach for\n  Unsupervised Reverse Dictionary","summary":"  Reverse Dictionary (RD) is the task of obtaining the most relevant word or\nset of words given a textual description or dictionary definition. Effective RD\nmethods have applications in accessibility, translation or writing support\nsystems. Moreover, in NLP research we find RD to be used to benchmark text\nencoders at various granularities, as it often requires word, definition and\nsentence embeddings. In this paper, we propose a simple approach to RD that\nleverages LLMs in combination with embedding models. Despite its simplicity,\nthis approach outperforms supervised baselines in well studied RD datasets,\nwhile also showing less over-fitting. We also conduct a number of experiments\non different dictionaries and analyze how different styles, registers and\ntarget audiences impact the quality of RD systems. We conclude that, on\naverage, untuned embeddings alone fare way below an LLM-only baseline (although\nthey are competitive in highly technical dictionaries), but are crucial for\nboosting performance in combined methods.\n","authors":["Fatemah Almeman","Luis Espinosa-Anke"],"pdf_url":"https://arxiv.org/pdf/2412.06654v1.pdf","comment":"9 pages, Accepted at COLING 2025"},{"id":"http://arxiv.org/abs/2408.15138v2","updated":"2024-12-09T16:53:42Z","published":"2024-08-27T15:23:09Z","title":"How transformers learn structured data: insights from hierarchical\n  filtering","summary":"  Understanding the learning process and the embedded computation in\ntransformers is becoming a central goal for the development of interpretable\nAI. In the present study, we introduce a hierarchical filtering procedure for\ngenerative models of sequences on trees, allowing us to hand-tune the range of\npositional correlations in the data. Leveraging this controlled setting, we\nprovide evidence that vanilla encoder-only transformers can approximate the\nexact inference algorithm when trained on root classification and masked\nlanguage modeling tasks, and study how this computation is discovered and\nimplemented. We find that correlations at larger distances, corresponding to\nincreasing layers of the hierarchy, are sequentially included by the network\nduring training. Moreover, by comparing attention maps from models trained with\nvarying degrees of filtering and by probing the different encoder levels, we\nfind clear evidence of a reconstruction of correlations on successive length\nscales corresponding to the various levels of the hierarchy, which we relate to\na plausible implementation of the exact inference algorithm within the same\narchitecture.\n","authors":["Jerome Garnier-Brun","Marc Mézard","Emanuele Moscato","Luca Saglietti"],"pdf_url":"https://arxiv.org/pdf/2408.15138v2.pdf","comment":"21 pages, 15 figures"},{"id":"http://arxiv.org/abs/2403.16851v2","updated":"2024-12-09T16:42:25Z","published":"2024-03-25T15:15:09Z","title":"Can tweets predict article retractions? A comparison between human and\n  LLM labelling","summary":"  Quickly detecting problematic research articles is crucial to safeguarding\nthe integrity of scientific research. This study explores whether Twitter\nmentions of retracted articles can signal potential problems with the articles\nprior to their retraction, potentially serving as an early warning system for\nscholars. To investigate this, we analysed a dataset of 4,354 Twitter mentions\nassociated with 504 retracted articles. The effectiveness of Twitter mentions\nin predicting article retractions was evaluated by both manual and Large\nLanguage Model (LLM) labelling. Manual labelling results indicated that 25.7%\nof tweets signalled problems before retraction. Using the manual labelling\nresults as the baseline, we found that LLMs (GPT-4o-mini, Gemini 1.5 Flash, and\nClaude-3.5-Haiku) outperformed lexicon-based sentiment analysis tools (e.g.,\nTextBlob) in detecting potential problems, suggesting that automatic detection\nof problematic articles from social media using LLMs is technically feasible.\nNevertheless, since only a small proportion of retracted articles (11.1%) were\ncriticised on Twitter prior to retraction, such automatic systems would detect\nonly a minority of problematic articles. Overall, this study offers insights\ninto how social media data, coupled with emerging generative AI techniques, can\nsupport research integrity.\n","authors":["Er-Te Zheng","Hui-Zhen Fu","Mike Thelwall","Zhichao Fang"],"pdf_url":"https://arxiv.org/pdf/2403.16851v2.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2411.04105v3","updated":"2024-12-09T16:36:34Z","published":"2024-11-06T18:35:32Z","title":"How Transformers Solve Propositional Logic Problems: A Mechanistic\n  Analysis","summary":"  Large language models (LLMs) have shown amazing performance on tasks that\nrequire planning and reasoning. Motivated by this, we investigate the internal\nmechanisms that underpin a network's ability to perform complex logical\nreasoning. We first construct a synthetic propositional logic problem that\nserves as a concrete test-bed for network training and evaluation. Crucially,\nthis problem demands nontrivial planning to solve. We perform our study on two\nfronts. First, we pursue an understanding of precisely how a three-layer\ntransformer, trained from scratch and attains perfect test accuracy, solves\nthis problem. We are able to identify certain \"planning\" and \"reasoning\"\nmechanisms in the network that necessitate cooperation between the attention\nblocks to implement the desired logic. Second, we study how pretrained LLMs,\nnamely Mistral-7B and Gemma-2-9B, solve this problem. We characterize their\nreasoning circuits through causal intervention experiments, providing necessity\nand sufficiency evidence for the circuits. We find evidence suggesting that the\ntwo models' latent reasoning strategies are surprisingly similar, and\nhuman-like. Overall, our work systemically uncovers novel aspects of small and\nlarge transformers, and continues the study of how they plan and reason.\n","authors":["Guan Zhe Hong","Nishanth Dikkala","Enming Luo","Cyrus Rashtchian","Xin Wang","Rina Panigrahy"],"pdf_url":"https://arxiv.org/pdf/2411.04105v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.02830v3","updated":"2024-12-09T16:26:09Z","published":"2024-12-03T20:52:35Z","title":"RARE: Retrieval-Augmented Reasoning Enhancement for Large Language\n  Models","summary":"  This work introduces RARE (Retrieval-Augmented Reasoning Enhancement), a\nversatile extension to the mutual reasoning framework (rStar), aimed at\nenhancing reasoning accuracy and factual integrity across large language models\n(LLMs) for complex, knowledge-intensive tasks such as commonsense and medical\nreasoning. RARE incorporates two innovative actions within the Monte Carlo Tree\nSearch (MCTS) framework: A6, which generates search queries based on the\ninitial problem statement, performs information retrieval using those queries,\nand augments reasoning with the retrieved data to formulate the final answer;\nand A7, which leverages information retrieval specifically for generated\nsub-questions and re-answers these sub-questions with the relevant contextual\ninformation. Additionally, a Retrieval-Augmented Factuality Scorer is proposed\nto replace the original discriminator, prioritizing reasoning paths that meet\nhigh standards of factuality. Experimental results with LLaMA 3.1 show that\nRARE enables open-source LLMs to achieve competitive performance with top\nopen-source models like GPT-4 and GPT-4o. This research establishes RARE as a\nscalable solution for improving LLMs in domains where logical coherence and\nfactual integrity are critical.\n","authors":["Hieu Tran","Zonghai Yao","Junda Wang","Yifan Zhang","Zhichao Yang","Hong Yu"],"pdf_url":"https://arxiv.org/pdf/2412.02830v3.pdf","comment":"24 pages, 8 figures"},{"id":"http://arxiv.org/abs/2412.06619v1","updated":"2024-12-09T16:13:17Z","published":"2024-12-09T16:13:17Z","title":"Copyright-Protected Language Generation via Adaptive Model Fusion","summary":"  The risk of language models reproducing copyrighted material from their\ntraining data has led to the development of various protective measures. Among\nthese, inference-time strategies that impose constraints via post-processing\nhave shown promise in addressing the complexities of copyright regulation.\nHowever, they often incur prohibitive computational costs or suffer from\nperformance trade-offs. To overcome these limitations, we introduce\nCopyright-Protecting Model Fusion (CP-Fuse), a novel approach that combines\nmodels trained on disjoint sets of copyrighted material during inference. In\nparticular, CP-Fuse adaptively aggregates the model outputs to minimize the\nreproduction of copyrighted content, adhering to a crucial balancing property\nthat prevents the regurgitation of memorized data. Through extensive\nexperiments, we show that CP-Fuse significantly reduces the reproduction of\nprotected material without compromising the quality of text and code\ngeneration. Moreover, its post-hoc nature allows seamless integration with\nother protective measures, further enhancing copyright safeguards. Lastly, we\nshow that CP-Fuse is robust against common techniques for extracting training\ndata.\n","authors":["Javier Abad","Konstantin Donhauser","Francesco Pinto","Fanny Yang"],"pdf_url":"https://arxiv.org/pdf/2412.06619v1.pdf","comment":"47 pages, 21 Figures. arXiv admin note: substantial text overlap with\n  arXiv:2407.20105"},{"id":"http://arxiv.org/abs/2412.06602v1","updated":"2024-12-09T15:50:25Z","published":"2024-12-09T15:50:25Z","title":"Towards Controllable Speech Synthesis in the Era of Large Language\n  Models: A Survey","summary":"  Text-to-speech (TTS), also known as speech synthesis, is a prominent research\narea that aims to generate natural-sounding human speech from text. Recently,\nwith the increasing industrial demand, TTS technologies have evolved beyond\nsynthesizing human-like speech to enabling controllable speech generation. This\nincludes fine-grained control over various attributes of synthesized speech\nsuch as emotion, prosody, timbre, and duration. Besides, advancements in deep\nlearning, such as diffusion and large language models, have significantly\nenhanced controllable TTS over the past several years. In this paper, we\nconduct a comprehensive survey of controllable TTS, covering approaches ranging\nfrom basic control techniques to methods utilizing natural language prompts,\naiming to provide a clear understanding of the current state of research. We\nexamine the general controllable TTS pipeline, challenges, model architectures,\nand control strategies, offering a comprehensive and clear taxonomy of existing\nmethods. Additionally, we provide a detailed summary of datasets and evaluation\nmetrics and shed some light on the applications and future directions of\ncontrollable TTS. To the best of our knowledge, this survey paper provides the\nfirst comprehensive review of emerging controllable TTS methods, which can\nserve as a beneficial resource for both academic researchers and industry\npractitioners.\n","authors":["Tianxin Xie","Yan Rong","Pengfei Zhang","Li Liu"],"pdf_url":"https://arxiv.org/pdf/2412.06602v1.pdf","comment":"A comprehensive survey on controllable TTS, 23 pages, 6 tables, 4\n  figures, 280 references"},{"id":"http://arxiv.org/abs/2412.06593v1","updated":"2024-12-09T15:45:03Z","published":"2024-12-09T15:45:03Z","title":"Anchoring Bias in Large Language Models: An Experimental Study","summary":"  Large Language Models (LLMs) like GPT-4 and Gemini have significantly\nadvanced artificial intelligence by enabling machines to generate and\ncomprehend human-like text. Despite their impressive capabilities, LLMs are not\nimmune to limitations, including various biases. While much research has\nexplored demographic biases, the cognitive biases in LLMs have not been equally\nscrutinized. This study delves into anchoring bias, a cognitive bias where\ninitial information disproportionately influences judgment. Utilizing an\nexperimental dataset, we examine how anchoring bias manifests in LLMs and\nverify the effectiveness of various mitigation strategies. Our findings\nhighlight the sensitivity of LLM responses to biased hints. At the same time,\nour experiments show that, to mitigate anchoring bias, one needs to collect\nhints from comprehensive angles to prevent the LLMs from being anchored to\nindividual pieces of information, while simple algorithms such as\nChain-of-Thought, Thoughts of Principles, Ignoring Anchor Hints, and Reflection\nare not sufficient.\n","authors":["Jiaxu Lou"],"pdf_url":"https://arxiv.org/pdf/2412.06593v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.05374v4","updated":"2024-12-09T15:39:30Z","published":"2024-02-08T03:12:25Z","title":"CIC: A Framework for Culturally-Aware Image Captioning","summary":"  Image Captioning generates descriptive sentences from images using\nVision-Language Pre-trained models (VLPs) such as BLIP, which has improved\ngreatly. However, current methods lack the generation of detailed descriptive\ncaptions for the cultural elements depicted in the images, such as the\ntraditional clothing worn by people from Asian cultural groups. In this paper,\nwe propose a new framework, Culturally-aware Image Captioning (CIC), that\ngenerates captions and describes cultural elements extracted from cultural\nvisual elements in images representing cultures. Inspired by methods combining\nvisual modality and Large Language Models (LLMs) through appropriate prompts,\nour framework (1) generates questions based on cultural categories from images,\n(2) extracts cultural visual elements from Visual Question Answering (VQA)\nusing generated questions, and (3) generates culturally-aware captions using\nLLMs with the prompts. Our human evaluation conducted on 45 participants from 4\ndifferent cultural groups with a high understanding of the corresponding\nculture shows that our proposed framework generates more culturally descriptive\ncaptions when compared to the image captioning baseline based on VLPs.\nResources can be found at https://shane3606.github.io/cic..\n","authors":["Youngsik Yun","Jihie Kim"],"pdf_url":"https://arxiv.org/pdf/2402.05374v4.pdf","comment":"Accepted in IJCAI 2024"},{"id":"http://arxiv.org/abs/2412.06575v1","updated":"2024-12-09T15:28:39Z","published":"2024-12-09T15:28:39Z","title":"Data Quality Enhancement on the Basis of Diversity with Large Language\n  Models for Text Classification: Uncovered, Difficult, and Noisy","summary":"  In recent years, the use of large language models (LLMs) for text\nclassification has attracted widespread attention. Despite this, the\nclassification accuracy of LLMs has not yet universally surpassed that of\nsmaller models. LLMs can enhance their performance in text classification\nthrough fine-tuning. However, existing data quality research based on LLMs is\nchallenging to apply directly to solve text classification problems. To further\nimprove the performance of LLMs in classification tasks, this paper proposes a\ndata quality enhancement (DQE) method for text classification based on LLMs.\nThis method starts by using a greedy algorithm to select data, dividing the\ndataset into sampled and unsampled subsets, and then performing fine-tuning of\nthe LLMs using the sampled data. Subsequently, this model is used to predict\nthe outcomes for the unsampled data, categorizing incorrectly predicted data\ninto uncovered, difficult, and noisy data. Experimental results demonstrate\nthat our method effectively enhances the performance of LLMs in text\nclassification tasks and significantly improves training efficiency, saving\nnearly half of the training time. Our method has achieved state-of-the-art\nperformance in several open-source classification tasks.\n","authors":["Min Zeng","Caiquan Liu","Shiqi Zhang","Li Xie","Chen Sang","Xiaoxin Chen","Xiaoxin Chen"],"pdf_url":"https://arxiv.org/pdf/2412.06575v1.pdf","comment":"Accepted by COLING 2025(main, long paper)"},{"id":"http://arxiv.org/abs/2409.11148v2","updated":"2024-12-09T15:16:02Z","published":"2024-09-17T13:02:19Z","title":"Improving the Efficiency of Visually Augmented Language Models","summary":"  Despite the impressive performance of autoregressive Language Models (LM) it\nhas been shown that due to reporting bias, LMs lack visual knowledge, i.e. they\ndo not know much about the visual world and its properties. To augment LMs with\nvisual knowledge, existing solutions often rely on explicit images, requiring\ntime-consuming retrieval or image generation systems. This paper shows that\nexplicit images are not necessary to visually augment an LM. Instead, we use\nvisually-grounded text representations obtained from the well-known CLIP\nmultimodal system. For a fair comparison, we modify VALM, a visually-augmented\nLM which uses image retrieval and representation, to work directly with\nvisually-grounded text representations. We name this new model BLIND-VALM. We\nshow that BLIND-VALM performs on par with VALM for Visual Language\nUnderstanding (VLU), Natural Language Understanding (NLU) and Language Modeling\ntasks, despite being significantly more efficient and simpler. We also show\nthat scaling up our model within the compute budget of VALM, either increasing\nthe model or pre-training corpus size, we outperform VALM for all the\nevaluation tasks.\n","authors":["Paula Ontalvilla","Aitor Ormazabal","Gorka Azkune"],"pdf_url":"https://arxiv.org/pdf/2409.11148v2.pdf","comment":"COLING 2025"},{"id":"http://arxiv.org/abs/2412.06559v1","updated":"2024-12-09T15:11:40Z","published":"2024-12-09T15:11:40Z","title":"ProcessBench: Identifying Process Errors in Mathematical Reasoning","summary":"  As language models regularly make mistakes when solving math problems,\nautomated identification of errors in the reasoning process becomes\nincreasingly significant for their scalable oversight. In this paper, we\nintroduce ProcessBench for measuring the ability to identify erroneous steps in\nmathematical reasoning. It consists of 3,400 test cases, primarily focused on\ncompetition- and Olympiad-level math problems. Each test case contains a\nstep-by-step solution with error location annotated by human experts. Models\nare required to identify the earliest step that contains an error, or conclude\nthat all steps are correct. We conduct extensive evaluation on ProcessBench,\ninvolving two types of models: process reward models (PRMs) and critic models,\nwhere for the latter we prompt general language models to critique each\nsolution step by step. We draw two main observations: (1) Existing PRMs\ntypically fail to generalize to more challenging math problems beyond GSM8K and\nMATH. They underperform both critic models (i.e., prompted general language\nmodels) and our own trained PRM that is straightforwardly fine-tuned on the\nPRM800K dataset. (2) The best open-source model, QwQ-32B-Preview, has\ndemonstrated the critique capability competitive with the proprietary model\nGPT-4o, despite that it still lags behind the reasoning-specialized o1-mini. We\nhope ProcessBench can foster future research in reasoning process assessment,\npaving the way toward scalable oversight of language models.\n","authors":["Chujie Zheng","Zhenru Zhang","Beichen Zhang","Runji Lin","Keming Lu","Bowen Yu","Dayiheng Liu","Jingren Zhou","Junyang Lin"],"pdf_url":"https://arxiv.org/pdf/2412.06559v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06538v1","updated":"2024-12-09T14:48:14Z","published":"2024-12-09T14:48:14Z","title":"Understanding Factual Recall in Transformers via Associative Memories","summary":"  Large language models have demonstrated an impressive ability to perform\nfactual recall. Prior work has found that transformers trained on factual\nrecall tasks can store information at a rate proportional to their parameter\ncount. In our work, we show that shallow transformers can use a combination of\nassociative memories to obtain such near optimal storage capacity. We begin by\nproving that the storage capacities of both linear and MLP associative memories\nscale linearly with parameter count. We next introduce a synthetic factual\nrecall task, and prove that a transformer with a single layer of self-attention\nfollowed by an MLP can obtain 100% accuracy on the task whenever either the\ntotal number of self-attention parameters or MLP parameters scales (up to log\nfactors) linearly with the number of facts. In particular, the transformer can\ntrade off between using the value matrices or the MLP as an associative memory\nto store the dataset of facts. We complement these expressivity results with an\nanalysis of the gradient flow trajectory of a simplified linear attention model\ntrained on our factual recall task, where we show that the model exhibits\nsequential learning behavior.\n","authors":["Eshaan Nichani","Jason D. Lee","Alberto Bietti"],"pdf_url":"https://arxiv.org/pdf/2412.06538v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.18659v5","updated":"2024-12-09T14:41:04Z","published":"2024-02-28T19:09:08Z","title":"Large Language Models and Games: A Survey and Roadmap","summary":"  Recent years have seen an explosive increase in research on large language\nmodels (LLMs), and accompanying public engagement on the topic. While starting\nas a niche area within natural language processing, LLMs have shown remarkable\npotential across a broad range of applications and domains, including games.\nThis paper surveys the current state of the art across the various applications\nof LLMs in and for games, and identifies the different roles LLMs can take\nwithin a game. Importantly, we discuss underexplored areas and promising\ndirections for future uses of LLMs in games and we reconcile the potential and\nlimitations of LLMs within the games domain. As the first comprehensive survey\nand roadmap at the intersection of LLMs and games, we are hopeful that this\npaper will serve as the basis for groundbreaking research and innovation in\nthis exciting new field.\n","authors":["Roberto Gallotta","Graham Todd","Marvin Zammit","Sam Earle","Antonios Liapis","Julian Togelius","Georgios N. Yannakakis"],"pdf_url":"https://arxiv.org/pdf/2402.18659v5.pdf","comment":"Accepted for publication at the IEEE Transactions on Games (19 pages,\n  6 figures)"},{"id":"http://arxiv.org/abs/2404.00929v3","updated":"2024-12-09T14:30:11Z","published":"2024-04-01T05:13:56Z","title":"A Survey on Multilingual Large Language Models: Corpora, Alignment, and\n  Bias","summary":"  Based on the foundation of Large Language Models (LLMs), Multilingual LLMs\n(MLLMs) have been developed to address the challenges faced in multilingual\nnatural language processing, hoping to achieve knowledge transfer from\nhigh-resource languages to low-resource languages. However, significant\nlimitations and challenges still exist, such as language imbalance,\nmultilingual alignment, and inherent bias. In this paper, we aim to provide a\ncomprehensive analysis of MLLMs, delving deeply into discussions surrounding\nthese critical issues. First of all, we start by presenting an overview of\nMLLMs, covering their evolutions, key techniques, and multilingual capacities.\nSecondly, we explore the multilingual training corpora of MLLMs and the\nmultilingual datasets oriented for downstream tasks that are crucial to enhance\nthe cross-lingual capability of MLLMs. Thirdly, we survey the state-of-the-art\nstudies of multilingual representations and investigate whether the current\nMLLMs can learn a universal language representation. Fourthly, we discuss bias\non MLLMs, including its categories, evaluation metrics, and debiasing\ntechniques. Finally, we discuss existing challenges and point out promising\nresearch directions of MLLMs.\n","authors":["Yuemei Xu","Ling Hu","Jiayi Zhao","Zihan Qiu","Kexin XU","Yuqi Ye","Hanwen Gu"],"pdf_url":"https://arxiv.org/pdf/2404.00929v3.pdf","comment":"The article has been accepted by Frontiers of Computer Science (FCS),\n  with the DOI: {10.1007/s11704-024-40579-4}"},{"id":"http://arxiv.org/abs/2409.01369v2","updated":"2024-12-09T14:26:42Z","published":"2024-09-02T16:48:57Z","title":"Imitating Language via Scalable Inverse Reinforcement Learning","summary":"  The majority of language model training builds on imitation learning. It\ncovers pretraining, supervised fine-tuning, and affects the starting conditions\nfor reinforcement learning from human feedback (RLHF). The simplicity and\nscalability of maximum likelihood estimation (MLE) for next token prediction\nled to its role as predominant paradigm. However, the broader field of\nimitation learning can more effectively utilize the sequential structure\nunderlying autoregressive generation. We focus on investigating the inverse\nreinforcement learning (IRL) perspective to imitation, extracting rewards and\ndirectly optimizing sequences instead of individual token likelihoods and\nevaluate its benefits for fine-tuning large language models. We provide a new\nangle, reformulating inverse soft-Q-learning as a temporal difference\nregularized extension of MLE. This creates a principled connection between MLE\nand IRL and allows trading off added complexity with increased performance and\ndiversity of generations in the supervised fine-tuning (SFT) setting. We find\nclear advantages for IRL-based imitation, in particular for retaining diversity\nwhile maximizing task performance, rendering IRL a strong alternative on fixed\nSFT datasets even without online data generation. Our analysis of IRL-extracted\nreward functions further indicates benefits for more robust reward functions\nvia tighter integration of supervised and preference-based LLM post-training.\n","authors":["Markus Wulfmeier","Michael Bloesch","Nino Vieillard","Arun Ahuja","Jorg Bornschein","Sandy Huang","Artem Sokolov","Matt Barnes","Guillaume Desjardins","Alex Bewley","Sarah Maria Elisabeth Bechtle","Jost Tobias Springenberg","Nikola Momchev","Olivier Bachem","Matthieu Geist","Martin Riedmiller"],"pdf_url":"https://arxiv.org/pdf/2409.01369v2.pdf","comment":"Published at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.09259v2","updated":"2024-12-09T14:22:14Z","published":"2024-11-14T07:51:51Z","title":"Jailbreak Attacks and Defenses against Multimodal Generative Models: A\n  Survey","summary":"  The rapid evolution of multimodal foundation models has led to significant\nadvancements in cross-modal understanding and generation across diverse\nmodalities, including text, images, audio, and video. However, these models\nremain susceptible to jailbreak attacks, which can bypass built-in safety\nmechanisms and induce the production of potentially harmful content.\nConsequently, understanding the methods of jailbreak attacks and existing\ndefense mechanisms is essential to ensure the safe deployment of multimodal\ngenerative models in real-world scenarios, particularly in security-sensitive\napplications. To provide comprehensive insight into this topic, this survey\nreviews jailbreak and defense in multimodal generative models. First, given the\ngeneralized lifecycle of multimodal jailbreak, we systematically explore\nattacks and corresponding defense strategies across four levels: input,\nencoder, generator, and output. Based on this analysis, we present a detailed\ntaxonomy of attack methods, defense mechanisms, and evaluation frameworks\nspecific to multimodal generative models. Additionally, we cover a wide range\nof input-output configurations, including modalities such as Any-to-Text,\nAny-to-Vision, and Any-to-Any within generative systems. Finally, we highlight\ncurrent research challenges and propose potential directions for future\nresearch. The open-source repository corresponding to this work can be found at\nhttps://github.com/liuxuannan/Awesome-Multimodal-Jailbreak.\n","authors":["Xuannan Liu","Xing Cui","Peipei Li","Zekun Li","Huaibo Huang","Shuhan Xia","Miaoxuan Zhang","Yueying Zou","Ran He"],"pdf_url":"https://arxiv.org/pdf/2411.09259v2.pdf","comment":"ongoing work"},{"id":"http://arxiv.org/abs/2412.06512v1","updated":"2024-12-09T14:14:21Z","published":"2024-12-09T14:14:21Z","title":"The Fusion of Large Language Models and Formal Methods for Trustworthy\n  AI Agents: A Roadmap","summary":"  Large Language Models (LLMs) have emerged as a transformative AI paradigm,\nprofoundly influencing daily life through their exceptional language\nunderstanding and contextual generation capabilities. Despite their remarkable\nperformance, LLMs face a critical challenge: the propensity to produce\nunreliable outputs due to the inherent limitations of their learning-based\nnature. Formal methods (FMs), on the other hand, are a well-established\ncomputation paradigm that provides mathematically rigorous techniques for\nmodeling, specifying, and verifying the correctness of systems. FMs have been\nextensively applied in mission-critical software engineering, embedded systems,\nand cybersecurity. However, the primary challenge impeding the deployment of\nFMs in real-world settings lies in their steep learning curves, the absence of\nuser-friendly interfaces, and issues with efficiency and adaptability.\n  This position paper outlines a roadmap for advancing the next generation of\ntrustworthy AI systems by leveraging the mutual enhancement of LLMs and FMs.\nFirst, we illustrate how FMs, including reasoning and certification techniques,\ncan help LLMs generate more reliable and formally certified outputs.\nSubsequently, we highlight how the advanced learning capabilities and\nadaptability of LLMs can significantly enhance the usability, efficiency, and\nscalability of existing FM tools. Finally, we show that unifying these two\ncomputation paradigms -- integrating the flexibility and intelligence of LLMs\nwith the rigorous reasoning abilities of FMs -- has transformative potential\nfor the development of trustworthy AI software systems. We acknowledge that\nthis integration has the potential to enhance both the trustworthiness and\nefficiency of software engineering practices while fostering the development of\nintelligent FM tools capable of addressing complex yet real-world challenges.\n","authors":["Yedi Zhang","Yufan Cai","Xinyue Zuo","Xiaokun Luan","Kailong Wang","Zhe Hou","Yifan Zhang","Zhiyuan Wei","Meng Sun","Jun Sun","Jing Sun","Jin Song Dong"],"pdf_url":"https://arxiv.org/pdf/2412.06512v1.pdf","comment":"24 pages, 4 figures"},{"id":"http://arxiv.org/abs/2403.07937v3","updated":"2024-12-09T13:43:15Z","published":"2024-03-08T08:10:29Z","title":"Speech Robust Bench: A Robustness Benchmark For Speech Recognition","summary":"  As Automatic Speech Recognition (ASR) models become ever more pervasive, it\nis important to ensure that they make reliable predictions under corruptions\npresent in the physical and digital world. We propose Speech Robust Bench\n(SRB), a comprehensive benchmark for evaluating the robustness of ASR models to\ndiverse corruptions. SRB is composed of 114 input perturbations which simulate\nan heterogeneous range of corruptions that ASR models may encounter when\ndeployed in the wild. We use SRB to evaluate the robustness of several\nstate-of-the-art ASR models and observe that model size and certain modeling\nchoices such as the use of discrete representations, or self-training appear to\nbe conducive to robustness. We extend this analysis to measure the robustness\nof ASR models on data from various demographic subgroups, namely English and\nSpanish speakers, and males and females. Our results revealed noticeable\ndisparities in the model's robustness across subgroups. We believe that SRB\nwill significantly facilitate future research towards robust ASR models, by\nmaking it easier to conduct comprehensive and comparable robustness\nevaluations.\n","authors":["Muhammad A. Shah","David Solans Noguero","Mikko A. Heikkila","Bhiksha Raj","Nicolas Kourtellis"],"pdf_url":"https://arxiv.org/pdf/2403.07937v3.pdf","comment":"submitted to NeurIPS datasets and benchmark track 2025"},{"id":"http://arxiv.org/abs/2405.01159v2","updated":"2024-12-09T13:41:31Z","published":"2024-05-02T10:28:52Z","title":"TartuNLP at EvaLatin 2024: Emotion Polarity Detection","summary":"  This paper presents the TartuNLP team submission to EvaLatin 2024 shared task\nof the emotion polarity detection for historical Latin texts. Our system relies\non two distinct approaches to annotating training data for supervised learning:\n1) creating heuristics-based labels by adopting the polarity lexicon provided\nby the organizers and 2) generating labels with GPT4. We employed parameter\nefficient fine-tuning using the adapters framework and experimented with both\nmonolingual and cross-lingual knowledge transfer for training language and task\nadapters. Our submission with the LLM-generated labels achieved the overall\nfirst place in the emotion polarity detection task. Our results show that\nLLM-based annotations show promising results on texts in Latin.\n","authors":["Aleksei Dorkin","Kairit Sirts"],"pdf_url":"https://arxiv.org/pdf/2405.01159v2.pdf","comment":"Added Acknowledgments section"},{"id":"http://arxiv.org/abs/2412.06484v1","updated":"2024-12-09T13:34:23Z","published":"2024-12-09T13:34:23Z","title":"Small Languages, Big Models: A Study of Continual Training on Languages\n  of Norway","summary":"  Training large language models requires vast amounts of data, posing a\nchallenge for less widely spoken languages like Norwegian and even more so for\ntruly low-resource languages like S\\'ami. To address this issue, we present a\nnovel three-stage continual training approach. We also experiment with\ncombining causal and masked language modeling to get more flexible models.\nBased on our findings, we train, evaluate, and openly release a new large\ngenerative language model for Norwegian Bokm\\r{a}l, Nynorsk, and Northern\nS\\'ami with 11.4 billion parameters: NorMistral-11B.\n","authors":["David Samuel","Vladislav Mikhailov","Erik Velldal","Lilja Øvrelid","Lucas Georges Gabriel Charpentier","Andrey Kutuzov"],"pdf_url":"https://arxiv.org/pdf/2412.06484v1.pdf","comment":"pre-print, under review"},{"id":"http://arxiv.org/abs/2412.06483v1","updated":"2024-12-09T13:31:46Z","published":"2024-12-09T13:31:46Z","title":"SafeWorld: Geo-Diverse Safety Alignment","summary":"  In the rapidly evolving field of Large Language Models (LLMs), ensuring\nsafety is a crucial and widely discussed topic. However, existing works often\noverlook the geo-diversity of cultural and legal standards across the world. To\ndemonstrate the challenges posed by geo-diverse safety standards, we introduce\nSafeWorld, a novel benchmark specifically designed to evaluate LLMs' ability to\ngenerate responses that are not only helpful but also culturally sensitive and\nlegally compliant across diverse global contexts. SafeWorld encompasses 2,342\ntest user queries, each grounded in high-quality, human-verified cultural norms\nand legal policies from 50 countries and 493 regions/races. On top of it, we\npropose a multi-dimensional automatic safety evaluation framework that assesses\nthe contextual appropriateness, accuracy, and comprehensiveness of responses.\nOur evaluations reveal that current LLMs struggle to meet these criteria. To\nenhance LLMs' alignment with geo-diverse safety standards, we synthesize\nhelpful preference pairs for Direct Preference Optimization (DPO) alignment\ntraining. The preference pair construction aims to encourage LLMs to behave\nappropriately and provide precise references to relevant cultural norms and\npolicies when necessary. Our trained SafeWorldLM outperforms all competing\nmodels, including GPT-4o on all three evaluation dimensions by a large margin.\nGlobal human evaluators also note a nearly 20% higher winning rate in\nhelpfulness and harmfulness evaluation. Our code and data can be found here:\nhttps://github.com/PlusLabNLP/SafeWorld.\n","authors":["Da Yin","Haoyi Qiu","Kung-Hsiang Huang","Kai-Wei Chang","Nanyun Peng"],"pdf_url":"https://arxiv.org/pdf/2412.06483v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2404.12845v2","updated":"2024-12-09T13:30:56Z","published":"2024-04-19T12:26:28Z","title":"TartuNLP @ SIGTYP 2024 Shared Task: Adapting XLM-RoBERTa for Ancient and\n  Historical Languages","summary":"  We present our submission to the unconstrained subtask of the SIGTYP 2024\nShared Task on Word Embedding Evaluation for Ancient and Historical Languages\nfor morphological annotation, POS-tagging, lemmatization, character- and\nword-level gap-filling. We developed a simple, uniform, and computationally\nlightweight approach based on the adapters framework using parameter-efficient\nfine-tuning. We applied the same adapter-based approach uniformly to all tasks\nand 16 languages by fine-tuning stacked language- and task-specific adapters.\nOur submission obtained an overall second place out of three submissions, with\nthe first place in word-level gap-filling. Our results show the feasibility of\nadapting language models pre-trained on modern languages to historical and\nancient languages via adapter training.\n","authors":["Aleksei Dorkin","Kairit Sirts"],"pdf_url":"https://arxiv.org/pdf/2404.12845v2.pdf","comment":"11 pages, 3 figures, added Acknowledgments section"},{"id":"http://arxiv.org/abs/2407.08582v2","updated":"2024-12-09T13:26:37Z","published":"2024-07-11T15:07:26Z","title":"On the Universal Truthfulness Hyperplane Inside LLMs","summary":"  While large language models (LLMs) have demonstrated remarkable abilities\nacross various fields, hallucination remains a significant challenge. Recent\nstudies have explored hallucinations through the lens of internal\nrepresentations, proposing mechanisms to decipher LLMs' adherence to facts.\nHowever, these approaches often fail to generalize to out-of-distribution data,\nleading to concerns about whether internal representation patterns reflect\nfundamental factual awareness, or only overfit spurious correlations on the\nspecific datasets. In this work, we investigate whether a universal\ntruthfulness hyperplane that distinguishes the model's factually correct and\nincorrect outputs exists within the model. To this end, we scale up the number\nof training datasets and conduct an extensive evaluation -- we train the\ntruthfulness hyperplane on a diverse collection of over 40 datasets and examine\nits cross-task, cross-domain, and in-domain generalization. Our results\nindicate that increasing the diversity of the training datasets significantly\nenhances the performance in all scenarios, while the volume of data samples\nplays a less critical role. This finding supports the optimistic hypothesis\nthat a universal truthfulness hyperplane may indeed exist within the model,\noffering promising directions for future research.\n","authors":["Junteng Liu","Shiqi Chen","Yu Cheng","Junxian He"],"pdf_url":"https://arxiv.org/pdf/2407.08582v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.11272v4","updated":"2024-12-09T13:21:45Z","published":"2024-09-17T15:23:08Z","title":"LOLA -- An Open-Source Massively Multilingual Large Language Model","summary":"  This paper presents LOLA, a massively multilingual large language model\ntrained on more than 160 languages using a sparse Mixture-of-Experts\nTransformer architecture. Our architectural and implementation choices address\nthe challenge of harnessing linguistic diversity while maintaining efficiency\nand avoiding the common pitfalls of multilinguality. Our analysis of the\nevaluation results shows competitive performance in natural language generation\nand understanding tasks. Additionally, we demonstrate how the learned\nexpert-routing mechanism exploits implicit phylogenetic linguistic patterns to\npotentially alleviate the curse of multilinguality. We provide an in-depth look\nat the training process, an analysis of the datasets, and a balanced\nexploration of the model's strengths and limitations. As an open-source model,\nLOLA promotes reproducibility and serves as a robust foundation for future\nresearch. Our findings enable the development of compute-efficient multilingual\nmodels with strong, scalable performance across languages.\n","authors":["Nikit Srivastava","Denis Kuchelev","Tatiana Moteu Ngoli","Kshitij Shetty","Michael Röder","Hamada Zahera","Diego Moussallem","Axel-Cyrille Ngonga Ngomo"],"pdf_url":"https://arxiv.org/pdf/2409.11272v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06464v1","updated":"2024-12-09T13:09:04Z","published":"2024-12-09T13:09:04Z","title":"Gated Delta Networks: Improving Mamba2 with Delta Rule","summary":"  Linear Transformers have gained attention as efficient alternatives to\nstandard Transformers, but their performance in retrieval and long-context\ntasks has been limited. To address these limitations, recent work has explored\ntwo distinct mechanisms: gating for adaptive memory control and the delta\nupdate rule for precise memory modifications. We observe that these mechanisms\nare complementary: gating enables rapid memory erasure while the delta rule\nfacilitates targeted updates. Building on this insight, we introduce the gated\ndelta rule and develop a parallel training algorithm optimized for modern\nhardware. Our proposed architecture, Gated DeltaNet, consistently surpasses\nexisting models like Mamba2 and DeltaNet across multiple benchmarks, including\nlanguage modeling, common-sense reasoning, in-context retrieval, length\nextrapolation, and long-context understanding. We further enhance performance\nby developing hybrid architectures that combine Gated DeltaNet layers with\nsliding window attention or Mamba2 layers, achieving both improved training\nefficiency and superior task performance.\n","authors":["Songlin Yang","Jan Kautz","Ali Hatamizadeh"],"pdf_url":"https://arxiv.org/pdf/2412.06464v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2411.17265v2","updated":"2024-12-09T13:04:50Z","published":"2024-11-26T09:42:07Z","title":"A Topic-level Self-Correctional Approach to Mitigate Hallucinations in\n  MLLMs","summary":"  Aligning the behaviors of Multimodal Large Language Models (MLLMs) with human\npreferences is crucial for developing robust and trustworthy AI systems. While\nrecent attempts have employed human experts or powerful auxiliary AI systems to\nprovide more accurate preference feedback, such as determining the preferable\nresponses from MLLMs or directly rewriting hallucination-free responses,\nextensive resource overhead compromise the scalability of the feedback\ncollection. In this work, we introduce Topic-level Preference Overwriting\n(TPO), a self-correctional approach that guide the model itself to mitigate its\nown hallucination at the topic level. Through a deconfounded strategy that\nreplaces each topic within the response with the best or worst alternatives\ngenerated by the model itself, TPO creates more contrasting pairwise preference\nfeedback, enhancing the feedback quality without human or proprietary model\nintervention. Notably, the experimental results demonstrate proposed TPO\nachieves state-of-the-art performance in trustworthiness, significantly\nreducing the object hallucinations by 92% and overall hallucinations by 38%.\nCode, model and dataset are available now.\n","authors":["Lehan He","Zeren Chen","Zhelun Shi","Tianyu Yu","Jing Shao","Lu Sheng"],"pdf_url":"https://arxiv.org/pdf/2411.17265v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17218v4","updated":"2024-12-09T12:45:53Z","published":"2024-10-22T17:43:39Z","title":"Creativity in AI: Progresses and Challenges","summary":"  Creativity is the ability to produce novel, useful, and surprising ideas, and\nhas been widely studied as a crucial aspect of human cognition. Machine\ncreativity on the other hand has been a long-standing challenge. With the rise\nof advanced generative AI, there has been renewed interest and debate regarding\nAI's creative capabilities. Therefore, it is imperative to revisit the state of\ncreativity in AI and identify key progresses and remaining challenges. In this\nwork, we survey leading works studying the creative capabilities of AI systems,\nfocusing on creative problem-solving, linguistic, artistic, and scientific\ncreativity. Our review suggests that while the latest AI models are largely\ncapable of producing linguistically and artistically creative outputs such as\npoems, images, and musical pieces, they struggle with tasks that require\ncreative problem-solving, abstract thinking and compositionality and their\ngenerations suffer from a lack of diversity, originality, long-range\nincoherence and hallucinations. We also discuss key questions concerning\ncopyright and authorship issues with generative models. Furthermore, we\nhighlight the need for a comprehensive evaluation of creativity that is\nprocess-driven and considers several dimensions of creativity. Finally, we\npropose future research directions to improve the creativity of AI outputs,\ndrawing inspiration from cognitive science and psychology.\n","authors":["Mete Ismayilzada","Debjit Paul","Antoine Bosselut","Lonneke van der Plas"],"pdf_url":"https://arxiv.org/pdf/2410.17218v4.pdf","comment":"minor updates to content + figures"},{"id":"http://arxiv.org/abs/2412.06441v1","updated":"2024-12-09T12:35:58Z","published":"2024-12-09T12:35:58Z","title":"BoRA: Bi-dimensional Weight-Decomposed Low-Rank Adaptation","summary":"  In recent years, Parameter-Efficient Fine-Tuning (PEFT) methods like Low-Rank\nAdaptation (LoRA) have significantly enhanced the adaptability of large-scale\npre-trained models. Weight-Decomposed Low-Rank Adaptation (DoRA) improves upon\nLoRA by separating the magnitude and direction components of the weight matrix,\nleading to superior performance. However, DoRA's improvements are limited to\nthe vertical dimension, resulting in an asymmetrical pattern between horizontal\nand vertical dimensions. This paper introduces BoRA, an innovative extension of\nLoRA and DoRA, characterized by symmetrical properties across horizontal and\nvertical dimensions. Our approach optimizes the weight matrix symmetrically by\nadjusting both column-wise and row-wise magnitudes. Extensive experiments\ndemonstrate that BoRA surpasses state-of-the-art PEFT methods, including LoRA\nand DoRA, achieving superior results across various benchmarks.\n","authors":["Qiushi Wang","Yuchen Fan","Junwei Bao","Hongfei Jiang","Yang Song"],"pdf_url":"https://arxiv.org/pdf/2412.06441v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06432v1","updated":"2024-12-09T12:20:33Z","published":"2024-12-09T12:20:33Z","title":"Integrating Expert Labels into LLM-based Emission Goal Detection:\n  Example Selection vs Automatic Prompt Design","summary":"  We address the detection of emission reduction goals in corporate reports, an\nimportant task for monitoring companies' progress in addressing climate change.\nSpecifically, we focus on the issue of integrating expert feedback in the form\nof labeled example passages into LLM-based pipelines, and compare the two\nstrategies of (1) a dynamic selection of few-shot examples and (2) the\nautomatic optimization of the prompt by the LLM itself. Our findings on a\npublic dataset of 769 climate-related passages from real-world business reports\nindicate that automatic prompt optimization is the superior approach, while\ncombining both methods provides only limited benefit. Qualitative results\nindicate that optimized prompts do indeed capture many intricacies of the\ntargeted emission goal extraction task.\n","authors":["Marco Wrzalik","Adrian Ulges","Anne Uersfeld","Florian Faust"],"pdf_url":"https://arxiv.org/pdf/2412.06432v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06419v1","updated":"2024-12-09T11:57:16Z","published":"2024-12-09T11:57:16Z","title":"LLM-BIP: Structured Pruning for Large Language Models with Block-Wise\n  Forward Importance Propagation","summary":"  Large language models (LLMs) have demonstrated remarkable performance across\nvarious language tasks, but their widespread deployment is impeded by their\nlarge size and high computational costs. Structural pruning is a prevailing\ntechnique used to introduce sparsity into pre-trained models and facilitate\ndirect hardware acceleration during inference by removing redundant connections\n(structurally-grouped parameters), such as channels and attention heads.\nExisting structural pruning approaches often employ either global or layer-wise\npruning criteria; however, they are hindered by ineffectiveness stemming from\ninaccurate evaluation of connection importance. Global pruning methods\ntypically assess component importance using near-zero and unreliable gradients,\nwhile layer-wise pruning approaches encounter significant pruning error\naccumulation issues. To this end, we propose a more accurate pruning metric\nbased on the block-wise importance score propagation, termed LLM-BIP.\nSpecifically, LLM-BIP precisely evaluates connection importance by gauging its\ninfluence on the respective transformer block output, which can be efficiently\napproximated in a single forward pass through an upper bound derived from the\nassumption of Lipschitz continuity. We evaluate the proposed method using\nLLaMA-7B, Vicuna-7B, and LLaMA-13B across common zero-shot tasks. The results\ndemonstrate that our approach achieves an average of 3.26% increase in accuracy\nfor common reasoning tasks compared to previous best baselines. It also reduces\nperplexity by 14.09 and 68.76 on average for the WikiText2 dataset and PTB\ndataset, respectively.\n","authors":["Haihang Wu"],"pdf_url":"https://arxiv.org/pdf/2412.06419v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06412v1","updated":"2024-12-09T11:40:06Z","published":"2024-12-09T11:40:06Z","title":"StarWhisper Telescope: Agent-Based Observation Assistant System to\n  Approach AI Astrophysicist","summary":"  With the rapid advancements in Large Language Models (LLMs), LLM-based agents\nhave introduced convenient and user-friendly methods for leveraging tools\nacross various domains. In the field of astronomical observation, the\nconstruction of new telescopes has significantly increased astronomers'\nworkload. Deploying LLM-powered agents can effectively alleviate this burden\nand reduce the costs associated with training personnel. Within the Nearby\nGalaxy Supernovae Survey (NGSS) project, which encompasses eight telescopes\nacross three observation sites, aiming to find the transients from the galaxies\nin 50 mpc, we have developed the \\textbf{StarWhisper Telescope System} to\nmanage the entire observation process. This system automates tasks such as\ngenerating observation lists, conducting observations, analyzing data, and\nproviding feedback to the observer. Observation lists are customized for\ndifferent sites and strategies to ensure comprehensive coverage of celestial\nobjects. After manual verification, these lists are uploaded to the telescopes\nvia the agents in the system, which initiates observations upon neutral\nlanguage. The observed images are analyzed in real-time, and the transients are\npromptly communicated to the observer. The agent modifies them into a real-time\nfollow-up observation proposal and send to the Xinglong observatory group chat,\nthen add them to the next-day observation lists. Additionally, the integration\nof AI agents within the system provides online accessibility, saving\nastronomers' time and encouraging greater participation from amateur\nastronomers in the NGSS project.\n","authors":["Cunshi Wang","Xinjie Hu","Yu Zhang","Xunhao Chen","Pengliang Du","Yiming Mao","Rui Wang","Yuyang Li","Ying Wu","Hang Yang","Yansong Li","Beichuan Wang","Haiyang Mu","Zheng Wang","Jianfeng Tian","Liang Ge","Yongna Mao","Shengming Li","Xiaomeng Lu","Jinhang Zou","Yang Huang","Ningchen Sun","Jie Zheng","Min He","Yu Bai","Junjie Jin","Hong Wu","Chaohui Shang","Jifeng Liu"],"pdf_url":"https://arxiv.org/pdf/2412.06412v1.pdf","comment":"21 pages, 18 figures"},{"id":"http://arxiv.org/abs/2402.08467v2","updated":"2024-12-09T11:34:28Z","published":"2024-02-13T13:50:08Z","title":"Lying Blindly: Bypassing ChatGPT's Safeguards to Generate Hard-to-Detect\n  Disinformation Claims","summary":"  As Large Language Models become more proficient, their misuse in coordinated\ndisinformation campaigns is a growing concern. This study explores the\ncapability of ChatGPT with GPT-3.5 to generate short-form disinformation claims\nabout the war in Ukraine, both in general and on a specific event, which is\nbeyond the GPT-3.5 knowledge cutoff. Unlike prior work, we do not provide the\nmodel with human-written disinformation narratives by including them in the\nprompt. Thus the generated short claims are hallucinations based on prior world\nknowledge and inference from the minimal prompt. With a straightforward\nprompting technique, we are able to bypass model safeguards and generate\nnumerous short claims. We compare those against human-authored false claims on\nthe war in Ukraine from ClaimReview, specifically with respect to differences\nin their linguistic properties. We also evaluate whether AI authorship can be\ndifferentiated by human readers or state-of-the-art authorship detection tools.\nThus, we demonstrate that ChatGPT can produce realistic, target-specific\ndisinformation claims, even on a specific post-cutoff event, and that they\ncannot be reliably distinguished by humans or existing automated tools.\n","authors":["Freddy Heppell","Mehmet E. Bakir","Kalina Bontcheva"],"pdf_url":"https://arxiv.org/pdf/2402.08467v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06394v1","updated":"2024-12-09T11:22:59Z","published":"2024-12-09T11:22:59Z","title":"GameArena: Evaluating LLM Reasoning through Live Computer Games","summary":"  Evaluating the reasoning abilities of large language models (LLMs) is\nchallenging. Existing benchmarks often depend on static datasets, which are\nvulnerable to data contamination and may get saturated over time, or on binary\nlive human feedback that conflates reasoning with other abilities. As the most\nprominent dynamic benchmark, Chatbot Arena evaluates open-ended questions in\nreal-world settings, but lacks the granularity in assessing specific reasoning\ncapabilities. We introduce GameArena, a dynamic benchmark designed to evaluate\nLLM reasoning capabilities through interactive gameplay with humans. GameArena\nconsists of three games designed to test specific reasoning capabilities (e.g.,\ndeductive and inductive reasoning), while keeping participants entertained and\nengaged. We analyze the gaming data retrospectively to uncover the underlying\nreasoning processes of LLMs and measure their fine-grained reasoning\ncapabilities. We collect over 2000 game sessions and provide detailed\nassessments of various reasoning capabilities for five state-of-the-art LLMs.\nOur user study with 100 participants suggests that GameArena improves user\nengagement compared to Chatbot Arena. For the first time, GameArena enables the\ncollection of step-by-step LLM reasoning data in the wild.\n","authors":["Lanxiang Hu","Qiyu Li","Anze Xie","Nan Jiang","Ion Stoica","Haojian Jin","Hao Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.06394v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.13591v4","updated":"2024-12-09T11:04:39Z","published":"2024-11-18T05:47:12Z","title":"Improved GUI Grounding via Iterative Narrowing","summary":"  Graphical User Interface (GUI) grounding plays a crucial role in enhancing\nthe capabilities of Vision-Language Model (VLM) agents. While general VLMs,\nsuch as GPT-4V, demonstrate strong performance across various tasks, their\nproficiency in GUI grounding remains suboptimal. Recent studies have focused on\nfine-tuning these models specifically for one-shot GUI grounding, yielding\nsignificant improvements over baseline performance. We introduce a visual\nprompting framework that employs an iterative narrowing mechanism to further\nimprove the performance of both general and fine-tuned models in GUI grounding.\nFor evaluation, we tested our method on a comprehensive benchmark comprising\nvarious UI platforms and provided the code to reproduce our results.\n","authors":["Anthony Nguyen"],"pdf_url":"https://arxiv.org/pdf/2411.13591v4.pdf","comment":"Code available at\n  https://github.com/ant-8/GUI-Grounding-via-Iterative-Narrowing"},{"id":"http://arxiv.org/abs/2306.07951v4","updated":"2024-12-09T10:47:06Z","published":"2023-06-13T17:48:27Z","title":"Questioning the Survey Responses of Large Language Models","summary":"  Surveys have recently gained popularity as a tool to study large language\nmodels. By comparing survey responses of models to those of human reference\npopulations, researchers aim to infer the demographics, political opinions, or\nvalues best represented by current language models. In this work, we critically\nexamine this methodology on the basis of the well-established American\nCommunity Survey by the U.S. Census Bureau. Evaluating 43 different language\nmodels using de-facto standard prompting methodologies, we establish two\ndominant patterns. First, models' responses are governed by ordering and\nlabeling biases, for example, towards survey responses labeled with the letter\n\"A\". Second, when adjusting for these systematic biases through randomized\nanswer ordering, models across the board trend towards uniformly random survey\nresponses, irrespective of model size or pre-training data. As a result, in\ncontrast to conjectures from prior work, survey-derived alignment measures\noften permit a simple explanation: models consistently appear to better\nrepresent subgroups whose aggregate statistics are closest to uniform for any\nsurvey under consideration.\n","authors":["Ricardo Dominguez-Olmedo","Moritz Hardt","Celestine Mendler-Dünner"],"pdf_url":"https://arxiv.org/pdf/2306.07951v4.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.21348v2","updated":"2024-12-09T10:11:22Z","published":"2024-10-28T11:07:33Z","title":"Large Language Model Benchmarks in Medical Tasks","summary":"  With the increasing application of large language models (LLMs) in the\nmedical domain, evaluating these models' performance using benchmark datasets\nhas become crucial. This paper presents a comprehensive survey of various\nbenchmark datasets employed in medical LLM tasks. These datasets span multiple\nmodalities including text, image, and multimodal benchmarks, focusing on\ndifferent aspects of medical knowledge such as electronic health records\n(EHRs), doctor-patient dialogues, medical question-answering, and medical image\ncaptioning. The survey categorizes the datasets by modality, discussing their\nsignificance, data structure, and impact on the development of LLMs for\nclinical tasks such as diagnosis, report generation, and predictive decision\nsupport. Key benchmarks include MIMIC-III, MIMIC-IV, BioASQ, PubMedQA, and\nCheXpert, which have facilitated advancements in tasks like medical report\ngeneration, clinical summarization, and synthetic data generation. The paper\nsummarizes the challenges and opportunities in leveraging these benchmarks for\nadvancing multimodal medical intelligence, emphasizing the need for datasets\nwith a greater degree of language diversity, structured omics data, and\ninnovative approaches to synthesis. This work also provides a foundation for\nfuture research in the application of LLMs in medicine, contributing to the\nevolving field of medical artificial intelligence.\n","authors":["Lawrence K. Q. Yan","Qian Niu","Ming Li","Yichao Zhang","Caitlyn Heqi Yin","Cheng Fei","Benji Peng","Ziqian Bi","Pohsun Feng","Keyu Chen","Tianyang Wang","Yunze Wang","Silin Chen","Ming Liu","Junyu Liu"],"pdf_url":"https://arxiv.org/pdf/2410.21348v2.pdf","comment":"25 pages, 5 tables"},{"id":"http://arxiv.org/abs/2406.10957v4","updated":"2024-12-09T09:57:05Z","published":"2024-06-16T14:24:30Z","title":"Eliminating Biased Length Reliance of Direct Preference Optimization via\n  Down-Sampled KL Divergence","summary":"  Direct Preference Optimization (DPO) has emerged as a prominent algorithm for\nthe direct and robust alignment of Large Language Models (LLMs) with human\npreferences, offering a more straightforward alternative to the complex\nReinforcement Learning from Human Feedback (RLHF). Despite its promising\nefficacy, DPO faces a notable drawback: \"verbosity\", a common over-optimization\nphenomenon also observed in RLHF. While previous studies mainly attributed\nverbosity to biased labels within the data, we propose that the issue also\nstems from an inherent algorithmic length reliance in DPO. Specifically, we\nsuggest that the discrepancy between sequence-level Kullback-Leibler (KL)\ndivergences between chosen and rejected sequences, used in DPO, results in\noverestimated or underestimated rewards due to varying token lengths.\nEmpirically, we utilize datasets with different label lengths to demonstrate\nthe presence of biased rewards. We then introduce an effective downsampling\napproach, named SamPO, to eliminate potential length reliance. Our experimental\nevaluations, conducted across three LLMs of varying scales and a diverse array\nof conditional and open-ended benchmarks, highlight the efficacy of SamPO in\nmitigating verbosity, achieving improvements of 5% to 12% over DPO through\ndebaised rewards. Our codes can be accessed at:\nhttps://github.com/LuJunru/SamPO/.\n","authors":["Junru Lu","Jiazheng Li","Siyu An","Meng Zhao","Yulan He","Di Yin","Xing Sun"],"pdf_url":"https://arxiv.org/pdf/2406.10957v4.pdf","comment":"EMNLP 2024 Main, Final Version"},{"id":"http://arxiv.org/abs/2305.08339v5","updated":"2024-12-09T09:56:59Z","published":"2023-05-15T04:10:13Z","title":"Assessing the potential of LLM-assisted annotation for corpus-based\n  pragmatics and discourse analysis: The case of apology","summary":"  Certain forms of linguistic annotation, like part of speech and semantic\ntagging, can be automated with high accuracy. However, manual annotation is\nstill necessary for complex pragmatic and discursive features that lack a\ndirect mapping to lexical forms. This manual process is time-consuming and\nerror-prone, limiting the scalability of function-to-form approaches in corpus\nlinguistics. To address this, our study explores the possibility of using large\nlanguage models (LLMs) to automate pragma-discursive corpus annotation. We\ncompare GPT-3.5 (the model behind the free-to-use version of ChatGPT), GPT-4\n(the model underpinning the precise mode of Bing chatbot), and a human coder in\nannotating apology components in English based on the local grammar framework.\nWe find that GPT-4 outperformed GPT-3.5, with accuracy approaching that of a\nhuman coder. These results suggest that LLMs can be successfully deployed to\naid pragma-discursive corpus annotation, making the process more efficient,\nscalable and accessible.\n","authors":["Danni Yu","Luyang Li","Hang Su","Matteo Fuoli"],"pdf_url":"https://arxiv.org/pdf/2305.08339v5.pdf","comment":"24 pages, 2 figures, 3 tablels"},{"id":"http://arxiv.org/abs/2402.11811v4","updated":"2024-12-09T09:53:07Z","published":"2024-02-19T03:56:44Z","title":"FIPO: Free-form Instruction-oriented Prompt Optimization with Preference\n  Dataset and Modular Fine-tuning Schema","summary":"  When the quality of naive prompts is carefully optimized by human experts,\nthe task performance of large language models (LLMs) can be significantly\nimproved. However, expert-based prompt optimizations are expensive. Herein,\nsome works have proposed Automatic Prompt Optimization (APO), to optimize naive\nprompts according to task outputs of given in-box testing models, with the help\nof advanced LLMs (e.g., GPT-4) in an ad-hoc way. Although effective, existing\nschemes suffer from poor generalization ability and privacy risk. To this end,\nwe collect the first large-scale Prompt Optimization Preference dataset (POP),\nfine-tune offline local LLM-based optimizers, then fairly test with various\ndownstream models. Our method allows accurate optimization of the core task\ninstruction part within the naive prompt in a model-agnostic manner, and thus\nis named Free-from Instruction-oriented Prompt Optimization (FIPO). In\nspecific, FIPO uses a modular APO template that dynamically integrate the naive\ntask instruction, optional instruction responses, and optional ground truth to\nproduce finely optimized prompts. The POP dataset is meticulously constructed\nusing advanced LLMs, undergoing rigorous cross-validation by human experts and\nanalytical models. Leveraging insights from the data with Tulu2 models and\ndiverse fine-tuning strategies, we validate the efficacy of FIPO framework\nacross five public benchmarks and six testing models. Check codes and data\nhere: https://github.com/LuJunru/FIPO_Project.\n","authors":["Junru Lu","Siyu An","Min Zhang","Yulan He","Di Yin","Xing Sun"],"pdf_url":"https://arxiv.org/pdf/2402.11811v4.pdf","comment":"COLING 2025, Final Version"},{"id":"http://arxiv.org/abs/2310.01432v3","updated":"2024-12-09T09:39:12Z","published":"2023-09-29T14:38:58Z","title":"Split and Merge: Aligning Position Biases in LLM-based Evaluators","summary":"  Large language models (LLMs) have shown promise as automated evaluators for\nassessing the quality of answers generated by AI systems. However, these\nLLM-based evaluators exhibit position bias, or inconsistency, when used to\nevaluate candidate answers in pairwise comparisons, favoring either the first\nor second answer regardless of content. To address this limitation, we propose\nPORTIA, an alignment-based system designed to mimic human comparison strategies\nto calibrate position bias in a lightweight yet effective manner. Specifically,\nPORTIA splits the answers into multiple segments, aligns similar content across\ncandidate answers, and then merges them back into a single prompt for\nevaluation by LLMs. We conducted extensive experiments with six diverse LLMs to\nevaluate 11,520 answer pairs. Our results show that PORTIA markedly enhances\nthe consistency rates for all the models and comparison forms tested, achieving\nan average relative improvement of 47.46%. Remarkably, PORTIA enables less\nadvanced GPT models to achieve 88% agreement with the state-of-the-art GPT-4\nmodel at just 10% of the cost. Furthermore, it rectifies around 80% of the\nposition bias instances within the GPT-4 model, elevating its consistency rate\nup to 98%. Subsequent human evaluations indicate that the PORTIA-enhanced\nGPT-3.5 model can even surpass the standalone GPT-4 in terms of alignment with\nhuman evaluators. These findings highlight PORTIA's ability to correct position\nbias, improve LLM consistency, and boost performance while keeping\ncost-efficiency. This represents a valuable step toward a more reliable and\nscalable use of LLMs for automated evaluations across diverse applications.\n","authors":["Zongjie Li","Chaozheng Wang","Pingchuan Ma","Daoyuan Wu","Shuai Wang","Cuiyun Gao","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2310.01432v3.pdf","comment":"Accepted by EMNLP 2024. Please cite the conference version of this\n  paper, e.g., \"Zongjie Li, Chaozheng Wang, Pingchuan Ma, Daoyuan Wu, Shuai\n  Wang, Cuiyun Gao, and Yang Liu. 2024. Split and Merge: Aligning Position\n  Biases in LLM-based Evaluators. (EMNLP 2024)\""},{"id":"http://arxiv.org/abs/2412.06332v1","updated":"2024-12-09T09:32:20Z","published":"2024-12-09T09:32:20Z","title":"Not All Errors Are Equal: Investigation of Speech Recognition Errors in\n  Alzheimer's Disease Detection","summary":"  Automatic Speech Recognition (ASR) plays an important role in speech-based\nautomatic detection of Alzheimer's disease (AD). However, recognition errors\ncould propagate downstream, potentially impacting the detection decisions.\nRecent studies have revealed a non-linear relationship between word error rates\n(WER) and AD detection performance, where ASR transcriptions with notable\nerrors could still yield AD detection accuracy equivalent to that based on\nmanual transcriptions. This work presents a series of analyses to explore the\neffect of ASR transcription errors in BERT-based AD detection systems. Our\ninvestigation reveals that not all ASR errors contribute equally to detection\nperformance. Certain words, such as stopwords, despite constituting a large\nproportion of errors, are shown to play a limited role in distinguishing AD. In\ncontrast, the keywords related to diagnosis tasks exhibit significantly greater\nimportance relative to other words. These findings provide insights into the\ninterplay between ASR errors and the downstream detection model.\n","authors":["Jiawen Kang","Junan Li","Jinchao Li","Xixin Wu","Helen Meng"],"pdf_url":"https://arxiv.org/pdf/2412.06332v1.pdf","comment":"Accepted by IEEE ISCSLP 2024"},{"id":"http://arxiv.org/abs/2410.09335v2","updated":"2024-12-09T09:31:39Z","published":"2024-10-12T02:48:34Z","title":"Rethinking Data Selection at Scale: Random Selection is Almost All You\n  Need","summary":"  Supervised fine-tuning (SFT) is crucial for aligning Large Language Models\n(LLMs) with human instructions. The primary goal during SFT is to select a\nsmall yet representative subset of training data from the larger pool, such\nthat fine-tuning with this subset achieves results comparable to or even\nexceeding those obtained using the entire dataset. However, most existing data\nselection techniques are designed for small-scale data pools, which fail to\nmeet the demands of real-world SFT scenarios. In this paper, we replicated\nseveral self-scoring methods those that do not rely on external model\nassistance on two million scale datasets, and found that nearly all methods\nstruggled to significantly outperform random selection when dealing with such\nlarge-scale data pools. Moreover, our comparisons suggest that, during SFT,\ndiversity in data selection is more critical than simply focusing on high\nquality data. We also analyzed the limitations of several current approaches,\nexplaining why they perform poorly on large-scale datasets and why they are\nunsuitable for such contexts. Finally, we found that filtering data by token\nlength offers a stable and efficient method for improving results. This\napproach, particularly when training on long text data, proves highly\nbeneficial for relatively weaker base models, such as Llama3.\n","authors":["Tingyu Xia","Bowen Yu","Kai Dang","An Yang","Yuan Wu","Yuan Tian","Yi Chang","Junyang Lin"],"pdf_url":"https://arxiv.org/pdf/2410.09335v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.04862v2","updated":"2024-12-09T09:31:10Z","published":"2024-12-06T08:53:46Z","title":"EXAONE 3.5: Series of Large Language Models for Real-world Use Cases","summary":"  This technical report introduces the EXAONE 3.5 instruction-tuned language\nmodels, developed and released by LG AI Research. The EXAONE 3.5 language\nmodels are offered in three configurations: 32B, 7.8B, and 2.4B. These models\nfeature several standout capabilities: 1) exceptional instruction following\ncapabilities in real-world scenarios, achieving the highest scores across seven\nbenchmarks, 2) outstanding long-context comprehension, attaining the top\nperformance in four benchmarks, and 3) competitive results compared to\nstate-of-the-art open models of similar sizes across nine general benchmarks.\nThe EXAONE 3.5 language models are open to anyone for research purposes and can\nbe downloaded from https://huggingface.co/LGAI-EXAONE. For commercial use,\nplease reach out to the official contact point of LG AI Research:\ncontact_us@lgresearch.ai.\n","authors":["LG AI Research","Soyoung An","Kyunghoon Bae","Eunbi Choi","Kibong Choi","Stanley Jungkyu Choi","Seokhee Hong","Junwon Hwang","Hyojin Jeon","Gerrard Jeongwon Jo","Hyunjik Jo","Jiyeon Jung","Yountae Jung","Hyosang Kim","Joonkee Kim","Seonghwan Kim","Soyeon Kim","Sunkyoung Kim","Yireun Kim","Yongil Kim","Youchul Kim","Edward Hwayoung Lee","Haeju Lee","Honglak Lee","Jinsik Lee","Kyungmin Lee","Woohyung Lim","Sangha Park","Sooyoun Park","Yongmin Park","Sihoon Yang","Heuiyeen Yeen","Hyeongu Yun"],"pdf_url":"https://arxiv.org/pdf/2412.04862v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2408.03541"},{"id":"http://arxiv.org/abs/2412.05248v2","updated":"2024-12-09T09:21:49Z","published":"2024-12-06T18:27:15Z","title":"Enhancing FKG.in: automating Indian food composition analysis","summary":"  This paper presents a novel approach to compute food composition data for\nIndian recipes using a knowledge graph for Indian food (FKG.in) and LLMs. The\nprimary focus is to provide a broad overview of an automated food composition\nanalysis workflow and describe its core functionalities: nutrition data\naggregation, food composition analysis, and LLM-augmented information\nresolution. This workflow aims to complement FKG.in and iteratively supplement\nfood composition data from verified knowledge bases. Additionally, this paper\nhighlights the challenges of representing Indian food and accessing food\ncomposition data digitally. It also reviews three key sources of food\ncomposition data: the Indian Food Composition Tables, the Indian Nutrient\nDatabank, and the Nutritionix API. Furthermore, it briefly outlines how users\ncan interact with the workflow to obtain diet-based health recommendations and\ndetailed food composition information for numerous recipes. We then explore the\ncomplex challenges of analyzing Indian recipe information across dimensions\nsuch as structure, multilingualism, and uncertainty as well as present our\nongoing work on LLM-based solutions to address these issues. The methods\nproposed in this workshop paper for AI-driven knowledge curation and\ninformation resolution are application-agnostic, generalizable, and replicable\nfor any domain.\n","authors":["Saransh Kumar Gupta","Lipika Dey","Partha Pratim Das","Geeta Trilok-Kumar","Ramesh Jain"],"pdf_url":"https://arxiv.org/pdf/2412.05248v2.pdf","comment":"15 pages, 5 figures, 30 references, International Conference on\n  Pattern Recognition 2024 - Multimedia Assisted Dietary Management Workshop"},{"id":"http://arxiv.org/abs/2408.09869v5","updated":"2024-12-09T09:20:54Z","published":"2024-08-19T10:20:06Z","title":"Docling Technical Report","summary":"  This technical report introduces Docling, an easy to use, self-contained,\nMIT-licensed open-source package for PDF document conversion. It is powered by\nstate-of-the-art specialized AI models for layout analysis (DocLayNet) and\ntable structure recognition (TableFormer), and runs efficiently on commodity\nhardware in a small resource budget. The code interface allows for easy\nextensibility and addition of new features and models.\n","authors":["Christoph Auer","Maksym Lysak","Ahmed Nassar","Michele Dolfi","Nikolaos Livathinos","Panos Vagenas","Cesar Berrospi Ramis","Matteo Omenetti","Fabian Lindlbauer","Kasper Dinkla","Lokesh Mishra","Yusik Kim","Shubham Gupta","Rafael Teixeira de Lima","Valery Weber","Lucas Morin","Ingmar Meijer","Viktor Kuropiatnyk","Peter W. J. Staar"],"pdf_url":"https://arxiv.org/pdf/2408.09869v5.pdf","comment":"Docling v1 report"},{"id":"http://arxiv.org/abs/2411.03817v3","updated":"2024-12-09T09:20:11Z","published":"2024-11-06T10:35:11Z","title":"From Novice to Expert: LLM Agent Policy Optimization via Step-wise\n  Reinforcement Learning","summary":"  The outstanding capabilities of large language models (LLMs) render them a\ncrucial component in various autonomous agent systems. While traditional\nmethods depend on the inherent knowledge of LLMs without fine-tuning, more\nrecent approaches have shifted toward the reinforcement learning strategy to\nfurther enhance agents' ability to solve complex interactive tasks with\nenvironments and tools. However, previous approaches are constrained by the\nsparse reward issue, where existing datasets solely provide a final scalar\nreward for each multi-step reasoning chain, potentially leading to\nineffectiveness and inefficiency in policy learning. In this paper, we\nintroduce StepAgent, which utilizes step-wise reward to optimize the agent's\nreinforcement learning process. Inheriting the spirit of novice-to-expert\ntheory, we first compare the actions of the expert and the agent to\nautomatically generate intermediate rewards for fine-grained optimization.\nAdditionally, we propose implicit-reward and inverse reinforcement learning\ntechniques to facilitate agent reflection and policy adjustment. Further\ntheoretical analysis demonstrates that the action distribution of the agent can\nconverge toward the expert action distribution over multiple training cycles.\nExperimental results across various datasets indicate that StepAgent\noutperforms existing baseline methods.\n","authors":["Zhirui Deng","Zhicheng Dou","Yutao Zhu","Ji-Rong Wen","Ruibin Xiong","Mang Wang","Weipeng Chen"],"pdf_url":"https://arxiv.org/pdf/2411.03817v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.10266v3","updated":"2024-12-09T09:14:47Z","published":"2024-07-14T16:20:42Z","title":"psifx -- Psychological and Social Interactions Feature Extraction\n  Package","summary":"  psifx is a plug-and-play multi-modal feature extraction toolkit, aiming to\nfacilitate and democratize the use of state-of-the-art machine learning\ntechniques for human sciences research. It is motivated by a need (a) to\nautomate and standardize data annotation processes, otherwise involving\nexpensive, lengthy, and inconsistent human labor, such as the transcription or\ncoding of behavior changes from audio and video sources; (b) to develop and\ndistribute open-source community-driven psychology research software; and (c)\nto enable large-scale access and ease of use to non-expert users. The framework\ncontains an array of tools for tasks, such as speaker diarization,\nclosed-caption transcription and translation from audio, as well as body, hand,\nand facial pose estimation and gaze tracking from video. The package has been\ndesigned with a modular and task-oriented approach, enabling the community to\nadd or update new tools easily. We strongly hope that this package will provide\npsychologists a simple and practical solution for efficiently a range of audio,\nlinguistic, and visual features from audio and video, thereby creating new\nopportunities for in-depth study of real-time behavioral phenomena.\n","authors":["Guillaume Rochette","Matthew J. Vowels","Mathieu Rochat"],"pdf_url":"https://arxiv.org/pdf/2407.10266v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.10542v2","updated":"2024-12-09T08:28:03Z","published":"2024-09-01T12:09:33Z","title":"SAM4MLLM: Enhance Multi-Modal Large Language Model for Referring\n  Expression Segmentation","summary":"  We introduce SAM4MLLM, an innovative approach which integrates the Segment\nAnything Model (SAM) with Multi-Modal Large Language Models (MLLMs) for\npixel-aware tasks. Our method enables MLLMs to learn pixel-level location\ninformation without requiring excessive modifications to the existing model\narchitecture or adding specialized tokens. We introduce an inquiry-based\napproach that can effectively find prompt points for SAM to perform\nsegmentation based on MLLM. It combines detailed visual information with the\npowerful expressive capabilities of large language models in a unified\nlanguage-based manner without additional computational overhead in learning.\nExperimental results on pubic benchmarks demonstrate the effectiveness of our\napproach.\n","authors":["Yi-Chia Chen","Wei-Hua Li","Cheng Sun","Yu-Chiang Frank Wang","Chu-Song Chen"],"pdf_url":"https://arxiv.org/pdf/2409.10542v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06287v1","updated":"2024-12-09T08:19:28Z","published":"2024-12-09T08:19:28Z","title":"PediaBench: A Comprehensive Chinese Pediatric Dataset for Benchmarking\n  Large Language Models","summary":"  The emergence of Large Language Models (LLMs) in the medical domain has\nstressed a compelling need for standard datasets to evaluate their\nquestion-answering (QA) performance. Although there have been several benchmark\ndatasets for medical QA, they either cover common knowledge across different\ndepartments or are specific to another department rather than pediatrics.\nMoreover, some of them are limited to objective questions and do not measure\nthe generation capacity of LLMs. Therefore, they cannot comprehensively assess\nthe QA ability of LLMs in pediatrics. To fill this gap, we construct\nPediaBench, the first Chinese pediatric dataset for LLM evaluation.\nSpecifically, it contains 4,565 objective questions and 1,632 subjective\nquestions spanning 12 pediatric disease groups. It adopts an integrated scoring\ncriterion based on different difficulty levels to thoroughly assess the\nproficiency of an LLM in instruction following, knowledge understanding,\nclinical case analysis, etc. Finally, we validate the effectiveness of\nPediaBench with extensive experiments on 20 open-source and commercial LLMs.\nThrough an in-depth analysis of experimental results, we offer insights into\nthe ability of LLMs to answer pediatric questions in the Chinese context,\nhighlighting their limitations for further improvements. Our code and data are\npublished at https://github.com/ACMISLab/PediaBench.\n","authors":["Qian Zhang","Panfeng Chen","Jiali Li","Linkun Feng","Shuyu Liu","Mei Chen","Hui Li","Yanhao Wang"],"pdf_url":"https://arxiv.org/pdf/2412.06287v1.pdf","comment":"21 pages, 12 figures"},{"id":"http://arxiv.org/abs/2412.06272v1","updated":"2024-12-09T07:46:14Z","published":"2024-12-09T07:46:14Z","title":"Methods for Legal Citation Prediction in the Age of LLMs: An Australian\n  Law Case Study","summary":"  In recent years, Large Language Models (LLMs) have shown great potential\nacross a wide range of legal tasks. Despite these advances, mitigating\nhallucination remains a significant challenge, with state-of-the-art LLMs still\nfrequently generating incorrect legal references. In this paper, we focus on\nthe problem of legal citation prediction within the Australian law context,\nwhere correctly identifying and citing relevant legislations or precedents is\ncritical. We compare several approaches: prompting general purpose and\nlaw-specialised LLMs, retrieval-only pipelines with both generic and\ndomain-specific embeddings, task-specific instruction-tuning of LLMs, and\nhybrid strategies that combine LLMs with retrieval augmentation, query\nexpansion, or voting ensembles. Our findings indicate that domain-specific\npre-training alone is insufficient for achieving satisfactory citation accuracy\neven after law-specialised pre-training. In contrast, instruction tuning on our\ntask-specific dataset dramatically boosts performance reaching the best results\nacross all settings. We also highlight that database granularity along with the\ntype of embeddings play a critical role in the performance of retrieval\nsystems. Among retrieval-based approaches, hybrid methods consistently\noutperform retrieval-only setups, and among these, ensemble voting delivers the\nbest result by combining the predictive quality of instruction-tuned LLMs with\nthe retrieval system.\n","authors":["Ehsan Shareghi","Jiuzhou Han","Paul Burgess"],"pdf_url":"https://arxiv.org/pdf/2412.06272v1.pdf","comment":"For code, data, and models see https://auslawbench.github.io"},{"id":"http://arxiv.org/abs/2410.20362v2","updated":"2024-12-09T07:17:07Z","published":"2024-10-27T07:38:39Z","title":"Rethinking Data Synthesis: A Teacher Model Training Recipe with\n  Interpretation","summary":"  Recent advances in large language model (LLM) training have highlighted the\nneed for diverse, high-quality instruction data. Recently, many works are\nexploring synthetic data generation using LLMs. However, they primarily focus\non prompt engineering with standard supervised instruction-finetuned models,\nwhich contains a fundamental limitation: these models are optimized for general\nquestion-answering/problem-solving rather than data generation. We propose a\nparadigm shift named \\textbf{NOMAD} by investigating how to specifically train\nmodels for data generation, demonstrating that this task differs significantly\nfrom training a classical LM. We identify two key factors: no-prompt-masked\ntraining and proper training set size selection. Our method, NOMAD, shows\nsubstantial improvements over baselines, achieving >4\\% gains in TriviaQA and\n>2\\% in GSM8K with limited training data. Finally, we offer new insights by\ninterpreting synthetic data through the lenses of \"relevance\" and \"novelty\".\n","authors":["Yifang Chen","David Zhu","Simon Du","Kevin Jamieson","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2410.20362v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.01469v3","updated":"2024-12-09T06:52:13Z","published":"2024-03-03T10:31:49Z","title":"KorMedMCQA: Multi-Choice Question Answering Benchmark for Korean\n  Healthcare Professional Licensing Examinations","summary":"  We present KorMedMCQA, the first Korean Medical Multiple-Choice Question\nAnswering benchmark, derived from professional healthcare licensing\nexaminations conducted in Korea between 2012 and 2024. The dataset contains\n7,469 questions from examinations for doctor, nurse, pharmacist, and dentist,\ncovering a wide range of medical disciplines. We evaluate the performance of 59\nlarge language models, spanning proprietary and open-source models,\nmultilingual and Korean-specialized models, and those fine-tuned for clinical\napplications. Our results show that applying Chain of Thought (CoT) reasoning\ncan enhance the model performance by up to 4.5% compared to direct answering\napproaches. We also investigate whether MedQA, one of the most widely used\nmedical benchmarks derived from the U.S. Medical Licensing Examination, can\nserve as a reliable proxy for evaluating model performance in other regions-in\nthis case, Korea. Our correlation analysis between model scores on KorMedMCQA\nand MedQA reveals that these two benchmarks align no better than benchmarks\nfrom entirely different domains (e.g., MedQA and MMLU-Pro). This finding\nunderscores the substantial linguistic and clinical differences between Korean\nand U.S. medical contexts, reinforcing the need for region-specific medical QA\nbenchmarks. To support ongoing research in Korean healthcare AI, we publicly\nrelease the KorMedMCQA via Huggingface.\n","authors":["Sunjun Kweon","Byungjin Choi","Gyouk Chu","Junyeong Song","Daeun Hyeon","Sujin Gan","Jueon Kim","Minkyu Kim","Rae Woong Park","Edward Choi"],"pdf_url":"https://arxiv.org/pdf/2403.01469v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06249v1","updated":"2024-12-09T06:47:42Z","published":"2024-12-09T06:47:42Z","title":"Optimizing Multi-Task Learning for Enhanced Performance in Large\n  Language Models","summary":"  This study aims to explore the performance improvement method of large\nlanguage models based on GPT-4 under the multi-task learning framework and\nconducts experiments on two tasks: text classification and automatic summary\ngeneration. Through the combined design of shared feature extractors and\ntask-specific modules, we achieve knowledge-sharing and optimization of\nmultiple tasks in the same model. The experiment uses multiple subtasks of the\nGLUE dataset to compare the performance of the multi-task model with the\nsingle-task GPT-4, the multi-task version of GPT-3, the BERT basic model, and\nthe classic Bi-LSTM with Attention model. The results show that the proposed\nmulti-task learning model outperforms other comparison models in terms of text\nclassification accuracy and ROUGE value of summary generation, demonstrating\nthe advantages of multi-task learning in improving model generalization ability\nand collaborative learning between tasks. The model maintains a stable loss\nconvergence rate during training, showing good learning efficiency and\nadaptability to the test set. This study verifies the applicability of the\nmulti-task learning framework in large language models, especially in improving\nthe model's ability to balance different tasks. In the future, with the\ncombination of large language models and multimodal data and the application of\ndynamic task adjustment technology, the framework based on multi-task learning\nis expected to play a greater role in practical applications across fields and\nprovide new ideas for the development of general artificial intelligence.\n","authors":["Zhen Qi","Jiajing Chen","Shuo Wang","Bingying Liu","Hongye Zheng","Chihang Wang"],"pdf_url":"https://arxiv.org/pdf/2412.06249v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.14785v2","updated":"2024-12-09T06:43:40Z","published":"2024-09-23T07:59:50Z","title":"Towards Efficient and Robust VQA-NLE Data Generation with Large\n  Vision-Language Models","summary":"  Natural Language Explanation (NLE) aims to elucidate the decision-making\nprocess by providing detailed, human-friendly explanations in natural language.\nIt helps demystify the decision-making processes of large vision-language\nmodels (LVLMs) through the use of language models. While existing methods for\ncreating a Vision Question-Answering with Natural Language Explanation\n(VQA-NLE) datasets can provide explanations, they heavily rely on human\nannotations that are time-consuming and costly. In this study, we propose a\nnovel approach that leverages LVLMs to efficiently generate high-quality\nsynthetic VQA-NLE datasets. By evaluating our synthetic data, we showcase how\nadvanced prompting techniques can lead to the production of high-quality\nVQA-NLE data. Our findings indicate that this proposed method achieves up to\n20x faster than human annotation, with only a minimal decrease in qualitative\nmetrics, achieving robust quality that is nearly equivalent to human-annotated\ndata. Furthermore, we show that incorporating visual prompts significantly\nenhances the relevance of text generation. Our study paves the way for a more\nefficient and robust automated generation of multi-modal NLE data, offering a\npromising solution to the problem.\n","authors":["Patrick Amadeus Irawan","Genta Indra Winata","Samuel Cahyawijaya","Ayu Purwarianti"],"pdf_url":"https://arxiv.org/pdf/2409.14785v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2412.06245v1","updated":"2024-12-09T06:37:35Z","published":"2024-12-09T06:37:35Z","title":"A Comparative Study of Learning Paradigms in Large Language Models via\n  Intrinsic Dimension","summary":"  The performance of Large Language Models (LLMs) on natural language tasks can\nbe improved through both supervised fine-tuning (SFT) and in-context learning\n(ICL), which operate via distinct mechanisms. Supervised fine-tuning updates\nthe model's weights by minimizing loss on training data, whereas in-context\nlearning leverages task demonstrations embedded in the prompt, without changing\nthe model's parameters. This study investigates the effects of these learning\nparadigms on the hidden representations of LLMs using Intrinsic Dimension (ID).\nWe use ID to estimate the number of degrees of freedom between representations\nextracted from LLMs as they perform specific natural language tasks. We first\nexplore how the ID of LLM representations evolves during SFT and how it varies\ndue to the number of demonstrations in ICL. We then compare the IDs induced by\nSFT and ICL and find that ICL consistently induces a higher ID compared to SFT,\nsuggesting that representations generated during ICL reside in higher\ndimensional manifolds in the embedding space.\n","authors":["Saahith Janapati","Yangfeng Ji"],"pdf_url":"https://arxiv.org/pdf/2412.06245v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.13792v2","updated":"2024-12-09T06:07:03Z","published":"2024-05-22T16:15:17Z","title":"xRAG: Extreme Context Compression for Retrieval-augmented Generation\n  with One Token","summary":"  This paper introduces xRAG, an innovative context compression method tailored\nfor retrieval-augmented generation. xRAG reinterprets document embeddings in\ndense retrieval--traditionally used solely for retrieval--as features from the\nretrieval modality. By employing a modality fusion methodology, xRAG seamlessly\nintegrates these embeddings into the language model representation space,\neffectively eliminating the need for their textual counterparts and achieving\nan extreme compression rate. In xRAG, the only trainable component is the\nmodality bridge, while both the retriever and the language model remain frozen.\nThis design choice allows for the reuse of offline-constructed document\nembeddings and preserves the plug-and-play nature of retrieval augmentation.\nExperimental results demonstrate that xRAG achieves an average improvement of\nover 10% across six knowledge-intensive tasks, adaptable to various language\nmodel backbones, ranging from a dense 7B model to an 8x7B Mixture of Experts\nconfiguration. xRAG not only significantly outperforms previous context\ncompression methods but also matches the performance of uncompressed models on\nseveral datasets, while reducing overall FLOPs by a factor of 3.53. Our work\npioneers new directions in retrieval-augmented generation from the perspective\nof multimodality fusion, and we hope it lays the foundation for future\nefficient and scalable retrieval-augmented systems\n","authors":["Xin Cheng","Xun Wang","Xingxing Zhang","Tao Ge","Si-Qing Chen","Furu Wei","Huishuai Zhang","Dongyan Zhao"],"pdf_url":"https://arxiv.org/pdf/2405.13792v2.pdf","comment":"Neurips 2024"},{"id":"http://arxiv.org/abs/2412.06229v1","updated":"2024-12-09T06:03:48Z","published":"2024-12-09T06:03:48Z","title":"LLMs as Debate Partners: Utilizing Genetic Algorithms and Adversarial\n  Search for Adaptive Arguments","summary":"  This paper introduces DebateBrawl, an innovative AI-powered debate platform\nthat integrates Large Language Models (LLMs), Genetic Algorithms (GA), and\nAdversarial Search (AS) to create an adaptive and engaging debating experience.\nDebateBrawl addresses the limitations of traditional LLMs in strategic planning\nby incorporating evolutionary optimization and game-theoretic techniques. The\nsystem demonstrates remarkable performance in generating coherent, contextually\nrelevant arguments while adapting its strategy in real-time. Experimental\nresults involving 23 debates show balanced outcomes between AI and human\nparticipants, with the AI system achieving an average score of 2.72 compared to\nthe human average of 2.67 out of 10. User feedback indicates significant\nimprovements in debating skills and a highly satisfactory learning experience,\nwith 85% of users reporting improved debating abilities and 78% finding the AI\nopponent appropriately challenging. The system's ability to maintain high\nfactual accuracy (92% compared to 78% in human-only debates) while generating\ndiverse arguments addresses critical concerns in AI-assisted discourse.\nDebateBrawl not only serves as an effective educational tool but also\ncontributes to the broader goal of improving public discourse through\nAI-assisted argumentation. The paper discusses the ethical implications of AI\nin persuasive contexts and outlines the measures implemented to ensure\nresponsible development and deployment of the system, including robust\nfact-checking mechanisms and transparency in decision-making processes.\n","authors":["Prakash Aryan"],"pdf_url":"https://arxiv.org/pdf/2412.06229v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16444v4","updated":"2024-12-09T05:49:01Z","published":"2023-11-28T02:51:13Z","title":"Exo2EgoDVC: Dense Video Captioning of Egocentric Procedural Activities\n  Using Web Instructional Videos","summary":"  We propose a novel benchmark for cross-view knowledge transfer of dense video\ncaptioning, adapting models from web instructional videos with exocentric views\nto an egocentric view. While dense video captioning (predicting time segments\nand their captions) is primarily studied with exocentric videos (e.g.,\nYouCook2), benchmarks with egocentric videos are restricted due to data\nscarcity. To overcome the limited video availability, transferring knowledge\nfrom abundant exocentric web videos is demanded as a practical approach.\nHowever, learning the correspondence between exocentric and egocentric views is\ndifficult due to their dynamic view changes. The web videos contain shots\nshowing either full-body or hand regions, while the egocentric view is\nconstantly shifting. This necessitates the in-depth study of cross-view\ntransfer under complex view changes. To this end, we first create a real-life\negocentric dataset (EgoYC2) whose captions follow the definition of YouCook2\ncaptions, enabling transfer learning between these datasets with access to\ntheir ground-truth. To bridge the view gaps, we propose a view-invariant\nlearning method using adversarial training, which consists of pre-training and\nfine-tuning stages. Our experiments confirm the effectiveness of overcoming the\nview change problem and knowledge transfer to egocentric views. Our benchmark\npushes the study of cross-view transfer into a new task domain of dense video\ncaptioning and envisions methodologies that describe egocentric videos in\nnatural language.\n","authors":["Takehiko Ohkawa","Takuma Yagi","Taichi Nishimura","Ryosuke Furuta","Atsushi Hashimoto","Yoshitaka Ushiku","Yoichi Sato"],"pdf_url":"https://arxiv.org/pdf/2311.16444v4.pdf","comment":"Accepted to WACV 2025. Project page:\n  https://tkhkaeio.github.io/projects/25-egodvc/"},{"id":"http://arxiv.org/abs/2410.05584v3","updated":"2024-12-09T05:06:20Z","published":"2024-10-08T00:52:03Z","title":"Rethinking Reward Model Evaluation: Are We Barking up the Wrong Tree?","summary":"  Reward Models (RMs) are crucial for aligning language models with human\npreferences. Currently, the evaluation of RMs depends on measuring accuracy\nagainst a validation set of manually annotated preference data. Although this\nmethod is straightforward and widely adopted, the relationship between RM\naccuracy and downstream policy performance remains under-explored. In this\nwork, we conduct experiments in a synthetic setting to investigate how\ndifferences in RM measured by accuracy translate into gaps in optimized policy\nperformance. Our findings reveal that while there is a weak positive\ncorrelation between accuracy and downstream performance, policies optimized\ntowards RMs with similar accuracy can exhibit quite different performance.\nMoreover, we discover that the way of measuring accuracy significantly impacts\nits ability to predict the final policy performance. Through the lens of the\nRegressional Goodhart effect, we recognize that accuracy, when used for\nmeasuring RM quality, can fail to fully capture the potential RM\noveroptimization. This underscores the inadequacy of relying solely on accuracy\nto reflect their impact on policy optimization.\n","authors":["Xueru Wen","Jie Lou","Yaojie Lu","Hongyu Lin","Xing Yu","Xinyu Lu","Ben He","Xianpei Han","Debing Zhang","Le Sun"],"pdf_url":"https://arxiv.org/pdf/2410.05584v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06206v1","updated":"2024-12-09T04:56:43Z","published":"2024-12-09T04:56:43Z","title":"SiReRAG: Indexing Similar and Related Information for Multihop Reasoning","summary":"  Indexing is an important step towards strong performance in\nretrieval-augmented generation (RAG) systems. However, existing methods\norganize data based on either semantic similarity (similarity) or related\ninformation (relatedness), but do not cover both perspectives comprehensively.\nOur analysis reveals that modeling only one perspective results in insufficient\nknowledge synthesis, leading to suboptimal performance on complex tasks\nrequiring multihop reasoning. In this paper, we propose SiReRAG, a novel RAG\nindexing approach that explicitly considers both similar and related\ninformation. On the similarity side, we follow existing work and explore some\nvariances to construct a similarity tree based on recursive summarization. On\nthe relatedness side, SiReRAG extracts propositions and entities from texts,\ngroups propositions via shared entities, and generates recursive summaries to\nconstruct a relatedness tree. We index and flatten both similarity and\nrelatedness trees into a unified retrieval pool. Our experiments demonstrate\nthat SiReRAG consistently outperforms state-of-the-art indexing methods on\nthree multihop datasets (MuSiQue, 2WikiMultiHopQA, and HotpotQA), with an\naverage 1.9% improvement in F1 scores. As a reasonably efficient solution,\nSiReRAG enhances existing reranking methods significantly, with up to 7.8%\nimprovement in average F1 scores.\n","authors":["Nan Zhang","Prafulla Kumar Choubey","Alexander Fabbri","Gabriel Bernadett-Shapiro","Rui Zhang","Prasenjit Mitra","Caiming Xiong","Chien-Sheng Wu"],"pdf_url":"https://arxiv.org/pdf/2412.06206v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16153v2","updated":"2024-12-09T04:47:26Z","published":"2024-10-21T16:19:41Z","title":"Pangea: A Fully Open Multilingual Multimodal LLM for 39 Languages","summary":"  Despite recent advances in multimodal large language models (MLLMs), their\ndevelopment has predominantly focused on English- and western-centric datasets\nand tasks, leaving most of the world's languages and diverse cultural contexts\nunderrepresented. This paper introduces Pangea, a multilingual multimodal LLM\ntrained on PangeaIns, a diverse 6M instruction dataset spanning 39 languages.\nPangeaIns features: 1) high-quality English instructions, 2) carefully\nmachine-translated instructions, and 3) culturally relevant multimodal tasks to\nensure cross-cultural coverage. To rigorously assess models' capabilities, we\nintroduce PangeaBench, a holistic evaluation suite encompassing 14 datasets\ncovering 47 languages. Results show that Pangea significantly outperforms\nexisting open-source models in multilingual settings and diverse cultural\ncontexts. Ablation studies further reveal the importance of English data\nproportions, language popularity, and the number of multimodal training samples\non overall performance. We fully open-source our data, code, and trained\ncheckpoints, to facilitate the development of inclusive and robust multilingual\nMLLMs, promoting equity and accessibility across a broader linguistic and\ncultural spectrum.\n","authors":["Xiang Yue","Yueqi Song","Akari Asai","Seungone Kim","Jean de Dieu Nyandwi","Simran Khanuja","Anjali Kantharuban","Lintang Sutawika","Sathyanarayanan Ramamoorthy","Graham Neubig"],"pdf_url":"https://arxiv.org/pdf/2410.16153v2.pdf","comment":"54 pages, 27 figures"},{"id":"http://arxiv.org/abs/2412.06198v1","updated":"2024-12-09T04:27:03Z","published":"2024-12-09T04:27:03Z","title":"SparseAccelerate: Efficient Long-Context Inference for Mid-Range GPUs","summary":"  As Large Language Models (LLMs) scale to longer context windows, the\ncomputational cost of attention mechanisms, which traditionally grows\nquadratically with input length, presents a critical challenge for real-time\nand memory-constrained deployments. Existing sparse attention techniques have\nsought to reduce this complexity, but they often incur significant overhead or\ncompromise accuracy, making them less practical for large contexts on mid-range\nhardware. In this paper, we introduce SparseAccelerate, a dynamic sparse\nattention method that adapts its sparsity patterns based on input\ncharacteristics, effectively flattening the attention complexity curve. Our\napproach is effective for input lengths starting at 16K tokens and scales\nefficiently up to 128K tokens on dual NVIDIA A5000 GPUs (24GB each).\nExperimental results show that SparseAccelerate achieves up to a 1.04x\nreduction in Time-To-First-Token (TTFT) latency at 32K tokens, while also\nproviding substantial memory savings. These improvements yield practical gains\nfor memory-intensive applications and long-context tasks that were previously\ninfeasible with standard attention. Beyond latency reductions, SparseAccelerate\nfundamentally shifts the scaling trend, demonstrating the smallest TTFT growth\ngradient relative to context length among competing methods. Ongoing\nevaluations on diverse benchmarks confirm its scalability, positioning\nSparseAccelerate as a critical advancement toward efficient, real-time, and\nlarge-context LLM inference on accessible hardware.\n","authors":["James Vo"],"pdf_url":"https://arxiv.org/pdf/2412.06198v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.05133v3","updated":"2024-12-09T04:21:08Z","published":"2024-02-06T04:18:58Z","title":"Personalized Language Modeling from Personalized Human Feedback","summary":"  Personalized large language models (LLMs) are designed to tailor responses to\nindividual user preferences. While Reinforcement Learning from Human Feedback\n(RLHF) is a commonly used framework for aligning LLMs with human preferences,\nvanilla RLHF assumes that all human preferences share the same distribution,\npreventing fine-tuned LLMs from generating personalized content when user\npreferences are diverse. In this work, we propose Personalized-RLHF (P-RLHF),\nan efficient framework that utilizes a lightweight user model to capture\nindividual user preferences and jointly learns the user model and the\npersonalized LLM from human feedback. P-RLHF exhibits the following three\ncharacteristics: (1) It enables an LLM to generate personalized content and\nscale efficiently with growing number of users. (2) It handles both explicit\nuser preferences described as textual input and implicit user preferences\nencoded in the feedback data. (3) It eliminates the need for users to fully\narticulate their preferences, which are normally needed for prompting LLMs to\ngenerate personalized content yet are often impractical to obtain in real-world\nscenarios. Our experimental results show that personalized LLMs trained using\nP-RLHF generate responses that are more closely aligned with individual user\npreferences, outperforming vanilla, non-personalized RLHF and prompting-based\npersonalization approaches across different tasks. We opensource our code at\nhttps://github.com/HumainLab/Personalized_RLHF.\n","authors":["Xinyu Li","Ruiyang Zhou","Zachary C. Lipton","Liu Leqi"],"pdf_url":"https://arxiv.org/pdf/2402.05133v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.10053v2","updated":"2024-12-09T03:53:19Z","published":"2024-09-16T07:29:40Z","title":"Householder Pseudo-Rotation: A Novel Approach to Activation Editing in\n  LLMs with Direction-Magnitude Perspective","summary":"  Activation Editing, which involves directly editting the internal\nrepresentations of large language models (LLMs) to alter their behaviors and\nachieve desired properties, has emerged as a promising area of research.\nExisting works primarily treat LLMs' activations as points in space and modify\nthem by adding steering vectors. However, this approach is limited in its\nability to achieve greater performance improvement while maintaining the\nnecessary consistency of activation magnitudes. To overcome these issues, we\npropose a novel editing method that views activations in terms of their\ndirections and magnitudes. Our method, named Householder Pseudo-Rotation (HPR),\nmimics the rotation transformation, thus preserving activation norms and\nresulting in an improved performance on various safety benchmarks.\n","authors":["Van-Cuong Pham","Thien Huu Nguyen"],"pdf_url":"https://arxiv.org/pdf/2409.10053v2.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2407.10805v6","updated":"2024-12-09T03:39:00Z","published":"2024-07-15T15:20:40Z","title":"Think-on-Graph 2.0: Deep and Faithful Large Language Model Reasoning\n  with Knowledge-guided Retrieval Augmented Generation","summary":"  Retrieval-augmented generation (RAG) has improved large language models\n(LLMs) by using knowledge retrieval to overcome knowledge deficiencies.\nHowever, current RAG methods often fall short of ensuring the depth and\ncompleteness of retrieved information, which is necessary for complex reasoning\ntasks. In this work, we introduce Think-on-Graph 2.0 (ToG-2), a hybrid RAG\nframework that iteratively retrieves information from both unstructured and\nstructured knowledge sources in a tight-coupling manner. Specifically, ToG-2\nleverages knowledge graphs (KGs) to link documents via entities, facilitating\ndeep and knowledge-guided context retrieval. Simultaneously, it utilizes\ndocuments as entity contexts to achieve precise and efficient graph retrieval.\nToG-2 alternates between graph retrieval and context retrieval to search for\nin-depth clues relevant to the question, enabling LLMs to generate answers. We\nconduct a series of well-designed experiments to highlight the following\nadvantages of ToG-2: 1) ToG-2 tightly couples the processes of context\nretrieval and graph retrieval, deepening context retrieval via the KG while\nenabling reliable graph retrieval based on contexts; 2) it achieves deep and\nfaithful reasoning in LLMs through an iterative knowledge retrieval process of\ncollaboration between contexts and the KG; and 3) ToG-2 is training-free and\nplug-and-play compatible with various LLMs. Extensive experiments demonstrate\nthat ToG-2 achieves overall state-of-the-art (SOTA) performance on 6 out of 7\nknowledge-intensive datasets with GPT-3.5, and can elevate the performance of\nsmaller models (e.g., LLAMA-2-13B) to the level of GPT-3.5's direct reasoning.\nThe source code is available on https://github.com/IDEA-FinAI/ToG-2.\n","authors":["Shengjie Ma","Chengjin Xu","Xuhui Jiang","Muzhi Li","Huaren Qu","Cehao Yang","Jiaxin Mao","Jian Guo"],"pdf_url":"https://arxiv.org/pdf/2407.10805v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06179v1","updated":"2024-12-09T03:32:40Z","published":"2024-12-09T03:32:40Z","title":"Annotations for Exploring Food Tweets From Multiple Aspects","summary":"  This research builds upon the Latvian Twitter Eater Corpus (LTEC), which is\nfocused on the narrow domain of tweets related to food, drinks, eating and\ndrinking. LTEC has been collected for more than 12 years and reaching almost 3\nmillion tweets with the basic information as well as extended automatically and\nmanually annotated metadata. In this paper we supplement the LTEC with manually\nannotated subsets of evaluation data for machine translation, named entity\nrecognition, timeline-balanced sentiment analysis, and text-image relation\nclassification. We experiment with each of the data sets using baseline models\nand highlight future challenges for various modelling approaches.\n","authors":["Matīss Rikters","Edison Marrese-Taylor","Rinalds Vīksna"],"pdf_url":"https://arxiv.org/pdf/2412.06179v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07870v4","updated":"2024-12-09T03:25:55Z","published":"2024-11-12T15:26:17Z","title":"Trustful LLMs: Customizing and Grounding Text Generation with Knowledge\n  Bases and Dual Decoders","summary":"  Although people are impressed by the content generation skills of large\nlanguage models, the use of LLMs, such as ChatGPT, is limited by the domain\ngrounding of the content. The correctness and groundedness of the generated\ncontent need to be based on a verified context, such as results from\nRetrieval-Augmented Generation (RAG). One important issue when adapting LLMs to\na customized domain is that the generated responses are often incomplete, or\nthe additions are not verified and may even be hallucinated. Prior studies on\nhallucination detection have focused on evaluation metrics, which are not\neasily adaptable to dynamic domains and can be vulnerable to attacks like\njail-breaking. In this work, we propose 1) a post-processing algorithm that\nleverages knowledge triplets in RAG context to correct hallucinations and 2) a\ndual-decoder model that fuses RAG context to guide the generation process.\n","authors":["Xiaofeng Zhu","Jaya Krishna Mandivarapu"],"pdf_url":"https://arxiv.org/pdf/2411.07870v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.04497v2","updated":"2024-12-09T03:00:42Z","published":"2024-11-30T00:10:56Z","title":"Opportunities and Challenges of Large Language Models for Low-Resource\n  Languages in Humanities Research","summary":"  Low-resource languages serve as invaluable repositories of human history,\nembodying cultural evolution and intellectual diversity. Despite their\nsignificance, these languages face critical challenges, including data scarcity\nand technological limitations, which hinder their comprehensive study and\npreservation. Recent advancements in large language models (LLMs) offer\ntransformative opportunities for addressing these challenges, enabling\ninnovative methodologies in linguistic, historical, and cultural research. This\nstudy systematically evaluates the applications of LLMs in low-resource\nlanguage research, encompassing linguistic variation, historical documentation,\ncultural expressions, and literary analysis. By analyzing technical frameworks,\ncurrent methodologies, and ethical considerations, this paper identifies key\nchallenges such as data accessibility, model adaptability, and cultural\nsensitivity. Given the cultural, historical, and linguistic richness inherent\nin low-resource languages, this work emphasizes interdisciplinary collaboration\nand the development of customized models as promising avenues for advancing\nresearch in this domain. By underscoring the potential of integrating\nartificial intelligence with the humanities to preserve and study humanity's\nlinguistic and cultural heritage, this study fosters global efforts towards\nsafeguarding intellectual diversity.\n","authors":["Tianyang Zhong","Zhenyuan Yang","Zhengliang Liu","Ruidong Zhang","Yiheng Liu","Haiyang Sun","Yi Pan","Yiwei Li","Yifan Zhou","Hanqi Jiang","Junhao Chen","Tianming Liu"],"pdf_url":"https://arxiv.org/pdf/2412.04497v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06162v1","updated":"2024-12-09T02:51:21Z","published":"2024-12-09T02:51:21Z","title":"Query-Efficient Planning with Language Models","summary":"  Planning in complex environments requires an agent to efficiently query a\nworld model to find a feasible sequence of actions from start to goal. Recent\nwork has shown that Large Language Models (LLMs), with their rich prior\nknowledge and reasoning capabilities, can potentially help with planning by\nsearching over promising states and adapting to feedback from the world. In\nthis paper, we propose and study two fundamentally competing frameworks that\nleverage LLMs for query-efficient planning. The first uses LLMs as a heuristic\nwithin a search-based planner to select promising nodes to expand and propose\npromising actions. The second uses LLMs as a generative planner to propose an\nentire sequence of actions from start to goal, query a world model, and adapt\nbased on feedback. We show that while both approaches improve upon comparable\nbaselines, using an LLM as a generative planner results in significantly fewer\ninteractions. Our key finding is that the LLM as a planner can more rapidly\nadapt its planning strategies based on immediate feedback than LLM as a\nheuristic. We present evaluations and ablations on Robotouille and PDDL\nplanning benchmarks and discuss connections to existing theory on\nquery-efficient planning algorithms. Code is available at\nhttps://github.com/portal-cornell/llms-for-planning\n","authors":["Gonzalo Gonzalez-Pumariega","Wayne Chen","Kushal Kedia","Sanjiban Choudhury"],"pdf_url":"https://arxiv.org/pdf/2412.06162v1.pdf","comment":"11 pages (not including references or appendix); 13 figures (9 main\n  paper, 4 appendix); (v1) preprint"},{"id":"http://arxiv.org/abs/2210.15629v4","updated":"2024-12-09T02:49:04Z","published":"2022-10-27T17:20:50Z","title":"Language Control Diffusion: Efficiently Scaling through Space, Time, and\n  Tasks","summary":"  Training generalist agents is difficult across several axes, requiring us to\ndeal with high-dimensional inputs (space), long horizons (time), and\ngeneralization to novel tasks. Recent advances with architectures have allowed\nfor improved scaling along one or two of these axes, but are still\ncomputationally prohibitive to use. In this paper, we propose to address all\nthree axes by leveraging \\textbf{L}anguage to \\textbf{C}ontrol\n\\textbf{D}iffusion models as a hierarchical planner conditioned on language\n(LCD). We effectively and efficiently scale diffusion models for planning in\nextended temporal, state, and task dimensions to tackle long horizon control\nproblems conditioned on natural language instructions, as a step towards\ngeneralist agents. Comparing LCD with other state-of-the-art models on the\nCALVIN language robotics benchmark finds that LCD outperforms other SOTA\nmethods in multi-task success rates, whilst improving inference speed over\nother comparable diffusion models by 3.3x~15x. We show that LCD can\nsuccessfully leverage the unique strength of diffusion models to produce\ncoherent long range plans while addressing their weakness in generating\nlow-level details and control.\n","authors":["Edwin Zhang","Yujie Lu","Shinda Huang","William Wang","Amy Zhang"],"pdf_url":"https://arxiv.org/pdf/2210.15629v4.pdf","comment":"ICLR 2024, Project and code available at\n  https://github.com/ezhang7423/language-control-diffusion"},{"id":"http://arxiv.org/abs/2406.18872v2","updated":"2024-12-09T02:45:45Z","published":"2024-06-27T03:52:35Z","title":"Efficacy of Language Model Self-Play in Non-Zero-Sum Games","summary":"  Game-playing agents like AlphaGo have achieved superhuman performance through\nself-play, which is theoretically guaranteed to yield optimal policies in\ncompetitive games. However, most language tasks are partially or fully\ncooperative, so it is an open question whether techniques like self-play can\neffectively be used to improve language models. We empirically investigate this\nquestion in a negotiation game setting known as Deal or No Deal (DoND).\nCrucially, the objective in DoND can be modified to produce a fully cooperative\ngame, a strictly competitive one, or anything in between. We finetune language\nmodels in self-play over multiple rounds of filtered behavior cloning in DoND\nfor each of these objectives and evaluate them in self-play and in\ncollaboration with humans. We find that language models improve substantially\nin self-play, achieving 14-17x higher scores in task reward after finetuning.\nFurther, the trained models generalize to both cooperation and competition with\nhumans, scoring 2.5-6x higher than base models. We view these results as an\nearly promising sign for language model self-play in cooperative settings,\ndespite a lack of theoretical guarantees.\n","authors":["Austen Liao","Nicholas Tomlin","Dan Klein"],"pdf_url":"https://arxiv.org/pdf/2406.18872v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.03712v2","updated":"2024-12-09T02:14:08Z","published":"2024-06-06T03:15:13Z","title":"A Survey on Medical Large Language Models: Technology, Application,\n  Trustworthiness, and Future Directions","summary":"  With the advent of Large Language Models (LLMs), medical artificial\nintelligence (AI) has experienced substantial technological progress and\nparadigm shifts, highlighting the potential of LLMs to streamline healthcare\ndelivery and improve patient outcomes. Considering this rapid technical\nprogress, in this survey, we trace the recent advances of Medical Large\nLanguage Models (Med-LLMs), including the background, key findings, and\nmainstream techniques, especially for the evolution from general-purpose models\nto medical-specialized applications. Firstly, we delve into the foundational\ntechnology of Med-LLMs, indicating how general models can be progressively\nadapted and refined for the complicated medical tasks. Secondly, the\nwide-ranging applications of Med-LLMs are investigated across various\nhealthcare domains, as well as an up-to-date review of existing Med-LLMs. The\ntransformative impact of these models on daily medical practice is evident\nthrough their ability to assist clinicians, educators, and patients.\nRecognizing the importance of responsible innovation, we discuss the challenges\nassociated with ensuring fairness, accountability, privacy, and robustness.\nEthical considerations, rigorous evaluation methodologies, and the\nestablishment of regulatory frameworks are crucial for building trustworthiness\nin the real-world system. We emphasize the need for ongoing scrutiny and\ndevelopment to maintain high standards of safety and reliability. Finally, we\nanticipate possible future trajectories for Med-LLMs, identifying key avenues\nfor prudent expansion. By consolidating these insights, our review aims to\nprovide professionals and researchers with a thorough understanding of the\nstrengths and limitations of Med-LLMs, fostering a balanced and ethical\napproach to their integration into the healthcare ecosystem.\n","authors":["Lei Liu","Xiaoyan Yang","Junchi Lei","Yue Shen","Jian Wang","Peng Wei","Zhixuan Chu","Zhan Qin","Kui Ren"],"pdf_url":"https://arxiv.org/pdf/2406.03712v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06148v1","updated":"2024-12-09T02:01:18Z","published":"2024-12-09T02:01:18Z","title":"The Computational Limits of State-Space Models and Mamba via the Lens of\n  Circuit Complexity","summary":"  In this paper, we analyze the computational limitations of Mamba and\nState-space Models (SSMs) by using the circuit complexity framework. Despite\nMamba's stateful design and recent attention as a strong candidate to\noutperform Transformers, we have demonstrated that both Mamba and SSMs with\n$\\mathrm{poly}(n)$-precision and constant-depth layers reside within the\n$\\mathsf{DLOGTIME}$-uniform $\\mathsf{TC}^0$ complexity class. This result\nindicates Mamba has the same computational capabilities as Transformer\ntheoretically, and it cannot solve problems like arithmetic formula problems,\nboolean formula value problems, and permutation composition problems if\n$\\mathsf{TC}^0 \\neq \\mathsf{NC}^1$. Therefore, it challenges the assumption\nMamba is more computationally expressive than Transformers. Our contributions\ninclude rigorous proofs showing that Selective SSM and Mamba architectures can\nbe simulated by $\\mathsf{DLOGTIME}$-uniform $\\mathsf{TC}^0$ circuits, and they\ncannot solve problems outside $\\mathsf{TC}^0$.\n","authors":["Yifang Chen","Xiaoyu Li","Yingyu Liang","Zhenmei Shi","Zhao Song"],"pdf_url":"https://arxiv.org/pdf/2412.06148v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06144v1","updated":"2024-12-09T01:58:10Z","published":"2024-12-09T01:58:10Z","title":"Hate Speech According to the Law: An Analysis for Effective Detection","summary":"  The issue of hate speech extends beyond the confines of the online realm. It\nis a problem with real-life repercussions, prompting most nations to formulate\nlegal frameworks that classify hate speech as a punishable offence. These legal\nframeworks differ from one country to another, contributing to the big chaos\nthat online platforms have to face when addressing reported instances of hate\nspeech. With the definitions of hate speech falling short in introducing a\nrobust framework, we turn our gaze onto hate speech laws. We consult the\nopinion of legal experts on a hate speech dataset and we experiment by\nemploying various approaches such as pretrained models both on hate speech and\nlegal data, as well as exploiting two large language models (Qwen2-7B-Instruct\nand Meta-Llama-3-70B). Due to the time-consuming nature of data acquisition for\nprosecutable hate speech, we use pseudo-labeling to improve our pretrained\nmodels. This study highlights the importance of amplifying research on\nprosecutable hate speech and provides insights into effective strategies for\ncombating hate speech within the parameters of legal frameworks. Our findings\nshow that legal knowledge in the form of annotations can be useful when\nclassifying prosecutable hate speech, yet more focus should be paid on the\ndifferences between the laws.\n","authors":["Katerina Korre","John Pavlopoulos","Paolo Gajo","Alberto Barrón-Cedeño"],"pdf_url":"https://arxiv.org/pdf/2412.06144v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01556v3","updated":"2024-12-09T01:55:03Z","published":"2024-10-02T13:52:55Z","title":"Integrative Decoding: Improve Factuality via Implicit Self-consistency","summary":"  Self-consistency-based approaches, which involve repeatedly sampling multiple\noutputs and selecting the most consistent one as the final response, prove to\nbe remarkably effective in improving the factual accuracy of large language\nmodels. Nonetheless, existing methods usually have strict constraints on the\ntask format, largely limiting their applicability. In this paper, we present\nIntegrative Decoding (ID), to unlock the potential of self-consistency in\nopen-ended generation tasks. ID operates by constructing a set of inputs, each\nprepended with a previously sampled response, and then processes them\nconcurrently, with the next token being selected by aggregating of all their\ncorresponding predictions at each decoding step. In essence, this simple\napproach implicitly incorporates self-consistency in the decoding objective.\nExtensive evaluation shows that ID consistently enhances factuality over a wide\nrange of language models, with substantial improvements on the TruthfulQA\n(+11.2%), Biographies (+15.4%) and LongFact (+8.5%) benchmarks. The performance\ngains amplify progressively as the number of sampled responses increases,\nindicating the potential of ID to scale up with repeated sampling.\n","authors":["Yi Cheng","Xiao Liang","Yeyun Gong","Wen Xiao","Song Wang","Yuji Zhang","Wenjun Hou","Kaishuai Xu","Wenge Liu","Wenjie Li","Jian Jiao","Qi Chen","Peng Cheng","Wayne Xiong"],"pdf_url":"https://arxiv.org/pdf/2410.01556v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06141v1","updated":"2024-12-09T01:50:39Z","published":"2024-12-09T01:50:39Z","title":"MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware\n  Multimodal Preference Optimization","summary":"  The advancement of Large Vision-Language Models (LVLMs) has propelled their\napplication in the medical field. However, Medical LVLMs (Med-LVLMs) encounter\nfactuality challenges due to modality misalignment, where the models prioritize\ntextual knowledge over visual input, leading to hallucinations that contradict\ninformation in medical images. Previous attempts to enhance modality alignment\nin Med-LVLMs through preference optimization have inadequately mitigated\nclinical relevance in preference data, making these samples easily\ndistinguishable and reducing alignment effectiveness. To address this\nchallenge, we propose MMedPO, a novel multimodal medical preference\noptimization approach that considers the clinical relevance of preference\nsamples to enhance Med-LVLM alignment. MMedPO curates multimodal preference\ndata by introducing two types of dispreference: (1) plausible hallucinations\ninjected through target Med-LVLMs or GPT-4o to produce medically inaccurate\nresponses, and (2) lesion region neglect achieved through local lesion-noising,\ndisrupting visual understanding of critical areas. We then calculate clinical\nrelevance for each sample based on scores from multiple Med-LLMs and visual\ntools, and integrate these scores into the preference optimization process as\nweights, enabling effective alignment. Our experiments demonstrate that MMedPO\nsignificantly enhances factual accuracy in Med-LVLMs, achieving substantial\nimprovements over existing preference optimization methods by averaging 14.2%\nand 51.7% across the Med-VQA and report generation tasks. Our code are\navailable in https://github.com/aiming-lab/MMedPO.\n","authors":["Kangyu Zhu","Peng Xia","Yun Li","Hongtu Zhu","Sheng Wang","Huaxiu Yao"],"pdf_url":"https://arxiv.org/pdf/2412.06141v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06136v1","updated":"2024-12-09T01:39:16Z","published":"2024-12-09T01:39:16Z","title":"AIDE: Task-Specific Fine Tuning with Attribute Guided Multi-Hop Data\n  Expansion","summary":"  Fine-tuning large language models (LLMs) for specific tasks requires\nhigh-quality, diverse training data relevant to the task. Recent research has\nleveraged LLMs to synthesize training data, but existing approaches either\ndepend on large seed datasets or struggle to ensure both task relevance and\ndata diversity in the generated outputs. To address these challenges, we\npropose AIDE, a novel data synthesis framework that uses a multi-hop process to\nexpand 10 seed data points while ensuring diversity and task relevance. AIDE\nextracts the main topic and key knowledge attributes from the seed data to\nguide the synthesis process. In each subsequent hop, it extracts the topic and\nattributes from the newly generated data and continues guided synthesis. This\nprocess repeats for a total of K hops. To prevent irrelevant data generation as\nthe hop depth increases, AIDE incorporates a residual connection mechanism and\nuses self-reflection to improve data quality. Our empirical results demonstrate\nthat fine-tuning Mistral-7B, Llama-3.1-8B and Llama-3.2-3B with AIDE achieves\nmore than 10% accuracy improvements over the base models across 13 tasks from 5\ndifferent benchmarks, while outperforming the models fine-tuned with\nstate-of-the-art data synthesis methods like Evol-Instruct, DataTune and\nPrompt2Model.\n","authors":["Jiayu Li","Xuan Zhu","Fang Liu","Yanjun Qi"],"pdf_url":"https://arxiv.org/pdf/2412.06136v1.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2412.06134v1","updated":"2024-12-09T01:29:47Z","published":"2024-12-09T01:29:47Z","title":"Evaluating and Mitigating Social Bias for Large Language Models in\n  Open-ended Settings","summary":"  Current social bias benchmarks for Large Language Models (LLMs) primarily\nrely on pre-defined question formats like multiple-choice, limiting their\nability to reflect the complexity and open-ended nature of real-world\ninteractions. To address this gap, we extend an existing BBQ dataset introduced\nby incorporating fill-in-the-blank and short-answer question types, designed to\nevaluate biases in an open-ended setting. Our finding reveals that LLMs tend to\nproduce responses that are more biased against certain protected attributes,\nlike age and socio-economic status. On the other hand, these biased outputs\nproduced by LLMs can serve as valuable contexts and chains of thought for\ndebiasing. Our debiasing approach combined zero-shot, few-shot, and\nchain-of-thought could significantly reduce the level of bias to almost 0. We\nopen-source our evaluation and debiasing code hoping to encourage further\nmeasurements and mitigation of bias and stereotype in LLMs.\n","authors":["Zhao Liu"],"pdf_url":"https://arxiv.org/pdf/2412.06134v1.pdf","comment":"12 panges"},{"id":"http://arxiv.org/abs/2406.11233v3","updated":"2024-12-09T23:53:27Z","published":"2024-06-17T06:00:24Z","title":"Probing the Decision Boundaries of In-context Learning in Large Language\n  Models","summary":"  In-context learning is a key paradigm in large language models (LLMs) that\nenables them to generalize to new tasks and domains by simply prompting these\nmodels with a few exemplars without explicit parameter updates. Many attempts\nhave been made to understand in-context learning in LLMs as a function of model\nscale, pretraining data, and other factors. In this work, we propose a new\nmechanism to probe and understand in-context learning from the lens of decision\nboundaries for in-context binary classification. Decision boundaries are\nstraightforward to visualize and provide important information about the\nqualitative behavior of the inductive biases of standard classifiers. To our\nsurprise, we find that the decision boundaries learned by current LLMs in\nsimple binary classification tasks are often irregular and non-smooth,\nregardless of linear separability in the underlying task. This paper\ninvestigates the factors influencing these decision boundaries and explores\nmethods to enhance their generalizability. We assess various approaches,\nincluding training-free and fine-tuning methods for LLMs, the impact of model\narchitecture, and the effectiveness of active prompting techniques for\nsmoothing decision boundaries in a data-efficient manner. Our findings provide\na deeper understanding of in-context learning dynamics and offer practical\nimprovements for enhancing robustness and generalizability of in-context\nlearning.\n","authors":["Siyan Zhao","Tung Nguyen","Aditya Grover"],"pdf_url":"https://arxiv.org/pdf/2406.11233v3.pdf","comment":"Accepted at NeurIPS 2024, code at\n  https://github.com/siyan-zhao/ICL_decision_boundary"},{"id":"http://arxiv.org/abs/2401.15861v4","updated":"2024-12-09T23:47:46Z","published":"2024-01-29T03:25:11Z","title":"BPDec: Unveiling the Potential of Masked Language Modeling Decoder in\n  BERT pretraining","summary":"  BERT (Bidirectional Encoder Representations from Transformers) has\nrevolutionized the field of natural language processing through its exceptional\nperformance on numerous tasks. Yet, the majority of researchers have mainly\nconcentrated on enhancements related to the model structure, such as relative\nposition embedding and more efficient attention mechanisms. Others have delved\ninto pretraining tricks associated with Masked Language Modeling, including\nwhole word masking. DeBERTa introduced an enhanced decoder adapted for BERT's\nencoder model for pretraining, proving to be highly effective. We argue that\nthe design and research around enhanced masked language modeling decoders have\nbeen underappreciated. In this paper, we propose several designs of enhanced\ndecoders and introduce BPDec (BERT Pretraining Decoder), a novel method for\nmodeling training. Typically, a pretrained BERT model is fine-tuned for\nspecific Natural Language Understanding (NLU) tasks. In our approach, we\nutilize the original BERT model as the encoder, making only changes to the\ndecoder without altering the encoder. This approach does not necessitate\nextensive modifications to the encoder architecture and can be seamlessly\nintegrated into existing fine-tuning pipelines and services, offering an\nefficient and effective enhancement strategy. Compared to other methods, while\nwe also incur a moderate training cost for the decoder during the pretraining\nprocess, our approach does not introduce additional training costs during the\nfine-tuning phase. We test multiple enhanced decoder structures after\npretraining and evaluate their performance on the GLUE tasks and SQuAD tasks.\nOur results demonstrate that BPDec, having only undergone subtle refinements to\nthe model structure during pretraining, significantly enhances model\nperformance without escalating the finetuning cost, inference time and serving\nbudget.\n","authors":["Wen Liang","Youzhi Liang"],"pdf_url":"https://arxiv.org/pdf/2401.15861v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.00115v2","updated":"2024-12-09T23:46:06Z","published":"2023-11-30T18:59:45Z","title":"A Video is Worth 10,000 Words: Training and Benchmarking with Diverse\n  Captions for Better Long Video Retrieval","summary":"  Existing long video retrieval systems are trained and tested in the\nparagraph-to-video retrieval regime, where every long video is described by a\nsingle long paragraph. This neglects the richness and variety of possible valid\ndescriptions of a video, which could range anywhere from moment-by-moment\ndetail to a single phrase summary. To provide a more thorough evaluation of the\ncapabilities of long video retrieval systems, we propose a pipeline that\nleverages state-of-the-art large language models to carefully generate a\ndiverse set of synthetic captions for long videos. We validate this pipeline's\nfidelity via rigorous human inspection. We use synthetic captions from this\npipeline to perform a benchmark of a representative set of video language\nmodels using long video datasets, and show that the models struggle on shorter\ncaptions. We show that finetuning on this data can both mitigate these issues\n(+2.8% R@1 over SOTA on ActivityNet with diverse captions), and even improve\nperformance on standard paragraph-to-video retrieval (+1.0% R@1 on\nActivityNet). We also use synthetic data from our pipeline as query expansion\nin the zero-shot setting (+3.4% R@1 on ActivityNet). We derive insights by\nanalyzing failure cases for retrieval with short captions. For data access and\nother details, please refer to our project website at\nhttps://mgwillia.github.io/10k-words.\n","authors":["Matthew Gwilliam","Michael Cogswell","Meng Ye","Karan Sikka","Abhinav Shrivastava","Ajay Divakaran"],"pdf_url":"https://arxiv.org/pdf/2312.00115v2.pdf","comment":"17 pages, 16 tables, 8 figures. To appear at WACV 2025"},{"id":"http://arxiv.org/abs/2412.07030v1","updated":"2024-12-09T22:35:44Z","published":"2024-12-09T22:35:44Z","title":"FM2DS: Few-Shot Multimodal Multihop Data Synthesis with Knowledge\n  Distillation for Question Answering","summary":"  Multimodal multihop question answering is a complex task that requires\nreasoning over multiple sources of information, such as images and text, to\nanswer questions. While there has been significant progress in visual question\nanswering, the multihop setting remains unexplored due to the lack of\nhigh-quality datasets. Current methods focus on single-hop question answering\nor a single modality, which makes them unsuitable for real-world scenarios such\nas analyzing multimodal educational materials, summarizing lengthy academic\narticles, or interpreting scientific studies that combine charts, images, and\ntext. To address this gap, we propose a novel methodology, introducing the\nfirst framework for creating a high-quality dataset that enables training\nmodels for multimodal multihop question answering. Our approach consists of a\n5-stage pipeline that involves acquiring relevant multimodal documents from\nWikipedia, synthetically generating high-level questions and answers, and\nvalidating them through rigorous criteria to ensure quality data. We evaluate\nour methodology by training models on our synthesized dataset and testing on\ntwo benchmarks, our results demonstrate that, with an equal sample size, models\ntrained on our synthesized data outperform those trained on human-collected\ndata by 1.9 in exact match (EM) on average. We believe our data synthesis\nmethod will serve as a strong foundation for training and evaluating multimodal\nmultihop question answering models.\n","authors":["Amirhossein Abaskohi","Spandana Gella","Giuseppe Carenini","Issam H. Laradji"],"pdf_url":"https://arxiv.org/pdf/2412.07030v1.pdf","comment":"20 pages, 11 figures, 10 tables, Submitted to CVPR 2025"},{"id":"http://arxiv.org/abs/2412.02980v2","updated":"2024-12-09T22:23:41Z","published":"2024-12-04T02:47:45Z","title":"Surveying the Effects of Quality, Diversity, and Complexity in Synthetic\n  Data From Large Language Models","summary":"  Synthetic data generation with Large Language Models is a promising paradigm\nfor augmenting natural data over a nearly infinite range of tasks. Given this\nvariety, direct comparisons among synthetic data generation algorithms are\nscarce, making it difficult to understand where improvement comes from and what\nbottlenecks exist. We propose to evaluate algorithms via the makeup of\nsynthetic data generated by each algorithm in terms of data quality, diversity,\nand complexity. We choose these three characteristics for their significance in\nopen-ended processes and the impact each has on the capabilities of downstream\nmodels. We find quality to be essential for in-distribution model\ngeneralization, diversity to be essential for out-of-distribution\ngeneralization, and complexity to be beneficial for both. Further, we emphasize\nthe existence of Quality-Diversity trade-offs in training data and the\ndownstream effects on model performance. We then examine the effect of various\ncomponents in the synthetic data pipeline on each data characteristic. This\nexamination allows us to taxonomize and compare synthetic data generation\nalgorithms through the components they utilize and the resulting effects on\ndata QDC composition. This analysis extends into a discussion on the importance\nof balancing QDC in synthetic data for efficient reinforcement learning and\nself-improvement algorithms. Analogous to the QD trade-offs in training data,\noften there exist trade-offs between model output quality and output diversity\nwhich impact the composition of synthetic data. We observe that many models are\ncurrently evaluated and optimized only for output quality, thereby limiting\noutput diversity and the potential for self-improvement. We argue that\nbalancing these trade-offs is essential to the development of future\nself-improvement algorithms and highlight a number of works making progress in\nthis direction.\n","authors":["Alex Havrilla","Andrew Dai","Laura O'Mahony","Koen Oostermeijer","Vera Zisler","Alon Albalak","Fabrizio Milo","Sharath Chandra Raparthy","Kanishk Gandhi","Baber Abbasi","Duy Phung","Maia Iyer","Dakota Mahan","Chase Blagden","Srishti Gureja","Mohammed Hamdy","Wen-Ding Li","Giovanni Paolini","Pawan Sasanka Ammanamanchi","Elliot Meyerson"],"pdf_url":"https://arxiv.org/pdf/2412.02980v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07019v1","updated":"2024-12-09T21:59:26Z","published":"2024-12-09T21:59:26Z","title":"Assessing the Impact of Conspiracy Theories Using Large Language Models","summary":"  Measuring the relative impact of CTs is important for prioritizing responses\nand allocating resources effectively, especially during crises. However,\nassessing the actual impact of CTs on the public poses unique challenges. It\nrequires not only the collection of CT-specific knowledge but also diverse\ninformation from social, psychological, and cultural dimensions. Recent\nadvancements in large language models (LLMs) suggest their potential utility in\nthis context, not only due to their extensive knowledge from large training\ncorpora but also because they can be harnessed for complex reasoning. In this\nwork, we develop datasets of popular CTs with human-annotated impacts.\nBorrowing insights from human impact assessment processes, we then design\ntailored strategies to leverage LLMs for performing human-like CT impact\nassessments. Through rigorous experiments, we textit{discover that an impact\nassessment mode using multi-step reasoning to analyze more CT-related evidence\ncritically produces accurate results; and most LLMs demonstrate strong bias,\nsuch as assigning higher impacts to CTs presented earlier in the prompt, while\ngenerating less accurate impact assessments for emotionally charged and verbose\nCTs.\n","authors":["Bohan Jiang","Dawei Li","Zhen Tan","Xinyi Zhou","Ashwin Rao","Kristina Lerman","H. Russell Bernard","Huan Liu"],"pdf_url":"https://arxiv.org/pdf/2412.07019v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07017v1","updated":"2024-12-09T21:53:10Z","published":"2024-12-09T21:53:10Z","title":"Asynchronous LLM Function Calling","summary":"  Large language models (LLMs) use function calls to interface with external\ntools and data source. However, the current approach to LLM function calling is\ninherently synchronous, where each call blocks LLM inference, limiting LLM\noperation and concurrent function execution. In this work, we propose AsyncLM,\na system for asynchronous LLM function calling. AsyncLM improves LLM's\noperational efficiency by enabling LLMs to generate and execute function calls\nconcurrently. Instead of waiting for each call's completion, AsyncLM introduces\nan interrupt mechanism to asynchronously notify the LLM in-flight when function\ncalls return. We design an in-context protocol for function calls and\ninterrupts, provide fine-tuning strategy to adapt LLMs to the interrupt\nsemantics, and implement these mechanisms efficiently on LLM inference process.\nWe demonstrate that AsyncLM can reduce end-to-end task completion latency from\n1.6x-5.4x compared to synchronous function calling on a set of benchmark tasks\nin the Berkeley function calling leaderboard (BFCL). Furthermore, we discuss\nhow interrupt mechanisms can be extended to enable novel human-LLM or LLM-LLM\ninteractions.\n","authors":["In Gim","Seung-seob Lee","Lin Zhong"],"pdf_url":"https://arxiv.org/pdf/2412.07017v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06975v1","updated":"2024-12-09T20:35:39Z","published":"2024-12-09T20:35:39Z","title":"AutoReason: Automatic Few-Shot Reasoning Decomposition","summary":"  Chain of Thought (CoT) was introduced in recent research as a method for\nimproving step-by-step reasoning in Large Language Models. However, CoT has\nlimited applications such as its need for hand-crafted few-shot exemplar\nprompts and no capability to adjust itself to different queries.\n  In this work, we propose a system to automatically generate rationales using\nCoT. Our method improves multi-step implicit reasoning capabilities by\ndecomposing the implicit query into several explicit questions. This provides\ninterpretability for the model, improving reasoning in weaker LLMs. We test our\napproach with two Q\\&A datasets: StrategyQA and HotpotQA. We show an increase\nin accuracy with both, especially on StrategyQA.\n  To facilitate further research in this field, the complete source code for\nthis study has been made publicly available on GitHub:\nhttps://github.com/miralab-ai/autoreason.\n","authors":["Arda Sevinc","Abdurrahman Gumus"],"pdf_url":"https://arxiv.org/pdf/2412.06975v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.06581v3","updated":"2024-12-09T20:32:47Z","published":"2024-06-04T16:09:13Z","title":"Order-Independence Without Fine Tuning","summary":"  The development of generative language models that can create long and\ncoherent textual outputs via autoregression has lead to a proliferation of uses\nand a corresponding sweep of analyses as researches work to determine the\nlimitations of this new paradigm. Unlike humans, these 'Large Language Models'\n(LLMs) are highly sensitive to small changes in their inputs, leading to\nunwanted inconsistency in their behavior. One problematic inconsistency when\nLLMs are used to answer multiple-choice questions or analyze multiple inputs is\norder dependency: the output of an LLM can (and often does) change\nsignificantly when sub-sequences are swapped, despite both orderings being\nsemantically identical. In this paper we present Set-Based Prompting, a\ntechnique that guarantees the output of an LLM will not have order dependence\non a specified set of sub-sequences. We show that this method provably\neliminates order dependency, and that it can be applied to any\ntransformer-based LLM to enable text generation that is unaffected by\nre-orderings. Delving into the implications of our method, we show that,\ndespite our inputs being out of distribution, the impact on expected accuracy\nis small, where the expectation is over the order of uniformly chosen shuffling\nof the candidate responses, and usually significantly less in practice. Thus,\nSet-Based Prompting can be used as a 'dropped-in' method on fully trained\nmodels. Finally, we discuss how our method's success suggests that other strong\nguarantees can be obtained on LLM performance via modifying the input\nrepresentations.\n","authors":["Reid McIlroy-Young","Katrina Brown","Conlan Olson","Linjun Zhang","Cynthia Dwork"],"pdf_url":"https://arxiv.org/pdf/2406.06581v3.pdf","comment":"29 pages, 27 figures, Published in NeurIPS 2024 code\n  https://github.com/reidmcy/set-based-prompting"},{"id":"http://arxiv.org/abs/2410.16204v2","updated":"2024-12-09T20:23:57Z","published":"2024-10-21T17:05:50Z","title":"Systematic Review: Text Processing Algorithms in Machine Learning and\n  Deep Learning for Mental Health Detection on Social Media","summary":"  The global rise in depression necessitates innovative detection methods for\nearly intervention. Social media provides a unique opportunity to identify\ndepression through user-generated posts. This systematic review evaluates\nmachine learning (ML) models for depression detection on social media, focusing\non biases and methodological challenges throughout the ML lifecycle. A search\nof PubMed, IEEE Xplore, and Google Scholar identified 47 relevant studies\npublished after 2010. The Prediction model Risk Of Bias ASsessment Tool\n(PROBAST) was utilized to assess methodological quality and risk of bias.\nSignificant biases impacting model reliability and generalizability were found.\nThere is a predominant reliance on Twitter (63.8%) and English-language content\n(over 90%), with most studies focusing on users from the United States and\nEurope. Non-probability sampling methods (approximately 80%) limit\nrepresentativeness. Only 23% of studies explicitly addressed linguistic nuances\nlike negations, crucial for accurate sentiment analysis. Inconsistent\nhyperparameter tuning was observed, with only 27.7% properly tuning models.\nAbout 17% did not adequately partition data into training, validation, and test\nsets, risking overfitting. While 74.5% used appropriate evaluation metrics for\nimbalanced data, others relied on accuracy without addressing class imbalance,\npotentially skewing results. Reporting transparency varied, often lacking\ncritical methodological details. These findings highlight the need to diversify\ndata sources, standardize preprocessing protocols, ensure consistent model\ndevelopment practices, address class imbalance, and enhance reporting\ntransparency. By overcoming these challenges, future research can develop more\nrobust and generalizable ML models for depression detection on social media,\ncontributing to improved mental health outcomes globally.\n","authors":["Yuchen Cao","Jianglai Dai","Zhongyan Wang","Yeyubei Zhang","Xiaorui Shen","Yunchong Liu","Yexin Tian"],"pdf_url":"https://arxiv.org/pdf/2410.16204v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06967v1","updated":"2024-12-09T20:22:06Z","published":"2024-12-09T20:22:06Z","title":"Effective Text Adaptation for LLM-based ASR through Soft Prompt\n  Fine-Tuning","summary":"  The advent of Large Language Models (LLM) has reformed the Automatic Speech\nRecognition (ASR). Prompting LLM with audio embeddings to generate\ntranscriptions becomes the new state-of-the-art ASR. Despite LLMs being trained\nwith an extensive amount of text corpora, high-quality domain-specific text\ndata can still significantly enhance ASR performance on domain adaptation\ntasks. Although LLM-based ASR can naturally incorporate more text corpora by\nfine-tuning the LLM decoder, fine-tuning such ASR on text-only data without\npaired prompts may diminish the effectiveness of domain-specific knowledge. To\nmitigate this issue, we propose a two-step soft prompt fine-tuning strategy\nthat enhances domain-specific text adaptation. Experimental results show that\ntext adaptation with our proposed method achieved a relative up to 9% Word\nError Rate (WER) reduction and up to 18% Entity Error Rate (EER) reduction on\nthe target domain compared to the baseline ASR. Combining this with\ndomain-specific Language Model (LM) fusion can further improve the EER by a\nrelative 2-5%\n","authors":["Yingyi Ma","Zhe Liu","Ozlem Kalinli"],"pdf_url":"https://arxiv.org/pdf/2412.06967v1.pdf","comment":"accepted as SLT 2024 proceeding"},{"id":"http://arxiv.org/abs/2406.18495v3","updated":"2024-12-09T20:21:56Z","published":"2024-06-26T16:58:20Z","title":"WildGuard: Open One-Stop Moderation Tools for Safety Risks, Jailbreaks,\n  and Refusals of LLMs","summary":"  We introduce WildGuard -- an open, light-weight moderation tool for LLM\nsafety that achieves three goals: (1) identifying malicious intent in user\nprompts, (2) detecting safety risks of model responses, and (3) determining\nmodel refusal rate. Together, WildGuard serves the increasing needs for\nautomatic safety moderation and evaluation of LLM interactions, providing a\none-stop tool with enhanced accuracy and broad coverage across 13 risk\ncategories. While existing open moderation tools such as Llama-Guard2 score\nreasonably well in classifying straightforward model interactions, they lag far\nbehind a prompted GPT-4, especially in identifying adversarial jailbreaks and\nin evaluating models' refusals, a key measure for evaluating safety behaviors\nin model responses.\n  To address these challenges, we construct WildGuardMix, a large-scale and\ncarefully balanced multi-task safety moderation dataset with 92K labeled\nexamples that cover vanilla (direct) prompts and adversarial jailbreaks, paired\nwith various refusal and compliance responses. WildGuardMix is a combination of\nWildGuardTrain, the training data of WildGuard, and WildGuardTest, a\nhigh-quality human-annotated moderation test set with 5K labeled items covering\nbroad risk scenarios. Through extensive evaluations on WildGuardTest and ten\nexisting public benchmarks, we show that WildGuard establishes state-of-the-art\nperformance in open-source safety moderation across all the three tasks\ncompared to ten strong existing open-source moderation models (e.g., up to\n26.4% improvement on refusal detection). Importantly, WildGuard matches and\nsometimes exceeds GPT-4 performance (e.g., up to 3.9% improvement on prompt\nharmfulness identification). WildGuard serves as a highly effective safety\nmoderator in an LLM interface, reducing the success rate of jailbreak attacks\nfrom 79.8% to 2.4%.\n","authors":["Seungju Han","Kavel Rao","Allyson Ettinger","Liwei Jiang","Bill Yuchen Lin","Nathan Lambert","Yejin Choi","Nouha Dziri"],"pdf_url":"https://arxiv.org/pdf/2406.18495v3.pdf","comment":"NeurIPS 2024 Camera Ready. First two authors contributed equally.\n  Third and fourth authors contributed equally"},{"id":"http://arxiv.org/abs/2402.01865v3","updated":"2024-12-09T20:06:44Z","published":"2024-02-02T19:43:15Z","title":"What Will My Model Forget? Forecasting Forgotten Examples in Language\n  Model Refinement","summary":"  Language models deployed in the wild make errors. However, simply updating\nthe model with the corrected error instances causes catastrophic forgetting --\nthe updated model makes errors on instances learned during the instruction\ntuning or upstream training phase. Randomly replaying upstream data yields\nunsatisfactory performance and often comes with high variance and poor\ncontrollability. To this end, we try to forecast upstream examples that will be\nforgotten due to a model update for improved controllability of the replay\nprocess and interpretability. We train forecasting models given a collection of\nonline learned examples and corresponding forgotten upstream pre-training\nexamples. We propose a partially interpretable forecasting model based on the\nobservation that changes in pre-softmax logit scores of pretraining examples\nresemble that of online learned examples, which performs decently on BART but\nfails on T5 models. We further show a black-box classifier based on inner\nproducts of example representations achieves better forecasting performance\nover a series of setups. Finally, we show that we reduce forgetting of upstream\npretraining examples by replaying examples that are forecasted to be forgotten,\ndemonstrating the practical utility of forecasting example forgetting.\n","authors":["Xisen Jin","Xiang Ren"],"pdf_url":"https://arxiv.org/pdf/2402.01865v3.pdf","comment":"ICML 2024 (Spotlight)"},{"id":"http://arxiv.org/abs/2412.06951v1","updated":"2024-12-09T19:54:54Z","published":"2024-12-09T19:54:54Z","title":"Analysing Public Transport User Sentiment on Low Resource Multilingual\n  Data","summary":"  Public transport systems in many Sub-Saharan countries often receive less\nattention compared to other sectors, underscoring the need for innovative\nsolutions to improve the Quality of Service (QoS) and overall user experience.\nThis study explored commuter opinion mining to understand sentiments toward\nexisting public transport systems in Kenya, Tanzania, and South Africa. We used\na qualitative research design, analysing data from X (formerly Twitter) to\nassess sentiments across rail, mini-bus taxis, and buses. By leveraging\nMultilingual Opinion Mining techniques, we addressed the linguistic diversity\nand code-switching present in our dataset, thus demonstrating the application\nof Natural Language Processing (NLP) in extracting insights from\nunder-resourced languages. We employed PLMs such as AfriBERTa, AfroXLMR,\nAfroLM, and PuoBERTa to conduct the sentiment analysis. The results revealed\npredominantly negative sentiments in South Africa and Kenya, while the\nTanzanian dataset showed mainly positive sentiments due to the advertising\nnature of the tweets. Furthermore, feature extraction using the Word2Vec model\nand K-Means clustering illuminated semantic relationships and primary themes\nfound within the different datasets. By prioritising the analysis of user\nexperiences and sentiments, this research paves the way for developing more\nresponsive, user-centered public transport systems in Sub-Saharan countries,\ncontributing to the broader goal of improving urban mobility and\nsustainability.\n","authors":["Rozina L. Myoya","Vukosi Marivate","Idris Abdulmumin"],"pdf_url":"https://arxiv.org/pdf/2412.06951v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06926v1","updated":"2024-12-09T19:11:54Z","published":"2024-12-09T19:11:54Z","title":"When Every Token Counts: Optimal Segmentation for Low-Resource Language\n  Models","summary":"  Traditional greedy tokenization methods have been a critical step in Natural\nLanguage Processing (NLP), influencing how text is converted into tokens and\ndirectly impacting model performance. While subword tokenizers like Byte-Pair\nEncoding (BPE) are widely used, questions remain about their optimality across\nmodel scales and languages. In this work, we demonstrate through extensive\nexperiments that an optimal BPE configuration significantly reduces token count\ncompared to greedy segmentation, yielding improvements in token-saving\npercentages and performance benefits, particularly for smaller models. We\nevaluate tokenization performance across various intrinsic and extrinsic tasks,\nincluding generation and classification. Our findings suggest that\ncompression-optimized tokenization strategies could provide substantial\nadvantages for multilingual and low-resource language applications,\nhighlighting a promising direction for further research and inclusive NLP.\n","authors":["Bharath Raj S","Garvit Suri","Vikrant Dewangan","Raghav Sonavane"],"pdf_url":"https://arxiv.org/pdf/2412.06926v1.pdf","comment":"LoResLM @ COLING 2025"},{"id":"http://arxiv.org/abs/2412.06877v1","updated":"2024-12-09T18:43:56Z","published":"2024-12-09T18:43:56Z","title":"LLMs for Generalizable Language-Conditioned Policy Learning under\n  Minimal Data Requirements","summary":"  To develop autonomous agents capable of executing complex, multi-step\ndecision-making tasks as specified by humans in natural language, existing\nreinforcement learning approaches typically require expensive labeled datasets\nor access to real-time experimentation. Moreover, conventional methods often\nface difficulties in generalizing to unseen goals and states, thereby limiting\ntheir practical applicability. This paper presents TEDUO, a novel training\npipeline for offline language-conditioned policy learning. TEDUO operates on\neasy-to-obtain, unlabeled datasets and is suited for the so-called in-the-wild\nevaluation, wherein the agent encounters previously unseen goals and states. To\naddress the challenges posed by such data and evaluation settings, our method\nleverages the prior knowledge and instruction-following capabilities of large\nlanguage models (LLMs) to enhance the fidelity of pre-collected offline data\nand enable flexible generalization to new goals and states. Empirical results\ndemonstrate that the dual role of LLMs in our framework-as data enhancers and\ngeneralizers-facilitates both effective and data-efficient learning of\ngeneralizable language-conditioned policies.\n","authors":["Thomas Pouplin","Katarzyna Kobalczyk","Hao Sun","Mihaela van der Schaar"],"pdf_url":"https://arxiv.org/pdf/2412.06877v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06874v1","updated":"2024-12-09T16:08:22Z","published":"2024-12-09T16:08:22Z","title":"Real-Time Performance Optimization of Travel Reservation Systems Using\n  AI and Microservices","summary":"  The rapid growth of the travel industry has increased the need for real-time\noptimization in reservation systems that could take care of huge data and\ntransaction volumes. This study proposes a hybrid framework that ut folds an\nArtificial Intelligence and a Microservices approach for the performance\noptimization of the system. The AI algorithms forecast demand patterns,\noptimize the allocation of resources, and enhance decision-making driven by\nMicroservices architecture, hence decentralizing system components for\nscalability, fault tolerance, and reduced downtime. The model provided focuses\non major problems associated with the travel reservation systems such as\nlatency of systems, load balancing and data consistency. It endows the systems\nwith predictive models based on AI improved ability to forecast user demands.\nMicroservices would also take care of different scales during uneven traffic\npatterns. Hence, both aspects ensure better handling of peak loads and spikes\nwhile minimizing delays and ensuring high service quality. A comparison was\nmade between traditional reservation models, which are monolithic and the new\nmodel of AI-Microservices. Comparatively, the analysis results state that there\nis a drastic improvement in processing times where the system uptime and\nresource utilization proved the capability of AI and the microservices in\ntransforming the travel industry in terms of reservation. This research work\nfocused on AI and Microservices towards real-time optimization, providing\ncritical insight into how to move forward with practical recommendations for\nupgrading travel reservation systems with this technology.\n","authors":["Biman Barua","M. Shamim Kaiser"],"pdf_url":"https://arxiv.org/pdf/2412.06874v1.pdf","comment":"19 pages, 12 figures"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2412.00430v3","updated":"2024-12-09T18:46:37Z","published":"2024-11-30T10:56:30Z","title":"Predictive Models in Sequential Recommendations: Bridging Performance\n  Laws with Data Quality Insights","summary":"  Sequential Recommendation (SR) plays a critical role in predicting users'\nsequential preferences. Despite its growing prominence in various industries,\nthe increasing scale of SR models incurs substantial computational costs and\nunpredictability, challenging developers to manage resources efficiently. Under\nthis predicament, Scaling Laws have achieved significant success by examining\nthe loss as models scale up. However, there remains a disparity between loss\nand model performance, which is of greater concern in practical applications.\nMoreover, as data continues to expand, it incorporates repetitive and\ninefficient data. In response, we introduce the Performance Law for SR models,\nwhich aims to theoretically investigate and model the relationship between\nmodel performance and data quality. Specifically, we first fit the HR and NDCG\nmetrics to transformer-based SR models. Subsequently, we propose Approximate\nEntropy (ApEn) to assess data quality, presenting a more nuanced approach\ncompared to traditional data quantity metrics. Our method enables accurate\npredictions across various dataset scales and model sizes, demonstrating a\nstrong correlation in large SR models and offering insights into achieving\noptimal performance for any given model configuration.\n","authors":["Tingjia Shen","Hao Wang","Chuhan Wu","Jin Yao Chin","Wei Guo","Yong Liu","Huifeng Guo","Defu Lian","Ruiming Tang","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2412.00430v3.pdf","comment":"12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2403.19546v3","updated":"2024-12-09T18:37:55Z","published":"2024-03-28T16:27:26Z","title":"Croissant: A Metadata Format for ML-Ready Datasets","summary":"  Data is a critical resource for machine learning (ML), yet working with data\nremains a key friction point. This paper introduces Croissant, a metadata\nformat for datasets that creates a shared representation across ML tools,\nframeworks, and platforms. Croissant makes datasets more discoverable,\nportable, and interoperable, thereby addressing significant challenges in ML\ndata management. Croissant is already supported by several popular dataset\nrepositories, spanning hundreds of thousands of datasets, enabling easy loading\ninto the most commonly-used ML frameworks, regardless of where the data is\nstored. Our initial evaluation by human raters shows that Croissant metadata is\nreadable, understandable, complete, yet concise.\n","authors":["Mubashara Akhtar","Omar Benjelloun","Costanza Conforti","Luca Foschini","Joan Giner-Miguelez","Pieter Gijsbers","Sujata Goswami","Nitisha Jain","Michalis Karamousadakis","Michael Kuchnik","Satyapriya Krishna","Sylvain Lesage","Quentin Lhoest","Pierre Marcenac","Manil Maskey","Peter Mattson","Luis Oala","Hamidah Oderinwale","Pierre Ruyssen","Tim Santos","Rajat Shinde","Elena Simperl","Arjun Suresh","Goeffry Thomas","Slava Tykhonov","Joaquin Vanschoren","Susheel Varma","Jos van der Velde","Steffen Vogler","Carole-Jean Wu","Luyao Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.19546v3.pdf","comment":"Published at the NeurIPS 2024 Datasets and Benchmark Track. A shorter\n  version appeared earlier in Proceedings of ACM SIGMOD/PODS'24 Data Management\n  for End-to-End Machine Learning (DEEM) Workshop\n  https://dl.acm.org/doi/10.1145/3650203.3663326"},{"id":"http://arxiv.org/abs/2412.06695v1","updated":"2024-12-09T17:41:25Z","published":"2024-12-09T17:41:25Z","title":"DEEPER: Dense Electroencephalography Passage Retrieval","summary":"  Information retrieval systems have historically relied on explicit query\nformulation, requiring users to translate their information needs into text.\nThis process is particularly disruptive during reading tasks, where users must\ninterrupt their natural flow to formulate queries. We present DEEPER (Dense\nElectroencephalography Passage Retrieval), a novel framework that enables\ndirect retrieval of relevant passages from users' neural signals during\nnaturalistic reading without intermediate text translation. Building on dense\nretrieval architectures, DEEPER employs a dual-encoder approach with\nspecialised components for processing neural data, mapping EEG signals and text\npassages into a shared semantic space. Through careful architecture design and\ncross-modal negative sampling strategies, our model learns to align neural\npatterns with their corresponding textual content. Experimental results on the\nZuCo dataset demonstrate that direct brain-to-passage retrieval significantly\noutperforms current EEG-to-text baselines, achieving a 571% improvement in\nPrecision@1. Our ablation studies reveal that the model successfully learns\naligned representations between EEG and text modalities (0.29 cosine\nsimilarity), while our hard negative sampling strategy contributes to overall\nperformance increases.\n","authors":["Niall McGuire","Yashar Moshfeghi"],"pdf_url":"https://arxiv.org/pdf/2412.06695v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.12207v2","updated":"2024-12-09T17:08:38Z","published":"2024-05-20T17:47:18Z","title":"Optimistic Query Routing in Clustering-based Approximate Maximum Inner\n  Product Search","summary":"  Clustering-based nearest neighbor search is an effective method in which\npoints are partitioned into geometric shards to form an index, with only a few\nshards searched during query processing to find a set of top-$k$ vectors. Even\nthough the search efficacy is heavily influenced by the algorithm that\nidentifies the shards to probe, it has received little attention in the\nliterature. This work bridges that gap by studying routing in clustering-based\nmaximum inner product search. We unpack existing routers and notice the\nsurprising contribution of optimism. We then take a page from the sequential\ndecision making literature and formalize that insight following the principle\nof ``optimism in the face of uncertainty.'' In particular, we present a\nframework that incorporates the moments of the distribution of inner products\nwithin each shard to estimate the maximum inner product. We then present an\ninstance of our algorithm that uses only the first two moments to reach the\nsame accuracy as state-of-the-art routers such as ScaNN by probing up to $50\\%$\nfewer points on benchmark datasets. Our algorithm is also space-efficient: we\ndesign a sketch of the second moment whose size is independent of the number of\npoints and requires $\\mathcal{O}(1)$ vectors per shard.\n","authors":["Sebastian Bruch","Aditya Krishnan","Franco Maria Nardini"],"pdf_url":"https://arxiv.org/pdf/2405.12207v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06649v1","updated":"2024-12-09T16:43:23Z","published":"2024-12-09T16:43:23Z","title":"Semantic Search and Recommendation Algorithm","summary":"  This paper introduces a new semantic search algorithm that uses Word2Vec and\nAnnoy Index to improve the efficiency of information retrieval from large\ndatasets. The proposed approach addresses the limitations of traditional search\nmethods by offering enhanced speed, accuracy, and scalability. Testing on\ndatasets up to 100GB demonstrates the method's effectiveness in processing vast\namounts of data while maintaining high precision and performance.\n","authors":["Aryan Duhan","Aryan Singhal","Shourya Sharma"," Neeraj","Arti MK"],"pdf_url":"https://arxiv.org/pdf/2412.06649v1.pdf","comment":"6 pages, 5 Figures"},{"id":"http://arxiv.org/abs/2409.05633v2","updated":"2024-12-09T09:44:27Z","published":"2024-09-09T14:04:17Z","title":"Enhancing Graph Contrastive Learning with Reliable and Informative\n  Augmentation for Recommendation","summary":"  Graph neural network(GNN) has been a powerful approach in collaborative\nfiltering(CF) due to its ability to model high-order user-item relationships.\nRecently, to alleviate the data sparsity and enhance representation learning,\nmany efforts have been conducted to integrate contrastive learning(CL) with\nGNNs. Despite the promising improvements, the contrastive view generation based\non structure and representation perturbations in existing methods potentially\ndisrupts the collaborative information in contrastive views, resulting in\nlimited effectiveness of positive alignment. To overcome this issue, we propose\nCoGCL, a novel framework that aims to enhance graph contrastive learning by\nconstructing contrastive views with stronger collaborative information via\ndiscrete codes. The core idea is to map users and items into discrete codes\nrich in collaborative information for reliable and informative contrastive view\ngeneration. To this end, we initially introduce a multi-level vector quantizer\nin an end-to-end manner to quantize user and item representations into discrete\ncodes. Based on these discrete codes, we enhance the collaborative information\nof contrastive views by considering neighborhood structure and semantic\nrelevance respectively. For neighborhood structure, we propose virtual neighbor\naugmentation by treating discrete codes as virtual neighbors, which expands an\nobserved user-item interaction into multiple edges involving discrete codes.\nRegarding semantic relevance, we identify similar users/items based on shared\ndiscrete codes and interaction targets to generate the semantically relevant\nview. Through these strategies, we construct contrastive views with stronger\ncollaborative information and develop a triple-view graph contrastive learning\napproach. Extensive experiments on four public datasets demonstrate the\neffectiveness of our proposed approach.\n","authors":["Bowen Zheng","Junjie Zhang","Hongyu Lu","Yu Chen","Ming Chen","Wayne Xin Zhao","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2409.05633v2.pdf","comment":"Accepted by KDD 2025"},{"id":"http://arxiv.org/abs/2412.05248v2","updated":"2024-12-09T09:21:49Z","published":"2024-12-06T18:27:15Z","title":"Enhancing FKG.in: automating Indian food composition analysis","summary":"  This paper presents a novel approach to compute food composition data for\nIndian recipes using a knowledge graph for Indian food (FKG.in) and LLMs. The\nprimary focus is to provide a broad overview of an automated food composition\nanalysis workflow and describe its core functionalities: nutrition data\naggregation, food composition analysis, and LLM-augmented information\nresolution. This workflow aims to complement FKG.in and iteratively supplement\nfood composition data from verified knowledge bases. Additionally, this paper\nhighlights the challenges of representing Indian food and accessing food\ncomposition data digitally. It also reviews three key sources of food\ncomposition data: the Indian Food Composition Tables, the Indian Nutrient\nDatabank, and the Nutritionix API. Furthermore, it briefly outlines how users\ncan interact with the workflow to obtain diet-based health recommendations and\ndetailed food composition information for numerous recipes. We then explore the\ncomplex challenges of analyzing Indian recipe information across dimensions\nsuch as structure, multilingualism, and uncertainty as well as present our\nongoing work on LLM-based solutions to address these issues. The methods\nproposed in this workshop paper for AI-driven knowledge curation and\ninformation resolution are application-agnostic, generalizable, and replicable\nfor any domain.\n","authors":["Saransh Kumar Gupta","Lipika Dey","Partha Pratim Das","Geeta Trilok-Kumar","Ramesh Jain"],"pdf_url":"https://arxiv.org/pdf/2412.05248v2.pdf","comment":"15 pages, 5 figures, 30 references, International Conference on\n  Pattern Recognition 2024 - Multimedia Assisted Dietary Management Workshop"},{"id":"http://arxiv.org/abs/2412.06308v1","updated":"2024-12-09T08:55:48Z","published":"2024-12-09T08:55:48Z","title":"PRECISE: Pre-training Sequential Recommenders with Collaborative and\n  Semantic Information","summary":"  Real-world recommendation systems commonly offer diverse content scenarios\nfor users to interact with. Considering the enormous number of users in\nindustrial platforms, it is infeasible to utilize a single unified\nrecommendation model to meet the requirements of all scenarios. Usually,\nseparate recommendation pipelines are established for each distinct scenario.\nThis practice leads to challenges in comprehensively grasping users' interests.\nRecent research endeavors have been made to tackle this problem by pre-training\nmodels to encapsulate the overall interests of users. Traditional pre-trained\nrecommendation models mainly capture user interests by leveraging collaborative\nsignals. Nevertheless, a prevalent drawback of these systems is their\nincapacity to handle long-tail items and cold-start scenarios. With the recent\nadvent of large language models, there has been a significant increase in\nresearch efforts focused on exploiting LLMs to extract semantic information for\nusers and items. However, text-based recommendations highly rely on elaborate\nfeature engineering and frequently fail to capture collaborative similarities.\nTo overcome these limitations, we propose a novel pre-training framework for\nsequential recommendation, termed PRECISE. This framework combines\ncollaborative signals with semantic information. Moreover, PRECISE employs a\nlearning framework that initially models users' comprehensive interests across\nall recommendation scenarios and subsequently concentrates on the specific\ninterests of target-scene behaviors. We demonstrate that PRECISE precisely\ncaptures the entire range of user interests and effectively transfers them to\nthe target interests. Empirical findings reveal that the PRECISE framework\nattains outstanding performance on both public and industrial datasets.\n","authors":["Chonggang Song","Chunxu Shen","Hao Gu","Yaoming Wu","Lingling Yi","Jie Wen","Chuan Chen"],"pdf_url":"https://arxiv.org/pdf/2412.06308v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06272v1","updated":"2024-12-09T07:46:14Z","published":"2024-12-09T07:46:14Z","title":"Methods for Legal Citation Prediction in the Age of LLMs: An Australian\n  Law Case Study","summary":"  In recent years, Large Language Models (LLMs) have shown great potential\nacross a wide range of legal tasks. Despite these advances, mitigating\nhallucination remains a significant challenge, with state-of-the-art LLMs still\nfrequently generating incorrect legal references. In this paper, we focus on\nthe problem of legal citation prediction within the Australian law context,\nwhere correctly identifying and citing relevant legislations or precedents is\ncritical. We compare several approaches: prompting general purpose and\nlaw-specialised LLMs, retrieval-only pipelines with both generic and\ndomain-specific embeddings, task-specific instruction-tuning of LLMs, and\nhybrid strategies that combine LLMs with retrieval augmentation, query\nexpansion, or voting ensembles. Our findings indicate that domain-specific\npre-training alone is insufficient for achieving satisfactory citation accuracy\neven after law-specialised pre-training. In contrast, instruction tuning on our\ntask-specific dataset dramatically boosts performance reaching the best results\nacross all settings. We also highlight that database granularity along with the\ntype of embeddings play a critical role in the performance of retrieval\nsystems. Among retrieval-based approaches, hybrid methods consistently\noutperform retrieval-only setups, and among these, ensemble voting delivers the\nbest result by combining the predictive quality of instruction-tuned LLMs with\nthe retrieval system.\n","authors":["Ehsan Shareghi","Jiuzhou Han","Paul Burgess"],"pdf_url":"https://arxiv.org/pdf/2412.06272v1.pdf","comment":"For code, data, and models see https://auslawbench.github.io"},{"id":"http://arxiv.org/abs/2405.13792v2","updated":"2024-12-09T06:07:03Z","published":"2024-05-22T16:15:17Z","title":"xRAG: Extreme Context Compression for Retrieval-augmented Generation\n  with One Token","summary":"  This paper introduces xRAG, an innovative context compression method tailored\nfor retrieval-augmented generation. xRAG reinterprets document embeddings in\ndense retrieval--traditionally used solely for retrieval--as features from the\nretrieval modality. By employing a modality fusion methodology, xRAG seamlessly\nintegrates these embeddings into the language model representation space,\neffectively eliminating the need for their textual counterparts and achieving\nan extreme compression rate. In xRAG, the only trainable component is the\nmodality bridge, while both the retriever and the language model remain frozen.\nThis design choice allows for the reuse of offline-constructed document\nembeddings and preserves the plug-and-play nature of retrieval augmentation.\nExperimental results demonstrate that xRAG achieves an average improvement of\nover 10% across six knowledge-intensive tasks, adaptable to various language\nmodel backbones, ranging from a dense 7B model to an 8x7B Mixture of Experts\nconfiguration. xRAG not only significantly outperforms previous context\ncompression methods but also matches the performance of uncompressed models on\nseveral datasets, while reducing overall FLOPs by a factor of 3.53. Our work\npioneers new directions in retrieval-augmented generation from the perspective\nof multimodality fusion, and we hope it lays the foundation for future\nefficient and scalable retrieval-augmented systems\n","authors":["Xin Cheng","Xun Wang","Xingxing Zhang","Tao Ge","Si-Qing Chen","Furu Wei","Huishuai Zhang","Dongyan Zhao"],"pdf_url":"https://arxiv.org/pdf/2405.13792v2.pdf","comment":"Neurips 2024"},{"id":"http://arxiv.org/abs/2412.07030v1","updated":"2024-12-09T22:35:44Z","published":"2024-12-09T22:35:44Z","title":"FM2DS: Few-Shot Multimodal Multihop Data Synthesis with Knowledge\n  Distillation for Question Answering","summary":"  Multimodal multihop question answering is a complex task that requires\nreasoning over multiple sources of information, such as images and text, to\nanswer questions. While there has been significant progress in visual question\nanswering, the multihop setting remains unexplored due to the lack of\nhigh-quality datasets. Current methods focus on single-hop question answering\nor a single modality, which makes them unsuitable for real-world scenarios such\nas analyzing multimodal educational materials, summarizing lengthy academic\narticles, or interpreting scientific studies that combine charts, images, and\ntext. To address this gap, we propose a novel methodology, introducing the\nfirst framework for creating a high-quality dataset that enables training\nmodels for multimodal multihop question answering. Our approach consists of a\n5-stage pipeline that involves acquiring relevant multimodal documents from\nWikipedia, synthetically generating high-level questions and answers, and\nvalidating them through rigorous criteria to ensure quality data. We evaluate\nour methodology by training models on our synthesized dataset and testing on\ntwo benchmarks, our results demonstrate that, with an equal sample size, models\ntrained on our synthesized data outperform those trained on human-collected\ndata by 1.9 in exact match (EM) on average. We believe our data synthesis\nmethod will serve as a strong foundation for training and evaluating multimodal\nmultihop question answering models.\n","authors":["Amirhossein Abaskohi","Spandana Gella","Giuseppe Carenini","Issam H. Laradji"],"pdf_url":"https://arxiv.org/pdf/2412.07030v1.pdf","comment":"20 pages, 11 figures, 10 tables, Submitted to CVPR 2025"},{"id":"http://arxiv.org/abs/2412.06954v1","updated":"2024-12-09T20:01:59Z","published":"2024-12-09T20:01:59Z","title":"CURE: Clinical Understanding & Retrieval Evaluation","summary":"  Given the dominance of dense retrievers that do not generalize well beyond\ntheir training dataset distributions, domain-specific test sets are essential\nin evaluating retrieval. There are few test datasets for retrieval systems\nintended for use by healthcare providers in a point-of-care setting. To fill\nthis gap we have collaborated with medical professionals to create CURE, an\nad-hoc retrieval test dataset for passage ranking with 2000 queries spanning 10\nmedical domains with a monolingual (English) and two cross-lingual\n(French/Spanish -> English) conditions. In this paper, we describe how CURE was\nconstructed and provide baseline results to showcase its effectiveness as an\nevaluation tool. CURE is published with a Creative Commons Attribution Non\nCommercial 4.0 license and can be accessed on Hugging Face.\n","authors":["Nadia Sheikh","Anne-Laure Jousse","Daniel Buades Marcos","Akintunde Oladipo","Olivier Rousseau","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2412.06954v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06949v1","updated":"2024-12-09T19:53:13Z","published":"2024-12-09T19:53:13Z","title":"Bridging Conversational and Collaborative Signals for Conversational\n  Recommendation","summary":"  Conversational recommendation systems (CRS) leverage contextual information\nfrom conversations to generate recommendations but often struggle due to a lack\nof collaborative filtering (CF) signals, which capture user-item interaction\npatterns essential for accurate recommendations. We introduce Reddit-ML32M, a\ndataset that links reddit conversations with interactions on MovieLens 32M, to\nenrich item representations by leveraging collaborative knowledge and\naddressing interaction sparsity in conversational datasets. We propose an\nLLM-based framework that uses Reddit-ML32M to align LLM-generated\nrecommendations with CF embeddings, refining rankings for better performance.\nWe evaluate our framework against three sets of baselines: CF-based\nrecommenders using only interactions from CRS tasks, traditional CRS models,\nand LLM-based methods relying on conversational context without item\nrepresentations. Our approach achieves consistent improvements, including a\n12.32% increase in Hit Rate and a 9.9% improvement in NDCG, outperforming the\nbest-performing baseline that relies on conversational context but lacks\ncollaborative item representations.\n","authors":["Ahmad Bin Rabiah","Nafis Sadeq","Julian McAuley"],"pdf_url":"https://arxiv.org/pdf/2412.06949v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06924v1","updated":"2024-12-09T19:10:03Z","published":"2024-12-09T19:10:03Z","title":"Efficient user history modeling with amortized inference for deep\n  learning recommendation models","summary":"  We study user history modeling via Transformer encoders in deep learning\nrecommendation models (DLRM). Such architectures can significantly improve\nrecommendation quality, but usually incur high latency cost necessitating\ninfrastructure upgrades or very small Transformer models. An important part of\nuser history modeling is early fusion of the candidate item and various methods\nhave been studied. We revisit early fusion and compare concatenation of the\ncandidate to each history item against appending it to the end of the list as a\nseparate item. Using the latter method, allows us to reformulate the recently\nproposed amortized history inference algorithm M-FALCON \\cite{zhai2024actions}\nfor the case of DLRM models. We show via experimental results that appending\nwith cross-attention performs on par with concatenation and that amortization\nsignificantly reduces inference costs. We conclude with results from deploying\nthis model on the LinkedIn Feed and Ads surfaces, where amortization reduces\nlatency by 30\\% compared to non-amortized inference.\n","authors":["Lars Hertel","Neil Daftary","Fedor Borisyuk","Aman Gupta","Rahul Mazumder"],"pdf_url":"https://arxiv.org/pdf/2412.06924v1.pdf","comment":"5 pages, 3 figures, WWW 2025"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2412.06784v1","updated":"2024-12-09T18:59:42Z","published":"2024-12-09T18:59:42Z","title":"P3-PO: Prescriptive Point Priors for Visuo-Spatial Generalization of\n  Robot Policies","summary":"  Developing generalizable robot policies that can robustly handle varied\nenvironmental conditions and object instances remains a fundamental challenge\nin robot learning. While considerable efforts have focused on collecting large\nrobot datasets and developing policy architectures to learn from such data,\nnaively learning from visual inputs often results in brittle policies that fail\nto transfer beyond the training data. This work presents Prescriptive Point\nPriors for Policies or P3-PO, a novel framework that constructs a unique state\nrepresentation of the environment leveraging recent advances in computer vision\nand robot learning to achieve improved out-of-distribution generalization for\nrobot manipulation. This representation is obtained through two steps. First, a\nhuman annotator prescribes a set of semantically meaningful points on a single\ndemonstration frame. These points are then propagated through the dataset using\noff-the-shelf vision models. The derived points serve as an input to\nstate-of-the-art policy architectures for policy learning. Our experiments\nacross four real-world tasks demonstrate an overall 43% absolute improvement\nover prior methods when evaluated in identical settings as training. Further,\nP3-PO exhibits 58% and 80% gains across tasks for new object instances and more\ncluttered environments respectively. Videos illustrating the robot's\nperformance are best viewed at point-priors.github.io.\n","authors":["Mara Levy","Siddhant Haldar","Lerrel Pinto","Abhinav Shirivastava"],"pdf_url":"https://arxiv.org/pdf/2412.06784v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06781v1","updated":"2024-12-09T18:59:04Z","published":"2024-12-09T18:59:04Z","title":"Around the World in 80 Timesteps: A Generative Approach to Global Visual\n  Geolocation","summary":"  Global visual geolocation predicts where an image was captured on Earth.\nSince images vary in how precisely they can be localized, this task inherently\ninvolves a significant degree of ambiguity. However, existing approaches are\ndeterministic and overlook this aspect. In this paper, we aim to close the gap\nbetween traditional geolocalization and modern generative methods. We propose\nthe first generative geolocation approach based on diffusion and Riemannian\nflow matching, where the denoising process operates directly on the Earth's\nsurface. Our model achieves state-of-the-art performance on three visual\ngeolocation benchmarks: OpenStreetView-5M, YFCC-100M, and iNat21. In addition,\nwe introduce the task of probabilistic visual geolocation, where the model\npredicts a probability distribution over all possible locations instead of a\nsingle point. We introduce new metrics and baselines for this task,\ndemonstrating the advantages of our diffusion-based approach. Codes and models\nwill be made available.\n","authors":["Nicolas Dufour","David Picard","Vicky Kalogeiton","Loic Landrieu"],"pdf_url":"https://arxiv.org/pdf/2412.06781v1.pdf","comment":"Project page: https://nicolas-dufour.github.io/plonk"},{"id":"http://arxiv.org/abs/2406.09408v2","updated":"2024-12-09T18:58:10Z","published":"2024-06-13T17:59:44Z","title":"Data Attribution for Text-to-Image Models by Unlearning Synthesized\n  Images","summary":"  The goal of data attribution for text-to-image models is to identify the\ntraining images that most influence the generation of a new image. Influence is\ndefined such that, for a given output, if a model is retrained from scratch\nwithout the most influential images, the model would fail to reproduce the same\noutput. Unfortunately, directly searching for these influential images is\ncomputationally infeasible, since it would require repeatedly retraining models\nfrom scratch. In our work, we propose an efficient data attribution method by\nsimulating unlearning the synthesized image. We achieve this by increasing the\ntraining loss on the output image, without catastrophic forgetting of other,\nunrelated concepts. We then identify training images with significant loss\ndeviations after the unlearning process and label these as influential. We\nevaluate our method with a computationally intensive but \"gold-standard\"\nretraining from scratch and demonstrate our method's advantages over previous\nmethods.\n","authors":["Sheng-Yu Wang","Aaron Hertzmann","Alexei A. Efros","Jun-Yan Zhu","Richard Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.09408v2.pdf","comment":"Updated v2 -- NeurIPS 2024 camera ready version. Project page:\n  https://peterwang512.github.io/AttributeByUnlearning Code:\n  https://github.com/PeterWang512/AttributeByUnlearning"},{"id":"http://arxiv.org/abs/2412.06777v1","updated":"2024-12-09T18:58:03Z","published":"2024-12-09T18:58:03Z","title":"Driv3R: Learning Dense 4D Reconstruction for Autonomous Driving","summary":"  Realtime 4D reconstruction for dynamic scenes remains a crucial challenge for\nautonomous driving perception. Most existing methods rely on depth estimation\nthrough self-supervision or multi-modality sensor fusion. In this paper, we\npropose Driv3R, a DUSt3R-based framework that directly regresses per-frame\npoint maps from multi-view image sequences. To achieve streaming dense\nreconstruction, we maintain a memory pool to reason both spatial relationships\nacross sensors and dynamic temporal contexts to enhance multi-view 3D\nconsistency and temporal integration. Furthermore, we employ a 4D flow\npredictor to identify moving objects within the scene to direct our network\nfocus more on reconstructing these dynamic regions. Finally, we align all\nper-frame pointmaps consistently to the world coordinate system in an\noptimization-free manner. We conduct extensive experiments on the large-scale\nnuScenes dataset to evaluate the effectiveness of our method. Driv3R\noutperforms previous frameworks in 4D dynamic scene reconstruction, achieving\n15x faster inference speed compared to methods requiring global alignment.\nCode: https://github.com/Barrybarry-Smith/Driv3R.\n","authors":["Xin Fei","Wenzhao Zheng","Yueqi Duan","Wei Zhan","Masayoshi Tomizuka","Kurt Keutzer","Jiwen Lu"],"pdf_url":"https://arxiv.org/pdf/2412.06777v1.pdf","comment":"Code is available at: https://github.com/Barrybarry-Smith/Driv3R"},{"id":"http://arxiv.org/abs/2412.04259v2","updated":"2024-12-09T18:57:27Z","published":"2024-12-05T15:39:13Z","title":"SCADE: Scalable Framework for Anomaly Detection in High-Performance\n  System","summary":"  As command-line interfaces remain integral to high-performance computing\nenvironments, the risk of exploitation through stealthy and complex\ncommand-line abuse grows. Conventional security solutions struggle to detect\nthese anomalies due to their context-specific nature, lack of labeled data, and\nthe prevalence of sophisticated attacks like Living-off-the-Land (LOL). To\naddress this gap, we introduce the Scalable Command-Line Anomaly Detection\nEngine (SCADE), a framework that combines global statistical models with local\ncontext-specific analysis for unsupervised anomaly detection. SCADE leverages\nnovel statistical methods, including BM25 and Log Entropy, alongside dynamic\nthresholding to adaptively detect rare, malicious command-line patterns in low\nsignal-to-noise ratio (SNR) environments. Experimental results show that SCADE\nachieves above 98% SNR in identifying anomalous behavior while minimizing false\npositives. Designed for scalability and precision, SCADE provides an\ninnovative, metadata-enriched approach to anomaly detection, offering a robust\nsolution for cybersecurity in high-computation environments. This work presents\nSCADE's architecture, detection methodology, and its potential for enhancing\nanomaly detection in enterprise systems. We argue that SCADE represents a\nsignificant advancement in unsupervised anomaly detection, offering a robust,\nadaptive framework for security analysts and researchers seeking to enhance\ndetection accuracy in high-computation environments.\n","authors":["Vaishali Vinay","Anjali Mangal"],"pdf_url":"https://arxiv.org/pdf/2412.04259v2.pdf","comment":"Updated title and abstract for broader scope. Submitted to ACM\n  CODASPY (The 15th ACM Conference on Data and Application Security and\n  Privacy) Conference"},{"id":"http://arxiv.org/abs/2412.06774v1","updated":"2024-12-09T18:57:24Z","published":"2024-12-09T18:57:24Z","title":"Visual Lexicon: Rich Image Features in Language Space","summary":"  We present Visual Lexicon, a novel visual language that encodes rich image\ninformation into the text space of vocabulary tokens while retaining intricate\nvisual details that are often challenging to convey in natural language. Unlike\ntraditional methods that prioritize either high-level semantics (e.g., CLIP) or\npixel-level reconstruction (e.g., VAE), ViLex simultaneously captures rich\nsemantic content and fine visual details, enabling high-quality image\ngeneration and comprehensive visual scene understanding. Through a\nself-supervised learning pipeline, ViLex generates tokens optimized for\nreconstructing input images using a frozen text-to-image (T2I) diffusion model,\npreserving the detailed information necessary for high-fidelity semantic-level\nreconstruction. As an image embedding in the language space, ViLex tokens\nleverage the compositionality of natural languages, allowing them to be used\nindependently as \"text tokens\" or combined with natural language tokens to\nprompt pretrained T2I models with both visual and textual inputs, mirroring how\nwe interact with vision-language models (VLMs). Experiments demonstrate that\nViLex achieves higher fidelity in image reconstruction compared to text\nembeddings--even with a single ViLex token. Moreover, ViLex successfully\nperforms various DreamBooth tasks in a zero-shot, unsupervised manner without\nfine-tuning T2I models. Additionally, ViLex serves as a powerful vision\nencoder, consistently improving vision-language model performance across 15\nbenchmarks relative to a strong SigLIP baseline.\n","authors":["XuDong Wang","Xingyi Zhou","Alireza Fathi","Trevor Darrell","Cordelia Schmid"],"pdf_url":"https://arxiv.org/pdf/2412.06774v1.pdf","comment":"Tech report. 16 pages, 10 figures"},{"id":"http://arxiv.org/abs/2412.06771v1","updated":"2024-12-09T18:56:32Z","published":"2024-12-09T18:56:32Z","title":"Proactive Agents for Multi-Turn Text-to-Image Generation Under\n  Uncertainty","summary":"  User prompts for generative AI models are often underspecified, leading to\nsub-optimal responses. This problem is particularly evident in text-to-image\n(T2I) generation, where users commonly struggle to articulate their precise\nintent. This disconnect between the user's vision and the model's\ninterpretation often forces users to painstakingly and repeatedly refine their\nprompts. To address this, we propose a design for proactive T2I agents equipped\nwith an interface to (1) actively ask clarification questions when uncertain,\nand (2) present their understanding of user intent as an understandable belief\ngraph that a user can edit. We build simple prototypes for such agents and\nverify their effectiveness through both human studies and automated evaluation.\nWe observed that at least 90% of human subjects found these agents and their\nbelief graphs helpful for their T2I workflow. Moreover, we develop a scalable\nautomated evaluation approach using two agents, one with a ground truth image\nand the other tries to ask as few questions as possible to align with the\nground truth. On DesignBench, a benchmark we created for artists and designers,\nthe COCO dataset (Lin et al., 2014), and ImageInWords (Garg et al., 2024), we\nobserved that these T2I agents were able to ask informative questions and\nelicit crucial information to achieve successful alignment with at least 2\ntimes higher VQAScore (Lin et al., 2024) than the standard single-turn T2I\ngeneration. Demo: https://github.com/google-deepmind/proactive_t2i_agents.\n","authors":["Meera Hahn","Wenjun Zeng","Nithish Kannen","Rich Galt","Kartikeya Badola","Been Kim","Zi Wang"],"pdf_url":"https://arxiv.org/pdf/2412.06771v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06748v1","updated":"2024-12-09T18:40:44Z","published":"2024-12-09T18:40:44Z","title":"Refusal Tokens: A Simple Way to Calibrate Refusals in Large Language\n  Models","summary":"  A key component of building safe and reliable language models is enabling the\nmodels to appropriately refuse to follow certain instructions or answer certain\nquestions. We may want models to output refusal messages for various categories\nof user queries, for example, ill-posed questions, instructions for committing\nillegal acts, or queries which require information past the model's knowledge\nhorizon. Engineering models that refuse to answer such questions is complicated\nby the fact that an individual may want their model to exhibit varying levels\nof sensitivity for refusing queries of various categories, and different users\nmay want different refusal rates. The current default approach involves\ntraining multiple models with varying proportions of refusal messages from each\ncategory to achieve the desired refusal rates, which is computationally\nexpensive and may require training a new model to accommodate each user's\ndesired preference over refusal rates. To address these challenges, we propose\nrefusal tokens, one such token for each refusal category or a single refusal\ntoken, which are prepended to the model's responses during training. We then\nshow how to increase or decrease the probability of generating the refusal\ntoken for each category during inference to steer the model's refusal behavior.\nRefusal tokens enable controlling a single model's refusal rates without the\nneed of any further fine-tuning, but only by selectively intervening during\ngeneration.\n","authors":["Neel Jain","Aditya Shrivastava","Chenyang Zhu","Daben Liu","Alfy Samuel","Ashwinee Panda","Anoop Kumar","Micah Goldblum","Tom Goldstein"],"pdf_url":"https://arxiv.org/pdf/2412.06748v1.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2403.19546v3","updated":"2024-12-09T18:37:55Z","published":"2024-03-28T16:27:26Z","title":"Croissant: A Metadata Format for ML-Ready Datasets","summary":"  Data is a critical resource for machine learning (ML), yet working with data\nremains a key friction point. This paper introduces Croissant, a metadata\nformat for datasets that creates a shared representation across ML tools,\nframeworks, and platforms. Croissant makes datasets more discoverable,\nportable, and interoperable, thereby addressing significant challenges in ML\ndata management. Croissant is already supported by several popular dataset\nrepositories, spanning hundreds of thousands of datasets, enabling easy loading\ninto the most commonly-used ML frameworks, regardless of where the data is\nstored. Our initial evaluation by human raters shows that Croissant metadata is\nreadable, understandable, complete, yet concise.\n","authors":["Mubashara Akhtar","Omar Benjelloun","Costanza Conforti","Luca Foschini","Joan Giner-Miguelez","Pieter Gijsbers","Sujata Goswami","Nitisha Jain","Michalis Karamousadakis","Michael Kuchnik","Satyapriya Krishna","Sylvain Lesage","Quentin Lhoest","Pierre Marcenac","Manil Maskey","Peter Mattson","Luis Oala","Hamidah Oderinwale","Pierre Ruyssen","Tim Santos","Rajat Shinde","Elena Simperl","Arjun Suresh","Goeffry Thomas","Slava Tykhonov","Joaquin Vanschoren","Susheel Varma","Jos van der Velde","Steffen Vogler","Carole-Jean Wu","Luyao Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.19546v3.pdf","comment":"Published at the NeurIPS 2024 Datasets and Benchmark Track. A shorter\n  version appeared earlier in Proceedings of ACM SIGMOD/PODS'24 Data Management\n  for End-to-End Machine Learning (DEEM) Workshop\n  https://dl.acm.org/doi/10.1145/3650203.3663326"},{"id":"http://arxiv.org/abs/2412.06745v1","updated":"2024-12-09T18:37:14Z","published":"2024-12-09T18:37:14Z","title":"ONEBench to Test Them All: Sample-Level Benchmarking Over Open-Ended\n  Capabilities","summary":"  Traditional fixed test sets fall short in evaluating open-ended capabilities\nof foundation models. To address this, we propose ONEBench(OpeN-Ended\nBenchmarking), a new testing paradigm that consolidates individual evaluation\ndatasets into a unified, ever-expanding sample pool. ONEBench allows users to\ngenerate custom, open-ended evaluation benchmarks from this pool, corresponding\nto specific capabilities of interest. By aggregating samples across test sets,\nONEBench enables the assessment of diverse capabilities beyond those covered by\nthe original test sets, while mitigating overfitting and dataset bias. Most\nimportantly, it frames model evaluation as a collective process of selecting\nand aggregating sample-level tests.\n  The shift from task-specific benchmarks to ONEBench introduces two\nchallenges: (1)heterogeneity and (2)incompleteness. Heterogeneity refers to the\naggregation over diverse metrics, while incompleteness describes comparing\nmodels evaluated on different data subsets. To address these challenges, we\nexplore algorithms to aggregate sparse measurements into reliable model scores.\nOur aggregation algorithm ensures identifiability(asymptotically recovering\nground-truth scores) and rapid convergence, enabling accurate model ranking\nwith less data. On homogenous datasets, we show our aggregation algorithm\nprovides rankings that highly correlate with those produced by average scores.\nWe also demonstrate robustness to ~95% of measurements missing, reducing\nevaluation cost by up to 20x with little-to-no change in model rankings. We\nintroduce ONEBench-LLM for language models and ONEBench-LMM for vision-language\nmodels, unifying evaluations across these domains. Overall, we present a\ntechnique for open-ended evaluation, which can aggregate over incomplete,\nheterogeneous sample-level measurements to continually grow a benchmark\nalongside the rapidly developing foundation models.\n","authors":["Adhiraj Ghosh","Sebastian Dziadzio","Ameya Prabhu","Vishaal Udandarao","Samuel Albanie","Matthias Bethge"],"pdf_url":"https://arxiv.org/pdf/2412.06745v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06740v1","updated":"2024-12-09T18:33:09Z","published":"2024-12-09T18:33:09Z","title":"Convolution goes higher-order: a biologically inspired mechanism\n  empowers image classification","summary":"  We propose a novel approach to image classification inspired by complex\nnonlinear biological visual processing, whereby classical convolutional neural\nnetworks (CNNs) are equipped with learnable higher-order convolutions. Our\nmodel incorporates a Volterra-like expansion of the convolution operator,\ncapturing multiplicative interactions akin to those observed in early and\nadvanced stages of biological visual processing. We evaluated this approach on\nsynthetic datasets by measuring sensitivity to testing higher-order\ncorrelations and performance in standard benchmarks (MNIST, FashionMNIST,\nCIFAR10, CIFAR100 and Imagenette). Our architecture outperforms traditional CNN\nbaselines, and achieves optimal performance with expansions up to 3rd/4th\norder, aligning remarkably well with the distribution of pixel intensities in\nnatural images. Through systematic perturbation analysis, we validate this\nalignment by isolating the contributions of specific image statistics to model\nperformance, demonstrating how different orders of convolution process distinct\naspects of visual information. Furthermore, Representational Similarity\nAnalysis reveals distinct geometries across network layers, indicating\nqualitatively different modes of visual information processing. Our work\nbridges neuroscience and deep learning, offering a path towards more effective,\nbiologically inspired computer vision models. It provides insights into visual\ninformation processing and lays the groundwork for neural networks that better\ncapture complex visual patterns, particularly in resource-constrained\nscenarios.\n","authors":["Simone Azeglio","Olivier Marre","Peter Neri","Ulisse Ferrari"],"pdf_url":"https://arxiv.org/pdf/2412.06740v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.11796v4","updated":"2024-12-09T18:31:01Z","published":"2024-08-21T17:38:48Z","title":"LLM Pruning and Distillation in Practice: The Minitron Approach","summary":"  We present a comprehensive report on compressing the Llama 3.1 8B and Mistral\nNeMo 12B models to 4B and 8B parameters, respectively, using pruning and\ndistillation. We explore two distinct pruning strategies: (1) depth pruning and\n(2) joint hidden/attention/MLP (width) pruning, and evaluate the results on\ncommon benchmarks from the LM Evaluation Harness. The models are then aligned\nwith NeMo Aligner and tested in instruct-tuned versions. This approach produces\na compelling 4B model from Llama 3.1 8B and a state-of-the-art\nMistral-NeMo-Minitron-8B (MN-Minitron-8B for brevity) model from Mistral NeMo\n12B. We found that with no access to the original data, it is beneficial to\nslightly fine-tune teacher models on the distillation dataset. We open-source\nour base model weights on Hugging Face with a permissive license.\n","authors":["Sharath Turuvekere Sreenivas","Saurav Muralidharan","Raviraj Joshi","Marcin Chochowski","Ameya Sunil Mahabaleshwarkar","Gerald Shen","Jiaqi Zeng","Zijia Chen","Yoshi Suhara","Shizhe Diao","Chenhan Yu","Wei-Chun Chen","Hayley Ross","Oluwatobi Olabiyi","Ashwath Aithal","Oleksii Kuchaiev","Daniel Korzekwa","Pavlo Molchanov","Mostofa Patwary","Mohammad Shoeybi","Jan Kautz","Bryan Catanzaro"],"pdf_url":"https://arxiv.org/pdf/2408.11796v4.pdf","comment":"v4: Update author order"},{"id":"http://arxiv.org/abs/2412.03782v2","updated":"2024-12-09T18:28:06Z","published":"2024-12-05T00:05:11Z","title":"The broader spectrum of in-context learning","summary":"  The ability of language models to learn a task from a few examples in context\nhas generated substantial interest. Here, we provide a perspective that\nsituates this type of supervised few-shot learning within a much broader\nspectrum of meta-learned in-context learning. Indeed, we suggest that any\ndistribution of sequences in which context non-trivially decreases loss on\nsubsequent predictions can be interpreted as eliciting a kind of in-context\nlearning. We suggest that this perspective helps to unify the broad set of\nin-context abilities that language models exhibit $\\unicode{x2014}$ such as\nadapting to tasks from instructions or role play, or extrapolating time series.\nThis perspective also sheds light on potential roots of in-context learning in\nlower-level processing of linguistic dependencies (e.g. coreference or parallel\nstructures). Finally, taking this perspective highlights the importance of\ngeneralization, which we suggest can be studied along several dimensions: not\nonly the ability to learn something novel, but also flexibility in learning\nfrom different presentations, and in applying what is learned. We discuss\nbroader connections to past literature in meta-learning and goal-conditioned\nagents, and other perspectives on learning and adaptation. We close by\nsuggesting that research on in-context learning should consider this broader\nspectrum of in-context capabilities and types of generalization.\n","authors":["Andrew Kyle Lampinen","Stephanie C. Y. Chan","Aaditya K. Singh","Murray Shanahan"],"pdf_url":"https://arxiv.org/pdf/2412.03782v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06717v1","updated":"2024-12-09T18:04:27Z","published":"2024-12-09T18:04:27Z","title":"Toward Non-Invasive Diagnosis of Bankart Lesions with Deep Learning","summary":"  Bankart lesions, or anterior-inferior glenoid labral tears, are\ndiagnostically challenging on standard MRIs due to their subtle imaging\nfeatures-often necessitating invasive MRI arthrograms (MRAs). This study\ndevelops deep learning (DL) models to detect Bankart lesions on both standard\nMRIs and MRAs, aiming to improve diagnostic accuracy and reduce reliance on\nMRAs. We curated a dataset of 586 shoulder MRIs (335 standard, 251 MRAs) from\n558 patients who underwent arthroscopy. Ground truth labels were derived from\nintraoperative findings, the gold standard for Bankart lesion diagnosis.\nSeparate DL models for MRAs and standard MRIs were trained using the Swin\nTransformer architecture, pre-trained on a public knee MRI dataset. Predictions\nfrom sagittal, axial, and coronal views were ensembled to optimize performance.\nThe models were evaluated on a 20% hold-out test set (117 MRIs: 46 MRAs, 71\nstandard MRIs). Bankart lesions were identified in 31.9% of MRAs and 8.6% of\nstandard MRIs. The models achieved AUCs of 0.87 (86% accuracy, 83% sensitivity,\n86% specificity) and 0.90 (85% accuracy, 82% sensitivity, 86% specificity) on\nstandard MRIs and MRAs, respectively. These results match or surpass\nradiologist performance on our dataset and reported literature metrics.\nNotably, our model's performance on non-invasive standard MRIs matched or\nsurpassed the radiologists interpreting MRAs. This study demonstrates the\nfeasibility of using DL to address the diagnostic challenges posed by subtle\npathologies like Bankart lesions. Our models demonstrate potential to improve\ndiagnostic confidence, reduce reliance on invasive imaging, and enhance\naccessibility to care.\n","authors":["Sahil Sethi","Sai Reddy","Mansi Sakarvadia","Jordan Serotte","Darlington Nwaudo","Nicholas Maassen","Lewis Shi"],"pdf_url":"https://arxiv.org/pdf/2412.06717v1.pdf","comment":"Accepted for presentation at SPIE Medical Imaging 2025:\n  Computer-Aided Diagnosis. The manuscript is expected to appear in the\n  conference proceedings"},{"id":"http://arxiv.org/abs/2412.06712v1","updated":"2024-12-09T18:01:13Z","published":"2024-12-09T18:01:13Z","title":"How to Merge Your Multimodal Models Over Time?","summary":"  Model merging combines multiple expert models - finetuned from a base\nfoundation model on diverse tasks and domains - into a single, more capable\nmodel. However, most existing model merging approaches assume that all experts\nare available simultaneously. In reality, new tasks and domains emerge\nprogressively over time, requiring strategies to integrate the knowledge of\nexpert models as they become available: a process we call temporal model\nmerging. The temporal dimension introduces unique challenges not addressed in\nprior work, raising new questions such as: when training for a new task, should\nthe expert model start from the merged past experts or from the original base\nmodel? Should we merge all models at each time step? Which merging techniques\nare best suited for temporal merging? Should different strategies be used to\ninitialize the training and deploy the model? To answer these questions, we\npropose a unified framework called TIME - Temporal Integration of Model\nExpertise - which defines temporal model merging across three axes: (1)\nInitialization Phase, (2) Deployment Phase, and (3) Merging Technique. Using\nTIME, we study temporal model merging across model sizes, compute budgets, and\nlearning horizons on the FoMo-in-Flux benchmark. Our comprehensive suite of\nexperiments across TIME allows us to uncover key insights for temporal model\nmerging, offering a better understanding of current challenges and best\npractices for effective temporal model merging.\n","authors":["Sebastian Dziadzio","Vishaal Udandarao","Karsten Roth","Ameya Prabhu","Zeynep Akata","Samuel Albanie","Matthias Bethge"],"pdf_url":"https://arxiv.org/pdf/2412.06712v1.pdf","comment":"Technical Report. Code at\n  https://github.com/ExplainableML/fomo_in_flux"},{"id":"http://arxiv.org/abs/2412.06711v1","updated":"2024-12-09T17:59:59Z","published":"2024-12-09T17:59:59Z","title":"MISFEAT: Feature Selection for Subgroups with Systematic Missing Data","summary":"  We investigate the problem of selecting features for datasets that can be\nnaturally partitioned into subgroups (e.g., according to socio-demographic\ngroups and age), each with its own dominant set of features. Within this\nsubgroup-oriented framework, we address the challenge of systematic missing\ndata, a scenario in which some feature values are missing for all tuples of a\nsubgroup, due to flawed data integration, regulatory constraints, or privacy\nconcerns. Feature selection is governed by finding mutual Information, a\npopular quantification of correlation, between features and a target variable.\nOur goal is to identify top-K feature subsets of some fixed size with the\nhighest joint mutual information with a target variable. In the presence of\nsystematic missing data, the closed form of mutual information could not simply\nbe applied. We argue that in such a setting, leveraging relationships between\navailable feature mutual information within a subgroup or across subgroups can\nassist inferring missing mutual information values. We propose a generalizable\nmodel based on heterogeneous graph neural network to identify interdependencies\nbetween feature-subgroup-target variable connections by modeling it as a\nmultiplex graph, and employing information propagation between its nodes. We\naddress two distinct scalability challenges related to training and propose\nprincipled solutions to tackle them. Through an extensive empirical evaluation,\nwe demonstrate the efficacy of the proposed solutions both qualitatively and\nrunning time wise.\n","authors":["Bar Genossar","Thinh On","Md. Mouinul Islam","Ben Eliav","Senjuti Basu Roy","Avigdor Gal"],"pdf_url":"https://arxiv.org/pdf/2412.06711v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.13674v2","updated":"2024-12-09T17:55:00Z","published":"2024-11-20T19:45:54Z","title":"FabuLight-ASD: Unveiling Speech Activity via Body Language","summary":"  Active speaker detection (ASD) in multimodal environments is crucial for\nvarious applications, from video conferencing to human-robot interaction. This\npaper introduces FabuLight-ASD, an advanced ASD model that integrates facial,\naudio, and body pose information to enhance detection accuracy and robustness.\nOur model builds upon the existing Light-ASD framework by incorporating human\npose data, represented through skeleton graphs, which minimises computational\noverhead. Using the Wilder Active Speaker Detection (WASD) dataset, renowned\nfor reliable face and body bounding box annotations, we demonstrate\nFabuLight-ASD's effectiveness in real-world scenarios. Achieving an overall\nmean average precision (mAP) of 94.3%, FabuLight-ASD outperforms Light-ASD,\nwhich has an overall mAP of 93.7% across various challenging scenarios. The\nincorporation of body pose information shows a particularly advantageous\nimpact, with notable improvements in mAP observed in scenarios with speech\nimpairment, face occlusion, and human voice background noise. Furthermore,\nefficiency analysis indicates only a modest increase in parameter count (27.3%)\nand multiply-accumulate operations (up to 2.4%), underscoring the model's\nefficiency and feasibility. These findings validate the efficacy of\nFabuLight-ASD in enhancing ASD performance through the integration of body pose\ndata. FabuLight-ASD's code and model weights are available at\nhttps://github.com/knowledgetechnologyuhh/FabuLight-ASD.\n","authors":["Hugo Carneiro","Stefan Wermter"],"pdf_url":"https://arxiv.org/pdf/2411.13674v2.pdf","comment":"23 pages, 8 figures, 3 tables, accepted for publication in Neural\n  Computing and Applications"},{"id":"http://arxiv.org/abs/2407.19389v3","updated":"2024-12-09T17:50:29Z","published":"2024-07-28T04:10:11Z","title":"FIARSE: Model-Heterogeneous Federated Learning via Importance-Aware\n  Submodel Extraction","summary":"  In federated learning (FL), accommodating clients' varied computational\ncapacities poses a challenge, often limiting the participation of those with\nconstrained resources in global model training. To address this issue, the\nconcept of model heterogeneity through submodel extraction has emerged,\noffering a tailored solution that aligns the model's complexity with each\nclient's computational capacity. In this work, we propose Federated\nImportance-Aware Submodel Extraction (FIARSE), a novel approach that\ndynamically adjusts submodels based on the importance of model parameters,\nthereby overcoming the limitations of previous static and dynamic submodel\nextraction methods. Compared to existing works, the proposed method offers a\ntheoretical foundation for the submodel extraction and eliminates the need for\nadditional information beyond the model parameters themselves to determine\nparameter importance, significantly reducing the overhead on clients. Extensive\nexperiments are conducted on various datasets to showcase the superior\nperformance of the proposed FIARSE.\n","authors":["Feijie Wu","Xingchen Wang","Yaqing Wang","Tianci Liu","Lu Su","Jing Gao"],"pdf_url":"https://arxiv.org/pdf/2407.19389v3.pdf","comment":"This paper has been accepted by NeurIPS 2024. In this updated\n  version, we have corrected the typos"},{"id":"http://arxiv.org/abs/2412.06693v1","updated":"2024-12-09T17:39:43Z","published":"2024-12-09T17:39:43Z","title":"OmniEvalKit: A Modular, Lightweight Toolbox for Evaluating Large\n  Language Model and its Omni-Extensions","summary":"  The rapid advancements in Large Language Models (LLMs) have significantly\nexpanded their applications, ranging from multilingual support to\ndomain-specific tasks and multimodal integration. In this paper, we present\nOmniEvalKit, a novel benchmarking toolbox designed to evaluate LLMs and their\nomni-extensions across multilingual, multidomain, and multimodal capabilities.\nUnlike existing benchmarks that often focus on a single aspect, OmniEvalKit\nprovides a modular, lightweight, and automated evaluation system. It is\nstructured with a modular architecture comprising a Static Builder and Dynamic\nData Flow, promoting the seamless integration of new models and datasets.\nOmniEvalKit supports over 100 LLMs and 50 evaluation datasets, covering\ncomprehensive evaluations across thousands of model-dataset combinations.\nOmniEvalKit is dedicated to creating an ultra-lightweight and fast-deployable\nevaluation framework, making downstream applications more convenient and\nversatile for the AI community.\n","authors":["Yi-Kai Zhang","Xu-Xiang Zhong","Shiyin Lu","Qing-Guo Chen","De-Chuan Zhan","Han-Jia Ye"],"pdf_url":"https://arxiv.org/pdf/2412.06693v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06689v1","updated":"2024-12-09T17:31:55Z","published":"2024-12-09T17:31:55Z","title":"Impact of Privacy Parameters on Deep Learning Models for Image\n  Classification","summary":"  The project aims to develop differentially private deep learning models for\nimage classification on CIFAR-10 datasets \\cite{cifar10} and analyze the impact\nof various privacy parameters on model accuracy. We have implemented five\ndifferent deep learning models, namely ConvNet, ResNet18, EfficientNet, ViT,\nand DenseNet121 and three supervised classifiers namely K-Nearest Neighbors,\nNaive Bayes Classifier and Support Vector Machine. We evaluated the performance\nof these models under varying settings. Our best performing model to date is\nEfficientNet with test accuracy of $59.63\\%$ with the following parameters\n(Adam optimizer, batch size 256, epoch size 100, epsilon value 5.0, learning\nrate $1e-3$, clipping threshold 1.0, and noise multiplier 0.912).\n","authors":["Basanta Chaulagain"],"pdf_url":"https://arxiv.org/pdf/2412.06689v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2412.06686v1","updated":"2024-12-09T17:28:29Z","published":"2024-12-09T17:28:29Z","title":"Some Best Practices in Operator Learning","summary":"  Hyperparameters searches are computationally expensive. This paper studies\nsome general choices of hyperparameters and training methods specifically for\noperator learning. It considers the architectures DeepONets, Fourier neural\noperators and Koopman autoencoders for several differential equations to find\nrobust trends. Some options considered are activation functions, dropout and\nstochastic weight averaging.\n","authors":["Dustin Enyeart","Guang Lin"],"pdf_url":"https://arxiv.org/pdf/2412.06686v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2412.04578"},{"id":"http://arxiv.org/abs/2411.18562v2","updated":"2024-12-09T17:28:07Z","published":"2024-11-27T18:03:26Z","title":"DexDiffuser: Interaction-aware Diffusion Planning for Adaptive Dexterous\n  Manipulation","summary":"  Dexterous manipulation with contact-rich interactions is crucial for advanced\nrobotics. While recent diffusion-based planning approaches show promise for\nsimpler manipulation tasks, they often produce unrealistic ghost states (e.g.,\nthe object automatically moves without hand contact) or lack adaptability when\nhandling complex sequential interactions. In this work, we introduce\nDexDiffuser, an interaction-aware diffusion planning framework for adaptive\ndexterous manipulation. DexDiffuser models joint state-action dynamics through\na dual-phase diffusion process which consists of pre-interaction contact\nalignment and post-contact goal-directed control, enabling goal-adaptive\ngeneralizable dexterous manipulation. Additionally, we incorporate dynamics\nmodel-based dual guidance and leverage large language models for automated\nguidance function generation, enhancing generalizability for physical\ninteractions and facilitating diverse goal adaptation through language cues.\nExperiments on physical interaction tasks such as door opening, pen and block\nre-orientation, and hammer striking demonstrate DexDiffuser's effectiveness on\ngoals outside training distributions, achieving over twice the average success\nrate (59.2% vs. 29.5%) compared to existing methods. Our framework achieves\n70.0% success on 30-degree door opening, 40.0% and 36.7% on pen and block\nhalf-side re-orientation respectively, and 46.7% on hammer nail half drive,\nhighlighting its robustness and flexibility in contact-rich manipulation.\n","authors":["Zhixuan Liang","Yao Mu","Yixiao Wang","Tianxing Chen","Wenqi Shao","Wei Zhan","Masayoshi Tomizuka","Ping Luo","Mingyu Ding"],"pdf_url":"https://arxiv.org/pdf/2411.18562v2.pdf","comment":"27 pages (with new appendix). Project page:\n  https://dexdiffuser.github.io/"},{"id":"http://arxiv.org/abs/2412.06685v1","updated":"2024-12-09T17:28:03Z","published":"2024-12-09T17:28:03Z","title":"Policy Agnostic RL: Offline RL and Online RL Fine-Tuning of Any Class\n  and Backbone","summary":"  Recent advances in learning decision-making policies can largely be\nattributed to training expressive policy models, largely via imitation\nlearning. While imitation learning discards non-expert data, reinforcement\nlearning (RL) can still learn from suboptimal data. However, instantiating RL\ntraining of a new policy class often presents a different challenge: most deep\nRL machinery is co-developed with assumptions on the policy class and backbone,\nresulting in poor performance when the policy class changes. For instance, SAC\nutilizes a low-variance reparameterization policy gradient for Gaussian\npolicies, but this is unstable for diffusion policies and intractable for\nautoregressive categorical policies. To address this issue, we develop an\noffline RL and online fine-tuning approach called policy-agnostic RL (PA-RL)\nthat can effectively train multiple policy classes, with varying architectures\nand sizes. We build off the basic idea that a universal supervised learning\nloss can replace the policy improvement step in RL, as long as it is applied on\n\"optimized\" actions. To obtain these optimized actions, we first sample\nmultiple actions from a base policy, and run global optimization (i.e.,\nre-ranking multiple action samples using the Q-function) and local optimization\n(i.e., running gradient steps on an action sample) to maximize the critic on\nthese candidates. PA-RL enables fine-tuning diffusion and transformer policies\nwith either autoregressive tokens or continuous action outputs, at different\nsizes, entirely via actor-critic RL. Moreover, PA-RL improves the performance\nand sample-efficiency by up to 2 times compared to existing offline RL and\nonline fine-tuning methods. We show the first result that successfully\nfine-tunes OpenVLA, a 7B generalist robot policy, autonomously with Cal-QL, an\nonline RL fine-tuning algorithm, improving from 40% to 70% in the real world in\n40 minutes.\n","authors":["Max Sobol Mark","Tian Gao","Georgia Gabriela Sampaio","Mohan Kumar Srirama","Archit Sharma","Chelsea Finn","Aviral Kumar"],"pdf_url":"https://arxiv.org/pdf/2412.06685v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06684v1","updated":"2024-12-09T17:27:04Z","published":"2024-12-09T17:27:04Z","title":"Exploring Critical Testing Scenarios for Decision-Making Policies: An\n  LLM Approach","summary":"  Recent years have witnessed surprising achievements of decision-making\npolicies across various fields, such as autonomous driving and robotics.\nTesting for decision-making policies is crucial with the existence of critical\nscenarios that may threaten their reliability. Numerous research efforts have\nbeen dedicated to testing these policies. However, there are still significant\nchallenges, such as low testing efficiency and diversity due to the complexity\nof the policies and environments under test. Inspired by the remarkable\ncapabilities of large language models (LLMs), in this paper, we propose an\nLLM-driven online testing framework for efficiently testing decision-making\npolicies. The main idea is to employ an LLM-based test scenario generator to\nintelligently generate challenging test cases through contemplation and\nreasoning. Specifically, we first design a \"generate-test-feedback\" pipeline\nand apply templated prompt engineering to fully leverage the knowledge and\nreasoning abilities of LLMs. Then, we introduce a multi-scale scenario\ngeneration strategy to address the inherent challenges LLMs face in making fine\nadjustments, further enhancing testing efficiency. Finally, we evaluate the\nLLM-driven approach on five widely used benchmarks. The experimental results\ndemonstrate that our method significantly outperforms baseline approaches in\nuncovering both critical and diverse scenarios.\n","authors":["Weichao Xu","Huaxin Pei","Jingxuan Yang","Yuchen Shi","Yi Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.06684v1.pdf","comment":"16 pages, 13 figures"},{"id":"http://arxiv.org/abs/2412.06676v1","updated":"2024-12-09T17:13:20Z","published":"2024-12-09T17:13:20Z","title":"I Don't Know: Explicit Modeling of Uncertainty with an [IDK] Token","summary":"  Large Language Models are known to capture real-world knowledge, allowing\nthem to excel in many downstream tasks. Despite recent advances, these models\nare still prone to what are commonly known as hallucinations, causing them to\nemit unwanted and factually incorrect text. In this work, we propose a novel\ncalibration method that can be used to combat hallucinations. We add a special\n[IDK] (\"I don't know\") token to the model's vocabulary and introduce an\nobjective function that shifts probability mass to the [IDK] token for\nincorrect predictions. This approach allows the model to express uncertainty in\nits output explicitly. We evaluate our proposed method across multiple model\narchitectures and factual downstream tasks. We find that models trained with\nour method are able to express uncertainty in places where they would\npreviously make mistakes while suffering only a small loss of encoded\nknowledge. We further perform extensive ablation studies of multiple variations\nof our approach and provide a detailed analysis of the precision-recall\ntradeoff of our method.\n","authors":["Roi Cohen","Konstantin Dobler","Eden Biran","Gerard de Melo"],"pdf_url":"https://arxiv.org/pdf/2412.06676v1.pdf","comment":"Published at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.15543v2","updated":"2024-12-09T17:12:13Z","published":"2024-10-21T00:00:31Z","title":"Distributed Thompson sampling under constrained communication","summary":"  In Bayesian optimization, a black-box function is maximized via the use of a\nsurrogate model. We apply distributed Thompson sampling, using a Gaussian\nprocess as a surrogate model, to approach the multi-agent Bayesian optimization\nproblem. In our distributed Thompson sampling implementation, each agent\nreceives sampled points from neighbors, where the communication network is\nencoded in a graph; each agent utilizes their own Gaussian process to model the\nobjective function. We demonstrate theoretical bounds on Bayesian simple regret\nand Bayesian average regret, where the bound depends on the structure of the\ncommunication graph. Unlike in batch Bayesian optimization, this bound is\napplicable in cases where the communication graph amongst agents is\nconstrained. When compared to sequential single-agent Thompson sampling, our\nbound guarantees faster convergence with respect to time as long as the\ncommunication graph is connected. We confirm the efficacy of our algorithm with\nnumerical simulations on traditional optimization test functions, illustrating\nthe significance of graph connectivity on improving regret convergence.\n","authors":["Saba Zerefa","Zhaolin Ren","Haitong Ma","Na Li"],"pdf_url":"https://arxiv.org/pdf/2410.15543v2.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2405.12207v2","updated":"2024-12-09T17:08:38Z","published":"2024-05-20T17:47:18Z","title":"Optimistic Query Routing in Clustering-based Approximate Maximum Inner\n  Product Search","summary":"  Clustering-based nearest neighbor search is an effective method in which\npoints are partitioned into geometric shards to form an index, with only a few\nshards searched during query processing to find a set of top-$k$ vectors. Even\nthough the search efficacy is heavily influenced by the algorithm that\nidentifies the shards to probe, it has received little attention in the\nliterature. This work bridges that gap by studying routing in clustering-based\nmaximum inner product search. We unpack existing routers and notice the\nsurprising contribution of optimism. We then take a page from the sequential\ndecision making literature and formalize that insight following the principle\nof ``optimism in the face of uncertainty.'' In particular, we present a\nframework that incorporates the moments of the distribution of inner products\nwithin each shard to estimate the maximum inner product. We then present an\ninstance of our algorithm that uses only the first two moments to reach the\nsame accuracy as state-of-the-art routers such as ScaNN by probing up to $50\\%$\nfewer points on benchmark datasets. Our algorithm is also space-efficient: we\ndesign a sketch of the second moment whose size is independent of the number of\npoints and requires $\\mathcal{O}(1)$ vectors per shard.\n","authors":["Sebastian Bruch","Aditya Krishnan","Franco Maria Nardini"],"pdf_url":"https://arxiv.org/pdf/2405.12207v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.01423v3","updated":"2024-12-09T16:59:29Z","published":"2023-06-02T10:29:33Z","title":"Break a Lag: Triple Exponential Moving Average for Enhanced Optimization","summary":"  The performance of deep learning models is critically dependent on\nsophisticated optimization strategies. While existing optimizers have shown\npromising results, many rely on first-order Exponential Moving Average (EMA)\ntechniques, which often limit their ability to track complex gradient trends\naccurately. This fact can lead to a significant lag in trend identification and\nsuboptimal optimization, particularly in highly dynamic gradient behavior. To\naddress this fundamental limitation, we introduce Fast Adaptive Moment\nEstimation (FAME), a novel optimization technique that leverages the power of\nTriple Exponential Moving Average. By incorporating an advanced tracking\nmechanism, FAME enhances responsiveness to data dynamics, mitigates trend\nidentification lag, and optimizes learning efficiency. Our comprehensive\nevaluation encompasses different computer vision tasks including image\nclassification, object detection, and semantic segmentation, integrating FAME\ninto 30 distinct architectures ranging from lightweight CNNs to Vision\nTransformers. Through rigorous benchmarking against state-of-the-art\noptimizers, FAME demonstrates superior accuracy and robustness. Notably, it\noffers high scalability, delivering substantial improvements across diverse\nmodel complexities, architectures, tasks, and benchmarks.\n","authors":["Roi Peleg","Yair Smadar","Teddy Lazebnik","Assaf Hoogi"],"pdf_url":"https://arxiv.org/pdf/2306.01423v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06655v1","updated":"2024-12-09T16:56:06Z","published":"2024-12-09T16:56:06Z","title":"Off-Policy Maximum Entropy RL with Future State and Action Visitation\n  Measures","summary":"  We introduce a new maximum entropy reinforcement learning framework based on\nthe distribution of states and actions visited by a policy. More precisely, an\nintrinsic reward function is added to the reward function of the Markov\ndecision process that shall be controlled. For each state and action, this\nintrinsic reward is the relative entropy of the discounted distribution of\nstates and actions (or features from these states and actions) visited during\nthe next time steps. We first prove that an optimal exploration policy, which\nmaximizes the expected discounted sum of intrinsic rewards, is also a policy\nthat maximizes a lower bound on the state-action value function of the decision\nprocess under some assumptions. We also prove that the visitation distribution\nused in the intrinsic reward definition is the fixed point of a contraction\noperator. Following, we describe how to adapt existing algorithms to learn this\nfixed point and compute the intrinsic rewards to enhance exploration. A new\npractical off-policy maximum entropy reinforcement learning algorithm is\nfinally introduced. Empirically, exploration policies have good state-action\nspace coverage, and high-performing control policies are computed efficiently.\n","authors":["Adrien Bolland","Gaspard Lambrechts","Damien Ernst"],"pdf_url":"https://arxiv.org/pdf/2412.06655v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.15138v2","updated":"2024-12-09T16:53:42Z","published":"2024-08-27T15:23:09Z","title":"How transformers learn structured data: insights from hierarchical\n  filtering","summary":"  Understanding the learning process and the embedded computation in\ntransformers is becoming a central goal for the development of interpretable\nAI. In the present study, we introduce a hierarchical filtering procedure for\ngenerative models of sequences on trees, allowing us to hand-tune the range of\npositional correlations in the data. Leveraging this controlled setting, we\nprovide evidence that vanilla encoder-only transformers can approximate the\nexact inference algorithm when trained on root classification and masked\nlanguage modeling tasks, and study how this computation is discovered and\nimplemented. We find that correlations at larger distances, corresponding to\nincreasing layers of the hierarchy, are sequentially included by the network\nduring training. Moreover, by comparing attention maps from models trained with\nvarying degrees of filtering and by probing the different encoder levels, we\nfind clear evidence of a reconstruction of correlations on successive length\nscales corresponding to the various levels of the hierarchy, which we relate to\na plausible implementation of the exact inference algorithm within the same\narchitecture.\n","authors":["Jerome Garnier-Brun","Marc Mézard","Emanuele Moscato","Luca Saglietti"],"pdf_url":"https://arxiv.org/pdf/2408.15138v2.pdf","comment":"21 pages, 15 figures"},{"id":"http://arxiv.org/abs/2412.06649v1","updated":"2024-12-09T16:43:23Z","published":"2024-12-09T16:43:23Z","title":"Semantic Search and Recommendation Algorithm","summary":"  This paper introduces a new semantic search algorithm that uses Word2Vec and\nAnnoy Index to improve the efficiency of information retrieval from large\ndatasets. The proposed approach addresses the limitations of traditional search\nmethods by offering enhanced speed, accuracy, and scalability. Testing on\ndatasets up to 100GB demonstrates the method's effectiveness in processing vast\namounts of data while maintaining high precision and performance.\n","authors":["Aryan Duhan","Aryan Singhal","Shourya Sharma"," Neeraj","Arti MK"],"pdf_url":"https://arxiv.org/pdf/2412.06649v1.pdf","comment":"6 pages, 5 Figures"},{"id":"http://arxiv.org/abs/2403.16851v2","updated":"2024-12-09T16:42:25Z","published":"2024-03-25T15:15:09Z","title":"Can tweets predict article retractions? A comparison between human and\n  LLM labelling","summary":"  Quickly detecting problematic research articles is crucial to safeguarding\nthe integrity of scientific research. This study explores whether Twitter\nmentions of retracted articles can signal potential problems with the articles\nprior to their retraction, potentially serving as an early warning system for\nscholars. To investigate this, we analysed a dataset of 4,354 Twitter mentions\nassociated with 504 retracted articles. The effectiveness of Twitter mentions\nin predicting article retractions was evaluated by both manual and Large\nLanguage Model (LLM) labelling. Manual labelling results indicated that 25.7%\nof tweets signalled problems before retraction. Using the manual labelling\nresults as the baseline, we found that LLMs (GPT-4o-mini, Gemini 1.5 Flash, and\nClaude-3.5-Haiku) outperformed lexicon-based sentiment analysis tools (e.g.,\nTextBlob) in detecting potential problems, suggesting that automatic detection\nof problematic articles from social media using LLMs is technically feasible.\nNevertheless, since only a small proportion of retracted articles (11.1%) were\ncriticised on Twitter prior to retraction, such automatic systems would detect\nonly a minority of problematic articles. Overall, this study offers insights\ninto how social media data, coupled with emerging generative AI techniques, can\nsupport research integrity.\n","authors":["Er-Te Zheng","Hui-Zhen Fu","Mike Thelwall","Zhichao Fang"],"pdf_url":"https://arxiv.org/pdf/2403.16851v2.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2402.15883v4","updated":"2024-12-09T16:41:37Z","published":"2024-02-24T19:06:41Z","title":"Extraction Propagation","summary":"  Running backpropagation end to end on large neural networks is fraught with\ndifficulties like vanishing gradients and degradation. In this paper we present\nan alternative architecture composed of many small neural networks that\ninteract with one another. Instead of propagating gradients back through the\narchitecture we propagate vector-valued messages computed via forward passes,\nwhich are then used to update the parameters. Currently the performance is\nconjectured as we are yet to implement the architecture. However, we do back it\nup with some theory. A previous version of this paper was entitled \"Fusion\nencoder networks\" and detailed a slightly different architecture.\n","authors":["Stephen Pasteris","Chris Hicks","Vasilios Mavroudis"],"pdf_url":"https://arxiv.org/pdf/2402.15883v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06646v1","updated":"2024-12-09T16:39:40Z","published":"2024-12-09T16:39:40Z","title":"The Narrow Gate: Localized Image-Text Communication in Vision-Language\n  Models","summary":"  Recent advances in multimodal training have significantly improved the\nintegration of image understanding and generation within a unified model. This\nstudy investigates how vision-language models (VLMs) handle image-understanding\ntasks, specifically focusing on how visual information is processed and\ntransferred to the textual domain. We compare VLMs that generate both images\nand text with those that output only text, highlighting key differences in\ninformation flow. We find that in models with multimodal outputs, image and\ntext embeddings are more separated within the residual stream. Additionally,\nmodels vary in how information is exchanged from visual to textual tokens. VLMs\nthat only output text exhibit a distributed communication pattern, where\ninformation is exchanged through multiple image tokens. In contrast, models\ntrained for image and text generation rely on a single token that acts as a\nnarrow gate for the visual information. We demonstrate that ablating this\nsingle token significantly deteriorates performance on image understanding\ntasks. Furthermore, modifying this token enables effective steering of the\nimage semantics, showing that targeted, local interventions can reliably\ncontrol the model's global behavior.\n","authors":["Alessandro Serra","Francesco Ortu","Emanuele Panizon","Lucrezia Valeriani","Lorenzo Basile","Alessio Ansuini","Diego Doimo","Alberto Cazzaniga"],"pdf_url":"https://arxiv.org/pdf/2412.06646v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17890v2","updated":"2024-12-09T16:37:12Z","published":"2024-06-25T18:58:39Z","title":"SigKAN: Signature-Weighted Kolmogorov-Arnold Networks for Time Series","summary":"  We propose a novel approach that enhances multivariate function approximation\nusing learnable path signatures and Kolmogorov-Arnold networks (KANs). We\nenhance the learning capabilities of these networks by weighting the values\nobtained by KANs using learnable path signatures, which capture important\ngeometric features of paths. This combination allows for a more comprehensive\nand flexible representation of sequential and temporal data. We demonstrate\nthrough studies that our SigKANs with learnable path signatures perform better\nthan conventional methods across a range of function approximation challenges.\nBy leveraging path signatures in neural networks, this method offers intriguing\nopportunities to enhance performance in time series analysis and time series\nforecasting, among other fields.\n","authors":["Hugo Inzirillo","Remi Genet"],"pdf_url":"https://arxiv.org/pdf/2406.17890v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2405.07344,\n  arXiv:2406.02486"},{"id":"http://arxiv.org/abs/2411.04105v3","updated":"2024-12-09T16:36:34Z","published":"2024-11-06T18:35:32Z","title":"How Transformers Solve Propositional Logic Problems: A Mechanistic\n  Analysis","summary":"  Large language models (LLMs) have shown amazing performance on tasks that\nrequire planning and reasoning. Motivated by this, we investigate the internal\nmechanisms that underpin a network's ability to perform complex logical\nreasoning. We first construct a synthetic propositional logic problem that\nserves as a concrete test-bed for network training and evaluation. Crucially,\nthis problem demands nontrivial planning to solve. We perform our study on two\nfronts. First, we pursue an understanding of precisely how a three-layer\ntransformer, trained from scratch and attains perfect test accuracy, solves\nthis problem. We are able to identify certain \"planning\" and \"reasoning\"\nmechanisms in the network that necessitate cooperation between the attention\nblocks to implement the desired logic. Second, we study how pretrained LLMs,\nnamely Mistral-7B and Gemma-2-9B, solve this problem. We characterize their\nreasoning circuits through causal intervention experiments, providing necessity\nand sufficiency evidence for the circuits. We find evidence suggesting that the\ntwo models' latent reasoning strategies are surprisingly similar, and\nhuman-like. Overall, our work systemically uncovers novel aspects of small and\nlarge transformers, and continues the study of how they plan and reason.\n","authors":["Guan Zhe Hong","Nishanth Dikkala","Enming Luo","Cyrus Rashtchian","Xin Wang","Rina Panigrahy"],"pdf_url":"https://arxiv.org/pdf/2411.04105v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06639v1","updated":"2024-12-09T16:33:28Z","published":"2024-12-09T16:33:28Z","title":"Beyond Scalars: Concept-Based Alignment Analysis in Vision Transformers","summary":"  Vision transformers (ViTs) can be trained using various learning paradigms,\nfrom fully supervised to self-supervised. Diverse training protocols often\nresult in significantly different feature spaces, which are usually compared\nthrough alignment analysis. However, current alignment measures quantify this\nrelationship in terms of a single scalar value, obscuring the distinctions\nbetween common and unique features in pairs of representations that share the\nsame scalar alignment. We address this limitation by combining alignment\nanalysis with concept discovery, which enables a breakdown of alignment into\nsingle concepts encoded in feature space. This fine-grained comparison reveals\nboth universal and unique concepts across different representations, as well as\nthe internal structure of concepts within each of them. Our methodological\ncontributions address two key prerequisites for concept-based alignment: 1) For\na description of the representation in terms of concepts that faithfully\ncapture the geometry of the feature space, we define concepts as the most\ngeneral structure they can possibly form - arbitrary manifolds, allowing hidden\nfeatures to be described by their proximity to these manifolds. 2) To measure\ndistances between concept proximity scores of two representations, we use a\ngeneralized Rand index and partition it for alignment between pairs of\nconcepts. We confirm the superiority of our novel concept definition for\nalignment analysis over existing linear baselines in a sanity check. The\nconcept-based alignment analysis of representations from four different ViTs\nreveals that increased supervision correlates with a reduction in the semantic\nstructure of learned representations.\n","authors":["Johanna Vielhaben","Dilyara Bareeva","Jim Berend","Wojciech Samek","Nils Strodthoff"],"pdf_url":"https://arxiv.org/pdf/2412.06639v1.pdf","comment":"19 pages, 17 figures, code: https://github.com/jvielhaben/NLMCD-ALIGN"},{"id":"http://arxiv.org/abs/2412.06629v1","updated":"2024-12-09T16:20:01Z","published":"2024-12-09T16:20:01Z","title":"PolytopeWalk: Sparse MCMC Sampling over Polytopes","summary":"  High dimensional sampling is an important computational tool in statistics\nand other computational disciplines, with applications ranging from Bayesian\nstatistical uncertainty quantification, metabolic modeling in systems biology\nto volume computation. We present $\\textsf{PolytopeWalk}$, a new scalable\nPython library designed for uniform sampling over polytopes. The library\nprovides an end-to-end solution, which includes preprocessing algorithms such\nas facial reduction and initialization methods. Six state-of-the-art MCMC\nalgorithms on polytopes are implemented, including the Dikin, Vaidya, and John\nWalk. Additionally, we introduce novel sparse constrained formulations of these\nalgorithms, enabling efficient sampling from sparse polytopes of the form $K_2\n= \\{x \\in \\mathbb{R}^d \\ | \\ Ax = b, x \\succeq_k 0\\}$. This implementation\nmaintains sparsity in $A$, ensuring scalability to high dimensional settings\n$(d > 10^5)$. We demonstrate the improved sampling efficiency and per-iteration\ncost on both Netlib datasets and structured polytopes. $\\textsf{PolytopeWalk}$\nis available at github.com/ethz-randomwalk/polytopewalk with documentation at\npolytopewalk.readthedocs.io .\n","authors":["Benny Sun","Yuansi Chen"],"pdf_url":"https://arxiv.org/pdf/2412.06629v1.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2412.06619v1","updated":"2024-12-09T16:13:17Z","published":"2024-12-09T16:13:17Z","title":"Copyright-Protected Language Generation via Adaptive Model Fusion","summary":"  The risk of language models reproducing copyrighted material from their\ntraining data has led to the development of various protective measures. Among\nthese, inference-time strategies that impose constraints via post-processing\nhave shown promise in addressing the complexities of copyright regulation.\nHowever, they often incur prohibitive computational costs or suffer from\nperformance trade-offs. To overcome these limitations, we introduce\nCopyright-Protecting Model Fusion (CP-Fuse), a novel approach that combines\nmodels trained on disjoint sets of copyrighted material during inference. In\nparticular, CP-Fuse adaptively aggregates the model outputs to minimize the\nreproduction of copyrighted content, adhering to a crucial balancing property\nthat prevents the regurgitation of memorized data. Through extensive\nexperiments, we show that CP-Fuse significantly reduces the reproduction of\nprotected material without compromising the quality of text and code\ngeneration. Moreover, its post-hoc nature allows seamless integration with\nother protective measures, further enhancing copyright safeguards. Lastly, we\nshow that CP-Fuse is robust against common techniques for extracting training\ndata.\n","authors":["Javier Abad","Konstantin Donhauser","Francesco Pinto","Fanny Yang"],"pdf_url":"https://arxiv.org/pdf/2412.06619v1.pdf","comment":"47 pages, 21 Figures. arXiv admin note: substantial text overlap with\n  arXiv:2407.20105"},{"id":"http://arxiv.org/abs/2412.06617v1","updated":"2024-12-09T16:09:44Z","published":"2024-12-09T16:09:44Z","title":"AI TrackMate: Finally, Someone Who Will Give Your Music More Than Just\n  \"Sounds Great!\"","summary":"  The rise of \"bedroom producers\" has democratized music creation, while\nchallenging producers to objectively evaluate their work. To address this, we\npresent AI TrackMate, an LLM-based music chatbot designed to provide\nconstructive feedback on music productions. By combining LLMs' inherent musical\nknowledge with direct audio track analysis, AI TrackMate offers\nproduction-specific insights, distinguishing it from text-only approaches. Our\nframework integrates a Music Analysis Module, an LLM-Readable Music Report, and\nMusic Production-Oriented Feedback Instruction, creating a plug-and-play,\ntraining-free system compatible with various LLMs and adaptable to future\nadvancements. We demonstrate AI TrackMate's capabilities through an interactive\nweb interface and present findings from a pilot study with a music producer. By\nbridging AI capabilities with the needs of independent producers, AI TrackMate\noffers on-demand analytical feedback, potentially supporting the creative\nprocess and skill development in music production. This system addresses the\ngrowing demand for objective self-assessment tools in the evolving landscape of\nindependent music production.\n","authors":["Yi-Lin Jiang","Chia-Ho Hsiung","Yen-Tung Yeh","Lu-Rong Chen","Bo-Yu Chen"],"pdf_url":"https://arxiv.org/pdf/2412.06617v1.pdf","comment":"Accepted for the NeurIPS 2024 Creative AI Track"},{"id":"http://arxiv.org/abs/2412.04455v2","updated":"2024-12-09T16:07:24Z","published":"2024-12-05T18:58:27Z","title":"Code-as-Monitor: Constraint-aware Visual Programming for Reactive and\n  Proactive Robotic Failure Detection","summary":"  Automatic detection and prevention of open-set failures are crucial in\nclosed-loop robotic systems. Recent studies often struggle to simultaneously\nidentify unexpected failures reactively after they occur and prevent\nforeseeable ones proactively. To this end, we propose Code-as-Monitor (CaM), a\nnovel paradigm leveraging the vision-language model (VLM) for both open-set\nreactive and proactive failure detection. The core of our method is to\nformulate both tasks as a unified set of spatio-temporal constraint\nsatisfaction problems and use VLM-generated code to evaluate them for real-time\nmonitoring. To enhance the accuracy and efficiency of monitoring, we further\nintroduce constraint elements that abstract constraint-related entities or\ntheir parts into compact geometric elements. This approach offers greater\ngenerality, simplifies tracking, and facilitates constraint-aware visual\nprogramming by leveraging these elements as visual prompts. Experiments show\nthat CaM achieves a 28.7% higher success rate and reduces execution time by\n31.8% under severe disturbances compared to baselines across three simulators\nand a real-world setting. Moreover, CaM can be integrated with open-loop\ncontrol policies to form closed-loop systems, enabling long-horizon tasks in\ncluttered scenes with dynamic environments.\n","authors":["Enshen Zhou","Qi Su","Cheng Chi","Zhizheng Zhang","Zhongyuan Wang","Tiejun Huang","Lu Sheng","He Wang"],"pdf_url":"https://arxiv.org/pdf/2412.04455v2.pdf","comment":"Project page: https://zhoues.github.io/Code-as-Monitor/"},{"id":"http://arxiv.org/abs/2412.05270v2","updated":"2024-12-09T16:01:00Z","published":"2024-12-06T18:55:34Z","title":"APOLLO: SGD-like Memory, AdamW-level Performance","summary":"  Large language models (LLMs) are notoriously memory-intensive during\ntraining, particularly with the popular AdamW optimizer. This memory burden\nnecessitates using more or higher-end GPUs or reducing batch sizes, limiting\ntraining scalability and throughput. To address this, various memory-efficient\noptimizers have been proposed to reduce optimizer memory usage. However, they\nface critical challenges: (i) reliance on costly SVD operations; (ii)\nsignificant performance trade-offs compared to AdamW; and (iii) still\nsubstantial optimizer memory overhead to maintain competitive performance.\n  In this work, we identify that AdamW's learning rate adaptation rule can be\neffectively coarsened as a structured learning rate update. Based on this\ninsight, we propose Approximated Gradient Scaling for Memory-Efficient LLM\nOptimization (APOLLO), which approximates learning rate scaling using an\nauxiliary low-rank optimizer state based on pure random projection. This\nstructured learning rate update rule makes APOLLO highly tolerant to further\nmemory reductions while delivering comparable pre-training performance. Even\nits rank-1 variant, APOLLO-Mini, achieves superior pre-training performance\ncompared to AdamW with SGD-level memory costs.\n  Extensive experiments demonstrate that the APOLLO series performs on-par with\nor better than AdamW, while achieving greater memory savings by nearly\neliminating the optimization states of AdamW. These savings provide significant\nsystem-level benefits: (1) Enhanced Throughput: 3x throughput on an 8xA100-80GB\nsetup compared to AdamW by supporting 4x larger batch sizes. (2) Improved Model\nScalability: Pre-training LLaMA-13B with naive DDP on A100-80GB GPUs without\nsystem-level optimizations. (3) Low-End GPU Friendly Pre-training: Pre-training\nLLaMA-7B on a single GPU using less than 12 GB of memory with weight\nquantization.\n","authors":["Hanqing Zhu","Zhenyu Zhang","Wenyan Cong","Xi Liu","Sem Park","Vikas Chandra","Bo Long","David Z. Pan","Zhangyang Wang","Jinwon Lee"],"pdf_url":"https://arxiv.org/pdf/2412.05270v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2406.02534v2","updated":"2024-12-09T15:58:55Z","published":"2024-06-04T17:54:44Z","title":"Enhancing predictive imaging biomarker discovery through treatment\n  effect analysis","summary":"  Identifying predictive covariates, which forecast individual treatment\neffectiveness, is crucial for decision-making across different disciplines such\nas personalized medicine. These covariates, referred to as biomarkers, are\nextracted from pre-treatment data, often within randomized controlled trials,\nand should be distinguished from prognostic biomarkers, which are independent\nof treatment assignment. Our study focuses on discovering predictive imaging\nbiomarkers, specific image features, by leveraging pre-treatment images to\nuncover new causal relationships. Unlike labor-intensive approaches relying on\nhandcrafted features prone to bias, we present a novel task of directly\nlearning predictive features from images. We propose an evaluation protocol to\nassess a model's ability to identify predictive imaging biomarkers and\ndifferentiate them from purely prognostic ones by employing statistical testing\nand a comprehensive analysis of image feature attribution. We explore the\nsuitability of deep learning models originally developed for estimating the\nconditional average treatment effect (CATE) for this task, which have been\nassessed primarily for their precision of CATE estimation while overlooking the\nevaluation of imaging biomarker discovery. Our proof-of-concept analysis\ndemonstrates the feasibility and potential of our approach in discovering and\nvalidating predictive imaging biomarkers from synthetic outcomes and real-world\nimage datasets. Our code is available at\n\\url{https://github.com/MIC-DKFZ/predictive_image_biomarker_analysis}.\n","authors":["Shuhan Xiao","Lukas Klein","Jens Petersen","Philipp Vollmuth","Paul F. Jaeger","Klaus H. Maier-Hein"],"pdf_url":"https://arxiv.org/pdf/2406.02534v2.pdf","comment":"Accepted to WACV 2025"},{"id":"http://arxiv.org/abs/2412.02779v2","updated":"2024-12-09T15:56:08Z","published":"2024-12-03T19:20:08Z","title":"Synergistic Development of Perovskite Memristors and Algorithms for\n  Robust Analog Computing","summary":"  Analog computing using non-volatile memristors has emerged as a promising\nsolution for energy-efficient deep learning. New materials, like\nperovskites-based memristors are recently attractive due to their\ncost-effectiveness, energy efficiency and flexibility. Yet, challenges in\nmaterial diversity and immature fabrications require extensive experimentation\nfor device development. Moreover, significant non-idealities in these\nmemristors often impede them for computing. Here, we propose a synergistic\nmethodology to concurrently optimize perovskite memristor fabrication and\ndevelop robust analog DNNs that effectively address the inherent non-idealities\nof these memristors. Employing Bayesian optimization (BO) with a focus on\nusability, we efficiently identify optimal materials and fabrication conditions\nfor perovskite memristors. Meanwhile, we developed \"BayesMulti\", a DNN training\nstrategy utilizing BO-guided noise injection to improve the resistance of\nanalog DNNs to memristor imperfections. Our approach theoretically ensures that\nwithin a certain range of parameter perturbations due to memristor\nnon-idealities, the prediction outcomes remain consistent. Our integrated\napproach enables use of analog computing in much deeper and wider networks,\nwhich significantly outperforms existing methods in diverse tasks like image\nclassification, autonomous driving, species identification, and large\nvision-language models, achieving up to 100-fold improvements. We further\nvalidate our methodology on a 10$\\times$10 optimized perovskite memristor\ncrossbar, demonstrating high accuracy in a classification task and low energy\nconsumption. This study offers a versatile solution for efficient optimization\nof various analog computing systems, encompassing both devices and algorithms.\n","authors":["Nanyang Ye","Qiao Sun","Yifei Wang","Liujia Yang","Jundong Zhou","Lei Wang","Guang-Zhong Yang","Xinbing Wang","Chenghu Zhou","Wei Ren","Leilei Gu","Huaqiang Wu","Qinying Gu"],"pdf_url":"https://arxiv.org/pdf/2412.02779v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06606v1","updated":"2024-12-09T15:55:20Z","published":"2024-12-09T15:55:20Z","title":"Vulnerability of Text-Matching in ML/AI Conference Reviewer Assignments\n  to Collusions","summary":"  In the peer review process of top-tier machine learning (ML) and artificial\nintelligence (AI) conferences, reviewers are assigned to papers through\nautomated methods. These assignment algorithms consider two main factors: (1)\nreviewers' expressed interests indicated by their bids for papers, and (2)\nreviewers' domain expertise inferred from the similarity between the text of\ntheir previously published papers and the submitted manuscripts. A significant\nchallenge these conferences face is the existence of collusion rings, where\ngroups of researchers manipulate the assignment process to review each other's\npapers, providing positive evaluations regardless of their actual quality. Most\nefforts to combat collusion rings have focused on preventing bid manipulation,\nunder the assumption that the text similarity component is secure. In this\npaper, we demonstrate that even in the absence of bidding, colluding reviewers\nand authors can exploit the machine learning based text-matching component of\nreviewer assignment used at top ML/AI venues to get assigned their target\npaper. We also highlight specific vulnerabilities within this system and offer\nsuggestions to enhance its robustness.\n","authors":[" Jhih-Yi"," Hsieh","Aditi Raghunathan","Nihar B. Shah"],"pdf_url":"https://arxiv.org/pdf/2412.06606v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06604v1","updated":"2024-12-09T15:53:02Z","published":"2024-12-09T15:53:02Z","title":"VOPy: A Framework for Black-box Vector Optimization","summary":"  We introduce VOPy, an open-source Python library designed to address\nblack-box vector optimization, where multiple objectives must be optimized\nsimultaneously with respect to a partial order induced by a convex cone. VOPy\nextends beyond traditional multi-objective optimization (MOO) tools by enabling\nflexible, cone-based ordering of solutions; with an application scope that\nincludes environments with observation noise, discrete or continuous design\nspaces, limited budgets, and batch observations. VOPy provides a modular\narchitecture, facilitating the integration of existing methods and the\ndevelopment of novel algorithms. We detail VOPy's architecture, usage, and\npotential to advance research and application in the field of vector\noptimization. The source code for VOPy is available at\nhttps://github.com/Bilkent-CYBORG/VOPy.\n","authors":["Yaşar Cahit Yıldırım","Efe Mert Karagözlü","İlter Onat Korkmaz","Çağın Ararat","Cem Tekin"],"pdf_url":"https://arxiv.org/pdf/2412.06604v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.08623v3","updated":"2024-12-09T15:50:49Z","published":"2024-07-11T16:00:22Z","title":"Surpassing Cosine Similarity for Multidimensional Comparisons: Dimension\n  Insensitive Euclidean Metric (DIEM)","summary":"  Advancements in computational power and hardware efficiency have enabled the\ntackling of increasingly complex and high-dimensional problems. While\nartificial intelligence (AI) achieved remarkable results, the interpretability\nof high-dimensional solutions remains challenging. A critical issue is the\ncomparison of multidimensional quantities, which is essential in techniques\nlike Principal Component Analysis (PCA), or k-means clustering. Common metrics\nsuch as cosine similarity, Euclidean distance, and Manhattan distance are often\nused for such comparisons - for example in muscular synergies of the human\nmotor control system. However, their applicability and interpretability\ndiminish as dimensionality increases. This paper provides a comprehensive\nanalysis of the effects of dimensionality on these metrics. Our results reveal\nsignificant limitations of cosine similarity, particularly its dependency on\nthe dimensionality of the vectors, leading to biased and poorly interpretable\noutcomes. To address this, we introduce the Dimension Insensitive Euclidean\nMetric (DIEM) which demonstrates superior robustness and generalizability\nacross dimensions. DIEM maintains consistent variability and eliminates the\nbiases observed in traditional metrics, making it a reliable tool for\nhigh-dimensional comparisons. This novel metric has the potential to replace\ncosine similarity, providing a more accurate and insightful method to analyze\nmultidimensional data in fields ranging from neuromotor control to machine and\ndeep learning.\n","authors":["Federico Tessari","Kunpeng Yao","Neville Hogan"],"pdf_url":"https://arxiv.org/pdf/2407.08623v3.pdf","comment":"13 pages, 17 figures"},{"id":"http://arxiv.org/abs/2412.06602v1","updated":"2024-12-09T15:50:25Z","published":"2024-12-09T15:50:25Z","title":"Towards Controllable Speech Synthesis in the Era of Large Language\n  Models: A Survey","summary":"  Text-to-speech (TTS), also known as speech synthesis, is a prominent research\narea that aims to generate natural-sounding human speech from text. Recently,\nwith the increasing industrial demand, TTS technologies have evolved beyond\nsynthesizing human-like speech to enabling controllable speech generation. This\nincludes fine-grained control over various attributes of synthesized speech\nsuch as emotion, prosody, timbre, and duration. Besides, advancements in deep\nlearning, such as diffusion and large language models, have significantly\nenhanced controllable TTS over the past several years. In this paper, we\nconduct a comprehensive survey of controllable TTS, covering approaches ranging\nfrom basic control techniques to methods utilizing natural language prompts,\naiming to provide a clear understanding of the current state of research. We\nexamine the general controllable TTS pipeline, challenges, model architectures,\nand control strategies, offering a comprehensive and clear taxonomy of existing\nmethods. Additionally, we provide a detailed summary of datasets and evaluation\nmetrics and shed some light on the applications and future directions of\ncontrollable TTS. To the best of our knowledge, this survey paper provides the\nfirst comprehensive review of emerging controllable TTS methods, which can\nserve as a beneficial resource for both academic researchers and industry\npractitioners.\n","authors":["Tianxin Xie","Yan Rong","Pengfei Zhang","Li Liu"],"pdf_url":"https://arxiv.org/pdf/2412.06602v1.pdf","comment":"A comprehensive survey on controllable TTS, 23 pages, 6 tables, 4\n  figures, 280 references"},{"id":"http://arxiv.org/abs/2412.06597v1","updated":"2024-12-09T15:47:36Z","published":"2024-12-09T15:47:36Z","title":"Self-Interested Agents in Collaborative Learning: An Incentivized\n  Adaptive Data-Centric Framework","summary":"  We propose a framework for adaptive data-centric collaborative learning among\nself-interested agents, coordinated by an arbiter. Designed to handle the\nincremental nature of real-world data, the framework operates in an online\nmanner: at each step, the arbiter collects a batch of data from agents, trains\na machine learning model, and provides each agent with a distinct model\nreflecting its data contributions. This setup establishes a feedback loop where\nshared data influence model updates, and the resulting models guide future\ndata-sharing strategies. Agents evaluate and partition their data, selecting a\npartition to share using a stochastic parameterized policy optimized via policy\ngradient methods to optimize the utility of the received model as defined by\nagent-specific evaluation functions. On the arbiter side, the expected loss\nfunction over the true data distribution is optimized, incorporating\nagent-specific weights to account for distributional differences arising from\ndiverse sources and selective sharing. A bilevel optimization algorithm jointly\nlearns the model parameters and agent-specific weights. Mean-zero noise,\ncomputed using a distortion function that adjusts these agent-specific weights,\nis introduced to generate distinct agent-specific models, promoting valuable\ndata sharing without requiring separate training. Our framework is underpinned\nby non-asymptotic analyses, ensuring convergence of the agent-side policy\noptimization to an approximate stationary point of the evaluation functions and\nconvergence of the arbiter-side optimization to an approximate stationary point\nof the expected loss function.\n","authors":["Nithia Vijayan","Bryan Kian Hsiang Low"],"pdf_url":"https://arxiv.org/pdf/2412.06597v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.18693v2","updated":"2024-12-09T15:39:01Z","published":"2024-07-26T12:17:57Z","title":"Deep learning for predicting the occurrence of tipping points","summary":"  Tipping points occur in many real-world systems, at which the system shifts\nsuddenly from one state to another. The ability to predict the occurrence of\ntipping points from time series data remains an outstanding challenge and a\nmajor interest in a broad range of research fields. Particularly, the widely\nused methods based on bifurcation theory are neither reliable in prediction\naccuracy nor applicable for irregularly-sampled time series which are commonly\nobserved from real-world systems. Here we address this challenge by developing\na deep learning algorithm for predicting the occurrence of tipping points in\nuntrained systems, by exploiting information about normal forms. Our algorithm\nnot only outperforms traditional methods for regularly-sampled model time\nseries but also achieves accurate predictions for irregularly-sampled model\ntime series and empirical time series. Our ability to predict tipping points\nfor complex systems paves the way for mitigation risks, prevention of\ncatastrophic failures, and restoration of degraded systems, with broad\napplications in social science, engineering, and biology.\n","authors":["Chengzuo Zhuge","Jiawei Li","Wei Chen"],"pdf_url":"https://arxiv.org/pdf/2407.18693v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00150v2","updated":"2024-12-09T15:28:13Z","published":"2024-09-30T18:47:26Z","title":"What If We Had Used a Different App? Reliable Counterfactual KPI\n  Analysis in Wireless Systems","summary":"  In modern wireless network architectures, such as Open Radio Access Network\n(O-RAN), the operation of the radio access network (RAN) is managed by\napplications, or apps for short, deployed at intelligent controllers. These\napps are selected from a given catalog based on current contextual information.\nFor instance, a scheduling app may be selected on the basis of current traffic\nand network conditions. Once an app is chosen and run, it is no longer possible\nto directly test the key performance indicators (KPIs) that would have been\nobtained with another app. In other words, we can never simultaneously observe\nboth the actual KPI, obtained by the selected app, and the counterfactual KPI,\nwhich would have been attained with another app, for the same network\ncondition, making individual-level counterfactual KPIs analysis particularly\nchallenging. This what-if analysis, however, would be valuable to monitor and\noptimize the network operation, e.g., to identify suboptimal app selection\nstrategies. This paper addresses the problem of estimating the values of KPIs\nthat would have been obtained if a different app had been implemented by the\nRAN. To this end, we propose a conformal-prediction-based counterfactual\nanalysis method for wireless systems that provides reliable error bars for the\nestimated KPIs, despite the inherent covariate shift between logged and test\ndata. Experimental results for medium access control-layer apps and for\nphysical-layer apps demonstrate the merits of the proposed method.\n","authors":["Qiushuo Hou","Sangwoo Park","Matteo Zecchin","Yunlong Cai","Guanding Yu","Osvaldo Simeone"],"pdf_url":"https://arxiv.org/pdf/2410.00150v2.pdf","comment":"This paper has been submitted to a journal"},{"id":"http://arxiv.org/abs/2408.06067v2","updated":"2024-12-09T15:27:50Z","published":"2024-08-12T11:39:21Z","title":"Neural Network Surrogate and Projected Gradient Descent for Fast and\n  Reliable Finite Element Model Calibration: a Case Study on an Intervertebral\n  Disc","summary":"  Accurate calibration of finite element (FE) models is essential across\nvarious biomechanical applications, including human intervertebral discs\n(IVDs), to ensure their reliability and use in diagnosing and planning\ntreatments. However, traditional calibration methods are computationally\nintensive, requiring iterative, derivative-free optimization algorithms that\noften take days to converge. This study addresses these challenges by\nintroducing a novel, efficient, and effective calibration method demonstrated\non a human L4-L5 IVD FE model as a case study using a neural network (NN)\nsurrogate. The NN surrogate predicts simulation outcomes with high accuracy,\noutperforming other machine learning models, and significantly reduces the\ncomputational cost associated with traditional FE simulations. Next, a\nProjected Gradient Descent (PGD) approach guided by gradients of the NN\nsurrogate is proposed to efficiently calibrate FE models. Our method explicitly\nenforces feasibility with a projection step, thus maintaining material bounds\nthroughout the optimization process. The proposed method is evaluated against\nSOTA Genetic Algorithm and inverse model baselines on synthetic and in vitro\nexperimental datasets. Our approach demonstrates superior performance on\nsynthetic data, achieving an MAE of 0.06 compared to the baselines' MAE of 0.18\nand 0.54, respectively. On experimental specimens, our method outperforms the\nbaseline in 5 out of 6 cases. While our approach requires initial dataset\ngeneration and surrogate training, these steps are performed only once, and the\nactual calibration takes under three seconds. In contrast, traditional\ncalibration time scales linearly with the number of specimens, taking up to 8\ndays in the worst-case. Such efficiency paves the way for applying more complex\nFE models, potentially extending beyond IVDs, and enabling accurate\npatient-specific simulations.\n","authors":["Matan Atad","Gabriel Gruber","Marx Ribeiro","Luis Fernando Nicolini","Robert Graf","Hendrik Möller","Kati Nispel","Ivan Ezhov","Daniel Rueckert","Jan S. Kirschke"],"pdf_url":"https://arxiv.org/pdf/2408.06067v2.pdf","comment":"In review. Project code: https://github.com/matanat/IVD-CalibNN/"},{"id":"http://arxiv.org/abs/2410.10578v6","updated":"2024-12-09T15:26:00Z","published":"2024-10-14T14:52:23Z","title":"Burning RED: Unlocking Subtask-Driven Reinforcement Learning and\n  Risk-Awareness in Average-Reward Markov Decision Processes","summary":"  Average-reward Markov decision processes (MDPs) provide a foundational\nframework for sequential decision-making under uncertainty. However,\naverage-reward MDPs have remained largely unexplored in reinforcement learning\n(RL) settings, with the majority of RL-based efforts having been allocated to\nepisodic and discounted MDPs. In this work, we study a unique structural\nproperty of average-reward MDPs and utilize it to introduce Reward-Extended\nDifferential (or RED) reinforcement learning: a novel RL framework that can be\nused to effectively and efficiently solve various subtasks simultaneously in\nthe average-reward setting. We introduce a family of RED learning algorithms\nfor prediction and control, including proven-convergent algorithms for the\ntabular case. We then showcase the power of these algorithms by demonstrating\nhow they can be used to learn a policy that optimizes, for the first time, the\nwell-known conditional value-at-risk (CVaR) risk measure in a fully-online\nmanner, without the use of an explicit bi-level optimization scheme or an\naugmented state-space.\n","authors":["Juan Sebastian Rojas","Chi-Guhn Lee"],"pdf_url":"https://arxiv.org/pdf/2410.10578v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06568v1","updated":"2024-12-09T15:24:11Z","published":"2024-12-09T15:24:11Z","title":"CONDEN-FI: Consistency and Diversity Learning-based Multi-View\n  Unsupervised Feature and In-stance Co-Selection","summary":"  The objective of multi-view unsupervised feature and instance co-selection is\nto simultaneously iden-tify the most representative features and samples from\nmulti-view unlabeled data, which aids in mit-igating the curse of\ndimensionality and reducing instance size to improve the performance of\ndown-stream tasks. However, existing methods treat feature selection and\ninstance selection as two separate processes, failing to leverage the potential\ninteractions between the feature and instance spaces. Addi-tionally, previous\nco-selection methods for multi-view data require concatenating different views,\nwhich overlooks the consistent information among them. In this paper, we\npropose a CONsistency and DivErsity learNing-based multi-view unsupervised\nFeature and Instance co-selection (CONDEN-FI) to address the above-mentioned\nissues. Specifically, CONDEN-FI reconstructs mul-ti-view data from both the\nsample and feature spaces to learn representations that are consistent across\nviews and specific to each view, enabling the simultaneous selection of the\nmost important features and instances. Moreover, CONDEN-FI adaptively learns a\nview-consensus similarity graph to help select both dissimilar and similar\nsamples in the reconstructed data space, leading to a more diverse selection of\ninstances. An efficient algorithm is developed to solve the resultant\noptimization problem, and the comprehensive experimental results on real-world\ndatasets demonstrate that CONDEN-FI is effective compared to state-of-the-art\nmethods.\n","authors":["Yanyong Huang","Yuxin Cai","Dongjie Wang","Xiuwen Yi","Tianrui Li"],"pdf_url":"https://arxiv.org/pdf/2412.06568v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06566v1","updated":"2024-12-09T15:18:04Z","published":"2024-12-09T15:18:04Z","title":"DEX: Data Channel Extension for Efficient CNN Inference on Tiny AI\n  Accelerators","summary":"  Tiny machine learning (TinyML) aims to run ML models on small devices and is\nincreasingly favored for its enhanced privacy, reduced latency, and low cost.\nRecently, the advent of tiny AI accelerators has revolutionized the TinyML\nfield by significantly enhancing hardware processing power. These accelerators,\nequipped with multiple parallel processors and dedicated per-processor memory\ninstances, offer substantial performance improvements over traditional\nmicrocontroller units (MCUs). However, their limited data memory often\nnecessitates downsampling input images, resulting in accuracy degradation. To\naddress this challenge, we propose Data channel EXtension (DEX), a novel\napproach for efficient CNN execution on tiny AI accelerators. DEX incorporates\nadditional spatial information from original images into input images through\npatch-wise even sampling and channel-wise stacking, effectively extending data\nacross input channels. By leveraging underutilized processors and data memory\nfor channel extension, DEX facilitates parallel execution without increasing\ninference latency. Our evaluation with four models and four datasets on tiny AI\naccelerators demonstrates that this simple idea improves accuracy on average by\n3.5%p while keeping the inference latency the same on the AI accelerator. The\nsource code is available at\nhttps://github.com/Nokia-Bell-Labs/data-channel-extension.\n","authors":["Taesik Gong","Fahim Kawsar","Chulhong Min"],"pdf_url":"https://arxiv.org/pdf/2412.06566v1.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2412.00789v2","updated":"2024-12-09T15:14:03Z","published":"2024-12-01T12:23:25Z","title":"A Cognac shot to forget bad memories: Corrective Unlearning in GNNs","summary":"  Graph Neural Networks (GNNs) are increasingly being used for a variety of ML\napplications on graph data. Because graph data does not follow the\nindependently and identically distributed (i.i.d.) assumption, adversarial\nmanipulations or incorrect data can propagate to other data points through\nmessage passing, which deteriorates the model's performance. To allow model\ndevelopers to remove the adverse effects of manipulated entities from a trained\nGNN, we study the recently formulated problem of Corrective Unlearning. We find\nthat current graph unlearning methods fail to unlearn the effect of\nmanipulations even when the whole manipulated set is known. We introduce a new\ngraph unlearning method, Cognac, which can unlearn the effect of the\nmanipulation set even when only 5% of it is identified. It recovers most of the\nperformance of a strong oracle with fully corrected training data, even beating\nretraining from scratch without the deletion set while being 8x more efficient.\nWe hope our work assists GNN developers in mitigating harmful effects caused by\nissues in real-world data post-training. Our code is publicly available at\nhttps://github.com/varshitakolipaka/corrective-unlearning-for-gnns\n","authors":["Varshita Kolipaka","Akshit Sinha","Debangan Mishra","Sumit Kumar","Arvindh Arun","Shashwat Goel","Ponnurangam Kumaraguru"],"pdf_url":"https://arxiv.org/pdf/2412.00789v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06559v1","updated":"2024-12-09T15:11:40Z","published":"2024-12-09T15:11:40Z","title":"ProcessBench: Identifying Process Errors in Mathematical Reasoning","summary":"  As language models regularly make mistakes when solving math problems,\nautomated identification of errors in the reasoning process becomes\nincreasingly significant for their scalable oversight. In this paper, we\nintroduce ProcessBench for measuring the ability to identify erroneous steps in\nmathematical reasoning. It consists of 3,400 test cases, primarily focused on\ncompetition- and Olympiad-level math problems. Each test case contains a\nstep-by-step solution with error location annotated by human experts. Models\nare required to identify the earliest step that contains an error, or conclude\nthat all steps are correct. We conduct extensive evaluation on ProcessBench,\ninvolving two types of models: process reward models (PRMs) and critic models,\nwhere for the latter we prompt general language models to critique each\nsolution step by step. We draw two main observations: (1) Existing PRMs\ntypically fail to generalize to more challenging math problems beyond GSM8K and\nMATH. They underperform both critic models (i.e., prompted general language\nmodels) and our own trained PRM that is straightforwardly fine-tuned on the\nPRM800K dataset. (2) The best open-source model, QwQ-32B-Preview, has\ndemonstrated the critique capability competitive with the proprietary model\nGPT-4o, despite that it still lags behind the reasoning-specialized o1-mini. We\nhope ProcessBench can foster future research in reasoning process assessment,\npaving the way toward scalable oversight of language models.\n","authors":["Chujie Zheng","Zhenru Zhang","Beichen Zhang","Runji Lin","Keming Lu","Bowen Yu","Dayiheng Liu","Jingren Zhou","Junyang Lin"],"pdf_url":"https://arxiv.org/pdf/2412.06559v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.17365v2","updated":"2024-12-09T15:10:19Z","published":"2024-04-26T12:30:32Z","title":"Similarity Equivariant Graph Neural Networks for Homogenization of\n  Metamaterials","summary":"  Soft, porous mechanical metamaterials exhibit pattern transformations that\nmay have important applications in soft robotics, sound reduction and\nbiomedicine. To design these innovative materials, it is important to be able\nto simulate them accurately and quickly, in order to tune their mechanical\nproperties. Since conventional simulations using the finite element method\nentail a high computational cost, in this article we aim to develop a machine\nlearning-based approach that scales favorably to serve as a surrogate model. To\nensure that the model is also able to handle various microstructures, including\nthose not encountered during training, we include the microstructure as part of\nthe network input. Therefore, we introduce a graph neural network that predicts\nglobal quantities (energy, stress stiffness) as well as the pattern\ntransformations that occur (the kinematics). To make our model as accurate and\ndata-efficient as possible, various symmetries are incorporated into the model.\nThe starting point is an E(n)-equivariant graph neural network (which respects\ntranslation, rotation and reflection) that has periodic boundary conditions\n(i.e., it is in-/equivariant with respect to the choice of RVE), is scale\nin-/equivariant, can simulate large deformations, and can predict scalars,\nvectors as well as second and fourth order tensors (specifically energy, stress\nand stiffness). The incorporation of scale equivariance makes the model\nequivariant with respect to the similarities group, of which the Euclidean\ngroup E(n) is a subgroup. We show that this network is more accurate and\ndata-efficient than graph neural networks with fewer symmetries. To create an\nefficient graph representation of the finite element discretization, we use\nonly the internal geometrical hole boundaries from the finite element mesh to\nachieve a better speed-up and scaling with the mesh size.\n","authors":["Fleur Hendriks","Vlado Menkovski","Martin Doškář","Marc G. D. Geers","Ondřej Rokoš"],"pdf_url":"https://arxiv.org/pdf/2404.17365v2.pdf","comment":"60 pages, 22 figures. Submitted to CMAME (Computer Methods in Applied\n  Mechanics and Engineering)"},{"id":"http://arxiv.org/abs/2409.14599v3","updated":"2024-12-09T15:06:46Z","published":"2024-09-22T21:22:35Z","title":"Implicit Dynamical Flow Fusion (IDFF) for Generative Modeling","summary":"  Conditional Flow Matching (CFM) models can generate high-quality samples from\na non-informative prior, but they can be slow, often needing hundreds of\nnetwork evaluations (NFE). To address this, we propose Implicit Dynamical Flow\nFusion (IDFF); IDFF learns a new vector field with an additional momentum term\nthat enables taking longer steps during sample generation while maintaining the\nfidelity of the generated distribution. Consequently, IDFFs reduce the NFEs by\na factor of ten (relative to CFMs) without sacrificing sample quality, enabling\nrapid sampling and efficient handling of image and time-series data generation\ntasks. We evaluate IDFF on standard benchmarks such as CIFAR-10 and CelebA for\nimage generation, where we achieve likelihood and quality performance\ncomparable to CFMs and diffusion-based models with fewer NFEs. IDFF also shows\nsuperior performance on time-series datasets modeling, including molecular\nsimulation and sea surface temperature (SST) datasets, highlighting its\nversatility and effectiveness across different\ndomains.\\href{https://github.com/MrRezaeiUofT/IDFF}{Github Repository}\n","authors":["Mohammad R. Rezaei","Rahul G. Krishnan","Milos R. Popovic","Milad Lankarany"],"pdf_url":"https://arxiv.org/pdf/2409.14599v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06555v1","updated":"2024-12-09T15:03:22Z","published":"2024-12-09T15:03:22Z","title":"When Dimensionality Reduction Meets Graph (Drawing) Theory: Introducing\n  a Common Framework, Challenges and Opportunities","summary":"  In the vast landscape of visualization research, Dimensionality Reduction\n(DR) and graph analysis are two popular subfields, often essential to most\nvisual data analytics setups. DR aims to create representations to support\nneighborhood and similarity analysis on complex, large datasets. Graph analysis\nfocuses on identifying the salient topological properties and key actors within\nnetworked data, with specialized research on investigating how such features\ncould be presented to the user to ease the comprehension of the underlying\nstructure. Although these two disciplines are typically regarded as disjoint\nsubfields, we argue that both fields share strong similarities and synergies\nthat can potentially benefit both. Therefore, this paper discusses and\nintroduces a unifying framework to help bridge the gap between DR and graph\n(drawing) theory. Our goal is to use the strongly math-grounded graph theory to\nimprove the overall process of creating DR visual representations. We propose\nhow to break the DR process into well-defined stages, discussing how to match\nsome of the DR state-of-the-art techniques to this framework and presenting\nideas on how graph drawing, topology features, and some popular algorithms and\nstrategies used in graph analysis can be employed to improve DR topology\nextraction, embedding generation, and result validation. We also discuss the\nchallenges and identify opportunities for implementing and using our framework,\nopening directions for future visualization research.\n","authors":["Fernando Paulovich","Alessio Arleo","Stef van den Elzen"],"pdf_url":"https://arxiv.org/pdf/2412.06555v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06549v1","updated":"2024-12-09T14:59:27Z","published":"2024-12-09T14:59:27Z","title":"Prediction of Occluded Pedestrians in Road Scenes using Human-like\n  Reasoning: Insights from the OccluRoads Dataset","summary":"  Pedestrian detection is a critical task in autonomous driving, aimed at\nenhancing safety and reducing risks on the road. Over recent years, significant\nadvancements have been made in improving detection performance. However, these\nachievements still fall short of human perception, particularly in cases\ninvolving occluded pedestrians, especially entirely invisible ones. In this\nwork, we present the Occlusion-Rich Road Scenes with Pedestrians (OccluRoads)\ndataset, which features a diverse collection of road scenes with partially and\nfully occluded pedestrians in both real and virtual environments. All scenes\nare meticulously labeled and enriched with contextual information that\nencapsulates human perception in such scenarios. Using this dataset, we\ndeveloped a pipeline to predict the presence of occluded pedestrians,\nleveraging Knowledge Graph (KG), Knowledge Graph Embedding (KGE), and a\nBayesian inference process. Our approach achieves a F1 score of 0.91,\nrepresenting an improvement of up to 42% compared to traditional machine\nlearning models.\n","authors":["Melo Castillo Angie Nataly","Martin Serrano Sergio","Salinas Carlota","Sotelo Miguel Angel"],"pdf_url":"https://arxiv.org/pdf/2412.06549v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06545v1","updated":"2024-12-09T14:56:23Z","published":"2024-12-09T14:56:23Z","title":"On How Iterative Magnitude Pruning Discovers Local Receptive Fields in\n  Fully Connected Neural Networks","summary":"  Since its use in the Lottery Ticket Hypothesis, iterative magnitude pruning\n(IMP) has become a popular method for extracting sparse subnetworks that can be\ntrained to high performance. Despite this, the underlying nature of IMP's\ngeneral success remains unclear. One possibility is that IMP is especially\ncapable of extracting and maintaining strong inductive biases. In support of\nthis, recent work has shown that applying IMP to fully connected neural\nnetworks (FCNs) leads to the emergence of local receptive fields (RFs), an\narchitectural feature present in mammalian visual cortex and convolutional\nneural networks. The question of how IMP is able to do this remains unanswered.\nInspired by results showing that training FCNs on synthetic images with highly\nnon-Gaussian statistics (e.g., sharp edges) is sufficient to drive the\nformation of local RFs, we hypothesize that IMP iteratively maximizes the\nnon-Gaussian statistics present in the representations of FCNs, creating a\nfeedback loop that enhances localization. We develop a new method for measuring\nthe effect of individual weights on the statistics of the FCN representations\n(\"cavity method\"), which allows us to find evidence in support of this\nhypothesis. Our work, which is the first to study the effect IMP has on the\nrepresentations of neural networks, sheds parsimonious light one way in which\nIMP can drive the formation of strong inductive biases.\n","authors":["William T. Redman","Zhangyang Wang","Alessandro Ingrosso","Sebastian Goldt"],"pdf_url":"https://arxiv.org/pdf/2412.06545v1.pdf","comment":"10 pages, 5 figures, comments welcome!"},{"id":"http://arxiv.org/abs/2412.06540v1","updated":"2024-12-09T14:51:26Z","published":"2024-12-09T14:51:26Z","title":"Sloth: scaling laws for LLM skills to predict multi-benchmark\n  performance across families","summary":"  Scaling laws for large language models (LLMs) predict model performance based\non parameters like size and training data. However, differences in training\nconfigurations and data processing across model families lead to significant\nvariations in benchmark performance, making it difficult for a single scaling\nlaw to generalize across all LLMs. On the other hand, training family-specific\nscaling laws requires training models of varying sizes for every family. In\nthis work, we propose Skills Scaling Laws (SSLaws, pronounced as Sloth), a\nnovel scaling law that leverages publicly available benchmark data and assumes\nLLM performance is driven by low-dimensional latent skills, such as reasoning\nand instruction following. These latent skills are influenced by computational\nresources like model size and training tokens but with varying efficiencies\nacross model families. Sloth exploits correlations across benchmarks to provide\nmore accurate and interpretable predictions while alleviating the need to train\nmultiple LLMs per family. We present both theoretical results on parameter\nidentification and empirical evaluations on 12 prominent benchmarks, from Open\nLLM Leaderboard v1/v2, demonstrating that Sloth predicts LLM performance\nefficiently and offers insights into scaling behaviors for downstream tasks\nsuch as coding and emotional intelligence applications.\n","authors":["Felipe Maia Polo","Seamus Somerstep","Leshem Choshen","Yuekai Sun","Mikhail Yurochkin"],"pdf_url":"https://arxiv.org/pdf/2412.06540v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.08256v2","updated":"2024-12-09T14:50:02Z","published":"2023-06-14T05:44:53Z","title":"Data Augmentation for Seizure Prediction with Generative Diffusion Model","summary":"  Data augmentation (DA) can significantly strengthen the electroencephalogram\n(EEG)-based seizure prediction methods. However, existing DA approaches are\njust the linear transformations of original data and cannot explore the feature\nspace to increase diversity effectively. Therefore, we propose a novel\ndiffusion-based DA method called DiffEEG. DiffEEG can fully explore data\ndistribution and generate samples with high diversity, offering extra\ninformation to classifiers. It involves two processes: the diffusion process\nand the denoised process. In the diffusion process, the model incrementally\nadds noise with different scales to EEG input and converts it into random\nnoise. In this way, the representation of data can be learned. In the denoised\nprocess, the model utilizes learned knowledge to sample synthetic data from\nrandom noise input by gradually removing noise. The randomness of input noise\nand the precise representation enable the synthetic samples to possess\ndiversity while ensuring the consistency of feature space. We compared DiffEEG\nwith original, down-sampling, sliding windows and recombination methods, and\nintegrated them into five representative classifiers. The experiments\ndemonstrate the effectiveness and generality of our method. With the\ncontribution of DiffEEG, the Multi-scale CNN achieves state-of-the-art\nperformance, with an average sensitivity, FPR, AUC of 95.4%, 0.051/h, 0.932 on\nthe CHB-MIT database and 93.6%, 0.121/h, 0.822 on the Kaggle database.\n","authors":["Kai Shu","Le Wu","Yuchang Zhao","Aiping Liu","Ruobing Qian","Xun Chen"],"pdf_url":"https://arxiv.org/pdf/2306.08256v2.pdf","comment":"15 pages, 9 figures"},{"id":"http://arxiv.org/abs/2412.06538v1","updated":"2024-12-09T14:48:14Z","published":"2024-12-09T14:48:14Z","title":"Understanding Factual Recall in Transformers via Associative Memories","summary":"  Large language models have demonstrated an impressive ability to perform\nfactual recall. Prior work has found that transformers trained on factual\nrecall tasks can store information at a rate proportional to their parameter\ncount. In our work, we show that shallow transformers can use a combination of\nassociative memories to obtain such near optimal storage capacity. We begin by\nproving that the storage capacities of both linear and MLP associative memories\nscale linearly with parameter count. We next introduce a synthetic factual\nrecall task, and prove that a transformer with a single layer of self-attention\nfollowed by an MLP can obtain 100% accuracy on the task whenever either the\ntotal number of self-attention parameters or MLP parameters scales (up to log\nfactors) linearly with the number of facts. In particular, the transformer can\ntrade off between using the value matrices or the MLP as an associative memory\nto store the dataset of facts. We complement these expressivity results with an\nanalysis of the gradient flow trajectory of a simplified linear attention model\ntrained on our factual recall task, where we show that the model exhibits\nsequential learning behavior.\n","authors":["Eshaan Nichani","Jason D. Lee","Alberto Bietti"],"pdf_url":"https://arxiv.org/pdf/2412.06538v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.04413v2","updated":"2024-12-09T14:46:09Z","published":"2024-12-05T18:33:59Z","title":"Efficient Task Grouping Through Samplewise Optimisation Landscape\n  Analysis","summary":"  Shared training approaches, such as multi-task learning (MTL) and\ngradient-based meta-learning, are widely used in various machine learning\napplications, but they often suffer from negative transfer, leading to\nperformance degradation in specific tasks. While several optimisation\ntechniques have been developed to mitigate this issue for pre-selected task\ncohorts, identifying optimal task combinations for joint learning - known as\ntask grouping - remains underexplored and computationally challenging due to\nthe exponential growth in task combinations and the need for extensive training\nand evaluation cycles. This paper introduces an efficient task grouping\nframework designed to reduce these overwhelming computational demands of the\nexisting methods. The proposed framework infers pairwise task similarities\nthrough a sample-wise optimisation landscape analysis, eliminating the need for\nthe shared model training required to infer task similarities in existing\nmethods. With task similarities acquired, a graph-based clustering algorithm is\nemployed to pinpoint near-optimal task groups, providing an approximate yet\nefficient and effective solution to the originally NP-hard problem. Empirical\nassessments conducted on 8 different datasets highlight the effectiveness of\nthe proposed framework, revealing a five-fold speed enhancement compared to\nprevious state-of-the-art methods. Moreover, the framework consistently\ndemonstrates comparable performance, confirming its remarkable efficiency and\neffectiveness in task grouping.\n","authors":["Anshul Thakur","Yichen Huang","Soheila Molaei","Yujiang Wang","David A. Clifton"],"pdf_url":"https://arxiv.org/pdf/2412.04413v2.pdf","comment":"Under review at IEEE Transactions on Pattern Analysis and Machine\n  Intelligence"},{"id":"http://arxiv.org/abs/2412.06534v1","updated":"2024-12-09T14:43:06Z","published":"2024-12-09T14:43:06Z","title":"Inverting Visual Representations with Detection Transformers","summary":"  Understanding the mechanisms underlying deep neural networks in computer\nvision remains a fundamental challenge. While many prior approaches have\nfocused on visualizing intermediate representations within deep neural\nnetworks, particularly convolutional neural networks, these techniques have yet\nto be thoroughly explored in transformer-based vision models. In this study, we\napply the approach of training inverse models to reconstruct input images from\nintermediate layers within a Detection Transformer, showing that this approach\nis efficient and feasible for transformer-based vision models. Through\nqualitative and quantitative evaluations of reconstructed images across model\nstages, we demonstrate critical properties of Detection Transformers, including\ncontextual shape preservation, inter-layer correlation, and robustness to color\nperturbations, illustrating how these characteristics emerge within the model's\narchitecture. Our findings contribute to a deeper understanding of\ntransformer-based vision models. The code for reproducing our experiments will\nbe made available at github.com/wiskott-lab/inverse-detection-transformer.\n","authors":["Jan Rathjens","Shirin Reyhanian","David Kappel","Laurenz Wiskott"],"pdf_url":"https://arxiv.org/pdf/2412.06534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.13108v3","updated":"2024-12-09T14:41:53Z","published":"2024-02-20T16:01:42Z","title":"On the Convergence of Gradient Descent for Large Learning Rates","summary":"  A vast literature on convergence guarantees for gradient descent and derived\nmethods exists at the moment. However, a simple practical situation remains\nunexplored: when a fixed step size is used, can we expect gradient descent to\nconverge starting from any initialization? We provide fundamental impossibility\nresults showing that convergence becomes impossible no matter the\ninitialization if the step size gets too big. Looking at the asymptotic value\nof the gradient norm along the optimization trajectory, we see that there is a\nsharp transition as the step size crosses a critical value. This has been\nobserved by practitioners, yet the true mechanisms through which this happens\nremain unclear beyond heuristics. Using results from dynamical systems theory,\nwe provide a proof of this in the case of linear neural networks with a squared\nloss. We also prove the impossibility of convergence for more general losses\nwithout requiring strong assumptions such as Lipschitz continuity for the\ngradient. We validate our findings through experiments with non-linear\nnetworks.\n","authors":["Alexandru Crăciun","Debarghya Ghoshdastidar"],"pdf_url":"https://arxiv.org/pdf/2402.13108v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.16089v2","updated":"2024-12-09T14:41:53Z","published":"2024-09-24T13:40:39Z","title":"From Pixels to Words: Leveraging Explainability in Face Recognition\n  through Interactive Natural Language Processing","summary":"  Face Recognition (FR) has advanced significantly with the development of deep\nlearning, achieving high accuracy in several applications. However, the lack of\ninterpretability of these systems raises concerns about their accountability,\nfairness, and reliability. In the present study, we propose an interactive\nframework to enhance the explainability of FR models by combining\nmodel-agnostic Explainable Artificial Intelligence (XAI) and Natural Language\nProcessing (NLP) techniques. The proposed framework is able to accurately\nanswer various questions of the user through an interactive chatbot. In\nparticular, the explanations generated by our proposed method are in the form\nof natural language text and visual representations, which for example can\ndescribe how different facial regions contribute to the similarity measure\nbetween two faces. This is achieved through the automatic analysis of the\noutput's saliency heatmaps of the face images and a BERT question-answering\nmodel, providing users with an interface that facilitates a comprehensive\nunderstanding of the FR decisions. The proposed approach is interactive,\nallowing the users to ask questions to get more precise information based on\nthe user's background knowledge. More importantly, in contrast to previous\nstudies, our solution does not decrease the face recognition performance. We\ndemonstrate the effectiveness of the method through different experiments,\nhighlighting its potential to make FR systems more interpretable and\nuser-friendly, especially in sensitive applications where decision-making\ntransparency is crucial.\n","authors":["Ivan DeAndres-Tame","Muhammad Faisal","Ruben Tolosana","Rouqaiah Al-Refai","Ruben Vera-Rodriguez","Philipp Terhörst"],"pdf_url":"https://arxiv.org/pdf/2409.16089v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06531v1","updated":"2024-12-09T14:34:31Z","published":"2024-12-09T14:34:31Z","title":"Unraveling the Complexity of Memory in RL Agents: an Approach for\n  Classification and Evaluation","summary":"  The incorporation of memory into agents is essential for numerous tasks\nwithin the domain of Reinforcement Learning (RL). In particular, memory is\nparamount for tasks that require the utilization of past information,\nadaptation to novel environments, and improved sample efficiency. However, the\nterm ``memory'' encompasses a wide range of concepts, which, coupled with the\nlack of a unified methodology for validating an agent's memory, leads to\nerroneous judgments about agents' memory capabilities and prevents objective\ncomparison with other memory-enhanced agents. This paper aims to streamline the\nconcept of memory in RL by providing practical precise definitions of agent\nmemory types, such as long-term versus short-term memory and declarative versus\nprocedural memory, inspired by cognitive science. Using these definitions, we\ncategorize different classes of agent memory, propose a robust experimental\nmethodology for evaluating the memory capabilities of RL agents, and\nstandardize evaluations. Furthermore, we empirically demonstrate the importance\nof adhering to the proposed methodology when evaluating different types of\nagent memory by conducting experiments with different RL agents and what its\nviolation leads to.\n","authors":["Egor Cherepanov","Nikita Kachaev","Artem Zholus","Alexey K. Kovalev","Aleksandr I. Panov"],"pdf_url":"https://arxiv.org/pdf/2412.06531v1.pdf","comment":"18 pages, 6 figures"},{"id":"http://arxiv.org/abs/2409.01369v2","updated":"2024-12-09T14:26:42Z","published":"2024-09-02T16:48:57Z","title":"Imitating Language via Scalable Inverse Reinforcement Learning","summary":"  The majority of language model training builds on imitation learning. It\ncovers pretraining, supervised fine-tuning, and affects the starting conditions\nfor reinforcement learning from human feedback (RLHF). The simplicity and\nscalability of maximum likelihood estimation (MLE) for next token prediction\nled to its role as predominant paradigm. However, the broader field of\nimitation learning can more effectively utilize the sequential structure\nunderlying autoregressive generation. We focus on investigating the inverse\nreinforcement learning (IRL) perspective to imitation, extracting rewards and\ndirectly optimizing sequences instead of individual token likelihoods and\nevaluate its benefits for fine-tuning large language models. We provide a new\nangle, reformulating inverse soft-Q-learning as a temporal difference\nregularized extension of MLE. This creates a principled connection between MLE\nand IRL and allows trading off added complexity with increased performance and\ndiversity of generations in the supervised fine-tuning (SFT) setting. We find\nclear advantages for IRL-based imitation, in particular for retaining diversity\nwhile maximizing task performance, rendering IRL a strong alternative on fixed\nSFT datasets even without online data generation. Our analysis of IRL-extracted\nreward functions further indicates benefits for more robust reward functions\nvia tighter integration of supervised and preference-based LLM post-training.\n","authors":["Markus Wulfmeier","Michael Bloesch","Nino Vieillard","Arun Ahuja","Jorg Bornschein","Sandy Huang","Artem Sokolov","Matt Barnes","Guillaume Desjardins","Alex Bewley","Sarah Maria Elisabeth Bechtle","Jost Tobias Springenberg","Nikola Momchev","Olivier Bachem","Matthieu Geist","Martin Riedmiller"],"pdf_url":"https://arxiv.org/pdf/2409.01369v2.pdf","comment":"Published at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2401.01923v4","updated":"2024-12-09T14:16:59Z","published":"2024-01-03T18:08:57Z","title":"The Internet of Things in the Era of Generative AI: Vision and\n  Challenges","summary":"  Advancements in Generative AI hold immense promise to push Internet of Things\n(IoT) to the next level. In this article, we share our vision on IoT in the era\nof Generative AI. We discuss some of the most important applications of\nGenerative AI in IoT-related domains. We also identify some of the most\ncritical challenges and discuss current gaps as well as promising opportunities\non enabling Generative AI for IoT. We hope this article can inspire new\nresearch on IoT in the era of Generative AI.\n","authors":["Xin Wang","Zhongwei Wan","Arvin Hekmati","Mingyu Zong","Samiul Alam","Mi Zhang","Bhaskar Krishnamachari"],"pdf_url":"https://arxiv.org/pdf/2401.01923v4.pdf","comment":"Featured article of IEEE Internet Computing, 2024, Volume: 28, Issue:\n  5"},{"id":"http://arxiv.org/abs/2412.06507v1","updated":"2024-12-09T14:11:56Z","published":"2024-12-09T14:11:56Z","title":"BATseg: Boundary-aware Multiclass Spinal Cord Tumor Segmentation on 3D\n  MRI Scans","summary":"  Spinal cord tumors significantly contribute to neurological morbidity and\nmortality. Precise morphometric quantification, encompassing the size,\nlocation, and type of such tumors, holds promise for optimizing treatment\nplanning strategies. Although recent methods have demonstrated excellent\nperformance in medical image segmentation, they primarily focus on discerning\nshapes with relatively large morphology such as brain tumors, ignoring the\nchallenging problem of identifying spinal cord tumors which tend to have tiny\nsizes, diverse locations, and shapes. To tackle this hard problem of multiclass\nspinal cord tumor segmentation, we propose a new method, called BATseg, to\nlearn a tumor surface distance field by applying our new multiclass\nboundary-aware loss function. To verify the effectiveness of our approach, we\nalso introduce the first and large-scale spinal cord tumor dataset. It\ncomprises gadolinium-enhanced T1-weighted 3D MRI scans from 653 patients and\ncontains the four most common spinal cord tumor types: astrocytomas,\nependymomas, hemangioblastomas, and spinal meningiomas. Extensive experiments\non our dataset and another public kidney tumor segmentation dataset show that\nour proposed method achieves superior performance for multiclass tumor\nsegmentation.\n","authors":["Hongkang Song","Zihui Zhang","Yanpeng Zhou","Jie Hu","Zishuo Wang","Hou Him Chan","Chon Lok Lei","Chen Xu","Yu Xin","Bo Yang"],"pdf_url":"https://arxiv.org/pdf/2412.06507v1.pdf","comment":"ECCV 2024 Workshop on BioImage Computing. Code and data are available\n  at: https://github.com/vLAR-group/BATseg"},{"id":"http://arxiv.org/abs/2409.11504v2","updated":"2024-12-09T14:03:33Z","published":"2024-09-17T19:16:03Z","title":"Preventing Representational Rank Collapse in MPNNs by Splitting the\n  Computational Graph","summary":"  The ability of message-passing neural networks (MPNNs) to fit complex\nfunctions over graphs is limited as most graph convolutions amplify the same\nsignal across all feature channels, a phenomenon known as rank collapse, and\nover-smoothing as a special case. Most approaches to mitigate over-smoothing\nextend common message-passing schemes, e.g., the graph convolutional network,\nby utilizing residual connections, gating mechanisms, normalization, or\nregularization techniques. Our work contrarily proposes to directly tackle the\ncause of this issue by modifying the message-passing scheme and exchanging\ndifferent types of messages using multi-relational graphs. We identify a\nsufficient condition to ensure linearly independent node representations. As\none instantion, we show that operating on multiple directed acyclic graphs\nalways satisfies our condition and propose to obtain these by defining a strict\npartial ordering of the nodes. We conduct comprehensive experiments that\nconfirm the benefits of operating on multi-relational graphs to achieve more\ninformative node representations.\n","authors":["Andreas Roth","Franka Bause","Nils M. Kriege","Thomas Liebig"],"pdf_url":"https://arxiv.org/pdf/2409.11504v2.pdf","comment":"Published at LoG 2024"},{"id":"http://arxiv.org/abs/2405.02385v3","updated":"2024-12-09T14:03:27Z","published":"2024-05-03T17:21:13Z","title":"Efficient Deep Learning with Decorrelated Backpropagation","summary":"  The backpropagation algorithm remains the dominant and most successful method\nfor training deep neural networks (DNNs). At the same time, training DNNs at\nscale comes at a significant computational cost and therefore a high carbon\nfootprint. Converging evidence suggests that input decorrelation may speed up\ndeep learning. However, to date, this has not yet translated into substantial\nimprovements in training efficiency in large-scale DNNs. This is mainly caused\nby the challenge of enforcing fast and stable network-wide decorrelation. Here,\nwe show for the first time that much more efficient training of very deep\nneural networks using decorrelated backpropagation is feasible. To achieve this\ngoal we made use of a novel algorithm which induces network-wide input\ndecorrelation using minimal computational overhead. By combining this algorithm\nwith careful optimizations, we obtain a more than two-fold speed-up and higher\ntest accuracy compared to backpropagation when training a 18-layer deep\nresidual network. This demonstrates that decorrelation provides exciting\nprospects for efficient deep learning at scale.\n","authors":["Sander Dalm","Joshua Offergeld","Nasir Ahmad","Marcel van Gerven"],"pdf_url":"https://arxiv.org/pdf/2405.02385v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13563v3","updated":"2024-12-09T14:00:13Z","published":"2024-10-17T14:00:18Z","title":"Ornstein-Uhlenbeck Adaptation as a Mechanism for Learning in Brains and\n  Machines","summary":"  Learning is a fundamental property of intelligent systems, observed across\nbiological organisms and engineered systems. While modern intelligent systems\ntypically rely on gradient descent for learning, the need for exact gradients\nand complex information flow makes its implementation in biological and\nneuromorphic systems challenging. This has motivated the exploration of\nalternative learning mechanisms that can operate locally and do not rely on\nexact gradients. In this work, we introduce a novel approach that leverages\nnoise in the parameters of the system and global reinforcement signals. Using\nan Ornstein-Uhlenbeck process with adaptive dynamics, our method balances\nexploration and exploitation during learning, driven by deviations from error\npredictions, akin to reward prediction error. Operating in continuous time,\nOrstein-Uhlenbeck adaptation (OUA) is proposed as a general mechanism for\nlearning dynamic, time-evolving environments. We validate our approach across\ndiverse tasks, including supervised learning and reinforcement learning in\nfeedforward and recurrent systems. Additionally, we demonstrate that it can\nperform meta-learning, adjusting hyper-parameters autonomously. Our results\nindicate that OUA provides a viable alternative to traditional gradient-based\nmethods, with potential applications in neuromorphic computing. It also hints\nat a possible mechanism for noise-driven learning in the brain, where\nstochastic neurotransmitter release may guide synaptic adjustments.\n","authors":["Jesus Garcia Fernandez","Nasir Ahmad","Marcel van Gerven"],"pdf_url":"https://arxiv.org/pdf/2410.13563v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.09776v3","updated":"2024-12-09T13:55:58Z","published":"2024-06-14T07:22:39Z","title":"Faster Convergence on Heterogeneous Federated Edge Learning: An Adaptive\n  Clustered Data Sharing Approach","summary":"  Federated Edge Learning (FEEL) emerges as a pioneering distributed machine\nlearning paradigm for the 6G Hyper-Connectivity, harnessing data from the\nInternet of Things (IoT) devices while upholding data privacy. However, current\nFEEL algorithms struggle with non-independent and non-identically distributed\n(non-IID) data, leading to elevated communication costs and compromised model\naccuracy. To address these statistical imbalances within FEEL, we introduce a\nclustered data sharing framework, mitigating data heterogeneity by selectively\nsharing partial data from cluster heads to trusted associates through\nsidelink-aided multicasting. The collective communication pattern is integral\nto FEEL training, where both cluster formation and the efficiency of\ncommunication and computation impact training latency and accuracy\nsimultaneously. To tackle the strictly coupled data sharing and resource\noptimization, we decompose the overall optimization problem into the clients\nclustering and effective data sharing subproblems. Specifically, a\ndistribution-based adaptive clustering algorithm (DACA) is devised basing on\nthree deductive cluster forming conditions, which ensures the maximum sharing\nyield. Meanwhile, we design a stochastic optimization based joint computed\nfrequency and shared data volume optimization (JFVO) algorithm, determining the\noptimal resource allocation with an uncertain objective function. The\nexperiments show that the proposed framework facilitates FEEL on non-IID\ndatasets with faster convergence rate and higher model accuracy in a limited\ncommunication environment.\n","authors":["Gang Hu","Yinglei Teng","Nan Wang","Zhu Han"],"pdf_url":"https://arxiv.org/pdf/2406.09776v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.02648v3","updated":"2024-12-09T13:52:19Z","published":"2024-03-05T04:35:59Z","title":"Remove that Square Root: A New Efficient Scale-Invariant Version of\n  AdaGrad","summary":"  Adaptive methods are extremely popular in machine learning as they make\nlearning rate tuning less expensive. This paper introduces a novel optimization\nalgorithm named KATE, which presents a scale-invariant adaptation of the\nwell-known AdaGrad algorithm. We prove the scale-invariance of KATE for the\ncase of Generalized Linear Models. Moreover, for general smooth non-convex\nproblems, we establish a convergence rate of $O \\left(\\frac{\\log T}{\\sqrt{T}}\n\\right)$ for KATE, matching the best-known ones for AdaGrad and Adam. We also\ncompare KATE to other state-of-the-art adaptive algorithms Adam and AdaGrad in\nnumerical experiments with different problems, including complex machine\nlearning tasks like image classification and text classification on real data.\nThe results indicate that KATE consistently outperforms AdaGrad and\nmatches/surpasses the performance of Adam in all considered scenarios.\n","authors":["Sayantan Choudhury","Nazarii Tupitsa","Nicolas Loizou","Samuel Horvath","Martin Takac","Eduard Gorbunov"],"pdf_url":"https://arxiv.org/pdf/2403.02648v3.pdf","comment":"31 pages, 12 figures"},{"id":"http://arxiv.org/abs/2412.06494v1","updated":"2024-12-09T13:50:52Z","published":"2024-12-09T13:50:52Z","title":"A cautionary tale on the cost-effectiveness of collaborative AI in\n  real-world medical applications","summary":"  Background. Federated learning (FL) has gained wide popularity as a\ncollaborative learning paradigm enabling collaborative AI in sensitive\nhealthcare applications. Nevertheless, the practical implementation of FL\npresents technical and organizational challenges, as it generally requires\ncomplex communication infrastructures. In this context, consensus-based\nlearning (CBL) may represent a promising collaborative learning alternative,\nthanks to the ability of combining local knowledge into a federated decision\nsystem, while potentially reducing deployment overhead. Methods. In this work\nwe propose an extensive benchmark of the accuracy and cost-effectiveness of a\npanel of FL and CBL methods in a wide range of collaborative medical data\nanalysis scenarios. The benchmark includes 7 different medical datasets,\nencompassing 3 machine learning tasks, 8 different data modalities, and\nmulti-centric settings involving 3 to 23 clients. Findings. Our results reveal\nthat CBL is a cost-effective alternative to FL. When compared across the panel\nof medical dataset in the considered benchmark, CBL methods provide equivalent\naccuracy to the one achieved by FL.Nonetheless, CBL significantly reduces\ntraining time and communication cost (resp. 15 fold and 60 fold decrease) (p <\n0.05). Interpretation. This study opens a novel perspective on the deployment\nof collaborative AI in real-world applications, whereas the adoption of\ncost-effective methods is instrumental to achieve sustainability and\ndemocratisation of AI by alleviating the need for extensive computational\nresources.\n","authors":["Francesco Cremonesi","Lucia Innocenti","Sebastien Ourselin","Vicky Goh","Michela Antonelli","Marco Lorenzi"],"pdf_url":"https://arxiv.org/pdf/2412.06494v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.07937v3","updated":"2024-12-09T13:43:15Z","published":"2024-03-08T08:10:29Z","title":"Speech Robust Bench: A Robustness Benchmark For Speech Recognition","summary":"  As Automatic Speech Recognition (ASR) models become ever more pervasive, it\nis important to ensure that they make reliable predictions under corruptions\npresent in the physical and digital world. We propose Speech Robust Bench\n(SRB), a comprehensive benchmark for evaluating the robustness of ASR models to\ndiverse corruptions. SRB is composed of 114 input perturbations which simulate\nan heterogeneous range of corruptions that ASR models may encounter when\ndeployed in the wild. We use SRB to evaluate the robustness of several\nstate-of-the-art ASR models and observe that model size and certain modeling\nchoices such as the use of discrete representations, or self-training appear to\nbe conducive to robustness. We extend this analysis to measure the robustness\nof ASR models on data from various demographic subgroups, namely English and\nSpanish speakers, and males and females. Our results revealed noticeable\ndisparities in the model's robustness across subgroups. We believe that SRB\nwill significantly facilitate future research towards robust ASR models, by\nmaking it easier to conduct comprehensive and comparable robustness\nevaluations.\n","authors":["Muhammad A. Shah","David Solans Noguero","Mikko A. Heikkila","Bhiksha Raj","Nicolas Kourtellis"],"pdf_url":"https://arxiv.org/pdf/2403.07937v3.pdf","comment":"submitted to NeurIPS datasets and benchmark track 2025"},{"id":"http://arxiv.org/abs/2412.06487v1","updated":"2024-12-09T13:38:19Z","published":"2024-12-09T13:38:19Z","title":"Improving text-conditioned latent diffusion for cancer pathology","summary":"  The development of generative models in the past decade has allowed for\nhyperrealistic data synthesis. While potentially beneficial, this synthetic\ndata generation process has been relatively underexplored in cancer\nhistopathology. One algorithm for synthesising a realistic image is diffusion;\nit iteratively converts an image to noise and learns the recovery process from\nthis noise [Wang and Vastola, 2023]. While effective, it is highly\ncomputationally expensive for high-resolution images, rendering it infeasible\nfor histopathology. The development of Variational Autoencoders (VAEs) has\nallowed us to learn the representation of complex high-resolution images in a\nlatent space. A vital by-product of this is the ability to compress\nhigh-resolution images to space and recover them lossless. The marriage of\ndiffusion and VAEs allows us to carry out diffusion in the latent space of an\nautoencoder, enabling us to leverage the realistic generative capabilities of\ndiffusion while maintaining reasonable computational requirements. Rombach et\nal. [2021b] and Yellapragada et al. [2023] build foundational models for this\ntask, paving the way to generate realistic histopathology images. In this\npaper, we discuss the pitfalls of current methods, namely [Yellapragada et al.,\n2023] and resolve critical errors while proposing improvements along the way.\nOur methods achieve an FID score of 21.11, beating its SOTA counterparts in\n[Yellapragada et al., 2023] by 1.2 FID, while presenting a train-time GPU\nmemory usage reduction of 7%.\n","authors":["Aakash Madhav Rao","Debayan Gupta"],"pdf_url":"https://arxiv.org/pdf/2412.06487v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06486v1","updated":"2024-12-09T13:35:46Z","published":"2024-12-09T13:35:46Z","title":"SimuDICE: Offline Policy Optimization Through World Model Updates and\n  DICE Estimation","summary":"  In offline reinforcement learning, deriving an effective policy from a\npre-collected set of experiences is challenging due to the distribution\nmismatch between the target policy and the behavioral policy used to collect\nthe data, as well as the limited sample size. Model-based reinforcement\nlearning improves sample efficiency by generating simulated experiences using a\nlearned dynamic model of the environment. However, these synthetic experiences\noften suffer from the same distribution mismatch. To address these challenges,\nwe introduce SimuDICE, a framework that iteratively refines the initial policy\nderived from offline data using synthetically generated experiences from the\nworld model. SimuDICE enhances the quality of these simulated experiences by\nadjusting the sampling probabilities of state-action pairs based on stationary\nDIstribution Correction Estimation (DICE) and the estimated confidence in the\nmodel's predictions. This approach guides policy improvement by balancing\nexperiences similar to those frequently encountered with ones that have a\ndistribution mismatch. Our experiments show that SimuDICE achieves performance\ncomparable to existing algorithms while requiring fewer pre-collected\nexperiences and planning steps, and it remains robust across varying data\ncollection policies.\n","authors":["Catalin E. Brita","Stephan Bongers","Frans A. Oliehoek"],"pdf_url":"https://arxiv.org/pdf/2412.06486v1.pdf","comment":"Published at BNAIC/BeNeLearn 2024"},{"id":"http://arxiv.org/abs/2412.06478v1","updated":"2024-12-09T13:28:19Z","published":"2024-12-09T13:28:19Z","title":"An inferential measure of dependence between two systems using Bayesian\n  model comparison","summary":"  We propose to quantify dependence between two systems $X$ and $Y$ in a\ndataset $D$ based on the Bayesian comparison of two models: one, $H_0$, of\nstatistical independence and another one, $H_1$, of dependence. In this\nframework, dependence between $X$ and $Y$ in $D$, denoted $B(X,Y|D)$, is\nquantified as $P(H_1|D)$, the posterior probability for the model of dependence\ngiven $D$, or any strictly increasing function thereof. It is therefore a\nmeasure of the evidence for dependence between $X$ and $Y$ as modeled by $H_1$\nand observed in $D$. We review several statistical models and reconsider\nstandard results in the light of $B(X,Y|D)$ as a measure of dependence. Using\nsimulations, we focus on two specific issues: the effect of noise and the\nbehavior of $B(X,Y|D)$ when $H_1$ has a parameter coding for the intensity of\ndependence. We then derive some general properties of $B(X,Y|D)$, showing that\nit quantifies the information contained in $D$ in favor of $H_1$ versus $H_0$.\nWhile some of these properties are typical of what is expected from a valid\nmeasure of dependence, others are novel and naturally appear as desired\nfeatures for specific measures of dependence, which we call inferential. We\nfinally put these results in perspective; in particular, we discuss the\nconsequences of using the Bayesian framework as well as the similarities and\ndifferences between $B(X,Y|D)$ and mutual information.\n","authors":["Guillaume Marrelec","Alain Giron"],"pdf_url":"https://arxiv.org/pdf/2412.06478v1.pdf","comment":"To be published in IEEE Transaction on Systems, Man, and Cybernetics:\n  Systems"},{"id":"http://arxiv.org/abs/2409.11272v4","updated":"2024-12-09T13:21:45Z","published":"2024-09-17T15:23:08Z","title":"LOLA -- An Open-Source Massively Multilingual Large Language Model","summary":"  This paper presents LOLA, a massively multilingual large language model\ntrained on more than 160 languages using a sparse Mixture-of-Experts\nTransformer architecture. Our architectural and implementation choices address\nthe challenge of harnessing linguistic diversity while maintaining efficiency\nand avoiding the common pitfalls of multilinguality. Our analysis of the\nevaluation results shows competitive performance in natural language generation\nand understanding tasks. Additionally, we demonstrate how the learned\nexpert-routing mechanism exploits implicit phylogenetic linguistic patterns to\npotentially alleviate the curse of multilinguality. We provide an in-depth look\nat the training process, an analysis of the datasets, and a balanced\nexploration of the model's strengths and limitations. As an open-source model,\nLOLA promotes reproducibility and serves as a robust foundation for future\nresearch. Our findings enable the development of compute-efficient multilingual\nmodels with strong, scalable performance across languages.\n","authors":["Nikit Srivastava","Denis Kuchelev","Tatiana Moteu Ngoli","Kshitij Shetty","Michael Röder","Hamada Zahera","Diego Moussallem","Axel-Cyrille Ngonga Ngomo"],"pdf_url":"https://arxiv.org/pdf/2409.11272v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06474v1","updated":"2024-12-09T13:21:07Z","published":"2024-12-09T13:21:07Z","title":"From Uncertainty to Trust: Enhancing Reliability in Vision-Language\n  Models with Uncertainty-Guided Dropout Decoding","summary":"  Large vision-language models (LVLMs) demonstrate remarkable capabilities in\nmultimodal tasks but are prone to misinterpreting visual inputs, often\nresulting in hallucinations and unreliable outputs. To address these\nchallenges, we propose Dropout Decoding, a novel inference-time approach that\nquantifies the uncertainty of visual tokens and selectively masks uncertain\ntokens to improve decoding. Our method measures the uncertainty of each visual\ntoken by projecting it onto the text space and decomposing it into aleatoric\nand epistemic components. Specifically, we focus on epistemic uncertainty,\nwhich captures perception-related errors more effectively. Inspired by dropout\nregularization, we introduce uncertainty-guided token dropout, which applies\nthe dropout principle to input visual tokens instead of model parameters, and\nduring inference rather than training. By aggregating predictions from an\nensemble of masked decoding contexts, Dropout Decoding robustly mitigates\nerrors arising from visual token misinterpretations. Evaluations on benchmarks\nincluding CHAIR, THRONE, and MMBench demonstrate that Dropout Decoding\nsignificantly reduces object hallucinations (OH) and enhances both reliability\nand quality of LVLM outputs across diverse visual contexts.\n","authors":["Yixiong Fang","Ziran Yang","Zhaorun Chen","Zhuokai Zhao","Jiawei Zhou"],"pdf_url":"https://arxiv.org/pdf/2412.06474v1.pdf","comment":"Code is released at https://github.com/kigb/DropoutDecoding"},{"id":"http://arxiv.org/abs/2412.06472v1","updated":"2024-12-09T13:17:28Z","published":"2024-12-09T13:17:28Z","title":"Food for thought: How can machine learning help better predict and\n  understand changes in food prices?","summary":"  In this work, we address a lack of systematic understanding of fluctuations\nin food affordability in Canada. Canada's Food Price Report (CPFR) is an annual\npublication that predicts food inflation over the next calendar year. The\npublished predictions are a collaborative effort between forecasting teams that\neach employ their own approach at Canadian Universities: Dalhousie University,\nthe University of British Columbia, the University of Saskatchewan, and the\nUniversity of Guelph/Vector Institute. While the University of Guelph/Vector\nInstitute forecasting team has leveraged machine learning (ML) in previous\nreports, the most recent editions (2024--2025) have also included a\nhuman-in-the-loop approach. For the 2025 report, this focus was expanded to\nevaluate several different data-centric approaches to improve forecast\naccuracy. In this study, we evaluate how different types of forecasting models\nperform when estimating food price fluctuations. We also examine the\nsensitivity of models that curate time series data representing key factors in\nfood pricing.\n","authors":["Kristina L. Kupferschmidt","James Requiema","Mya Simpson","Zohrah Varsallay","Ethan Jackson","Cody Kupferschmidt","Sara El-Shawa","Graham W. Taylor"],"pdf_url":"https://arxiv.org/pdf/2412.06472v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06470v1","updated":"2024-12-09T13:15:52Z","published":"2024-12-09T13:15:52Z","title":"Active Learning with Context Sampling and One-vs-Rest Entropy for\n  Semantic Segmentation","summary":"  Multi-class semantic segmentation remains a cornerstone challenge in computer\nvision. Yet, dataset creation remains excessively demanding in time and effort,\nespecially for specialized domains. Active Learning (AL) mitigates this\nchallenge by selecting data points for annotation strategically. However,\nexisting patch-based AL methods often overlook boundary pixels critical\ninformation, essential for accurate segmentation. We present OREAL, a novel\npatch-based AL method designed for multi-class semantic segmentation. OREAL\nenhances boundary detection by employing maximum aggregation of pixel-wise\nuncertainty scores. Additionally, we introduce one-vs-rest entropy, a novel\nuncertainty score function that computes class-wise uncertainties while\nachieving implicit class balancing during dataset creation. Comprehensive\nexperiments across diverse datasets and model architectures validate our\nhypothesis.\n","authors":["Fei Wu","Pablo Marquez-Neila","Hedyeh Rafi-Tarii","Raphael Sznitman"],"pdf_url":"https://arxiv.org/pdf/2412.06470v1.pdf","comment":"WACV 2025, 8 pages"},{"id":"http://arxiv.org/abs/2412.06464v1","updated":"2024-12-09T13:09:04Z","published":"2024-12-09T13:09:04Z","title":"Gated Delta Networks: Improving Mamba2 with Delta Rule","summary":"  Linear Transformers have gained attention as efficient alternatives to\nstandard Transformers, but their performance in retrieval and long-context\ntasks has been limited. To address these limitations, recent work has explored\ntwo distinct mechanisms: gating for adaptive memory control and the delta\nupdate rule for precise memory modifications. We observe that these mechanisms\nare complementary: gating enables rapid memory erasure while the delta rule\nfacilitates targeted updates. Building on this insight, we introduce the gated\ndelta rule and develop a parallel training algorithm optimized for modern\nhardware. Our proposed architecture, Gated DeltaNet, consistently surpasses\nexisting models like Mamba2 and DeltaNet across multiple benchmarks, including\nlanguage modeling, common-sense reasoning, in-context retrieval, length\nextrapolation, and long-context understanding. We further enhance performance\nby developing hybrid architectures that combine Gated DeltaNet layers with\nsliding window attention or Mamba2 layers, achieving both improved training\nefficiency and superior task performance.\n","authors":["Songlin Yang","Jan Kautz","Ali Hatamizadeh"],"pdf_url":"https://arxiv.org/pdf/2412.06464v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2412.06451v1","updated":"2024-12-09T12:50:27Z","published":"2024-12-09T12:50:27Z","title":"How Certain are Uncertainty Estimates? Three Novel Earth Observation\n  Datasets for Benchmarking Uncertainty Quantification in Machine Learning","summary":"  Uncertainty quantification (UQ) is essential for assessing the reliability of\nEarth observation (EO) products. However, the extensive use of machine learning\nmodels in EO introduces an additional layer of complexity, as those models\nthemselves are inherently uncertain. While various UQ methods do exist for\nmachine learning models, their performance on EO datasets remains largely\nunevaluated. A key challenge in the community is the absence of the ground\ntruth for uncertainty, i.e. how certain the uncertainty estimates are, apart\nfrom the labels for the image/signal. This article fills this gap by\nintroducing three benchmark datasets specifically designed for UQ in EO machine\nlearning models. These datasets address three common problem types in EO:\nregression, image segmentation, and scene classification. They enable a\ntransparent comparison of different UQ methods for EO machine learning models.\nWe describe the creation and characteristics of each dataset, including data\nsources, preprocessing steps, and label generation, with a particular focus on\ncalculating the reference uncertainty. We also showcase baseline performance of\nseveral machine learning models on each dataset, highlighting the utility of\nthese benchmarks for model development and comparison. Overall, this article\noffers a valuable resource for researchers and practitioners working in\nartificial intelligence for EO, promoting a more accurate and reliable quality\nmeasure of the outputs of machine learning models. The dataset and code are\naccessible via https://gitlab.lrz.de/ai4eo/WG_Uncertainty.\n","authors":["Yuanyuan Wang","Qian Song","Dawood Wasif","Muhammad Shahzad","Christoph Koller","Jonathan Bamber","Xiao Xiang Zhu"],"pdf_url":"https://arxiv.org/pdf/2412.06451v1.pdf","comment":"Submitted to IEEE Geoscience and Remote Sensing Magazine"},{"id":"http://arxiv.org/abs/2412.06445v1","updated":"2024-12-09T12:44:03Z","published":"2024-12-09T12:44:03Z","title":"Echocardiography to Cardiac MRI View Transformation for Real-Time Blind\n  Restoration","summary":"  Echocardiography is the most widely used imaging to monitor cardiac\nfunctions, serving as the first line in early detection of myocardial ischemia\nand infarction. However, echocardiography often suffers from several artifacts\nincluding sensor noise, lack of contrast, severe saturation, and missing\nmyocardial segments which severely limit its usage in clinical diagnosis. In\nrecent years, several machine learning methods have been proposed to improve\nechocardiography views. Yet, these methods usually address only a specific\nproblem (e.g. denoising) and thus cannot provide a robust and reliable\nrestoration in general. On the other hand, cardiac MRI provides a clean view of\nthe heart without suffering such severe issues. However, due to its\nsignificantly higher cost, it is often only afforded by a few major hospitals,\nhence hindering its use and accessibility. In this pilot study, we propose a\nnovel approach to transform echocardiography into the cardiac MRI view. For\nthis purpose, Echo2MRI dataset, consisting of echocardiography and real cardiac\nMRI image pairs, is composed and will be shared publicly. A dedicated\nCycle-consistent Generative Adversarial Network (Cycle-GAN) is trained to learn\nthe transformation from echocardiography frames to cardiac MRI views. An\nextensive set of qualitative evaluations shows that the proposed transformer\ncan synthesize high-quality artifact-free synthetic cardiac MRI views from a\ngiven sequence of echocardiography frames. Medical evaluations performed by a\ngroup of cardiologists further demonstrate that synthetic MRI views are\nindistinguishable from their original counterparts and are preferred over their\ninitial sequence of echocardiography frames for diagnosis in 78.9% of the\ncases.\n","authors":["Ilke Adalioglu","Serkan Kiranyaz","Mete Ahishali","Aysen Degerli","Tahir Hamid","Rahmat Ghaffar","Ridha Hamila","Moncef Gabbouj"],"pdf_url":"https://arxiv.org/pdf/2412.06445v1.pdf","comment":"18 pages, 42 figures"},{"id":"http://arxiv.org/abs/2404.11374v2","updated":"2024-12-09T12:39:16Z","published":"2024-04-17T13:32:05Z","title":"Fast Polypharmacy Side Effect Prediction Using Tensor Factorisation","summary":"  Motivation: Adverse reactions from drug combinations are increasingly common,\nmaking their accurate prediction a crucial challenge in modern medicine.\nLaboratory-based identification of these reactions is insufficient due to the\ncombinatorial nature of the problem. While many computational approaches have\nbeen proposed, tensor factorisation models have shown mixed results,\nnecessitating a thorough investigation of their capabilities when properly\noptimized.\n  Results: We demonstrate that tensor factorisation models can achieve\nstate-of-the-art performance on polypharmacy side effect prediction, with our\nbest model (SimplE) achieving median scores of 0.978 AUROC, 0.971 AUPRC, and\n1.000 AP@50 across 963 side effects. Notably, this model reaches 98.3\\% of its\nmaximum performance after just two epochs of training (approximately 4\nminutes), making it substantially faster than existing approaches while\nmaintaining comparable accuracy. We also find that incorporating monopharmacy\ndata as self-looping edges in the graph performs marginally better than using\nit to initialize embeddings.\n  Availability and Implementation: All code used in the experiments is\navailable in our GitHub repository (https://doi.org/10.5281/zenodo.10684402).\nThe implementation was carried out using Python 3.8.12 with PyTorch 1.7.1,\naccelerated with CUDA 11.4 on NVIDIA GeForce RTX 2080 Ti GPUs.\n  Contact: oliver.lloyd@bristol.ac.uk\n  Supplementary information: Supplementary data, including precision-recall\ncurves and F1 curves for the best performing model, are available at\nBioinformatics online.\n","authors":["Oliver Lloyd","Yi Liu","Tom R. Gaunt"],"pdf_url":"https://arxiv.org/pdf/2404.11374v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.19214v3","updated":"2024-12-09T12:29:54Z","published":"2024-09-28T02:45:14Z","title":"Group & Reweight: A Novel Cost-Sensitive Approach to Mitigating Class\n  Imbalance in Network Traffic Classification","summary":"  Internet services have led to the eruption of network traffic, and machine\nlearning on these Internet data has become an indispensable tool, especially\nwhen the application is risk-sensitive. This paper focuses on network traffic\nclassification in the presence of class imbalance, which fundamentally and\nubiquitously exists in Internet data analysis. This existence of class\nimbalance mostly drifts the optimal decision boundary and results in a less\noptimal solution. This brings severe safety concerns in the network traffic\nfield when pattern recognition is challenging with numerous minority malicious\nclasses. To alleviate these effects, we design a \\textit{group \\& reweight}\nstrategy for alleviating the class imbalance. Inspired by the group\ndistributionally optimization framework, our approach heuristically clusters\nclasses into groups, iteratively updates the non-parametric weights for\nseparate classes and optimizes the learning model by minimizing reweighted\nlosses. We theoretically interpret the optimization process from a Stackelberg\ngame and perform extensive experiments on typical benchmarks. Results show that\nour approach can not only suppress the negative effect of class imbalance but\nalso improve the comprehensive performance in prediction.\n","authors":["Wumei Du","Dong Liang","Yiqin Lv","Xingxing Liang","Guanlin Wu","Qi Wang","Zheng Xie"],"pdf_url":"https://arxiv.org/pdf/2409.19214v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06438v1","updated":"2024-12-09T12:27:21Z","published":"2024-12-09T12:27:21Z","title":"Can foundation models actively gather information in interactive\n  environments to test hypotheses?","summary":"  While problem solving is a standard evaluation task for foundation models, a\ncrucial component of problem solving -- actively and strategically gathering\ninformation to test hypotheses -- has not been closely investigated. To assess\nthe information gathering abilities of foundation models in interactive\nenvironments, we introduce a framework in which a model must determine the\nfactors influencing a hidden reward function by iteratively reasoning about its\npreviously gathered information and proposing its next exploratory action to\nmaximize information gain at each step. We implement this framework in both a\ntext-based environment, which offers a tightly controlled setting and enables\nhigh-throughput parameter sweeps, and in an embodied 3D environment, which\nrequires addressing complexities of multi-modal interaction more relevant to\nreal-world applications. We further investigate whether approaches such as\nself-correction and increased inference time improve information gathering\nefficiency. In a relatively simple task that requires identifying a single\nrewarding feature, we find that LLM's information gathering capability is close\nto optimal. However, when the model must identify a conjunction of rewarding\nfeatures, performance is suboptimal. The hit in performance is due partly to\nthe model translating task description to a policy and partly to the model's\neffectiveness in using its in-context memory. Performance is comparable in both\ntext and 3D embodied environments, although imperfect visual object recognition\nreduces its accuracy in drawing conclusions from gathered information in the 3D\nembodied case. For single-feature-based rewards, we find that smaller models\ncuriously perform better; for conjunction-based rewards, incorporating self\ncorrection into the model improves performance.\n","authors":["Nan Rosemary Ke","Danny P. Sawyer","Hubert Soyer","Martin Engelcke","David P Reichert","Drew A. Hudson","John Reid","Alexander Lerchner","Danilo Jimenez Rezende","Timothy P Lillicrap","Michael Mozer","Jane X Wang"],"pdf_url":"https://arxiv.org/pdf/2412.06438v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06436v1","updated":"2024-12-09T12:26:26Z","published":"2024-12-09T12:26:26Z","title":"An Adaptively Inexact Method for Bilevel Learning Using Primal-Dual\n  Style Differentiation","summary":"  We consider a bilevel learning framework for learning linear operators. In\nthis framework, the learnable parameters are optimized via a loss function that\nalso depends on the minimizer of a convex optimization problem (denoted\nlower-level problem). We utilize an iterative algorithm called `piggyback' to\ncompute the gradient of the loss and minimizer of the lower-level problem.\nGiven that the lower-level problem is solved numerically, the loss function and\nthus its gradient can only be computed inexactly. To estimate the accuracy of\nthe computed hypergradient, we derive an a-posteriori error bound, which\nprovides guides for setting the tolerance for the lower-level problem, as well\nas the piggyback algorithm. To efficiently solve the upper-level optimization,\nwe also propose an adaptive method for choosing a suitable step-size. To\nillustrate the proposed method, we consider a few learned regularizer problems,\nsuch as training an input-convex neural network.\n","authors":["Lea Bogensperger","Matthias J. Ehrhardt","Thomas Pock","Mohammad Sadegh Salehi","Hok Shing Wong"],"pdf_url":"https://arxiv.org/pdf/2412.06436v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.01658v2","updated":"2024-12-09T12:23:59Z","published":"2023-12-04T06:20:14Z","title":"AGD: an Auto-switchable Optimizer using Stepwise Gradient Difference for\n  Preconditioning Matrix","summary":"  Adaptive optimizers, such as Adam, have achieved remarkable success in deep\nlearning. A key component of these optimizers is the so-called preconditioning\nmatrix, providing enhanced gradient information and regulating the step size of\neach gradient direction. In this paper, we propose a novel approach to\ndesigning the preconditioning matrix by utilizing the gradient difference\nbetween two successive steps as the diagonal elements. These diagonal elements\nare closely related to the Hessian and can be perceived as an approximation of\nthe inner product between the Hessian row vectors and difference of the\nadjacent parameter vectors. Additionally, we introduce an auto-switching\nfunction that enables the preconditioning matrix to switch dynamically between\nStochastic Gradient Descent (SGD) and the adaptive optimizer. Based on these\ntwo techniques, we develop a new optimizer named AGD that enhances the\ngeneralization performance. We evaluate AGD on public datasets of Natural\nLanguage Processing (NLP), Computer Vision (CV), and Recommendation Systems\n(RecSys). Our experimental results demonstrate that AGD outperforms the\nstate-of-the-art (SOTA) optimizers, achieving highly competitive or\nsignificantly better predictive performance. Furthermore, we analyze how AGD is\nable to switch automatically between SGD and the adaptive optimizer and its\nactual effects on various scenarios. The code is available at\nhttps://github.com/intelligent-machine-learning/atorch/tree/main/atorch/optimizers.\n","authors":["Yun Yue","Zhiling Ye","Jiadi Jiang","Yongchao Liu","Ke Zhang"],"pdf_url":"https://arxiv.org/pdf/2312.01658v2.pdf","comment":"21 pages. Accepted as a conference paper at NeurIPS '23"},{"id":"http://arxiv.org/abs/2412.06432v1","updated":"2024-12-09T12:20:33Z","published":"2024-12-09T12:20:33Z","title":"Integrating Expert Labels into LLM-based Emission Goal Detection:\n  Example Selection vs Automatic Prompt Design","summary":"  We address the detection of emission reduction goals in corporate reports, an\nimportant task for monitoring companies' progress in addressing climate change.\nSpecifically, we focus on the issue of integrating expert feedback in the form\nof labeled example passages into LLM-based pipelines, and compare the two\nstrategies of (1) a dynamic selection of few-shot examples and (2) the\nautomatic optimization of the prompt by the LLM itself. Our findings on a\npublic dataset of 769 climate-related passages from real-world business reports\nindicate that automatic prompt optimization is the superior approach, while\ncombining both methods provides only limited benefit. Qualitative results\nindicate that optimized prompts do indeed capture many intricacies of the\ntargeted emission goal extraction task.\n","authors":["Marco Wrzalik","Adrian Ulges","Anne Uersfeld","Florian Faust"],"pdf_url":"https://arxiv.org/pdf/2412.06432v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13745v3","updated":"2024-12-09T11:50:26Z","published":"2023-11-23T00:27:13Z","title":"Improved Sample Complexity Bounds for Diffusion Model Training","summary":"  Diffusion models have become the most popular approach to deep generative\nmodeling of images, largely due to their empirical performance and reliability.\nFrom a theoretical standpoint, a number of recent\nworks~\\cite{chen2022,chen2022improved,benton2023linear} have studied the\niteration complexity of sampling, assuming access to an accurate diffusion\nmodel. In this work, we focus on understanding the \\emph{sample complexity} of\ntraining such a model; how many samples are needed to learn an accurate\ndiffusion model using a sufficiently expressive neural network? Prior\nwork~\\cite{BMR20} showed bounds polynomial in the dimension, desired Total\nVariation error, and Wasserstein error. We show an \\emph{exponential\nimprovement} in the dependence on Wasserstein error and depth, along with\nimproved dependencies on other relevant parameters.\n","authors":["Shivam Gupta","Aditya Parulekar","Eric Price","Zhiyang Xun"],"pdf_url":"https://arxiv.org/pdf/2311.13745v3.pdf","comment":"Bugfix"},{"id":"http://arxiv.org/abs/2405.06642v4","updated":"2024-12-09T11:49:18Z","published":"2024-03-05T13:26:42Z","title":"PPFlow: Target-aware Peptide Design with Torsional Flow Matching","summary":"  Therapeutic peptides have proven to have great pharmaceutical value and\npotential in recent decades. However, methods of AI-assisted peptide drug\ndiscovery are not fully explored. To fill the gap, we propose a target-aware\npeptide design method called \\textsc{PPFlow}, based on conditional flow\nmatching on torus manifolds, to model the internal geometries of torsion angles\nfor the peptide structure design. Besides, we establish a protein-peptide\nbinding dataset named PPBench2024 to fill the void of massive data for the task\nof structure-based peptide drug design and to allow the training of deep\nlearning methods. Extensive experiments show that PPFlow reaches\nstate-of-the-art performance in tasks of peptide drug generation and\noptimization in comparison with baseline models, and can be generalized to\nother tasks including docking and side-chain packing.\n","authors":["Haitao Lin","Odin Zhang","Huifeng Zhao","Dejun Jiang","Lirong Wu","Zicheng Liu","Yufei Huang","Stan Z. Li"],"pdf_url":"https://arxiv.org/pdf/2405.06642v4.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2412.06414v1","updated":"2024-12-09T11:43:03Z","published":"2024-12-09T11:43:03Z","title":"Federated Split Learning with Model Pruning and Gradient Quantization in\n  Wireless Networks","summary":"  As a paradigm of distributed machine learning, federated learning typically\nrequires all edge devices to train a complete model locally. However, with the\nincreasing scale of artificial intelligence models, the limited resources on\nedge devices often become a bottleneck for efficient fine-tuning. To address\nthis challenge, federated split learning (FedSL) implements collaborative\ntraining across the edge devices and the server through model splitting. In\nthis paper, we propose a lightweight FedSL scheme, that further alleviates the\ntraining burden on resource-constrained edge devices by pruning the client-side\nmodel dynamicly and using quantized gradient updates to reduce computation\noverhead. Additionally, we apply random dropout to the activation values at the\nsplit layer to reduce communication overhead. We conduct theoretical analysis\nto quantify the convergence performance of the proposed scheme. Finally,\nsimulation results verify the effectiveness and advantages of the proposed\nlightweight FedSL in wireless network environments.\n","authors":["Junhe Zhang","Wanli Ni","Dongyu Wang"],"pdf_url":"https://arxiv.org/pdf/2412.06414v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.14319v2","updated":"2024-12-09T11:41:35Z","published":"2024-04-22T16:30:03Z","title":"Multi-Agent Hybrid SAC for Joint SS-DSA in CRNs","summary":"  Opportunistic spectrum access has the potential to increase the efficiency of\nspectrum utilization in cognitive radio networks (CRNs). In CRNs, both spectrum\nsensing and resource allocation (SSRA) are critical to maximizing system\nthroughput while minimizing collisions of secondary users with the primary\nnetwork. However, many works in dynamic spectrum access do not consider the\nimpact of imperfect sensing information such as mis-detected channels, which\nthe additional information available in joint SSRA can help remediate. In this\nwork, we examine joint SSRA as an optimization which seeks to maximize a CRN's\nnet communication rate subject to constraints on channel sensing, channel\naccess, and transmit power. Given the non-trivial nature of the problem, we\nleverage multi-agent reinforcement learning to enable a network of secondary\nusers to dynamically access unoccupied spectrum via only local test statistics,\nformulated under the energy detection paradigm of spectrum sensing. In doing\nso, we develop a novel multi-agent implementation of hybrid soft actor critic,\nMHSAC, based on the QMIX mixing scheme. Through experiments, we find that our\nSSRA algorithm, HySSRA, is successful in maximizing the CRN's utilization of\nspectrum resources while also limiting its interference with the primary\nnetwork, and outperforms the current state-of-the-art by a wide margin. We also\nexplore the impact of wireless variations such as coherence time on the\nefficacy of the system.\n","authors":["David R. Nickel","Anindya Bijoy Das","David J. Love","Christopher G. Brinton"],"pdf_url":"https://arxiv.org/pdf/2404.14319v2.pdf","comment":"Upon further exploration, model is not converging as expected under\n  current formulation. We are working to update the inputs and objective so\n  that it performs in an expected manner"},{"id":"http://arxiv.org/abs/2407.11910v2","updated":"2024-12-09T11:39:08Z","published":"2024-07-16T17:02:20Z","title":"Benchmarking the Attribution Quality of Vision Models","summary":"  Attribution maps are one of the most established tools to explain the\nfunctioning of computer vision models. They assign importance scores to input\nfeatures, indicating how relevant each feature is for the prediction of a deep\nneural network. While much research has gone into proposing new attribution\nmethods, their proper evaluation remains a difficult challenge. In this work,\nwe propose a novel evaluation protocol that overcomes two fundamental\nlimitations of the widely used incremental-deletion protocol, i.e., the\nout-of-domain issue and lacking inter-model comparisons. This allows us to\nevaluate 23 attribution methods and how different design choices of popular\nvision backbones affect their attribution quality. We find that intrinsically\nexplainable models outperform standard models and that raw attribution values\nexhibit a higher attribution quality than what is known from previous work.\nFurther, we show consistent changes in the attribution quality when varying the\nnetwork design, indicating that some standard design choices promote\nattribution quality.\n","authors":["Robin Hesse","Simone Schaub-Meyer","Stefan Roth"],"pdf_url":"https://arxiv.org/pdf/2407.11910v2.pdf","comment":"NeurIPS 2024 Datasets and Benchmarks Track, project page and code:\n  https://github.com/visinf/idsds"},{"id":"http://arxiv.org/abs/2412.06410v1","updated":"2024-12-09T11:39:00Z","published":"2024-12-09T11:39:00Z","title":"BatchTopK Sparse Autoencoders","summary":"  Sparse autoencoders (SAEs) have emerged as a powerful tool for interpreting\nlanguage model activations by decomposing them into sparse, interpretable\nfeatures. A popular approach is the TopK SAE, that uses a fixed number of the\nmost active latents per sample to reconstruct the model activations. We\nintroduce BatchTopK SAEs, a training method that improves upon TopK SAEs by\nrelaxing the top-k constraint to the batch-level, allowing for a variable\nnumber of latents to be active per sample. As a result, BatchTopK adaptively\nallocates more or fewer latents depending on the sample, improving\nreconstruction without sacrificing average sparsity. We show that BatchTopK\nSAEs consistently outperform TopK SAEs in reconstructing activations from GPT-2\nSmall and Gemma 2 2B, and achieve comparable performance to state-of-the-art\nJumpReLU SAEs. However, an advantage of BatchTopK is that the average number of\nlatents can be directly specified, rather than approximately tuned through a\ncostly hyperparameter sweep. We provide code for training and evaluating\nBatchTopK SAEs at https://github.com/bartbussmann/BatchTopK\n","authors":["Bart Bussmann","Patrick Leask","Neel Nanda"],"pdf_url":"https://arxiv.org/pdf/2412.06410v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.24070v3","updated":"2024-12-09T11:29:18Z","published":"2024-10-31T16:07:21Z","title":"Dynamical similarity analysis uniquely captures how computations develop\n  in RNNs","summary":"  Methods for analyzing representations in neural systems have become a popular\ntool in both neuroscience and mechanistic interpretability. Having measures to\ncompare how similar activations of neurons are across conditions,\narchitectures, and species, gives us a scalable way of learning how information\nis transformed within different neural networks. In contrast to this trend,\nrecent investigations have revealed how some metrics can respond to spurious\nsignals and hence give misleading results. To identify the most reliable metric\nand understand how measures could be improved, it is going to be important to\nidentify specific test cases which can serve as benchmarks. Here we propose\nthat the phenomena of compositional learning in recurrent neural networks\n(RNNs) allows us to build a test case for dynamical representation alignment\nmetrics. By implementing this case, we show it enables us to test whether\nmetrics can identify representations which gradually develop throughout\nlearning and probe whether representations identified by metrics are relevant\nto computations executed by networks. By building both an attractor- and\nRNN-based test case, we show that the new Dynamical Similarity Analysis (DSA)\nis more noise robust and identifies behaviorally relevant representations more\nreliably than prior metrics (Procrustes, CKA). We also show how test cases can\nbe used beyond evaluating metrics to study new architectures. Specifically,\nresults from applying DSA to modern (Mamba) state space models, suggest that,\nin contrast to RNNs, these models may not exhibit changes to their recurrent\ndynamics due to their expressiveness. Overall, by developing test cases, we\nshow DSA's exceptional ability to detect compositional dynamical motifs,\nthereby enhancing our understanding of how computations unfold in RNNs.\n","authors":["Quentin Guilhot","Michał Wójcik","Jascha Achterberg","Rui Ponte Costa"],"pdf_url":"https://arxiv.org/pdf/2410.24070v3.pdf","comment":"19 pages, 11 figures"},{"id":"http://arxiv.org/abs/2412.06390v1","updated":"2024-12-09T11:17:04Z","published":"2024-12-09T11:17:04Z","title":"Edge Delayed Deep Deterministic Policy Gradient: efficient continuous\n  control for edge scenarios","summary":"  Deep Reinforcement Learning is gaining increasing attention thanks to its\ncapability to learn complex policies in high-dimensional settings. Recent\nadvancements utilize a dual-network architecture to learn optimal policies\nthrough the Q-learning algorithm. However, this approach has notable drawbacks,\nsuch as an overestimation bias that can disrupt the learning process and\ndegrade the performance of the resulting policy. To address this, novel\nalgorithms have been developed that mitigate overestimation bias by employing\nmultiple Q-functions. Edge scenarios, which prioritize privacy, have recently\ngained prominence. In these settings, limited computational resources pose a\nsignificant challenge for complex Machine Learning approaches, making the\nefficiency of algorithms crucial for their performance. In this work, we\nintroduce a novel Reinforcement Learning algorithm tailored for edge scenarios,\ncalled Edge Delayed Deep Deterministic Policy Gradient (EdgeD3). EdgeD3\nenhances the Deep Deterministic Policy Gradient (DDPG) algorithm, achieving\nsignificantly improved performance with $25\\%$ less Graphics Process Unit (GPU)\ntime while maintaining the same memory usage. Additionally, EdgeD3 consistently\nmatches or surpasses the performance of state-of-the-art methods across various\nbenchmarks, all while using $30\\%$ fewer computational resources and requiring\n$30\\%$ less memory.\n","authors":["Alberto Sinigaglia","Niccolò Turcato","Ruggero Carli","Gian Antonio Susto"],"pdf_url":"https://arxiv.org/pdf/2412.06390v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06389v1","updated":"2024-12-09T11:15:47Z","published":"2024-12-09T11:15:47Z","title":"Exploring the Impact of Synthetic Data on Human Gesture Recognition\n  Tasks Using GANs","summary":"  In the evolving domain of Human Activity Recognition (HAR) using Internet of\nThings (IoT) devices, there is an emerging interest in employing Deep\nGenerative Models (DGMs) to address data scarcity, enhance data quality, and\nimprove classification metrics scores. Among these types of models, Generative\nAdversarial Networks (GANs) have arisen as a powerful tool for generating\nsynthetic data that mimic real-world scenarios with high fidelity. However,\nHuman Gesture Recognition (HGR), a subset of HAR, particularly in healthcare\napplications, using time series data such as allergic gestures, remains highly\nunexplored.\n  In this paper, we examine and evaluate the performance of two GANs in the\ngeneration of synthetic gesture motion data that compose a part of an\nopen-source benchmark dataset. The data is related to the disease\nidentification domain and healthcare, specifically to allergic rhinitis. We\nalso focus on these AI models' performance in terms of fidelity, diversity, and\nprivacy. Furthermore, we examine the scenario if the synthetic data can\nsubstitute real data, in training scenarios and how well models trained on\nsynthetic data can be generalized for the allergic rhinitis gestures. In our\nwork, these gestures are related to 6-axes accelerometer and gyroscope data,\nserving as multi-variate time series instances, and retrieved from smart\nwearable devices. To the best of our knowledge, this study is the first to\nexplore the feasibility of synthesizing motion gestures for allergic rhinitis\nfrom wearable IoT device data using Generative Adversarial Networks (GANs) and\ntesting their impact on the generalization of gesture recognition systems. It\nis worth noting that, even if our method has been applied to a specific\ncategory of gestures, it is designed to be generalized and can be deployed also\nto other motion data in the HGR domain.\n","authors":["George Kontogiannis","Pantelis Tzamalis","Sotiris Nikoletseas"],"pdf_url":"https://arxiv.org/pdf/2412.06389v1.pdf","comment":"8 pages, 5 figures, 20th International Conference on Distributed\n  Computing in Smart Systems and the Internet of Things (DCOSS-IoT), 2024"},{"id":"http://arxiv.org/abs/2406.04928v2","updated":"2024-12-09T11:08:35Z","published":"2024-06-07T13:34:17Z","title":"AGBD: A Global-scale Biomass Dataset","summary":"  Accurate estimates of Above Ground Biomass (AGB) are essential in addressing\ntwo of humanity's biggest challenges, climate change and biodiversity loss.\nExisting datasets for AGB estimation from satellite imagery are limited. Either\nthey focus on specific, local regions at high resolution, or they offer global\ncoverage at low resolution. There is a need for a machine learning-ready,\nglobally representative, high-resolution benchmark. Our findings indicate\nsignificant variability in biomass estimates across different vegetation types,\nemphasizing the necessity for a dataset that accurately captures global\ndiversity. To address these gaps, we introduce a comprehensive new dataset that\nis globally distributed, covers a range of vegetation types, and spans several\nyears. This dataset combines AGB reference data from the GEDI mission with data\nfrom Sentinel-2 and PALSAR-2 imagery. Additionally, it includes pre-processed\nhigh-level features such as a dense canopy height map, an elevation map, and a\nland-cover classification map. We also produce a dense, high-resolution (10m)\nmap of AGB predictions for the entire area covered by the dataset. Rigorously\ntested, our dataset is accompanied by several benchmark models and is publicly\navailable. It can be easily accessed using a single line of code, offering a\nsolid basis for efforts towards global AGB estimation. The GitHub repository\ngithub.com/ghjuliasialelli/AGBD serves as a one-stop shop for all code and\ndata.\n","authors":["Ghjulia Sialelli","Torben Peters","Jan D. Wegner","Konrad Schindler"],"pdf_url":"https://arxiv.org/pdf/2406.04928v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06382v1","updated":"2024-12-09T11:00:55Z","published":"2024-12-09T11:00:55Z","title":"PyPulse: A Python Library for Biosignal Imputation","summary":"  We introduce PyPulse, a Python package for imputation of biosignals in both\nclinical and wearable sensor settings. Missingness is commonplace in these\nsettings and can arise from multiple causes, such as insecure sensor attachment\nor data transmission loss. PyPulse's framework provides a modular and\nextendable framework with high ease-of-use for a broad userbase, including\nnon-machine-learning bioresearchers. Specifically, its new capabilities include\nusing pre-trained imputation methods out-of-the-box on custom datasets, running\nthe full workflow of training or testing a baseline method with a single line\nof code, and comparing baseline methods in an interactive visualization tool.\nWe released PyPulse under the MIT License on Github and PyPI. The source code\ncan be found at: https://github.com/rehg-lab/pulseimpute.\n","authors":["Kevin Gao","Maxwell A. Xu","James M. Rehg","Alexander Moreno"],"pdf_url":"https://arxiv.org/pdf/2412.06382v1.pdf","comment":"7 pages, 3 figures. Implementation and documentation are available at\n  https://github.com/rehg-lab/pulseimpute"},{"id":"http://arxiv.org/abs/2412.06381v1","updated":"2024-12-09T10:59:39Z","published":"2024-12-09T10:59:39Z","title":"Gentle robustness implies Generalization","summary":"  Robustness and generalization ability of machine learning models are of\nutmost importance in various application domains. There is a wide interest in\nefficient ways to analyze those properties. One important direction is to\nanalyze connection between those two properties. Prior theories suggest that a\nrobust learning algorithm can produce trained models with a high generalization\nability. However, we show in this work that the existing error bounds are\nvacuous for the Bayes optimal classifier which is the best among all measurable\nclassifiers for a classification problem with overlapping classes. Those bounds\ncannot converge to the true error of this ideal classifier. This is\nundesirable, surprizing, and never known before. We then present a class of\nnovel bounds, which are model-dependent and provably tighter than the existing\nrobustness-based ones. Unlike prior ones, our bounds are guaranteed to converge\nto the true error of the best classifier, as the number of samples increases.\nWe further provide an extensive experiment and find that two of our bounds are\noften non-vacuous for a large class of deep neural networks, pretrained from\nImageNet.\n","authors":["Khoat Than","Dat Phan","Giang Vu"],"pdf_url":"https://arxiv.org/pdf/2412.06381v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06380v1","updated":"2024-12-09T10:58:23Z","published":"2024-12-09T10:58:23Z","title":"Low-Rank Matrix Factorizations with Volume-based Constraints and\n  Regularizations","summary":"  Low-rank matrix factorizations are a class of linear models widely used in\nvarious fields such as machine learning, signal processing, and data analysis.\nThese models approximate a matrix as the product of two smaller matrices, where\nthe left matrix captures latent features while the right matrix linearly\ndecomposes the data based on these features. There are many ways to define what\nmakes a component \"important.\" Standard LRMFs, such as the truncated singular\nvalue decomposition, focus on minimizing the distance between the original\nmatrix and its low-rank approximation. In this thesis, the notion of\n\"importance\" is closely linked to interpretability and uniqueness, which are\nkey to obtaining reliable and meaningful results.\n  This thesis thus focuses on volume-based constraints and regularizations\ndesigned to enhance interpretability and uniqueness. We first introduce two new\nvolume-constrained LRMFs designed to enhance these properties. The first\nassumes that data points are naturally bounded (e.g., movie ratings between 1\nand 5 stars) and can be explained by convex combinations of features within the\nsame bounds, allowing them to be interpreted in the same way as the data. The\nsecond model is more general, constraining the factors to belong to convex\npolytopes. Then, two variants of volume-regularized LRMFs are proposed. The\nfirst minimizes the volume of the latent features, encouraging them to cluster\nclosely together, while the second maximizes the volume of the decompositions,\npromoting sparse representations. Across all these models, uniqueness is\nachieved under the core principle that the factors must be \"sufficiently\nscattered\" within their respective feasible sets.\n  Motivated by applications such as blind source separation and missing data\nimputation, this thesis also proposes efficient algorithms that make these\nmodels practical for real-world applications.\n","authors":["Olivier Vu Thanh"],"pdf_url":"https://arxiv.org/pdf/2412.06380v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.02507v2","updated":"2024-12-09T10:58:16Z","published":"2024-06-04T17:25:59Z","title":"Guiding a Diffusion Model with a Bad Version of Itself","summary":"  The primary axes of interest in image-generating diffusion models are image\nquality, the amount of variation in the results, and how well the results align\nwith a given condition, e.g., a class label or a text prompt. The popular\nclassifier-free guidance approach uses an unconditional model to guide a\nconditional model, leading to simultaneously better prompt alignment and\nhigher-quality images at the cost of reduced variation. These effects seem\ninherently entangled, and thus hard to control. We make the surprising\nobservation that it is possible to obtain disentangled control over image\nquality without compromising the amount of variation by guiding generation\nusing a smaller, less-trained version of the model itself rather than an\nunconditional model. This leads to significant improvements in ImageNet\ngeneration, setting record FIDs of 1.01 for 64x64 and 1.25 for 512x512, using\npublicly available networks. Furthermore, the method is also applicable to\nunconditional diffusion models, drastically improving their quality.\n","authors":["Tero Karras","Miika Aittala","Tuomas Kynkäänniemi","Jaakko Lehtinen","Timo Aila","Samuli Laine"],"pdf_url":"https://arxiv.org/pdf/2406.02507v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2407.13316v3","updated":"2024-12-09T10:46:23Z","published":"2024-07-18T09:17:47Z","title":"Deterministic Trajectory Optimization through Probabilistic Optimal\n  Control","summary":"  In this article, we discuss two algorithms tailored to discrete-time\ndeterministic finite-horizon nonlinear optimal control problems or so-called\ndeterministic trajectory optimization problems. Both algorithms can be derived\nfrom an emerging theoretical paradigm that we refer to as probabilistic optimal\ncontrol. The paradigm reformulates stochastic optimal control as an equivalent\nprobabilistic inference problem and can be viewed as a generalisation of the\nformer. The merit of this perspective is that it allows to address the problem\nusing the Expectation-Maximization algorithm. It is shown that the application\nof this algorithm results in a fixed point iteration of probabilistic policies\nthat converge to the deterministic optimal policy. Two strategies for policy\nevaluation are discussed, using state-of-the-art uncertainty quantification\nmethods resulting into two distinct algorithms. The algorithms are structurally\nclosest related to the differential dynamic programming algorithm and related\nmethods that use sigma-point methods to avoid direct gradient evaluations. The\nmain advantage of the algorithms is an improved balance between exploration and\nexploitation over the iterations, leading to improved numerical stability and\naccelerated convergence. These properties are demonstrated on different\nnonlinear systems.\n","authors":["Mohammad Mahmoudi Filabadi","Tom Lefebvre","Guillaume Crevecoeur"],"pdf_url":"https://arxiv.org/pdf/2407.13316v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06370v1","updated":"2024-12-09T10:44:47Z","published":"2024-12-09T10:44:47Z","title":"Exploring Memorization and Copyright Violation in Frontier LLMs: A Study\n  of the New York Times v. OpenAI 2023 Lawsuit","summary":"  Copyright infringement in frontier LLMs has received much attention recently\ndue to the New York Times v. OpenAI lawsuit, filed in December 2023. The New\nYork Times claims that GPT-4 has infringed its copyrights by reproducing\narticles for use in LLM training and by memorizing the inputs, thereby publicly\ndisplaying them in LLM outputs. Our work aims to measure the propensity of\nOpenAI's LLMs to exhibit verbatim memorization in its outputs relative to other\nLLMs, specifically focusing on news articles. We discover that both GPT and\nClaude models use refusal training and output filters to prevent verbatim\noutput of the memorized articles. We apply a basic prompt template to bypass\nthe refusal training and show that OpenAI models are currently less prone to\nmemorization elicitation than models from Meta, Mistral, and Anthropic. We find\nthat as models increase in size, especially beyond 100 billion parameters, they\ndemonstrate significantly greater capacity for memorization. Our findings have\npractical implications for training: more attention must be placed on\npreventing verbatim memorization in very large models. Our findings also have\nlegal significance: in assessing the relative memorization capacity of OpenAI's\nLLMs, we probe the strength of The New York Times's copyright infringement\nclaims and OpenAI's legal defenses, while underscoring issues at the\nintersection of generative AI, law, and policy.\n","authors":["Joshua Freeman","Chloe Rippe","Edoardo Debenedetti","Maksym Andriushchenko"],"pdf_url":"https://arxiv.org/pdf/2412.06370v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06368v1","updated":"2024-12-09T10:38:30Z","published":"2024-12-09T10:38:30Z","title":"Measuring Pre-training Data Quality without Labels for Time Series\n  Foundation Models","summary":"  Recently, there has been a growing interest in time series foundation models\nthat generalize across different downstream tasks. A key to strong foundation\nmodels is a diverse pre-training dataset, which is particularly challenging to\ncollect for time series classification. In this work, we explore the\nperformance of a contrastive-learning-based foundation model as a function of\nthe data used for pre-training. We introduce contrastive accuracy, a new\nmeasure to evaluate the quality of the representation space learned by the\nfoundation model. Our experiments reveal the positive correlation between the\nproposed measure and the accuracy of the model on a collection of downstream\ntasks. This suggests that the contrastive accuracy can serve as a criterion to\nsearch for time series datasets that can enhance the pre-training and improve\nthereby the foundation model's generalization.\n","authors":["Songkang Wen","Vasilii Feofanov","Jianfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.06368v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14725v3","updated":"2024-12-09T10:33:44Z","published":"2023-11-20T10:21:50Z","title":"Identifying percolation phase transitions with unsupervised learning\n  based on largest clusters","summary":"  The application of machine learning in the study of phase transitions has\nachieved remarkable success in both equilibrium and non-equilibrium systems. It\nis widely recognized that unsupervised learning can retrieve phase transition\ninformation through hidden variables. However, using unsupervised methods to\nidentify the critical point of percolation models has remained an intriguing\nchallenge. This paper suggests that, by inputting the largest cluster rather\nthan the original configuration into the learning model, unsupervised learning\ncan indeed predict the critical point of the percolation model. Furthermore, we\nobserve that when the largest cluster configuration is randomly\nshuffled-altering the positions of occupied sites or bonds-there is no\nsignificant difference in the output compared to learning the largest cluster\nconfiguration directly. This finding suggests a more general principle:\nunsupervised learning primarily captures particle density, or more\nspecifically, occupied site density. However, shuffling does impact the\nformation of the largest cluster, which is directly related to phase\ntransitions. As randomness increases, we observe that the correlation length\ntends to decrease, providing direct evidence of this relationship. We also\npropose a method called Fake Finite Size Scaling (FFSS) to calculate the\ncritical value, which improves the accuracy of fitting to a great extent.\n","authors":["Dian Xu","Shanshan Wang","Weibing Deng","Feng Gao","Wei Li","Jianmin Shen"],"pdf_url":"https://arxiv.org/pdf/2311.14725v3.pdf","comment":"15 pages,40 figures,39 references"},{"id":"http://arxiv.org/abs/2412.06354v1","updated":"2024-12-09T10:14:01Z","published":"2024-12-09T10:14:01Z","title":"GraphNeuralNetworks.jl: Deep Learning on Graphs with Julia","summary":"  GraphNeuralNetworks.jl is an open-source framework for deep learning on\ngraphs, written in the Julia programming language. It supports multiple GPU\nbackends, generic sparse or dense graph representations, and offers convenient\ninterfaces for manipulating standard, heterogeneous, and temporal graphs with\nattributes at the node, edge, and graph levels. The framework allows users to\ndefine custom graph convolutional layers using gather/scatter message-passing\nprimitives or optimized fused operations. It also includes several popular\nlayers, enabling efficient experimentation with complex deep architectures. The\npackage is available on GitHub:\n\\url{https://github.com/JuliaGraphs/GraphNeuralNetworks.jl}.\n","authors":["Carlo Lucibello","Aurora Rossi"],"pdf_url":"https://arxiv.org/pdf/2412.06354v1.pdf","comment":"Submitted to JMLR OSS"},{"id":"http://arxiv.org/abs/2403.03945v3","updated":"2024-12-09T10:10:40Z","published":"2024-03-06T18:52:39Z","title":"SPEAR:Exact Gradient Inversion of Batches in Federated Learning","summary":"  Federated learning is a framework for collaborative machine learning where\nclients only share gradient updates and not their private data with a server.\nHowever, it was recently shown that gradient inversion attacks can reconstruct\nthis data from the shared gradients. In the important honest-but-curious\nsetting, existing attacks enable exact reconstruction only for batch size of\n$b=1$, with larger batches permitting only approximate reconstruction. In this\nwork, we propose SPEAR, the first algorithm reconstructing whole batches with\n$b >1$ exactly. SPEAR combines insights into the explicit low-rank structure of\ngradients with a sampling-based algorithm. Crucially, we leverage ReLU-induced\ngradient sparsity to precisely filter out large numbers of incorrect samples,\nmaking a final reconstruction step tractable. We provide an efficient GPU\nimplementation for fully connected networks and show that it recovers\nhigh-dimensional ImageNet inputs in batches of up to $b \\lesssim 25$ exactly\nwhile scaling to large networks. Finally, we show theoretically that much\nlarger batches can be reconstructed with high probability given exponential\ntime.\n","authors":["Dimitar I. Dimitrov","Maximilian Baader","Mark Niklas Müller","Martin Vechev"],"pdf_url":"https://arxiv.org/pdf/2403.03945v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06342v1","updated":"2024-12-09T09:49:15Z","published":"2024-12-09T09:49:15Z","title":"Tracking control of latent dynamic systems with application to\n  spacecraft attitude control","summary":"  When intelligent spacecraft or space robots perform tasks in a complex\nenvironment, the controllable variables are usually not directly available and\nhave to be inferred from high-dimensional observable variables, such as outputs\nof neural networks or images. While the dynamics of these observations are\nhighly complex, the mechanisms behind them may be simple, which makes it\npossible to regard them as latent dynamic systems. For control of latent\ndynamic systems, methods based on reinforcement learning suffer from sample\ninefficiency and generalization problems. In this work, we propose an\nasymptotic tracking controller for latent dynamic systems. The latent variables\nare related to the high-dimensional observations through an unknown nonlinear\nfunction. The dynamics are unknown but assumed to be affine nonlinear. To\nrealize asymptotic tracking, an identifiable latent dynamic model is learned to\nrecover the latents and estimate the dynamics. This training process does not\ndepend on the goals or reference trajectories. Based on the learned model, we\nuse a manually designed feedback linearization controller to ensure the\nasymptotic tracking property of the closed-loop system. After considering fully\ncontrollable systems, the results are extended to the case that uncontrollable\nenvironmental latents exist. As an application, simulation experiments on a\nlatent spacecraft attitude dynamic model are conducted to verify the proposed\nmethods, and the observation noise and control deviation are taken into\nconsideration.\n","authors":["Congxi Zhang","Yongchun Xie"],"pdf_url":"https://arxiv.org/pdf/2412.06342v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06333v1","updated":"2024-12-09T09:34:40Z","published":"2024-12-09T09:34:40Z","title":"Augmenting the action space with conventions to improve multi-agent\n  cooperation in Hanabi","summary":"  The card game Hanabi is considered a strong medium for the testing and\ndevelopment of multi-agent reinforcement learning (MARL) algorithms, due to its\ncooperative nature, hidden information, limited communication and remarkable\ncomplexity. Previous research efforts have explored the capabilities of MARL\nalgorithms within Hanabi, focusing largely on advanced architecture design and\nalgorithmic manipulations to achieve state-of-the-art performance for a various\nnumber of cooperators. However, this often leads to complex solution strategies\nwith high computational cost and requiring large amounts of training data. For\nhumans to solve the Hanabi game effectively, they require the use of\nconventions, which often allows for a means to implicitly convey ideas or\nknowledge based on a predefined, and mutually agreed upon, set of ``rules''.\nMulti-agent problems containing partial observability, especially when limited\ncommunication is present, can benefit greatly from the use of implicit\nknowledge sharing. In this paper, we propose a novel approach to augmenting the\naction space using conventions, which act as special cooperative actions that\nspan over multiple time steps and multiple agents, requiring agents to actively\nopt in for it to reach fruition. These conventions are based on existing human\nconventions, and result in a significant improvement on the performance of\nexisting techniques for self-play and cross-play across a various number of\ncooperators within Hanabi.\n","authors":["F. Bredell","H. A. Engelbrecht","J. C. Schoeman"],"pdf_url":"https://arxiv.org/pdf/2412.06333v1.pdf","comment":"This paper is under review at the journal of autonomous agents and\n  multi-agent systems (JAAMAS)"},{"id":"http://arxiv.org/abs/2412.06332v1","updated":"2024-12-09T09:32:20Z","published":"2024-12-09T09:32:20Z","title":"Not All Errors Are Equal: Investigation of Speech Recognition Errors in\n  Alzheimer's Disease Detection","summary":"  Automatic Speech Recognition (ASR) plays an important role in speech-based\nautomatic detection of Alzheimer's disease (AD). However, recognition errors\ncould propagate downstream, potentially impacting the detection decisions.\nRecent studies have revealed a non-linear relationship between word error rates\n(WER) and AD detection performance, where ASR transcriptions with notable\nerrors could still yield AD detection accuracy equivalent to that based on\nmanual transcriptions. This work presents a series of analyses to explore the\neffect of ASR transcription errors in BERT-based AD detection systems. Our\ninvestigation reveals that not all ASR errors contribute equally to detection\nperformance. Certain words, such as stopwords, despite constituting a large\nproportion of errors, are shown to play a limited role in distinguishing AD. In\ncontrast, the keywords related to diagnosis tasks exhibit significantly greater\nimportance relative to other words. These findings provide insights into the\ninterplay between ASR errors and the downstream detection model.\n","authors":["Jiawen Kang","Junan Li","Jinchao Li","Xixin Wu","Helen Meng"],"pdf_url":"https://arxiv.org/pdf/2412.06332v1.pdf","comment":"Accepted by IEEE ISCSLP 2024"},{"id":"http://arxiv.org/abs/2407.17543v2","updated":"2024-12-09T09:28:34Z","published":"2024-07-24T15:23:26Z","title":"Dataset Distribution Impacts Model Fairness: Single vs. Multi-Task\n  Learning","summary":"  The influence of bias in datasets on the fairness of model predictions is a\ntopic of ongoing research in various fields. We evaluate the performance of\nskin lesion classification using ResNet-based CNNs, focusing on patient sex\nvariations in training data and three different learning strategies. We present\na linear programming method for generating datasets with varying patient sex\nand class labels, taking into account the correlations between these variables.\nWe evaluated the model performance using three different learning strategies: a\nsingle-task model, a reinforcing multi-task model, and an adversarial learning\nscheme. Our observations include: 1) sex-specific training data yields better\nresults, 2) single-task models exhibit sex bias, 3) the reinforcement approach\ndoes not remove sex bias, 4) the adversarial model eliminates sex bias in cases\ninvolving only female patients, and 5) datasets that include male patients\nenhance model performance for the male subgroup, even when female patients are\nthe majority. To generalise these findings, in future research, we will examine\nmore demographic attributes, like age, and other possibly confounding factors,\nsuch as skin colour and artefacts in the skin lesions. We make all data and\nmodels available on GitHub.\n","authors":["Ralf Raumanns","Gerard Schouten","Josien P. W. Pluim","Veronika Cheplygina"],"pdf_url":"https://arxiv.org/pdf/2407.17543v2.pdf","comment":"Published in the FAIMI EPIMI 2024 Workshop"},{"id":"http://arxiv.org/abs/2412.06329v1","updated":"2024-12-09T09:28:06Z","published":"2024-12-09T09:28:06Z","title":"Normalizing Flows are Capable Generative Models","summary":"  Normalizing Flows (NFs) are likelihood-based models for continuous inputs.\n  They have demonstrated promising results on both density estimation and\ngenerative modeling tasks, but have received relatively little attention in\nrecent years.\n  In this work, we demonstrate that NFs are more powerful than previously\nbelieved.\n  We present \\textit{TarFlow}: a simple and scalable architecture that enables\nhighly performant NF models.\n  TarFlow can be thought of as a Transformer-based variant\n  of Masked Autoregressive Flows (MAFs): it consists of a\n  stack of autoregressive Transformer blocks on image patches,\n  alternating the autoregression direction between layers.\n  TarFlow is straightforward to train end-to-end,\n  and capable of directly modeling and generating pixels.\n  We also propose three key techniques to improve sample quality: Gaussian\nnoise augmentation during training, a post training denoising procedure,\n  and an effective guidance method for both class-conditional and\n  unconditional settings.\n  Putting these together,\n  TarFlow sets new state-of-the-art results on likelihood estimation for\nimages, beating the previous best methods by a large margin,\n  and generates samples with quality and diversity comparable to diffusion\nmodels, for the first time with a stand-alone NF model. We make our code\navailable at\n\\href{https://github.com/apple/ml-tarflow}{https://github.com/apple/ml-tarflow}.\n","authors":["Shuangfei Zhai","Ruixiang Zhang","Preetum Nakkiran","David Berthelot","Jiatao Gu","Huangjie Zheng","Tianrong Chen","Miguel Angel Bautista","Navdeep Jaitly","Josh Susskind"],"pdf_url":"https://arxiv.org/pdf/2412.06329v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.20587v2","updated":"2024-12-09T09:26:23Z","published":"2024-10-27T20:47:29Z","title":"Generator Matching: Generative modeling with arbitrary Markov processes","summary":"  We introduce generator matching, a modality-agnostic framework for generative\nmodeling using arbitrary Markov processes. Generators characterize the\ninfinitesimal evolution of a Markov process, which we leverage for generative\nmodeling in a similar vein to flow matching: we construct conditional\ngenerators which generate single data points, then learn to approximate the\nmarginal generator which generates the full data distribution. We show that\ngenerator matching unifies various generative modeling methods, including\ndiffusion models, flow matching and discrete diffusion models. Furthermore, it\nprovides the foundation to expand the design space to new and unexplored Markov\nprocesses such as jump processes. Finally, generator matching enables the\nconstruction of superpositions of Markov generative processes and enables the\nconstruction of multimodal models in a rigorous manner. We empirically validate\nour method on protein and image structure generation, showing that\nsuperposition with a jump process improves image generation.\n","authors":["Peter Holderrieth","Marton Havasi","Jason Yim","Neta Shaul","Itai Gat","Tommi Jaakkola","Brian Karrer","Ricky T. Q. Chen","Yaron Lipman"],"pdf_url":"https://arxiv.org/pdf/2410.20587v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.16560v2","updated":"2024-12-09T09:21:17Z","published":"2024-05-26T13:11:55Z","title":"Task Groupings Regularization: Data-Free Meta-Learning with\n  Heterogeneous Pre-trained Models","summary":"  Data-Free Meta-Learning (DFML) aims to derive knowledge from a collection of\npre-trained models without accessing their original data, enabling the rapid\nadaptation to new unseen tasks. Current methods often overlook the\nheterogeneity among pre-trained models, which leads to performance degradation\ndue to task conflicts. In this paper, we empirically and theoretically identify\nand analyze the model heterogeneity in DFML. We find that model heterogeneity\nintroduces a heterogeneity-homogeneity trade-off, where homogeneous models\nreduce task conflicts but also increase the overfitting risk. Balancing this\ntrade-off is crucial for learning shared representations across tasks. Based on\nour findings, we propose Task Groupings Regularization that benefits from model\nheterogeneity by grouping and aligning conflicting tasks. Specifically, we\nembed pre-trained models into a task space to compute dissimilarity, and group\nheterogeneous models together based on this measure. Then, we introduce\nimplicit gradient regularization within each group to mitigate potential\nconflicts. By encouraging a gradient direction suitable for all tasks, the\nmeta-model captures shared representations that generalize across tasks.\nComprehensive experiments showcase the superiority of our approach in multiple\nbenchmarks, effectively tackling the model heterogeneity in challenging\nmulti-domain and multi-architecture scenarios.\n","authors":["Yongxian Wei","Zixuan Hu","Li Shen","Zhenyi Wang","Yu Li","Chun Yuan","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2405.16560v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.10266v3","updated":"2024-12-09T09:14:47Z","published":"2024-07-14T16:20:42Z","title":"psifx -- Psychological and Social Interactions Feature Extraction\n  Package","summary":"  psifx is a plug-and-play multi-modal feature extraction toolkit, aiming to\nfacilitate and democratize the use of state-of-the-art machine learning\ntechniques for human sciences research. It is motivated by a need (a) to\nautomate and standardize data annotation processes, otherwise involving\nexpensive, lengthy, and inconsistent human labor, such as the transcription or\ncoding of behavior changes from audio and video sources; (b) to develop and\ndistribute open-source community-driven psychology research software; and (c)\nto enable large-scale access and ease of use to non-expert users. The framework\ncontains an array of tools for tasks, such as speaker diarization,\nclosed-caption transcription and translation from audio, as well as body, hand,\nand facial pose estimation and gaze tracking from video. The package has been\ndesigned with a modular and task-oriented approach, enabling the community to\nadd or update new tools easily. We strongly hope that this package will provide\npsychologists a simple and practical solution for efficiently a range of audio,\nlinguistic, and visual features from audio and video, thereby creating new\nopportunities for in-depth study of real-time behavioral phenomena.\n","authors":["Guillaume Rochette","Matthew J. Vowels","Mathieu Rochat"],"pdf_url":"https://arxiv.org/pdf/2407.10266v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.17797v2","updated":"2024-12-09T09:12:00Z","published":"2023-11-29T16:46:24Z","title":"Learning to Simulate: Generative Metamodeling via Quantile Regression","summary":"  Stochastic simulation models effectively capture complex system dynamics but\nare often too slow for real-time decision-making. Traditional metamodeling\ntechniques learn relationships between simulator inputs and a single output\nsummary statistic, such as the mean or median. These techniques enable\nreal-time predictions without additional simulations. However, they require\nprior selection of one appropriate output summary statistic, limiting their\nflexibility in practical applications. We propose a new concept: generative\nmetamodeling. It aims to construct a \"fast simulator of the simulator,\"\ngenerating random outputs significantly faster than the original simulator\nwhile preserving approximately equal conditional distributions. Generative\nmetamodels enable rapid generation of numerous random outputs upon input\nspecification, facilitating immediate computation of any summary statistic for\nreal-time decision-making. We introduce a new algorithm,\nquantile-regression-based generative metamodeling (QRGMM), and establish its\ndistributional convergence and convergence rate. Extensive numerical\nexperiments demonstrate QRGMM's efficacy compared to other state-of-the-art\ngenerative algorithms in practical real-time decision-making scenarios.\n","authors":["L. Jeff Hong","Yanxi Hou","Qingkai Zhang","Xiaowei Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.17797v2.pdf","comment":"Main body: 42 pages, 10 figures; supplemental material: 22 pages"},{"id":"http://arxiv.org/abs/2412.06313v1","updated":"2024-12-09T09:05:52Z","published":"2024-12-09T09:05:52Z","title":"Vision-Based Deep Reinforcement Learning of UAV Autonomous Navigation\n  Using Privileged Information","summary":"  The capability of UAVs for efficient autonomous navigation and obstacle\navoidance in complex and unknown environments is critical for applications in\nagricultural irrigation, disaster relief and logistics. In this paper, we\npropose the DPRL (Distributed Privileged Reinforcement Learning) navigation\nalgorithm, an end-to-end policy designed to address the challenge of high-speed\nautonomous UAV navigation under partially observable environmental conditions.\nOur approach combines deep reinforcement learning with privileged learning to\novercome the impact of observation data corruption caused by partial\nobservability. We leverage an asymmetric Actor-Critic architecture to provide\nthe agent with privileged information during training, which enhances the\nmodel's perceptual capabilities. Additionally, we present a multi-agent\nexploration strategy across diverse environments to accelerate experience\ncollection, which in turn expedites model convergence. We conducted extensive\nsimulations across various scenarios, benchmarking our DPRL algorithm against\nthe state-of-the-art navigation algorithms. The results consistently\ndemonstrate the superior performance of our algorithm in terms of flight\nefficiency, robustness and overall success rate.\n","authors":["Junqiao Wang","Zhongliang Yu","Dong Zhou","Jiaqi Shi","Runran Deng"],"pdf_url":"https://arxiv.org/pdf/2412.06313v1.pdf","comment":"19 pages, 9 figures"},{"id":"http://arxiv.org/abs/2405.00984v2","updated":"2024-12-09T09:05:23Z","published":"2024-05-02T03:43:19Z","title":"FREE: Faster and Better Data-Free Meta-Learning","summary":"  Data-Free Meta-Learning (DFML) aims to extract knowledge from a collection of\npre-trained models without requiring the original data, presenting practical\nbenefits in contexts constrained by data privacy concerns. Current DFML methods\nprimarily focus on the data recovery from these pre-trained models. However,\nthey suffer from slow recovery speed and overlook gaps inherent in\nheterogeneous pre-trained models. In response to these challenges, we introduce\nthe Faster and Better Data-Free Meta-Learning (FREE) framework, which contains:\n(i) a meta-generator for rapidly recovering training tasks from pre-trained\nmodels; and (ii) a meta-learner for generalizing to new unseen tasks.\nSpecifically, within the module Faster Inversion via Meta-Generator, each\npre-trained model is perceived as a distinct task. The meta-generator can\nrapidly adapt to a specific task in just five steps, significantly accelerating\nthe data recovery. Furthermore, we propose Better Generalization via\nMeta-Learner and introduce an implicit gradient alignment algorithm to optimize\nthe meta-learner. This is achieved as aligned gradient directions alleviate\npotential conflicts among tasks from heterogeneous pre-trained models.\nEmpirical experiments on multiple benchmarks affirm the superiority of our\napproach, marking a notable speed-up (20$\\times$) and performance enhancement\n(1.42%$\\sim$4.78%) in comparison to the state-of-the-art.\n","authors":["Yongxian Wei","Zixuan Hu","Zhenyi Wang","Li Shen","Chun Yuan","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2405.00984v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.09236v2","updated":"2024-12-09T09:00:53Z","published":"2024-02-14T15:23:59Z","title":"Learning Interpretable Concepts: Unifying Causal Representation Learning\n  and Foundation Models","summary":"  To build intelligent machine learning systems, there are two broad\napproaches. One approach is to build inherently interpretable models, as\nendeavored by the growing field of causal representation learning. The other\napproach is to build highly-performant foundation models and then invest\nefforts into understanding how they work. In this work, we relate these two\napproaches and study how to learn human-interpretable concepts from data.\nWeaving together ideas from both fields, we formally define a notion of\nconcepts and show that they can be provably recovered from diverse data.\nExperiments on synthetic data and large language models show the utility of our\nunified approach.\n","authors":["Goutham Rajendran","Simon Buchholz","Bryon Aragam","Bernhard Schölkopf","Pradeep Ravikumar"],"pdf_url":"https://arxiv.org/pdf/2402.09236v2.pdf","comment":"To appear in NeurIPS 2024 under the modified title 'From Causal to\n  Concept-Based Representation Learning'"},{"id":"http://arxiv.org/abs/2407.08464v2","updated":"2024-12-09T08:50:46Z","published":"2024-07-11T13:01:18Z","title":"TLDR: Unsupervised Goal-Conditioned RL via Temporal Distance-Aware\n  Representations","summary":"  Unsupervised goal-conditioned reinforcement learning (GCRL) is a promising\nparadigm for developing diverse robotic skills without external supervision.\nHowever, existing unsupervised GCRL methods often struggle to cover a wide\nrange of states in complex environments due to their limited exploration and\nsparse or noisy rewards for GCRL. To overcome these challenges, we propose a\nnovel unsupervised GCRL method that leverages TemporaL Distance-aware\nRepresentations (TLDR). Based on temporal distance, TLDR selects faraway goals\nto initiate exploration and computes intrinsic exploration rewards and\ngoal-reaching rewards. Specifically, our exploration policy seeks states with\nlarge temporal distances (i.e. covering a large state space), while the\ngoal-conditioned policy learns to minimize the temporal distance to the goal\n(i.e. reaching the goal). Our results in six simulated locomotion environments\ndemonstrate that TLDR significantly outperforms prior unsupervised GCRL methods\nin achieving a wide range of states.\n","authors":["Junik Bae","Kwanyoung Park","Youngwoon Lee"],"pdf_url":"https://arxiv.org/pdf/2407.08464v2.pdf","comment":"CoRL 2024"},{"id":"http://arxiv.org/abs/2412.06303v1","updated":"2024-12-09T08:47:05Z","published":"2024-12-09T08:47:05Z","title":"DSAI: Unbiased and Interpretable Latent Feature Extraction for\n  Data-Centric AI","summary":"  Large language models (LLMs) often struggle to objectively identify latent\ncharacteristics in large datasets due to their reliance on pre-trained\nknowledge rather than actual data patterns. To address this data grounding\nissue, we propose Data Scientist AI (DSAI), a framework that enables unbiased\nand interpretable feature extraction through a multi-stage pipeline with\nquantifiable prominence metrics for evaluating extracted features. On synthetic\ndatasets with known ground-truth features, DSAI demonstrates high recall in\nidentifying expert-defined features while faithfully reflecting the underlying\ndata. Applications on real-world datasets illustrate the framework's practical\nutility in uncovering meaningful patterns with minimal expert oversight,\nsupporting use cases such as interpretable classification.\n  The title of our paper is chosen from multiple candidates based on\nDSAI-generated criteria.\n","authors":["Hyowon Cho","Soonwon Ka","Daechul Park","Jaewook Kang","Minjoon Seo","Bokyung Son"],"pdf_url":"https://arxiv.org/pdf/2412.06303v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06289v1","updated":"2024-12-09T08:24:11Z","published":"2024-12-09T08:24:11Z","title":"S$^{2}$FT: Efficient, Scalable and Generalizable LLM Fine-tuning by\n  Structured Sparsity","summary":"  Current PEFT methods for LLMs can achieve either high quality, efficient\ntraining, or scalable serving, but not all three simultaneously. To address\nthis limitation, we investigate sparse fine-tuning and observe a remarkable\nimprovement in generalization ability. Utilizing this key insight, we propose a\nfamily of Structured Sparse Fine-Tuning (S$^{2}$FT) methods for LLMs, which\nconcurrently achieve state-of-the-art fine-tuning performance, training\nefficiency, and inference scalability. S$^{2}$FT accomplishes this by\n\"selecting sparsely and computing densely\". It selects a few heads and channels\nin the MHA and FFN modules for each Transformer block, respectively. Next, it\nco-permutes weight matrices on both sides of the coupled structures in LLMs to\nconnect the selected components in each layer into a dense submatrix. Finally,\nS$^{2}$FT performs in-place gradient updates on all submatrices. Through\ntheoretical analysis and empirical results, our method prevents overfitting and\nforgetting, delivers SOTA performance on both commonsense and arithmetic\nreasoning with 4.6% and 1.3% average improvements compared to LoRA, and\nsurpasses full FT by 11.5% when generalizing to various domains after\ninstruction tuning. Using our partial backpropagation algorithm, S$^{2}$FT\nsaves training memory up to 3$\\times$ and improves latency by 1.5-2.7$\\times$\ncompared to full FT, while delivering an average 10% improvement over LoRA on\nboth metrics. We further demonstrate that the weight updates in S$^{2}$FT can\nbe decoupled into adapters, enabling effective fusion, fast switch, and\nefficient parallelism for serving multiple fine-tuned models.\n","authors":["Xinyu Yang","Jixuan Leng","Geyang Guo","Jiawei Zhao","Ryumei Nakada","Linjun Zhang","Huaxiu Yao","Beidi Chen"],"pdf_url":"https://arxiv.org/pdf/2412.06289v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.01585v3","updated":"2024-12-09T07:57:49Z","published":"2024-12-02T15:04:51Z","title":"FairML: A Julia Package for Fair Classification","summary":"  In this paper, we propose FairML.jl, a Julia package providing a framework\nfor fair classification in machine learning. In this framework, the fair\nlearning process is divided into three stages. Each stage aims to reduce\nunfairness, such as disparate impact and disparate mistreatment, in the final\nprediction. For the preprocessing stage, we present a resampling method that\naddresses unfairness coming from data imbalances. The in-processing phase\nconsist of a classification method. This can be either one coming from the\nMLJ.jl package, or a user defined one. For this phase, we incorporate fair ML\nmethods that can handle unfairness to a certain degree through their\noptimization process. In the post-processing, we discuss the choice of the\ncut-off value for fair prediction. With simulations, we show the performance of\nthe single phases and their combinations.\n","authors":["Jan Pablo Burgard","João Vitor Pamplona"],"pdf_url":"https://arxiv.org/pdf/2412.01585v3.pdf","comment":"25 pages, 8 figures"},{"id":"http://arxiv.org/abs/2412.06265v1","updated":"2024-12-09T07:24:31Z","published":"2024-12-09T07:24:31Z","title":"Table2Image: Interpretable Tabular data Classification with Realistic\n  Image Transformations","summary":"  Recent advancements in deep learning for tabular data have demonstrated\npromising performance, yet interpretable models remain limited, with many\nrelying on complex and large-scale architectures. This paper introduces\nTable2Image, an interpretable framework that transforms tabular data into\nrealistic image representations for classification, achieving competitive\nperformance with relatively lightweight models. Additionally, we propose\nvariance inflation factor (VIF) initialization, which reflects the statistical\nproperties of the data, and a novel interpretability framework that integrates\ninsights from both the original tabular data and its image transformations. By\nleveraging Shapley additive explanations (SHAP) with methods to minimize\ndistributional discrepancies, our approach combines tabular and image-based\nrepresentations. Experiments on benchmark datasets showcase competitive\nclassification accuracy, area under the curve (AUC), and improved\ninterpretability, offering a scalable and reliable solution. Our code is\navailable at https://github.com/duneag2/table2image.\n","authors":["Seungeun Lee","Seungsang Oh"],"pdf_url":"https://arxiv.org/pdf/2412.06265v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06264v1","updated":"2024-12-09T07:22:38Z","published":"2024-12-09T07:22:38Z","title":"Flow Matching Guide and Code","summary":"  Flow Matching (FM) is a recent framework for generative modeling that has\nachieved state-of-the-art performance across various domains, including image,\nvideo, audio, speech, and biological structures. This guide offers a\ncomprehensive and self-contained review of FM, covering its mathematical\nfoundations, design choices, and extensions. By also providing a PyTorch\npackage featuring relevant examples (e.g., image and text generation), this\nwork aims to serve as a resource for both novice and experienced researchers\ninterested in understanding, applying and further developing FM.\n","authors":["Yaron Lipman","Marton Havasi","Peter Holderrieth","Neta Shaul","Matt Le","Brian Karrer","Ricky T. Q. Chen","David Lopez-Paz","Heli Ben-Hamu","Itai Gat"],"pdf_url":"https://arxiv.org/pdf/2412.06264v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.09273v8","updated":"2024-12-09T07:14:54Z","published":"2024-05-15T11:42:41Z","title":"Fair Generalized Linear Mixed Models","summary":"  When using machine learning for automated prediction, it is important to\naccount for fairness in the prediction. Fairness in machine learning aims to\nensure that biases in the data and model inaccuracies do not lead to\ndiscriminatory decisions. E.g., predictions from fair machine learning models\nshould not discriminate against sensitive variables such as sexual orientation\nand ethnicity. The training data often in obtained from social surveys. In\nsocial surveys, oftentimes the data collection process is a strata sampling,\ne.g. due to cost restrictions. In strata samples, the assumption of\nindependence between the observation is not fulfilled. Hence, if the machine\nlearning models do not account for the strata correlations, the results may be\nbiased. Especially high is the bias in cases where the strata assignment is\ncorrelated to the variable of interest. We present in this paper an algorithm\nthat can handle both problems simultaneously, and we demonstrate the impact of\nstratified sampling on the quality of fair machine learning predictions in a\nreproducible simulation study.\n","authors":["Jan Pablo Burgard","João Vitor Pamplona"],"pdf_url":"https://arxiv.org/pdf/2405.09273v8.pdf","comment":"25 pages, 12 figures. arXiv admin note: text overlap with\n  arXiv:2405.06433"},{"id":"http://arxiv.org/abs/2404.11869v5","updated":"2024-12-09T06:54:48Z","published":"2024-04-18T03:03:37Z","title":"An Efficient Loop and Clique Coarsening Algorithm for Graph\n  Classification","summary":"  Graph Transformers (GTs) have made remarkable achievements in graph-level\ntasks. However, most existing works regard graph structures as a form of\nguidance or bias for enhancing node representations, which focuses on\nnode-central perspectives and lacks explicit representations of edges and\nstructures. One natural question arises as to whether we can leverage a\nhypernode to represent some structures. Through experimental analysis, we\nexplore the feasibility of this assumption. Based on our findings, we propose\nan efficient Loop and Clique Coarsening algorithm with linear complexity for\nGraph Classification (LCC4GC) on GT architecture. Specifically, we build three\nunique views, original, coarsening, and conversion, to learn a thorough\nstructural representation. We compress loops and cliques via hierarchical\nheuristic graph coarsening and restrict them with well-designed constraints,\nwhich builds the coarsening view to learn high-level interactions between\nstructures. We also introduce line graphs for edge embeddings and switch to\nedge-central perspective to alleviate the impact of coarsening reduction.\nExperiments on eight real-world datasets demonstrate the improvements of LCC4GC\nover 31 baselines from various architectures.\n","authors":["Xiaorui Qi","Qijie Bai","Yanlong Wen","Haiwei Zhang","Xiaojie Yuan"],"pdf_url":"https://arxiv.org/pdf/2404.11869v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06249v1","updated":"2024-12-09T06:47:42Z","published":"2024-12-09T06:47:42Z","title":"Optimizing Multi-Task Learning for Enhanced Performance in Large\n  Language Models","summary":"  This study aims to explore the performance improvement method of large\nlanguage models based on GPT-4 under the multi-task learning framework and\nconducts experiments on two tasks: text classification and automatic summary\ngeneration. Through the combined design of shared feature extractors and\ntask-specific modules, we achieve knowledge-sharing and optimization of\nmultiple tasks in the same model. The experiment uses multiple subtasks of the\nGLUE dataset to compare the performance of the multi-task model with the\nsingle-task GPT-4, the multi-task version of GPT-3, the BERT basic model, and\nthe classic Bi-LSTM with Attention model. The results show that the proposed\nmulti-task learning model outperforms other comparison models in terms of text\nclassification accuracy and ROUGE value of summary generation, demonstrating\nthe advantages of multi-task learning in improving model generalization ability\nand collaborative learning between tasks. The model maintains a stable loss\nconvergence rate during training, showing good learning efficiency and\nadaptability to the test set. This study verifies the applicability of the\nmulti-task learning framework in large language models, especially in improving\nthe model's ability to balance different tasks. In the future, with the\ncombination of large language models and multimodal data and the application of\ndynamic task adjustment technology, the framework based on multi-task learning\nis expected to play a greater role in practical applications across fields and\nprovide new ideas for the development of general artificial intelligence.\n","authors":["Zhen Qi","Jiajing Chen","Shuo Wang","Bingying Liu","Hongye Zheng","Chihang Wang"],"pdf_url":"https://arxiv.org/pdf/2412.06249v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.01843v5","updated":"2024-12-09T06:38:53Z","published":"2024-05-03T04:26:03Z","title":"Closing the Gap: Achieving Global Convergence (Last Iterate) of\n  Actor-Critic under Markovian Sampling with Neural Network Parametrization","summary":"  The current state-of-the-art theoretical analysis of Actor-Critic (AC)\nalgorithms significantly lags in addressing the practical aspects of AC\nimplementations. This crucial gap needs bridging to bring the analysis in line\nwith practical implementations of AC. To address this, we advocate for\nconsidering the MMCLG criteria: \\textbf{M}ulti-layer neural network\nparametrization for actor/critic, \\textbf{M}arkovian sampling,\n\\textbf{C}ontinuous state-action spaces, the performance of the \\textbf{L}ast\niterate, and \\textbf{G}lobal optimality. These aspects are practically\nsignificant and have been largely overlooked in existing theoretical analyses\nof AC algorithms. In this work, we address these gaps by providing the first\ncomprehensive theoretical analysis of AC algorithms that encompasses all five\ncrucial practical aspects (covers MMCLG criteria). We establish global\nconvergence sample complexity bounds of\n$\\tilde{\\mathcal{O}}\\left({\\epsilon^{-3}}\\right)$. We achieve this result\nthrough our novel use of the weak gradient domination property of MDP's and our\nunique analysis of the error in critic estimation.\n","authors":["Mudit Gaur","Amrit Singh Bedi","Di Wang","Vaneet Aggarwal"],"pdf_url":"https://arxiv.org/pdf/2405.01843v5.pdf","comment":"Accepted at ICML 2024. This is a revised version of arXiv:2306.10486,\n  where we have gone from finite action space to continuous action space, from\n  average iterate convergence to last iterate convergence and from\n  $\\epsilon^{-4}$ to $\\epsilon^{-3}$ sample complexity. This version fixes the\n  related work result of (Xu et al., 2020a), based on their result update on\n  arXiv"},{"id":"http://arxiv.org/abs/2403.14713v3","updated":"2024-12-09T06:30:38Z","published":"2024-03-18T21:09:06Z","title":"Auditing Fairness under Unobserved Confounding","summary":"  Many definitions of fairness or inequity involve unobservable causal\nquantities that cannot be directly estimated without strong assumptions. For\ninstance, it is particularly difficult to estimate notions of fairness that\nrely on hard-to-measure concepts such as risk (e.g., quantifying whether\npatients at the same risk level have equal probability of treatment, regardless\nof group membership). Such measurements of risk can be accurately obtained when\nno unobserved confounders have jointly influenced past decisions and outcomes.\nHowever, in the real world, this assumption rarely holds. In this paper, we\nshow that, surprisingly, one can still compute meaningful bounds on treatment\nrates for high-risk individuals (i.e., conditional on their true,\n\\textit{unobserved} negative outcome), even when entirely eliminating or\nrelaxing the assumption that we observe all relevant risk factors used by\ndecision makers. We use the fact that in many real-world settings (e.g., the\nrelease of a new treatment) we have data from prior to any allocation to derive\nunbiased estimates of risk. This result enables us to audit unfair outcomes of\nexisting decision-making systems in a principled manner. We demonstrate the\neffectiveness of our framework with a real-world study of Paxlovid allocation,\nprovably identifying that observed racial inequity cannot be explained by\nunobserved confounders of the same strength as important observed covariates.\n","authors":["Yewon Byun","Dylan Sam","Michael Oberst","Zachary C. Lipton","Bryan Wilder"],"pdf_url":"https://arxiv.org/pdf/2403.14713v3.pdf","comment":"AISTATS 2024"},{"id":"http://arxiv.org/abs/2412.06237v1","updated":"2024-12-09T06:24:33Z","published":"2024-12-09T06:24:33Z","title":"In Silico Pharmacokinetic and Molecular Docking Studies of Natural\n  Plants against Essential Protein KRAS for Treatment of Pancreatic Cancer","summary":"  A kind of pancreatic cancer called Pancreatic Ductal Adenocarcinoma (PDAC) is\nanticipated to be one of the main causes of mortality during past years.\nEvidence from several researches supported the concept that the oncogenic KRAS\n(Ki-ras2 Kirsten rat sarcoma viral oncogene) mutation is the major cause of\npancreatic cancer. KRAS acts as an on-off switch that promotes cell growth. But\nwhen the KRAS gene is mutated, it will be in one position, allowing the cell\ngrowth uncontrollably. This uncontrollable multiplication of cells causes\ncancer growth. Therefore, KRAS was selected as the target protein in the study.\nFifty plant-derived compounds are selected for the study. To determine whether\nthe examined drugs could bind to the KRAS complex's binding pocket, molecular\ndocking was performed. Computational analyses were used to assess the possible\nability of tested substances to pass the Blood Brain Barrier (BBB). To predict\nthe bioactivity of ligands a machine learning model was created. Five machine\nlearning models were created and have chosen the best one among them for\nanalyzing the bioactivity of each ligand. From the fifty plant-derived\ncompounds the compounds with the least binding energies are selected. Then\nbioactivity of these six compounds is analyzed using Random Forest Regression\nmodel. Adsorption, Distribution, Metabolism, Excretion (ADME) properties of\ncompounds are analyzed. The results showed that borneol has powerful effects\nand acts as a promising agent for the treatment of pancreatic cancer. This\nsuggests that borneol found in plants like mint, ginger, rosemary, etc., is a\nsuccessful compound for the treatment of pancreatic cancer.\n","authors":["Marsha Mariya Kappan","Joby George"],"pdf_url":"https://arxiv.org/pdf/2412.06237v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06235v1","updated":"2024-12-09T06:21:11Z","published":"2024-12-09T06:21:11Z","title":"VariFace: Fair and Diverse Synthetic Dataset Generation for Face\n  Recognition","summary":"  The use of large-scale, web-scraped datasets to train face recognition models\nhas raised significant privacy and bias concerns. Synthetic methods mitigate\nthese concerns and provide scalable and controllable face generation to enable\nfair and accurate face recognition. However, existing synthetic datasets\ndisplay limited intraclass and interclass diversity and do not match the face\nrecognition performance obtained using real datasets. Here, we propose\nVariFace, a two-stage diffusion-based pipeline to create fair and diverse\nsynthetic face datasets to train face recognition models. Specifically, we\nintroduce three methods: Face Recognition Consistency to refine demographic\nlabels, Face Vendi Score Guidance to improve interclass diversity, and\nDivergence Score Conditioning to balance the identity preservation-intraclass\ndiversity trade-off. When constrained to the same dataset size, VariFace\nconsiderably outperforms previous synthetic datasets (0.9200 $\\rightarrow$\n0.9405) and achieves comparable performance to face recognition models trained\nwith real data (Real Gap = -0.0065). In an unconstrained setting, VariFace not\nonly consistently achieves better performance compared to previous synthetic\nmethods across dataset sizes but also, for the first time, outperforms the real\ndataset (CASIA-WebFace) across six evaluation datasets. This sets a new\nstate-of-the-art performance with an average face verification accuracy of\n0.9567 (Real Gap = +0.0097) across LFW, CFP-FP, CPLFW, AgeDB, and CALFW\ndatasets and 0.9366 (Real Gap = +0.0380) on the RFW dataset.\n","authors":["Michael Yeung","Toya Teramoto","Songtao Wu","Tatsuo Fujiwara","Kenji Suzuki","Tamaki Kojima"],"pdf_url":"https://arxiv.org/pdf/2412.06235v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06233v1","updated":"2024-12-09T06:14:47Z","published":"2024-12-09T06:14:47Z","title":"Representational Transfer Learning for Matrix Completion","summary":"  We propose to transfer representational knowledge from multiple sources to a\ntarget noisy matrix completion task by aggregating singular subspaces\ninformation. Under our representational similarity framework, we first\nintegrate linear representation information by solving a two-way principal\ncomponent analysis problem based on a properly debiased matrix-valued dataset.\nAfter acquiring better column and row representation estimators from the\nsources, the original high-dimensional target matrix completion problem is then\ntransformed into a low-dimensional linear regression, of which the statistical\nefficiency is guaranteed. A variety of extensional arguments, including\npost-transfer statistical inference and robustness against negative transfer,\nare also discussed alongside. Finally, extensive simulation results and a\nnumber of real data cases are reported to support our claims.\n","authors":["Yong He","Zeyu Li","Dong Liu","Kangxiang Qin","Jiahui Xie"],"pdf_url":"https://arxiv.org/pdf/2412.06233v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06231v1","updated":"2024-12-09T06:08:23Z","published":"2024-12-09T06:08:23Z","title":"A Scalable Decentralized Reinforcement Learning Framework for UAV Target\n  Localization Using Recurrent PPO","summary":"  The rapid advancements in unmanned aerial vehicles (UAVs) have unlocked\nnumerous applications, including environmental monitoring, disaster response,\nand agricultural surveying. Enhancing the collective behavior of multiple\ndecentralized UAVs can significantly improve these applications through more\nefficient and coordinated operations. In this study, we explore a Recurrent PPO\nmodel for target localization in perceptually degraded environments like places\nwithout GNSS/GPS signals. We first developed a single-drone approach for target\nidentification, followed by a decentralized two-drone model. Our approach can\nutilize two types of sensors on the UAVs, a detection sensor and a target\nsignal sensor. The single-drone model achieved an accuracy of 93%, while the\ntwo-drone model achieved an accuracy of 86%, with the latter requiring fewer\naverage steps to locate the target. This demonstrates the potential of our\nmethod in UAV swarms, offering efficient and effective localization of radiant\ntargets in complex environmental conditions.\n","authors":["Leon Fernando","Billy Pik Lik Lau","Chau Yuen","U-Xuan Tan"],"pdf_url":"https://arxiv.org/pdf/2412.06231v1.pdf","comment":"Submitted to TENCON 2024"},{"id":"http://arxiv.org/abs/2412.04065v2","updated":"2024-12-09T06:02:36Z","published":"2024-12-05T10:59:54Z","title":"Space to Policy: Scalable Brick Kiln Detection and Automatic Compliance\n  Monitoring with Geospatial Data","summary":"  Air pollution kills 7 million people annually. The brick kiln sector\nsignificantly contributes to economic development but also accounts for 8-14\\%\nof air pollution in India. Policymakers have implemented compliance measures to\nregulate brick kilns. Emission inventories are critical for air quality\nmodeling and source apportionment studies. However, the largely unorganized\nnature of the brick kiln sector necessitates labor-intensive survey efforts for\nmonitoring. Recent efforts by air quality researchers have relied on manual\nannotation of brick kilns using satellite imagery to build emission\ninventories, but this approach lacks scalability. Machine-learning-based object\ndetection methods have shown promise for detecting brick kilns; however,\nprevious studies often rely on costly high-resolution imagery and fail to\nintegrate with governmental policies. In this work, we developed a scalable\nmachine-learning pipeline that detected and classified 30638 brick kilns across\nfive states in the Indo-Gangetic Plain using free, moderate-resolution\nsatellite imagery from Planet Labs. Our detections have a high correlation with\non-ground surveys. We performed automated compliance analysis based on\ngovernment policies. In the Delhi airshed, stricter policy enforcement has led\nto the adoption of efficient brick kiln technologies. This study highlights the\nneed for inclusive policies that balance environmental sustainability with the\nlivelihoods of workers.\n","authors":["Zeel B Patel","Rishabh Mondal","Shataxi Dubey","Suraj Jaiswal","Sarath Guttikunda","Nipun Batra"],"pdf_url":"https://arxiv.org/pdf/2412.04065v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.07904v2","updated":"2024-12-09T05:45:00Z","published":"2024-06-12T06:12:04Z","title":"Grounding Multimodal Large Language Models in Actions","summary":"  Multimodal Large Language Models (MLLMs) have demonstrated a wide range of\ncapabilities across many domains, including Embodied AI. In this work, we study\nhow to best ground a MLLM into different embodiments and their associated\naction spaces, with the goal of leveraging the multimodal world knowledge of\nthe MLLM. We first generalize a number of methods through a unified\narchitecture and the lens of action space adaptors. For continuous actions, we\nshow that a learned tokenization allows for sufficient modeling precision,\nyielding the best performance on downstream tasks. For discrete actions, we\ndemonstrate that semantically aligning these actions with the native output\ntoken space of the MLLM leads to the strongest performance. We arrive at these\nlessons via a thorough study of seven action space adapters on five different\nenvironments, encompassing over 114 embodied tasks.\n","authors":["Andrew Szot","Bogdan Mazoure","Harsh Agrawal","Devon Hjelm","Zsolt Kira","Alexander Toshev"],"pdf_url":"https://arxiv.org/pdf/2406.07904v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06212v1","updated":"2024-12-09T05:16:32Z","published":"2024-12-09T05:16:32Z","title":"A Self-guided Multimodal Approach to Enhancing Graph Representation\n  Learning for Alzheimer's Diseases","summary":"  Graph neural networks (GNNs) are powerful machine learning models designed to\nhandle irregularly structured data. However, their generic design often proves\ninadequate for analyzing brain connectomes in Alzheimer's Disease (AD),\nhighlighting the need to incorporate domain knowledge for optimal performance.\nInfusing AD-related knowledge into GNNs is a complicated task. Existing methods\ntypically rely on collaboration between computer scientists and domain experts,\nwhich can be both time-intensive and resource-demanding. To address these\nlimitations, this paper presents a novel self-guided, knowledge-infused\nmultimodal GNN that autonomously incorporates domain knowledge into the model\ndevelopment process. Our approach conceptualizes domain knowledge as natural\nlanguage and introduces a specialized multimodal GNN capable of leveraging this\nuncurated knowledge to guide the learning process of the GNN, such that it can\nimprove the model performance and strengthen the interpretability of the\npredictions. To evaluate our framework, we curated a comprehensive dataset of\nrecent peer-reviewed papers on AD and integrated it with multiple real-world AD\ndatasets. Experimental results demonstrate the ability of our method to extract\nrelevant domain knowledge, provide graph-based explanations for AD diagnosis,\nand improve the overall performance of the GNN. This approach provides a more\nscalable and efficient alternative to inject domain knowledge for AD compared\nwith the manual design from the domain expert, advancing both prediction\naccuracy and interpretability in AD diagnosis.\n","authors":["Zhepeng Wang","Runxue Bao","Yawen Wu","Guodong Liu","Lei Yang","Liang Zhan","Feng Zheng","Weiwen Jiang","Yanfu Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.06212v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01322v2","updated":"2024-12-09T05:13:27Z","published":"2024-10-02T08:26:37Z","title":"Forte : Finding Outliers with Representation Typicality Estimation","summary":"  Generative models can now produce photorealistic synthetic data which is\nvirtually indistinguishable from the real data used to train it. This is a\nsignificant evolution over previous models which could produce reasonable\nfacsimiles of the training data, but ones which could be visually distinguished\nfrom the training data by human evaluation. Recent work on OOD detection has\nraised doubts that generative model likelihoods are optimal OOD detectors due\nto issues involving likelihood misestimation, entropy in the generative\nprocess, and typicality. We speculate that generative OOD detectors also failed\nbecause their models focused on the pixels rather than the semantic content of\nthe data, leading to failures in near-OOD cases where the pixels may be similar\nbut the information content is significantly different. We hypothesize that\nestimating typical sets using self-supervised learners leads to better OOD\ndetectors. We introduce a novel approach that leverages representation\nlearning, and informative summary statistics based on manifold estimation, to\naddress all of the aforementioned issues. Our method outperforms other\nunsupervised approaches and achieves state-of-the art performance on\nwell-established challenging benchmarks, and new synthetic data detection\ntasks.\n","authors":["Debargha Ganguly","Warren Morningstar","Andrew Yu","Vipin Chaudhary"],"pdf_url":"https://arxiv.org/pdf/2410.01322v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05584v3","updated":"2024-12-09T05:06:20Z","published":"2024-10-08T00:52:03Z","title":"Rethinking Reward Model Evaluation: Are We Barking up the Wrong Tree?","summary":"  Reward Models (RMs) are crucial for aligning language models with human\npreferences. Currently, the evaluation of RMs depends on measuring accuracy\nagainst a validation set of manually annotated preference data. Although this\nmethod is straightforward and widely adopted, the relationship between RM\naccuracy and downstream policy performance remains under-explored. In this\nwork, we conduct experiments in a synthetic setting to investigate how\ndifferences in RM measured by accuracy translate into gaps in optimized policy\nperformance. Our findings reveal that while there is a weak positive\ncorrelation between accuracy and downstream performance, policies optimized\ntowards RMs with similar accuracy can exhibit quite different performance.\nMoreover, we discover that the way of measuring accuracy significantly impacts\nits ability to predict the final policy performance. Through the lens of the\nRegressional Goodhart effect, we recognize that accuracy, when used for\nmeasuring RM quality, can fail to fully capture the potential RM\noveroptimization. This underscores the inadequacy of relying solely on accuracy\nto reflect their impact on policy optimization.\n","authors":["Xueru Wen","Jie Lou","Yaojie Lu","Hongyu Lin","Xing Yu","Xinyu Lu","Ben He","Xianpei Han","Debing Zhang","Le Sun"],"pdf_url":"https://arxiv.org/pdf/2410.05584v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06210v1","updated":"2024-12-09T05:05:47Z","published":"2024-12-09T05:05:47Z","title":"H-FedSN: Personalized Sparse Networks for Efficient and Accurate\n  Hierarchical Federated Learning for IoT Applications","summary":"  The proliferation of Internet of Things (IoT) has increased interest in\nfederated learning (FL) for privacy-preserving distributed data utilization.\nHowever, traditional two-tier FL architectures inadequately adapt to multi-tier\nIoT environments. While Hierarchical Federated Learning (HFL) improves\npracticality in multi-tier IoT environments by multi-layer aggregation, it\nstill faces challenges in communication efficiency and accuracy due to high\ndata transfer volumes, data heterogeneity, and imbalanced device distribution,\nstruggling to meet the low-latency and high-accuracy model training\nrequirements of practical IoT scenarios. To overcome these limitations, we\npropose H-FedSN, an innovative approach for practical IoT environments. H-FedSN\nintroduces a binary mask mechanism with shared and personalized layers to\nreduce communication overhead by creating a sparse network while keeping\noriginal weights frozen. To address data heterogeneity and imbalanced device\ndistribution, we integrate personalized layers for local data adaptation and\napply Bayesian aggregation with cumulative Beta distribution updates at edge\nand cloud levels, effectively balancing contributions from diverse client\ngroups. Evaluations on three real-world IoT datasets and MNIST under non-IID\nsettings demonstrate that H-FedSN significantly reduces communication costs by\n58 to 238 times compared to HierFAVG while achieving high accuracy, making it\nhighly effective for practical IoT applications in hierarchical federated\nlearning scenarios.\n","authors":["Jiechao Gao","Yuangang Li","Yue Zhao","Brad Campbell"],"pdf_url":"https://arxiv.org/pdf/2412.06210v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06207v1","updated":"2024-12-09T04:58:14Z","published":"2024-12-09T04:58:14Z","title":"Skill-Enhanced Reinforcement Learning Acceleration from Demonstrations","summary":"  Learning from Demonstration (LfD) aims to facilitate rapid Reinforcement\nLearning (RL) by leveraging expert demonstrations to pre-train the RL agent.\nHowever, the limited availability of expert demonstration data often hinders\nits ability to effectively aid downstream RL learning. To address this problem,\nwe propose a novel two-stage method dubbed as Skill-enhanced Reinforcement\nLearning Acceleration (SeRLA). SeRLA introduces a skill-level adversarial\nPositive-Unlabeled (PU) learning model to extract useful skill prior knowledge\nby enabling learning from both limited expert data and general low-cost\ndemonstration data in the offline prior learning stage. Subsequently, it\ndeploys a skill-based soft actor-critic algorithm to leverage this acquired\nprior knowledge in the downstream online RL stage for efficient training of a\nskill policy network. Moreover, we develop a simple skill-level data\nenhancement technique to further alleviate data sparsity and improve both skill\nprior learning and downstream skill policy training. Our experimental results\non multiple standard RL environments show the proposed SeRLA method achieves\nstate-of-the-art performance on accelerating reinforcement learning on\ndownstream tasks, especially in the early learning phase.\n","authors":["Hanping Zhang","Yuhong Guo"],"pdf_url":"https://arxiv.org/pdf/2412.06207v1.pdf","comment":"ICML 2024 AutoRL Workshop; 9 pages"}]," Artificial Intelligence":[{"id":"http://arxiv.org/abs/2412.06787v1","updated":"2024-12-09T18:59:56Z","published":"2024-12-09T18:59:56Z","title":"[MASK] is All You Need","summary":"  In generative models, two paradigms have gained attraction in various\napplications: next-set prediction-based Masked Generative Models and next-noise\nprediction-based Non-Autoregressive Models, e.g., Diffusion Models. In this\nwork, we propose using discrete-state models to connect them and explore their\nscalability in the vision domain. First, we conduct a step-by-step analysis in\na unified design space across two types of models including\ntimestep-independence, noise schedule, temperature, guidance strength, etc in a\nscalable manner. Second, we re-cast typical discriminative tasks, e.g., image\nsegmentation, as an unmasking process from [MASK]tokens on a discrete-state\nmodel. This enables us to perform various sampling processes, including\nflexible conditional sampling by only training once to model the joint\ndistribution. All aforementioned explorations lead to our framework named\nDiscrete Interpolants, which enables us to achieve state-of-the-art or\ncompetitive performance compared to previous discrete-state based methods in\nvarious benchmarks, like ImageNet256, MS COCO, and video dataset FaceForensics.\nIn summary, by leveraging [MASK] in discrete-state models, we can bridge Masked\nGenerative and Non-autoregressive Diffusion models, as well as generative and\ndiscriminative tasks.\n","authors":["Vincent Tao Hu","Björn Ommer"],"pdf_url":"https://arxiv.org/pdf/2412.06787v1.pdf","comment":"Technical Report (WIP), Project Page(code, model, dataset):\n  https://compvis.github.io/mask/"},{"id":"http://arxiv.org/abs/2412.06784v1","updated":"2024-12-09T18:59:42Z","published":"2024-12-09T18:59:42Z","title":"P3-PO: Prescriptive Point Priors for Visuo-Spatial Generalization of\n  Robot Policies","summary":"  Developing generalizable robot policies that can robustly handle varied\nenvironmental conditions and object instances remains a fundamental challenge\nin robot learning. While considerable efforts have focused on collecting large\nrobot datasets and developing policy architectures to learn from such data,\nnaively learning from visual inputs often results in brittle policies that fail\nto transfer beyond the training data. This work presents Prescriptive Point\nPriors for Policies or P3-PO, a novel framework that constructs a unique state\nrepresentation of the environment leveraging recent advances in computer vision\nand robot learning to achieve improved out-of-distribution generalization for\nrobot manipulation. This representation is obtained through two steps. First, a\nhuman annotator prescribes a set of semantically meaningful points on a single\ndemonstration frame. These points are then propagated through the dataset using\noff-the-shelf vision models. The derived points serve as an input to\nstate-of-the-art policy architectures for policy learning. Our experiments\nacross four real-world tasks demonstrate an overall 43% absolute improvement\nover prior methods when evaluated in identical settings as training. Further,\nP3-PO exhibits 58% and 80% gains across tasks for new object instances and more\ncluttered environments respectively. Videos illustrating the robot's\nperformance are best viewed at point-priors.github.io.\n","authors":["Mara Levy","Siddhant Haldar","Lerrel Pinto","Abhinav Shirivastava"],"pdf_url":"https://arxiv.org/pdf/2412.06784v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06779v1","updated":"2024-12-09T18:58:43Z","published":"2024-12-09T18:58:43Z","title":"AnyBimanual: Transferring Unimanual Policy for General Bimanual\n  Manipulation","summary":"  Performing general language-conditioned bimanual manipulation tasks is of\ngreat importance for many applications ranging from household service to\nindustrial assembly. However, collecting bimanual manipulation data is\nexpensive due to the high-dimensional action space, which poses challenges for\nconventional methods to handle general bimanual manipulation tasks. In\ncontrast, unimanual policy has recently demonstrated impressive\ngeneralizability across a wide range of tasks because of scaled model\nparameters and training data, which can provide sharable manipulation knowledge\nfor bimanual systems. To this end, we propose a plug-and-play method named\nAnyBimanual, which transfers pre-trained unimanual policy to general bimanual\nmanipulation policy with few bimanual demonstrations. Specifically, we first\nintroduce a skill manager to dynamically schedule the skill representations\ndiscovered from pre-trained unimanual policy for bimanual manipulation tasks,\nwhich linearly combines skill primitives with task-oriented compensation to\nrepresent the bimanual manipulation instruction. To mitigate the observation\ndiscrepancy between unimanual and bimanual systems, we present a visual aligner\nto generate soft masks for visual embedding of the workspace, which aims to\nalign visual input of unimanual policy model for each arm with those during\npretraining stage. AnyBimanual shows superiority on 12 simulated tasks from\nRLBench2 with a sizable 12.67% improvement in success rate over previous\nmethods. Experiments on 9 real-world tasks further verify its practicality with\nan average success rate of 84.62%.\n","authors":["Guanxing Lu","Tengbo Yu","Haoyuan Deng","Season Si Chen","Yansong Tang","Ziwei Wang"],"pdf_url":"https://arxiv.org/pdf/2412.06779v1.pdf","comment":"Project page: https://anybimanual.github.io/"},{"id":"http://arxiv.org/abs/2412.06777v1","updated":"2024-12-09T18:58:03Z","published":"2024-12-09T18:58:03Z","title":"Driv3R: Learning Dense 4D Reconstruction for Autonomous Driving","summary":"  Realtime 4D reconstruction for dynamic scenes remains a crucial challenge for\nautonomous driving perception. Most existing methods rely on depth estimation\nthrough self-supervision or multi-modality sensor fusion. In this paper, we\npropose Driv3R, a DUSt3R-based framework that directly regresses per-frame\npoint maps from multi-view image sequences. To achieve streaming dense\nreconstruction, we maintain a memory pool to reason both spatial relationships\nacross sensors and dynamic temporal contexts to enhance multi-view 3D\nconsistency and temporal integration. Furthermore, we employ a 4D flow\npredictor to identify moving objects within the scene to direct our network\nfocus more on reconstructing these dynamic regions. Finally, we align all\nper-frame pointmaps consistently to the world coordinate system in an\noptimization-free manner. We conduct extensive experiments on the large-scale\nnuScenes dataset to evaluate the effectiveness of our method. Driv3R\noutperforms previous frameworks in 4D dynamic scene reconstruction, achieving\n15x faster inference speed compared to methods requiring global alignment.\nCode: https://github.com/Barrybarry-Smith/Driv3R.\n","authors":["Xin Fei","Wenzhao Zheng","Yueqi Duan","Wei Zhan","Masayoshi Tomizuka","Kurt Keutzer","Jiwen Lu"],"pdf_url":"https://arxiv.org/pdf/2412.06777v1.pdf","comment":"Code is available at: https://github.com/Barrybarry-Smith/Driv3R"},{"id":"http://arxiv.org/abs/2412.06775v1","updated":"2024-12-09T18:57:57Z","published":"2024-12-09T18:57:57Z","title":"Delve into Visual Contrastive Decoding for Hallucination Mitigation of\n  Large Vision-Language Models","summary":"  While large vision-language models (LVLMs) have shown impressive capabilities\nin generating plausible responses correlated with input visual contents, they\nstill suffer from hallucinations, where the generated text inaccurately\nreflects visual contents. To address this, recent approaches apply contrastive\ndecoding to calibrate the model's response via contrasting output distributions\nwith original and visually distorted samples, demonstrating promising\nhallucination mitigation in a training-free manner. However, the potential of\nchanging information in visual inputs is not well-explored, so a deeper\ninvestigation into the behaviors of visual contrastive decoding is of great\ninterest. In this paper, we first explore various methods for contrastive\ndecoding to change visual contents, including image downsampling and editing.\nDownsampling images reduces the detailed textual information while editing\nyields new contents in images, providing new aspects as visual contrastive\nsamples. To further study benefits by using different contrastive samples, we\nanalyze probability-level metrics, including entropy and distribution distance.\nInterestingly, the effect of these samples in mitigating hallucinations varies\na lot across LVLMs and benchmarks. Based on our analysis, we propose a simple\nyet effective method to combine contrastive samples, offering a practical\nsolution for applying contrastive decoding across various scenarios. Extensive\nexperiments are conducted to validate the proposed fusion method among\ndifferent benchmarks.\n","authors":["Yi-Lun Lee","Yi-Hsuan Tsai","Wei-Chen Chiu"],"pdf_url":"https://arxiv.org/pdf/2412.06775v1.pdf","comment":"Under review. Project pages: https://github.com/YiLunLee/VCD_Analysis"},{"id":"http://arxiv.org/abs/2412.06774v1","updated":"2024-12-09T18:57:24Z","published":"2024-12-09T18:57:24Z","title":"Visual Lexicon: Rich Image Features in Language Space","summary":"  We present Visual Lexicon, a novel visual language that encodes rich image\ninformation into the text space of vocabulary tokens while retaining intricate\nvisual details that are often challenging to convey in natural language. Unlike\ntraditional methods that prioritize either high-level semantics (e.g., CLIP) or\npixel-level reconstruction (e.g., VAE), ViLex simultaneously captures rich\nsemantic content and fine visual details, enabling high-quality image\ngeneration and comprehensive visual scene understanding. Through a\nself-supervised learning pipeline, ViLex generates tokens optimized for\nreconstructing input images using a frozen text-to-image (T2I) diffusion model,\npreserving the detailed information necessary for high-fidelity semantic-level\nreconstruction. As an image embedding in the language space, ViLex tokens\nleverage the compositionality of natural languages, allowing them to be used\nindependently as \"text tokens\" or combined with natural language tokens to\nprompt pretrained T2I models with both visual and textual inputs, mirroring how\nwe interact with vision-language models (VLMs). Experiments demonstrate that\nViLex achieves higher fidelity in image reconstruction compared to text\nembeddings--even with a single ViLex token. Moreover, ViLex successfully\nperforms various DreamBooth tasks in a zero-shot, unsupervised manner without\nfine-tuning T2I models. Additionally, ViLex serves as a powerful vision\nencoder, consistently improving vision-language model performance across 15\nbenchmarks relative to a strong SigLIP baseline.\n","authors":["XuDong Wang","Xingyi Zhou","Alireza Fathi","Trevor Darrell","Cordelia Schmid"],"pdf_url":"https://arxiv.org/pdf/2412.06774v1.pdf","comment":"Tech report. 16 pages, 10 figures"},{"id":"http://arxiv.org/abs/2412.06771v1","updated":"2024-12-09T18:56:32Z","published":"2024-12-09T18:56:32Z","title":"Proactive Agents for Multi-Turn Text-to-Image Generation Under\n  Uncertainty","summary":"  User prompts for generative AI models are often underspecified, leading to\nsub-optimal responses. This problem is particularly evident in text-to-image\n(T2I) generation, where users commonly struggle to articulate their precise\nintent. This disconnect between the user's vision and the model's\ninterpretation often forces users to painstakingly and repeatedly refine their\nprompts. To address this, we propose a design for proactive T2I agents equipped\nwith an interface to (1) actively ask clarification questions when uncertain,\nand (2) present their understanding of user intent as an understandable belief\ngraph that a user can edit. We build simple prototypes for such agents and\nverify their effectiveness through both human studies and automated evaluation.\nWe observed that at least 90% of human subjects found these agents and their\nbelief graphs helpful for their T2I workflow. Moreover, we develop a scalable\nautomated evaluation approach using two agents, one with a ground truth image\nand the other tries to ask as few questions as possible to align with the\nground truth. On DesignBench, a benchmark we created for artists and designers,\nthe COCO dataset (Lin et al., 2014), and ImageInWords (Garg et al., 2024), we\nobserved that these T2I agents were able to ask informative questions and\nelicit crucial information to achieve successful alignment with at least 2\ntimes higher VQAScore (Lin et al., 2024) than the standard single-turn T2I\ngeneration. Demo: https://github.com/google-deepmind/proactive_t2i_agents.\n","authors":["Meera Hahn","Wenjun Zeng","Nithish Kannen","Rich Galt","Kartikeya Badola","Been Kim","Zi Wang"],"pdf_url":"https://arxiv.org/pdf/2412.06771v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12668v3","updated":"2024-12-09T18:54:36Z","published":"2023-11-21T15:20:48Z","title":"From Concept to Manufacturing: Evaluating Vision-Language Models for\n  Engineering Design","summary":"  Engineering design is undergoing a transformative shift with the advent of\nAI, marking a new era in how we approach product, system, and service planning.\nLarge language models have demonstrated impressive capabilities in enabling\nthis shift. Yet, with text as their only input modality, they cannot leverage\nthe large body of visual artifacts that engineers have used for centuries and\nare accustomed to. This gap is addressed with the release of multimodal\nvision-language models (VLMs), such as GPT-4V, enabling AI to impact many more\ntypes of tasks. Our work presents a comprehensive evaluation of VLMs across a\nspectrum of engineering design tasks, categorized into four main areas:\nConceptual Design, System-Level and Detailed Design, Manufacturing and\nInspection, and Engineering Education Tasks. Specifically in this paper, we\nassess the capabilities of two VLMs, GPT-4V and LLaVA 1.6 34B, in design tasks\nsuch as sketch similarity analysis, CAD generation, topology optimization,\nmanufacturability assessment, and engineering textbook problems. Through this\nstructured evaluation, we not only explore VLMs' proficiency in handling\ncomplex design challenges but also identify their limitations in complex\nengineering design applications. Our research establishes a foundation for\nfuture assessments of vision language models. It also contributes a set of\nbenchmark testing datasets, with more than 1000 queries, for ongoing\nadvancements and applications in this field.\n","authors":["Cyril Picard","Kristen M. Edwards","Anna C. Doris","Brandon Man","Giorgio Giannone","Md Ferdous Alam","Faez Ahmed"],"pdf_url":"https://arxiv.org/pdf/2311.12668v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06759v1","updated":"2024-12-09T18:49:27Z","published":"2024-12-09T18:49:27Z","title":"XRZoo: A Large-Scale and Versatile Dataset of Extended Reality (XR)\n  Applications","summary":"  The rapid advancement of Extended Reality (XR, encompassing AR, MR, and VR)\nand spatial computing technologies forms a foundational layer for the emerging\nMetaverse, enabling innovative applications across healthcare, education,\nmanufacturing, and entertainment. However, research in this area is often\nlimited by the lack of large, representative, and highquality application\ndatasets that can support empirical studies and the development of new\napproaches benefiting XR software processes. In this paper, we introduce XRZoo,\na comprehensive and curated dataset of XR applications designed to bridge this\ngap. XRZoo contains 12,528 free XR applications, spanning nine app stores,\nacross all XR techniques (i.e., AR, MR, and VR) and use cases, with detailed\nmetadata on key aspects such as application descriptions, application\ncategories, release dates, user review numbers, and hardware specifications,\netc. By making XRZoo publicly available, we aim to foster reproducible XR\nsoftware engineering and security research, enable cross-disciplinary\ninvestigations, and also support the development of advanced XR systems by\nproviding examples to developers. Our dataset serves as a valuable resource for\nresearchers and practitioners interested in improving the scalability,\nusability, and effectiveness of XR applications. XRZoo will be released and\nactively maintained.\n","authors":["Shuqing Li","Chenran Zhang","Cuiyun Gao","Michael R. Lyu"],"pdf_url":"https://arxiv.org/pdf/2412.06759v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.00430v3","updated":"2024-12-09T18:46:37Z","published":"2024-11-30T10:56:30Z","title":"Predictive Models in Sequential Recommendations: Bridging Performance\n  Laws with Data Quality Insights","summary":"  Sequential Recommendation (SR) plays a critical role in predicting users'\nsequential preferences. Despite its growing prominence in various industries,\nthe increasing scale of SR models incurs substantial computational costs and\nunpredictability, challenging developers to manage resources efficiently. Under\nthis predicament, Scaling Laws have achieved significant success by examining\nthe loss as models scale up. However, there remains a disparity between loss\nand model performance, which is of greater concern in practical applications.\nMoreover, as data continues to expand, it incorporates repetitive and\ninefficient data. In response, we introduce the Performance Law for SR models,\nwhich aims to theoretically investigate and model the relationship between\nmodel performance and data quality. Specifically, we first fit the HR and NDCG\nmetrics to transformer-based SR models. Subsequently, we propose Approximate\nEntropy (ApEn) to assess data quality, presenting a more nuanced approach\ncompared to traditional data quantity metrics. Our method enables accurate\npredictions across various dataset scales and model sizes, demonstrating a\nstrong correlation in large SR models and offering insights into achieving\noptimal performance for any given model configuration.\n","authors":["Tingjia Shen","Hao Wang","Chuhan Wu","Jin Yao Chin","Wei Guo","Yong Liu","Huifeng Guo","Defu Lian","Ruiming Tang","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2412.00430v3.pdf","comment":"12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2401.14279v3","updated":"2024-12-09T18:41:35Z","published":"2024-01-25T16:10:33Z","title":"ZS4C: Zero-Shot Synthesis of Compilable Code for Incomplete Code\n  Snippets using LLMs","summary":"  Technical Q&A sites are valuable for software developers seeking knowledge,\nbut the code snippets they provide are often uncompilable and incomplete due to\nunresolved types and missing libraries. This poses a challenge for users who\nwish to reuse or analyze these snippets. Existing methods either do not focus\non creating compilable code or have low success rates. To address this, we\npropose ZS4C, a lightweight approach for zero-shot synthesis of compilable code\nfrom incomplete snippets using Large Language Models (LLMs). ZS4C operates in\ntwo stages: first, it uses an LLM, like GPT-3.5, to identify missing import\nstatements in a snippet; second, it collaborates with a validator (e.g.,\ncompiler) to fix compilation errors caused by incorrect imports and syntax\nissues. We evaluated ZS4C on the StatType-SO benchmark and a new dataset,\nPython-SO, which includes 539 Python snippets from Stack Overflow across the 20\nmost popular Python libraries. ZS4C significantly outperforms existing methods,\nimproving the compilation rate from 63% to 95.1% compared to the\nstate-of-the-art SnR, marking a 50.1% improvement. On average, ZS4C can infer\nmore accurate import statements (with an F1 score of 0.98) than SnR, with an\nimprovement of 8.5% in the F1.\n","authors":["Azmain Kabir","Shaowei Wang","Yuan Tian","Tse-Hsun Chen","Muhammad Asaduzzaman","Wenbin Zhang"],"pdf_url":"https://arxiv.org/pdf/2401.14279v3.pdf","comment":"This paper has been accepted and published in ACM Transactions on\n  Software Engineering and Methodology (TOSEM), [2024],\n  [https://dl.acm.org/doi/10.1145/3702979]"},{"id":"http://arxiv.org/abs/2403.19546v3","updated":"2024-12-09T18:37:55Z","published":"2024-03-28T16:27:26Z","title":"Croissant: A Metadata Format for ML-Ready Datasets","summary":"  Data is a critical resource for machine learning (ML), yet working with data\nremains a key friction point. This paper introduces Croissant, a metadata\nformat for datasets that creates a shared representation across ML tools,\nframeworks, and platforms. Croissant makes datasets more discoverable,\nportable, and interoperable, thereby addressing significant challenges in ML\ndata management. Croissant is already supported by several popular dataset\nrepositories, spanning hundreds of thousands of datasets, enabling easy loading\ninto the most commonly-used ML frameworks, regardless of where the data is\nstored. Our initial evaluation by human raters shows that Croissant metadata is\nreadable, understandable, complete, yet concise.\n","authors":["Mubashara Akhtar","Omar Benjelloun","Costanza Conforti","Luca Foschini","Joan Giner-Miguelez","Pieter Gijsbers","Sujata Goswami","Nitisha Jain","Michalis Karamousadakis","Michael Kuchnik","Satyapriya Krishna","Sylvain Lesage","Quentin Lhoest","Pierre Marcenac","Manil Maskey","Peter Mattson","Luis Oala","Hamidah Oderinwale","Pierre Ruyssen","Tim Santos","Rajat Shinde","Elena Simperl","Arjun Suresh","Goeffry Thomas","Slava Tykhonov","Joaquin Vanschoren","Susheel Varma","Jos van der Velde","Steffen Vogler","Carole-Jean Wu","Luyao Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.19546v3.pdf","comment":"Published at the NeurIPS 2024 Datasets and Benchmark Track. A shorter\n  version appeared earlier in Proceedings of ACM SIGMOD/PODS'24 Data Management\n  for End-to-End Machine Learning (DEEM) Workshop\n  https://dl.acm.org/doi/10.1145/3650203.3663326"},{"id":"http://arxiv.org/abs/2412.02889v2","updated":"2024-12-09T18:37:17Z","published":"2024-12-03T22:47:47Z","title":"Deep-Learning Based Docking Methods: Fair Comparisons to Conventional\n  Docking Workflows","summary":"  The diffusion learning method, DiffDock, for docking small-molecule ligands\ninto protein binding sites was recently introduced. Results included\ncomparisons to more conventional docking approaches, with DiffDock showing\nsuperior performance. Here, we employ a fully automatic workflow using the\nSurflex-Dock methods to generate a fair baseline for conventional docking\napproaches. Results were generated for the common and expected situation where\na binding site location is known and also for the condition of an unknown\nbinding site. For the known binding site condition, Surflex-Dock success rates\nat 2.0 Angstroms RMSD far exceeded those for DiffDock (Top-1/Top-5 success\nrates, respectively, were 68/81% compared with 45/51%). Glide performed with\nsimilar success rates (67/73%) to Surflex-Dock for the known binding site\ncondition, and results for AutoDock Vina and Gnina followed this pattern. For\nthe unknown binding site condition, using an automated method to identify\nmultiple binding pockets, Surflex-Dock success rates again exceeded those of\nDiffDock, but by a somewhat lesser margin. DiffDock made use of roughly 17,000\nco-crystal structures for learning (98% of PDBBind version 2020, pre-2019\nstructures) for a training set in order to predict on 363 test cases (2% of\nPDBBind 2020) from 2019 forward. DiffDock's performance was inextricably linked\nwith the presence of near-neighbor cases of close to identical protein-ligand\ncomplexes in the training set for over half of the test set cases. DiffDock\nexhibited a 40 percentage point difference on near-neighbor cases (two-thirds\nof all test cases) compared with cases with no near-neighbor training case.\nDiffDock has apparently encoded a type of table-lookup during its learning\nprocess, rendering meaningful applications beyond its reach. Further, it does\nnot perform even close to competitively with a competently run modern docking\nworkflow.\n","authors":["Ajay N. Jain","Ann E. Cleves","W. Patrick Walters"],"pdf_url":"https://arxiv.org/pdf/2412.02889v2.pdf","comment":"Post-Conclusion addendum added with additional reference and context,\n  19 pages including references and appendices, 7 figures"},{"id":"http://arxiv.org/abs/2412.06742v1","updated":"2024-12-09T18:34:49Z","published":"2024-12-09T18:34:49Z","title":"ContRail: A Framework for Realistic Railway Image Synthesis using\n  ControlNet","summary":"  Deep Learning became an ubiquitous paradigm due to its extraordinary\neffectiveness and applicability in numerous domains. However, the approach\nsuffers from the high demand of data required to achieve the potential of this\ntype of model. An ever-increasing sub-field of Artificial Intelligence, Image\nSynthesis, aims to address this limitation through the design of intelligent\nmodels capable of creating original and realistic images, endeavour which could\ndrastically reduce the need for real data. The Stable Diffusion generation\nparadigm recently propelled state-of-the-art approaches to exceed all previous\nbenchmarks. In this work, we propose the ContRail framework based on the novel\nStable Diffusion model ControlNet, which we empower through a multi-modal\nconditioning method. We experiment with the task of synthetic railway image\ngeneration, where we improve the performance in rail-specific tasks, such as\nrail semantic segmentation by enriching the dataset with realistic synthetic\nimages.\n","authors":["Andrei-Robert Alexandrescu","Razvan-Gabriel Petec","Alexandru Manole","Laura-Silvia Diosan"],"pdf_url":"https://arxiv.org/pdf/2412.06742v1.pdf","comment":"9 pages, 5 figures, 2 tables"},{"id":"http://arxiv.org/abs/2408.11796v4","updated":"2024-12-09T18:31:01Z","published":"2024-08-21T17:38:48Z","title":"LLM Pruning and Distillation in Practice: The Minitron Approach","summary":"  We present a comprehensive report on compressing the Llama 3.1 8B and Mistral\nNeMo 12B models to 4B and 8B parameters, respectively, using pruning and\ndistillation. We explore two distinct pruning strategies: (1) depth pruning and\n(2) joint hidden/attention/MLP (width) pruning, and evaluate the results on\ncommon benchmarks from the LM Evaluation Harness. The models are then aligned\nwith NeMo Aligner and tested in instruct-tuned versions. This approach produces\na compelling 4B model from Llama 3.1 8B and a state-of-the-art\nMistral-NeMo-Minitron-8B (MN-Minitron-8B for brevity) model from Mistral NeMo\n12B. We found that with no access to the original data, it is beneficial to\nslightly fine-tune teacher models on the distillation dataset. We open-source\nour base model weights on Hugging Face with a permissive license.\n","authors":["Sharath Turuvekere Sreenivas","Saurav Muralidharan","Raviraj Joshi","Marcin Chochowski","Ameya Sunil Mahabaleshwarkar","Gerald Shen","Jiaqi Zeng","Zijia Chen","Yoshi Suhara","Shizhe Diao","Chenhan Yu","Wei-Chun Chen","Hayley Ross","Oluwatobi Olabiyi","Ashwath Aithal","Oleksii Kuchaiev","Daniel Korzekwa","Pavlo Molchanov","Mostofa Patwary","Mohammad Shoeybi","Jan Kautz","Bryan Catanzaro"],"pdf_url":"https://arxiv.org/pdf/2408.11796v4.pdf","comment":"v4: Update author order"},{"id":"http://arxiv.org/abs/2404.03657v2","updated":"2024-12-09T18:19:05Z","published":"2024-04-04T17:59:58Z","title":"OW-VISCapTor: Abstractors for Open-World Video Instance Segmentation and\n  Captioning","summary":"  We propose the new task 'open-world video instance segmentation and\ncaptioning'. It requires to detect, segment, track and describe with rich\ncaptions never before seen objects. This challenging task can be addressed by\ndeveloping \"abstractors\" which connect a vision model and a language foundation\nmodel. Concretely, we connect a multi-scale visual feature extractor and a\nlarge language model (LLM) by developing an object abstractor and an\nobject-to-text abstractor. The object abstractor, consisting of a prompt\nencoder and transformer blocks, introduces spatially-diverse open-world object\nqueries to discover never before seen objects in videos. An inter-query\ncontrastive loss further encourages the diversity of object queries. The\nobject-to-text abstractor is augmented with masked cross-attention and acts as\na bridge between the object queries and a frozen LLM to generate rich and\ndescriptive object-centric captions for each detected object. Our generalized\napproach surpasses the baseline that jointly addresses the tasks of open-world\nvideo instance segmentation and dense video object captioning by 13% on never\nbefore seen objects, and by 10% on object-centric captions.\n","authors":["Anwesa Choudhuri","Girish Chowdhary","Alexander G. Schwing"],"pdf_url":"https://arxiv.org/pdf/2404.03657v2.pdf","comment":"Project page: https://anwesachoudhuri.github.io/OpenWorldVISCap/"},{"id":"http://arxiv.org/abs/2412.06717v1","updated":"2024-12-09T18:04:27Z","published":"2024-12-09T18:04:27Z","title":"Toward Non-Invasive Diagnosis of Bankart Lesions with Deep Learning","summary":"  Bankart lesions, or anterior-inferior glenoid labral tears, are\ndiagnostically challenging on standard MRIs due to their subtle imaging\nfeatures-often necessitating invasive MRI arthrograms (MRAs). This study\ndevelops deep learning (DL) models to detect Bankart lesions on both standard\nMRIs and MRAs, aiming to improve diagnostic accuracy and reduce reliance on\nMRAs. We curated a dataset of 586 shoulder MRIs (335 standard, 251 MRAs) from\n558 patients who underwent arthroscopy. Ground truth labels were derived from\nintraoperative findings, the gold standard for Bankart lesion diagnosis.\nSeparate DL models for MRAs and standard MRIs were trained using the Swin\nTransformer architecture, pre-trained on a public knee MRI dataset. Predictions\nfrom sagittal, axial, and coronal views were ensembled to optimize performance.\nThe models were evaluated on a 20% hold-out test set (117 MRIs: 46 MRAs, 71\nstandard MRIs). Bankart lesions were identified in 31.9% of MRAs and 8.6% of\nstandard MRIs. The models achieved AUCs of 0.87 (86% accuracy, 83% sensitivity,\n86% specificity) and 0.90 (85% accuracy, 82% sensitivity, 86% specificity) on\nstandard MRIs and MRAs, respectively. These results match or surpass\nradiologist performance on our dataset and reported literature metrics.\nNotably, our model's performance on non-invasive standard MRIs matched or\nsurpassed the radiologists interpreting MRAs. This study demonstrates the\nfeasibility of using DL to address the diagnostic challenges posed by subtle\npathologies like Bankart lesions. Our models demonstrate potential to improve\ndiagnostic confidence, reduce reliance on invasive imaging, and enhance\naccessibility to care.\n","authors":["Sahil Sethi","Sai Reddy","Mansi Sakarvadia","Jordan Serotte","Darlington Nwaudo","Nicholas Maassen","Lewis Shi"],"pdf_url":"https://arxiv.org/pdf/2412.06717v1.pdf","comment":"Accepted for presentation at SPIE Medical Imaging 2025:\n  Computer-Aided Diagnosis. The manuscript is expected to appear in the\n  conference proceedings"},{"id":"http://arxiv.org/abs/2412.06709v1","updated":"2024-12-09T17:58:24Z","published":"2024-12-09T17:58:24Z","title":"Parkinson's Disease Diagnosis Through Deep Learning: A Novel LSTM-Based\n  Approach for Freezing of Gait Detection","summary":"  Deep learning holds tremendous potential in healthcare for uncovering hidden\npatterns within extensive clinical datasets, aiding in the diagnosis of various\ndiseases. Parkinson's disease (PD) is a neurodegenerative condition\ncharacterized by the deterioration of brain function. In the initial stages of\nPD, automatic diagnosis poses a challenge due to the similarity in behavior\nbetween individuals with PD and those who are healthy. Our objective is to\npropose an effective model that can aid in the early detection of Parkinson's\ndisease. We employed the VGRF gait signal dataset sourced from Physionet for\ndistinguishing between healthy individuals and those diagnosed with Parkinson's\ndisease. This paper introduces a novel deep learning architecture based on the\nLSTM network for automatically detecting freezing of gait episodes in\nParkinson's disease patients. In contrast to conventional machine learning\nalgorithms, this method eliminates manual feature engineering and proficiently\ncaptures prolonged temporal dependencies in gait patterns, thereby improving\nthe diagnosis of Parkinson's disease. The LSTM network resolves the issue of\nvanishing gradients by employing memory blocks in place of self-connected\nhidden units, allowing for optimal information assimilation. To prevent\noverfitting, dropout and L2 regularization techniques have been employed.\nAdditionally, the stochastic gradient-based optimizer Adam is used for the\noptimization process. The results indicate that our proposed approach surpasses\ncurrent state-of-the-art models in FOG episode detection, achieving an accuracy\nof 97.71%, sensitivity of 99%, precision of 98%, and specificity of 96%. This\ndemonstrates its potential as a superior classification method for Parkinson's\ndisease detection.\n","authors":["Aqib Nazir Mir","Iqra Nissar","Mumtaz Ahmed","Sarfaraz Masood","Danish Raza Rizvi"],"pdf_url":"https://arxiv.org/pdf/2412.06709v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06703v1","updated":"2024-12-09T17:49:14Z","published":"2024-12-09T17:49:14Z","title":"Source Separation & Automatic Transcription for Music","summary":"  Source separation is the process of isolating individual sounds in an\nauditory mixture of multiple sounds [1], and has a variety of applications\nranging from speech enhancement and lyric transcription [2] to digital audio\nproduction for music. Furthermore, Automatic Music Transcription (AMT) is the\nprocess of converting raw music audio into sheet music that musicians can read\n[3]. Historically, these tasks have faced challenges such as significant audio\nnoise, long training times, and lack of free-use data due to copyright\nrestrictions. However, recent developments in deep learning have brought new\npromising approaches to building low-distortion stems and generating sheet\nmusic from audio signals [4]. Using spectrogram masking, deep neural networks,\nand the MuseScore API, we attempt to create an end-to-end pipeline that allows\nfor an initial music audio mixture (e.g...wav file) to be separated into\ninstrument stems, converted into MIDI files, and transcribed into sheet music\nfor each component instrument.\n","authors":["Bradford Derby","Lucas Dunker","Samarth Galchar","Shashank Jarmale","Akash Setti"],"pdf_url":"https://arxiv.org/pdf/2412.06703v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.05546v3","updated":"2024-12-09T17:41:12Z","published":"2023-11-09T17:45:32Z","title":"Multi-Agent Quantum Reinforcement Learning using Evolutionary\n  Optimization","summary":"  Multi-Agent Reinforcement Learning is becoming increasingly more important in\ntimes of autonomous driving and other smart industrial applications.\nSimultaneously a promising new approach to Reinforcement Learning arises using\nthe inherent properties of quantum mechanics, reducing the trainable parameters\nof a model significantly. However, gradient-based Multi-Agent Quantum\nReinforcement Learning methods often have to struggle with barren plateaus,\nholding them back from matching the performance of classical approaches. We\nbuild upon an existing approach for gradient free Quantum Reinforcement\nLearning and propose three genetic variations with Variational Quantum Circuits\nfor Multi-Agent Reinforcement Learning using evolutionary optimization. We\nevaluate our genetic variations in the Coin Game environment and also compare\nthem to classical approaches. We showed that our Variational Quantum Circuit\napproaches perform significantly better compared to a neural network with a\nsimilar amount of trainable parameters. Compared to the larger neural network,\nour approaches archive similar results using $97.88\\%$ less parameters.\n","authors":["Michael Kölle","Felix Topp","Thomy Phan","Philipp Altmann","Jonas Nüßlein","Claudia Linnhoff-Popien"],"pdf_url":"https://arxiv.org/pdf/2311.05546v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06694v1","updated":"2024-12-09T17:40:37Z","published":"2024-12-09T17:40:37Z","title":"Digital Transformation in the Water Distribution System based on the\n  Digital Twins Concept","summary":"  Digital Twins have emerged as a disruptive technology with great potential;\nthey can enhance WDS by offering real-time monitoring, predictive maintenance,\nand optimization capabilities. This paper describes the development of a\nstate-of-the-art DT platform for WDS, introducing advanced technologies such as\nthe Internet of Things, Artificial Intelligence, and Machine Learning models.\nThis paper provides insight into the architecture of the proposed\nplatform-CAUCCES-that, informed by both historical and meteorological data,\neffectively deploys AI/ML models like LSTM networks, Prophet, LightGBM, and\nXGBoost in trying to predict water consumption patterns. Furthermore, we delve\ninto how optimization in the maintenance of WDS can be achieved by formulating\na Constraint Programming problem for scheduling, hence minimizing the\noperational cost efficiently with reduced environmental impacts. It also\nfocuses on cybersecurity and protection to ensure the integrity and reliability\nof the DT platform. In this view, the system will contribute to improvements in\ndecision-making capabilities, operational efficiency, and system reliability,\nwith reassurance being drawn from the important role it can play toward\nsustainable management of water resources.\n","authors":["MohammadHossein Homaei","Agustín Javier Di Bartolo","Mar Ávila","Óscar Mogollón-Gutiérrez","Andrés Caro"],"pdf_url":"https://arxiv.org/pdf/2412.06694v1.pdf","comment":"78 pages, 18 figures"},{"id":"http://arxiv.org/abs/2412.06693v1","updated":"2024-12-09T17:39:43Z","published":"2024-12-09T17:39:43Z","title":"OmniEvalKit: A Modular, Lightweight Toolbox for Evaluating Large\n  Language Model and its Omni-Extensions","summary":"  The rapid advancements in Large Language Models (LLMs) have significantly\nexpanded their applications, ranging from multilingual support to\ndomain-specific tasks and multimodal integration. In this paper, we present\nOmniEvalKit, a novel benchmarking toolbox designed to evaluate LLMs and their\nomni-extensions across multilingual, multidomain, and multimodal capabilities.\nUnlike existing benchmarks that often focus on a single aspect, OmniEvalKit\nprovides a modular, lightweight, and automated evaluation system. It is\nstructured with a modular architecture comprising a Static Builder and Dynamic\nData Flow, promoting the seamless integration of new models and datasets.\nOmniEvalKit supports over 100 LLMs and 50 evaluation datasets, covering\ncomprehensive evaluations across thousands of model-dataset combinations.\nOmniEvalKit is dedicated to creating an ultra-lightweight and fast-deployable\nevaluation framework, making downstream applications more convenient and\nversatile for the AI community.\n","authors":["Yi-Kai Zhang","Xu-Xiang Zhong","Shiyin Lu","Qing-Guo Chen","De-Chuan Zhan","Han-Jia Ye"],"pdf_url":"https://arxiv.org/pdf/2412.06693v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.00892v4","updated":"2024-12-09T17:35:55Z","published":"2024-05-01T22:33:45Z","title":"Wake Vision: A Tailored Dataset and Benchmark Suite for TinyML Computer\n  Vision Applications","summary":"  Tiny machine learning (TinyML) for low-power devices lacks robust datasets\nfor development. We present Wake Vision, a large-scale dataset for person\ndetection that contains over 6 million quality-filtered images. We provide two\nvariants: Wake Vision (Large) and Wake Vision (Quality), leveraging the large\nvariant for pretraining and knowledge distillation, while the higher-quality\nlabels drive final model performance. The manually labeled validation and test\nsets reduce error rates from 7.8% to 2.2% compared to previous standards. In\naddition, we introduce five detailed benchmark sets to evaluate model\nperformance in real-world scenarios, including varying lighting, camera\ndistances, and demographic characteristics. Training with Wake Vision improves\naccuracy by 1.93% over existing datasets, demonstrating the importance of\ndataset quality for low-capacity models and dataset size for high-capacity\nmodels. The dataset, benchmarks, code, and models are available under the CC-BY\n4.0 license, maintained by the Edge AI Foundation.\n","authors":["Colby Banbury","Emil Njor","Andrea Mattia Garavagno","Matthew Stewart","Pete Warden","Manjunath Kudlur","Nat Jeffries","Xenofon Fafoutis","Vijay Janapa Reddi"],"pdf_url":"https://arxiv.org/pdf/2405.00892v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11319v3","updated":"2024-12-09T17:33:28Z","published":"2023-11-19T13:28:01Z","title":"GeoSAM: Fine-tuning SAM with Multi-Modal Prompts for Mobility\n  Infrastructure Segmentation","summary":"  In geographical image segmentation, performance is often constrained by the\nlimited availability of training data and a lack of generalizability,\nparticularly for segmenting mobility infrastructure such as roads, sidewalks,\nand crosswalks. Vision foundation models like the Segment Anything Model (SAM),\npre-trained on millions of natural images, have demonstrated impressive\nzero-shot segmentation performance, providing a potential solution. However,\nSAM struggles with geographical images, such as aerial and satellite imagery,\ndue to its training being confined to natural images and the narrow features\nand textures of these objects blending into their surroundings. To address\nthese challenges, we propose Geographical SAM (GeoSAM), a SAM-based framework\nthat fine-tunes SAM with automatically generated multi-modal prompts, combining\npoint prompts from a pre-trained task-specific model as primary visual guidance\nand text prompts from a large language model as secondary semantic guidance to\nenhance model comprehension. GeoSAM outperforms existing approaches for\nmobility infrastructure segmentation in both familiar and completely unseen\nregions by at least 5\\% in mIoU, representing a significant leap in leveraging\nfoundation models to segment mobility infrastructure, including both road and\npedestrian infrastructure in geographical images. The source code can be found\nin this GitHub Repository: https://github.com/rafiibnsultan/GeoSAM.\n","authors":["Rafi Ibn Sultan","Chengyin Li","Hui Zhu","Prashant Khanduri","Marco Brocanelli","Dongxiao Zhu"],"pdf_url":"https://arxiv.org/pdf/2311.11319v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.00535v3","updated":"2024-12-09T17:31:54Z","published":"2024-11-30T16:58:42Z","title":"FullStack Bench: Evaluating LLMs as Full Stack Coders","summary":"  As the capabilities of code large language models (LLMs) continue to expand,\ntheir applications across diverse code intelligence domains are rapidly\nincreasing. However, most existing datasets only evaluate limited application\ndomains. To address this gap, we have developed a comprehensive code evaluation\ndataset FullStack Bench focusing on full-stack programming, which encompasses a\nwide range of application domains (e.g., basic programming, data analysis,\nsoftware engineering, mathematics, and machine learning). Besides, to assess\nmultilingual programming capabilities, in FullStack Bench, we design real-world\ninstructions and corresponding unit test cases from 16 widely-used programming\nlanguages to reflect real-world usage scenarios rather than simple\ntranslations. Moreover, we also release an effective code sandbox execution\ntool (i.e., SandboxFusion) supporting various programming languages and\npackages to evaluate the performance of our FullStack Bench efficiently.\nComprehensive experimental results on our FullStack Bench demonstrate the\nnecessity and effectiveness of our FullStack Bench and SandboxFusion.\n","authors":["Siyao Liu","He Zhu","Jerry Liu","Shulin Xin","Aoyan Li","Rui Long","Li Chen","Jack Yang","Jinxiang Xia","Z. Y. Peng","Shukai Liu","Zhaoxiang Zhang","Jing Mai","Ge Zhang","Wenhao Huang","Kai Shen","Liang Xiang"],"pdf_url":"https://arxiv.org/pdf/2412.00535v3.pdf","comment":"26 pages"},{"id":"http://arxiv.org/abs/2412.06685v1","updated":"2024-12-09T17:28:03Z","published":"2024-12-09T17:28:03Z","title":"Policy Agnostic RL: Offline RL and Online RL Fine-Tuning of Any Class\n  and Backbone","summary":"  Recent advances in learning decision-making policies can largely be\nattributed to training expressive policy models, largely via imitation\nlearning. While imitation learning discards non-expert data, reinforcement\nlearning (RL) can still learn from suboptimal data. However, instantiating RL\ntraining of a new policy class often presents a different challenge: most deep\nRL machinery is co-developed with assumptions on the policy class and backbone,\nresulting in poor performance when the policy class changes. For instance, SAC\nutilizes a low-variance reparameterization policy gradient for Gaussian\npolicies, but this is unstable for diffusion policies and intractable for\nautoregressive categorical policies. To address this issue, we develop an\noffline RL and online fine-tuning approach called policy-agnostic RL (PA-RL)\nthat can effectively train multiple policy classes, with varying architectures\nand sizes. We build off the basic idea that a universal supervised learning\nloss can replace the policy improvement step in RL, as long as it is applied on\n\"optimized\" actions. To obtain these optimized actions, we first sample\nmultiple actions from a base policy, and run global optimization (i.e.,\nre-ranking multiple action samples using the Q-function) and local optimization\n(i.e., running gradient steps on an action sample) to maximize the critic on\nthese candidates. PA-RL enables fine-tuning diffusion and transformer policies\nwith either autoregressive tokens or continuous action outputs, at different\nsizes, entirely via actor-critic RL. Moreover, PA-RL improves the performance\nand sample-efficiency by up to 2 times compared to existing offline RL and\nonline fine-tuning methods. We show the first result that successfully\nfine-tunes OpenVLA, a 7B generalist robot policy, autonomously with Cal-QL, an\nonline RL fine-tuning algorithm, improving from 40% to 70% in the real world in\n40 minutes.\n","authors":["Max Sobol Mark","Tian Gao","Georgia Gabriela Sampaio","Mohan Kumar Srirama","Archit Sharma","Chelsea Finn","Aviral Kumar"],"pdf_url":"https://arxiv.org/pdf/2412.06685v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06681v1","updated":"2024-12-09T17:24:41Z","published":"2024-12-09T17:24:41Z","title":"Toward LLM-Agent-Based Modeling of Transportation Systems: A Conceptual\n  Framework","summary":"  In transportation system demand modeling and simulation, agent-based models\nand microsimulations are current state-of-the-art approaches. However, existing\nagent-based models still have some limitations on behavioral realism and\nresource demand that limit their applicability. In this study, leveraging the\nemerging technology of large language models (LLMs) and LLM-based agents, we\npropose a general LLM-agent-based modeling framework for transportation\nsystems. We argue that LLM agents not only possess the essential capabilities\nto function as agents but also offer promising solutions to overcome some\nlimitations of existing agent-based models. Our conceptual framework design\nclosely replicates the decision-making and interaction processes and traits of\nhuman travelers within transportation networks, and we demonstrate that the\nproposed systems can meet critical behavioral criteria for decision-making and\nlearning behaviors using related studies and a demonstrative example of LLM\nagents' learning and adjustment in the bottleneck setting. Although further\nrefinement of the LLM-agent-based modeling framework is necessary, we believe\nthat this approach has the potential to improve transportation system modeling\nand simulation.\n","authors":["Tianming Liu","Jirong Yang","Yafeng Yin"],"pdf_url":"https://arxiv.org/pdf/2412.06681v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06649v1","updated":"2024-12-09T16:43:23Z","published":"2024-12-09T16:43:23Z","title":"Semantic Search and Recommendation Algorithm","summary":"  This paper introduces a new semantic search algorithm that uses Word2Vec and\nAnnoy Index to improve the efficiency of information retrieval from large\ndatasets. The proposed approach addresses the limitations of traditional search\nmethods by offering enhanced speed, accuracy, and scalability. Testing on\ndatasets up to 100GB demonstrates the method's effectiveness in processing vast\namounts of data while maintaining high precision and performance.\n","authors":["Aryan Duhan","Aryan Singhal","Shourya Sharma"," Neeraj","Arti MK"],"pdf_url":"https://arxiv.org/pdf/2412.06649v1.pdf","comment":"6 pages, 5 Figures"},{"id":"http://arxiv.org/abs/2403.16851v2","updated":"2024-12-09T16:42:25Z","published":"2024-03-25T15:15:09Z","title":"Can tweets predict article retractions? A comparison between human and\n  LLM labelling","summary":"  Quickly detecting problematic research articles is crucial to safeguarding\nthe integrity of scientific research. This study explores whether Twitter\nmentions of retracted articles can signal potential problems with the articles\nprior to their retraction, potentially serving as an early warning system for\nscholars. To investigate this, we analysed a dataset of 4,354 Twitter mentions\nassociated with 504 retracted articles. The effectiveness of Twitter mentions\nin predicting article retractions was evaluated by both manual and Large\nLanguage Model (LLM) labelling. Manual labelling results indicated that 25.7%\nof tweets signalled problems before retraction. Using the manual labelling\nresults as the baseline, we found that LLMs (GPT-4o-mini, Gemini 1.5 Flash, and\nClaude-3.5-Haiku) outperformed lexicon-based sentiment analysis tools (e.g.,\nTextBlob) in detecting potential problems, suggesting that automatic detection\nof problematic articles from social media using LLMs is technically feasible.\nNevertheless, since only a small proportion of retracted articles (11.1%) were\ncriticised on Twitter prior to retraction, such automatic systems would detect\nonly a minority of problematic articles. Overall, this study offers insights\ninto how social media data, coupled with emerging generative AI techniques, can\nsupport research integrity.\n","authors":["Er-Te Zheng","Hui-Zhen Fu","Mike Thelwall","Zhichao Fang"],"pdf_url":"https://arxiv.org/pdf/2403.16851v2.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2412.06643v1","updated":"2024-12-09T16:37:27Z","published":"2024-12-09T16:37:27Z","title":"Detecting Facial Image Manipulations with Multi-Layer CNN Models","summary":"  The rapid evolution of digital image manipulation techniques poses\nsignificant challenges for content verification, with models such as stable\ndiffusion and mid-journey producing highly realistic, yet synthetic, images\nthat can deceive human perception. This research develops and evaluates\nconvolutional neural networks (CNNs) specifically tailored for the detection of\nthese manipulated images. The study implements a comparative analysis of three\nprogressively complex CNN architectures, assessing their ability to classify\nand localize manipulations across various facial image modifications.\nRegularization and optimization techniques were systematically incorporated to\nimprove feature extraction and performance. The results indicate that the\nproposed models achieve an accuracy of up to 76\\% in distinguishing manipulated\nimages from genuine ones, surpassing traditional approaches. This research not\nonly highlights the potential of CNNs in enhancing the robustness of digital\nmedia verification tools, but also provides insights into effective\narchitectural adaptations and training strategies for low-computation\nenvironments. Future work will build on these findings by extending the\narchitectures to handle more diverse manipulation techniques and integrating\nmulti-modal data for improved detection capabilities.\n","authors":["Alejandro Marco Montejano","Angela Sanchez Perez","Javier Barrachina","David Ortiz-Perez","Manuel Benavent-Lledo","Jose Garcia-Rodriguez"],"pdf_url":"https://arxiv.org/pdf/2412.06643v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04105v3","updated":"2024-12-09T16:36:34Z","published":"2024-11-06T18:35:32Z","title":"How Transformers Solve Propositional Logic Problems: A Mechanistic\n  Analysis","summary":"  Large language models (LLMs) have shown amazing performance on tasks that\nrequire planning and reasoning. Motivated by this, we investigate the internal\nmechanisms that underpin a network's ability to perform complex logical\nreasoning. We first construct a synthetic propositional logic problem that\nserves as a concrete test-bed for network training and evaluation. Crucially,\nthis problem demands nontrivial planning to solve. We perform our study on two\nfronts. First, we pursue an understanding of precisely how a three-layer\ntransformer, trained from scratch and attains perfect test accuracy, solves\nthis problem. We are able to identify certain \"planning\" and \"reasoning\"\nmechanisms in the network that necessitate cooperation between the attention\nblocks to implement the desired logic. Second, we study how pretrained LLMs,\nnamely Mistral-7B and Gemma-2-9B, solve this problem. We characterize their\nreasoning circuits through causal intervention experiments, providing necessity\nand sufficiency evidence for the circuits. We find evidence suggesting that the\ntwo models' latent reasoning strategies are surprisingly similar, and\nhuman-like. Overall, our work systemically uncovers novel aspects of small and\nlarge transformers, and continues the study of how they plan and reason.\n","authors":["Guan Zhe Hong","Nishanth Dikkala","Enming Luo","Cyrus Rashtchian","Xin Wang","Rina Panigrahy"],"pdf_url":"https://arxiv.org/pdf/2411.04105v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06639v1","updated":"2024-12-09T16:33:28Z","published":"2024-12-09T16:33:28Z","title":"Beyond Scalars: Concept-Based Alignment Analysis in Vision Transformers","summary":"  Vision transformers (ViTs) can be trained using various learning paradigms,\nfrom fully supervised to self-supervised. Diverse training protocols often\nresult in significantly different feature spaces, which are usually compared\nthrough alignment analysis. However, current alignment measures quantify this\nrelationship in terms of a single scalar value, obscuring the distinctions\nbetween common and unique features in pairs of representations that share the\nsame scalar alignment. We address this limitation by combining alignment\nanalysis with concept discovery, which enables a breakdown of alignment into\nsingle concepts encoded in feature space. This fine-grained comparison reveals\nboth universal and unique concepts across different representations, as well as\nthe internal structure of concepts within each of them. Our methodological\ncontributions address two key prerequisites for concept-based alignment: 1) For\na description of the representation in terms of concepts that faithfully\ncapture the geometry of the feature space, we define concepts as the most\ngeneral structure they can possibly form - arbitrary manifolds, allowing hidden\nfeatures to be described by their proximity to these manifolds. 2) To measure\ndistances between concept proximity scores of two representations, we use a\ngeneralized Rand index and partition it for alignment between pairs of\nconcepts. We confirm the superiority of our novel concept definition for\nalignment analysis over existing linear baselines in a sanity check. The\nconcept-based alignment analysis of representations from four different ViTs\nreveals that increased supervision correlates with a reduction in the semantic\nstructure of learned representations.\n","authors":["Johanna Vielhaben","Dilyara Bareeva","Jim Berend","Wojciech Samek","Nils Strodthoff"],"pdf_url":"https://arxiv.org/pdf/2412.06639v1.pdf","comment":"19 pages, 17 figures, code: https://github.com/jvielhaben/NLMCD-ALIGN"},{"id":"http://arxiv.org/abs/2412.06624v1","updated":"2024-12-09T16:16:25Z","published":"2024-12-09T16:16:25Z","title":"Fundus Image-based Visual Acuity Assessment with PAC-Guarantees","summary":"  Timely detection and treatment are essential for maintaining eye health.\nVisual acuity (VA), which measures the clarity of vision at a distance, is a\ncrucial metric for managing eye health. Machine learning (ML) techniques have\nbeen introduced to assist in VA measurement, potentially alleviating\nclinicians' workloads. However, the inherent uncertainties in ML models make\nrelying solely on them for VA prediction less than ideal. The VA prediction\ntask involves multiple sources of uncertainty, requiring more robust\napproaches. A promising method is to build prediction sets or intervals rather\nthan point estimates, offering coverage guarantees through techniques like\nconformal prediction and Probably Approximately Correct (PAC) prediction sets.\nDespite the potential, to date, these approaches have not been applied to the\nVA prediction task.To address this, we propose a method for deriving prediction\nintervals for estimating visual acuity from fundus images with a PAC guarantee.\nOur experimental results demonstrate that the PAC guarantees are upheld, with\nperformance comparable to or better than that of two prior works that do not\nprovide such guarantees.\n","authors":["Sooyong Jang","Kuk Jin Jang","Hyonyoung Choi","Yong-Seop Han","Seongjin Lee","Jin-hyun Kim","Insup Lee"],"pdf_url":"https://arxiv.org/pdf/2412.06624v1.pdf","comment":"To be published in ML4H 2024"},{"id":"http://arxiv.org/abs/2412.04455v2","updated":"2024-12-09T16:07:24Z","published":"2024-12-05T18:58:27Z","title":"Code-as-Monitor: Constraint-aware Visual Programming for Reactive and\n  Proactive Robotic Failure Detection","summary":"  Automatic detection and prevention of open-set failures are crucial in\nclosed-loop robotic systems. Recent studies often struggle to simultaneously\nidentify unexpected failures reactively after they occur and prevent\nforeseeable ones proactively. To this end, we propose Code-as-Monitor (CaM), a\nnovel paradigm leveraging the vision-language model (VLM) for both open-set\nreactive and proactive failure detection. The core of our method is to\nformulate both tasks as a unified set of spatio-temporal constraint\nsatisfaction problems and use VLM-generated code to evaluate them for real-time\nmonitoring. To enhance the accuracy and efficiency of monitoring, we further\nintroduce constraint elements that abstract constraint-related entities or\ntheir parts into compact geometric elements. This approach offers greater\ngenerality, simplifies tracking, and facilitates constraint-aware visual\nprogramming by leveraging these elements as visual prompts. Experiments show\nthat CaM achieves a 28.7% higher success rate and reduces execution time by\n31.8% under severe disturbances compared to baselines across three simulators\nand a real-world setting. Moreover, CaM can be integrated with open-loop\ncontrol policies to form closed-loop systems, enabling long-horizon tasks in\ncluttered scenes with dynamic environments.\n","authors":["Enshen Zhou","Qi Su","Cheng Chi","Zhizheng Zhang","Zhongyuan Wang","Tiejun Huang","Lu Sheng","He Wang"],"pdf_url":"https://arxiv.org/pdf/2412.04455v2.pdf","comment":"Project page: https://zhoues.github.io/Code-as-Monitor/"},{"id":"http://arxiv.org/abs/2412.03600v2","updated":"2024-12-09T16:06:08Z","published":"2024-12-03T08:53:32Z","title":"Social Media Informatics for Sustainable Cities and Societies: An\n  Overview of the Applications, associated Challenges, and Potential Solutions","summary":"  In the modern world, our cities and societies face several technological and\nsocietal challenges, such as rapid urbanization, global warming & climate\nchange, the digital divide, and social inequalities, increasing the need for\nmore sustainable cities and societies. Addressing these challenges requires a\nmultifaceted approach involving all the stakeholders, sustainable planning,\nefficient resource management, innovative solutions, and modern technologies.\nLike other modern technologies, social media informatics also plays its part in\ndeveloping more sustainable and resilient cities and societies. Despite its\nlimitations, social media informatics has proven very effective in various\nsustainable cities and society applications. In this paper, we review and\nanalyze the role of social media informatics in sustainable cities and society\nby providing a detailed overview of its applications, associated challenges,\nand potential solutions. This work is expected to provide a baseline for future\nresearch in the domain.\n","authors":["Jebran Khan","Kashif Ahmad","Senthil Kumar Jagatheesaperumal","Nasir Ahmad","Kyung-Ah Sohn"],"pdf_url":"https://arxiv.org/pdf/2412.03600v2.pdf","comment":"35 pages, 3 tables, and 4 figures"},{"id":"http://arxiv.org/abs/2412.05270v2","updated":"2024-12-09T16:01:00Z","published":"2024-12-06T18:55:34Z","title":"APOLLO: SGD-like Memory, AdamW-level Performance","summary":"  Large language models (LLMs) are notoriously memory-intensive during\ntraining, particularly with the popular AdamW optimizer. This memory burden\nnecessitates using more or higher-end GPUs or reducing batch sizes, limiting\ntraining scalability and throughput. To address this, various memory-efficient\noptimizers have been proposed to reduce optimizer memory usage. However, they\nface critical challenges: (i) reliance on costly SVD operations; (ii)\nsignificant performance trade-offs compared to AdamW; and (iii) still\nsubstantial optimizer memory overhead to maintain competitive performance.\n  In this work, we identify that AdamW's learning rate adaptation rule can be\neffectively coarsened as a structured learning rate update. Based on this\ninsight, we propose Approximated Gradient Scaling for Memory-Efficient LLM\nOptimization (APOLLO), which approximates learning rate scaling using an\nauxiliary low-rank optimizer state based on pure random projection. This\nstructured learning rate update rule makes APOLLO highly tolerant to further\nmemory reductions while delivering comparable pre-training performance. Even\nits rank-1 variant, APOLLO-Mini, achieves superior pre-training performance\ncompared to AdamW with SGD-level memory costs.\n  Extensive experiments demonstrate that the APOLLO series performs on-par with\nor better than AdamW, while achieving greater memory savings by nearly\neliminating the optimization states of AdamW. These savings provide significant\nsystem-level benefits: (1) Enhanced Throughput: 3x throughput on an 8xA100-80GB\nsetup compared to AdamW by supporting 4x larger batch sizes. (2) Improved Model\nScalability: Pre-training LLaMA-13B with naive DDP on A100-80GB GPUs without\nsystem-level optimizations. (3) Low-End GPU Friendly Pre-training: Pre-training\nLLaMA-7B on a single GPU using less than 12 GB of memory with weight\nquantization.\n","authors":["Hanqing Zhu","Zhenyu Zhang","Wenyan Cong","Xi Liu","Sem Park","Vikas Chandra","Bo Long","David Z. Pan","Zhangyang Wang","Jinwon Lee"],"pdf_url":"https://arxiv.org/pdf/2412.05270v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2406.02534v2","updated":"2024-12-09T15:58:55Z","published":"2024-06-04T17:54:44Z","title":"Enhancing predictive imaging biomarker discovery through treatment\n  effect analysis","summary":"  Identifying predictive covariates, which forecast individual treatment\neffectiveness, is crucial for decision-making across different disciplines such\nas personalized medicine. These covariates, referred to as biomarkers, are\nextracted from pre-treatment data, often within randomized controlled trials,\nand should be distinguished from prognostic biomarkers, which are independent\nof treatment assignment. Our study focuses on discovering predictive imaging\nbiomarkers, specific image features, by leveraging pre-treatment images to\nuncover new causal relationships. Unlike labor-intensive approaches relying on\nhandcrafted features prone to bias, we present a novel task of directly\nlearning predictive features from images. We propose an evaluation protocol to\nassess a model's ability to identify predictive imaging biomarkers and\ndifferentiate them from purely prognostic ones by employing statistical testing\nand a comprehensive analysis of image feature attribution. We explore the\nsuitability of deep learning models originally developed for estimating the\nconditional average treatment effect (CATE) for this task, which have been\nassessed primarily for their precision of CATE estimation while overlooking the\nevaluation of imaging biomarker discovery. Our proof-of-concept analysis\ndemonstrates the feasibility and potential of our approach in discovering and\nvalidating predictive imaging biomarkers from synthetic outcomes and real-world\nimage datasets. Our code is available at\n\\url{https://github.com/MIC-DKFZ/predictive_image_biomarker_analysis}.\n","authors":["Shuhan Xiao","Lukas Klein","Jens Petersen","Philipp Vollmuth","Paul F. Jaeger","Klaus H. Maier-Hein"],"pdf_url":"https://arxiv.org/pdf/2406.02534v2.pdf","comment":"Accepted to WACV 2025"},{"id":"http://arxiv.org/abs/2412.02779v2","updated":"2024-12-09T15:56:08Z","published":"2024-12-03T19:20:08Z","title":"Synergistic Development of Perovskite Memristors and Algorithms for\n  Robust Analog Computing","summary":"  Analog computing using non-volatile memristors has emerged as a promising\nsolution for energy-efficient deep learning. New materials, like\nperovskites-based memristors are recently attractive due to their\ncost-effectiveness, energy efficiency and flexibility. Yet, challenges in\nmaterial diversity and immature fabrications require extensive experimentation\nfor device development. Moreover, significant non-idealities in these\nmemristors often impede them for computing. Here, we propose a synergistic\nmethodology to concurrently optimize perovskite memristor fabrication and\ndevelop robust analog DNNs that effectively address the inherent non-idealities\nof these memristors. Employing Bayesian optimization (BO) with a focus on\nusability, we efficiently identify optimal materials and fabrication conditions\nfor perovskite memristors. Meanwhile, we developed \"BayesMulti\", a DNN training\nstrategy utilizing BO-guided noise injection to improve the resistance of\nanalog DNNs to memristor imperfections. Our approach theoretically ensures that\nwithin a certain range of parameter perturbations due to memristor\nnon-idealities, the prediction outcomes remain consistent. Our integrated\napproach enables use of analog computing in much deeper and wider networks,\nwhich significantly outperforms existing methods in diverse tasks like image\nclassification, autonomous driving, species identification, and large\nvision-language models, achieving up to 100-fold improvements. We further\nvalidate our methodology on a 10$\\times$10 optimized perovskite memristor\ncrossbar, demonstrating high accuracy in a classification task and low energy\nconsumption. This study offers a versatile solution for efficient optimization\nof various analog computing systems, encompassing both devices and algorithms.\n","authors":["Nanyang Ye","Qiao Sun","Yifei Wang","Liujia Yang","Jundong Zhou","Lei Wang","Guang-Zhong Yang","Xinbing Wang","Chenghu Zhou","Wei Ren","Leilei Gu","Huaqiang Wu","Qinying Gu"],"pdf_url":"https://arxiv.org/pdf/2412.02779v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06602v1","updated":"2024-12-09T15:50:25Z","published":"2024-12-09T15:50:25Z","title":"Towards Controllable Speech Synthesis in the Era of Large Language\n  Models: A Survey","summary":"  Text-to-speech (TTS), also known as speech synthesis, is a prominent research\narea that aims to generate natural-sounding human speech from text. Recently,\nwith the increasing industrial demand, TTS technologies have evolved beyond\nsynthesizing human-like speech to enabling controllable speech generation. This\nincludes fine-grained control over various attributes of synthesized speech\nsuch as emotion, prosody, timbre, and duration. Besides, advancements in deep\nlearning, such as diffusion and large language models, have significantly\nenhanced controllable TTS over the past several years. In this paper, we\nconduct a comprehensive survey of controllable TTS, covering approaches ranging\nfrom basic control techniques to methods utilizing natural language prompts,\naiming to provide a clear understanding of the current state of research. We\nexamine the general controllable TTS pipeline, challenges, model architectures,\nand control strategies, offering a comprehensive and clear taxonomy of existing\nmethods. Additionally, we provide a detailed summary of datasets and evaluation\nmetrics and shed some light on the applications and future directions of\ncontrollable TTS. To the best of our knowledge, this survey paper provides the\nfirst comprehensive review of emerging controllable TTS methods, which can\nserve as a beneficial resource for both academic researchers and industry\npractitioners.\n","authors":["Tianxin Xie","Yan Rong","Pengfei Zhang","Li Liu"],"pdf_url":"https://arxiv.org/pdf/2412.06602v1.pdf","comment":"A comprehensive survey on controllable TTS, 23 pages, 6 tables, 4\n  figures, 280 references"},{"id":"http://arxiv.org/abs/2412.06600v1","updated":"2024-12-09T15:49:18Z","published":"2024-12-09T15:49:18Z","title":"Advancing Music Therapy: Integrating Eastern Five-Element Music Theory\n  and Western Techniques with AI in the Novel Five-Element Harmony System","summary":"  In traditional medical practices, music therapy has proven effective in\ntreating various psychological and physiological ailments. Particularly in\nEastern traditions, the Five Elements Music Therapy (FEMT), rooted in\ntraditional Chinese medicine, possesses profound cultural significance and\nunique therapeutic philosophies. With the rapid advancement of Information\nTechnology and Artificial Intelligence, applying these modern technologies to\nFEMT could enhance the personalization and cultural relevance of the therapy\nand potentially improve therapeutic outcomes. In this article, we developed a\nmusic therapy system for the first time by applying the theory of the five\nelements in music therapy to practice. This innovative approach integrates\nadvanced Information Technology and Artificial Intelligence with Five-Element\nMusic Therapy (FEMT) to enhance personalized music therapy practices. As\ntraditional music therapy predominantly follows Western methodologies, the\nunique aspects of Eastern practices, specifically the Five-Element theory from\ntraditional Chinese medicine, should be considered. This system aims to bridge\nthis gap by utilizing computational technologies to provide a more\npersonalized, culturally relevant, and therapeutically effective music therapy\nexperience.\n","authors":["Yubo Zhou","Weizhen Bian","Kaitai Zhang","Xiaohan Gu"],"pdf_url":"https://arxiv.org/pdf/2412.06600v1.pdf","comment":"5 pages, 1 figure. Accepted for Publication in the International\n  Symposium on Chinese Spoken Language Processing"},{"id":"http://arxiv.org/abs/2402.05374v4","updated":"2024-12-09T15:39:30Z","published":"2024-02-08T03:12:25Z","title":"CIC: A Framework for Culturally-Aware Image Captioning","summary":"  Image Captioning generates descriptive sentences from images using\nVision-Language Pre-trained models (VLPs) such as BLIP, which has improved\ngreatly. However, current methods lack the generation of detailed descriptive\ncaptions for the cultural elements depicted in the images, such as the\ntraditional clothing worn by people from Asian cultural groups. In this paper,\nwe propose a new framework, Culturally-aware Image Captioning (CIC), that\ngenerates captions and describes cultural elements extracted from cultural\nvisual elements in images representing cultures. Inspired by methods combining\nvisual modality and Large Language Models (LLMs) through appropriate prompts,\nour framework (1) generates questions based on cultural categories from images,\n(2) extracts cultural visual elements from Visual Question Answering (VQA)\nusing generated questions, and (3) generates culturally-aware captions using\nLLMs with the prompts. Our human evaluation conducted on 45 participants from 4\ndifferent cultural groups with a high understanding of the corresponding\nculture shows that our proposed framework generates more culturally descriptive\ncaptions when compared to the image captioning baseline based on VLPs.\nResources can be found at https://shane3606.github.io/cic..\n","authors":["Youngsik Yun","Jihie Kim"],"pdf_url":"https://arxiv.org/pdf/2402.05374v4.pdf","comment":"Accepted in IJCAI 2024"},{"id":"http://arxiv.org/abs/2412.06581v1","updated":"2024-12-09T15:36:37Z","published":"2024-12-09T15:36:37Z","title":"EmoSpeech: A Corpus of Emotionally Rich and Contextually Detailed Speech\n  Annotations","summary":"  Advances in text-to-speech (TTS) technology have significantly improved the\nquality of generated speech, closely matching the timbre and intonation of the\ntarget speaker. However, due to the inherent complexity of human emotional\nexpression, the development of TTS systems capable of controlling subtle\nemotional differences remains a formidable challenge. Existing emotional speech\ndatabases often suffer from overly simplistic labelling schemes that fail to\ncapture a wide range of emotional states, thus limiting the effectiveness of\nemotion synthesis in TTS applications. To this end, recent efforts have\nfocussed on building databases that use natural language annotations to\ndescribe speech emotions. However, these approaches are costly and require more\nemotional depth to train robust systems. In this paper, we propose a novel\nprocess aimed at building databases by systematically extracting emotion-rich\nspeech segments and annotating them with detailed natural language descriptions\nthrough a generative model. This approach enhances the emotional granularity of\nthe database and significantly reduces the reliance on costly manual\nannotations by automatically augmenting the data with high-level language\nmodels. The resulting rich database provides a scalable and economically viable\nsolution for developing a more nuanced and dynamic basis for developing\nemotionally controlled TTS systems.\n","authors":["Weizhen Bian","Yubo Zhou","Kaitai Zhang","Xiaohan Gu"],"pdf_url":"https://arxiv.org/pdf/2412.06581v1.pdf","comment":"4 pages, 1 figure. To appear in the Proceedings of the International\n  Symposium on Chinese Spoken Language Processing, 7-10 November 2024, Beijing,\n  China"},{"id":"http://arxiv.org/abs/2410.21939v2","updated":"2024-12-09T15:29:55Z","published":"2024-10-29T10:57:11Z","title":"AI Cyber Risk Benchmark: Automated Exploitation Capabilities","summary":"  We introduce a new benchmark for assessing AI models' capabilities and risks\nin automated software exploitation, focusing on their ability to detect and\nexploit vulnerabilities in real-world software systems. Using DARPA's AI Cyber\nChallenge (AIxCC) framework and the Nginx challenge project, a deliberately\nmodified version of the widely used Nginx web server, we evaluate several\nleading language models, including OpenAI's o1-preview and o1-mini, Anthropic's\nClaude-3.5-sonnet-20241022 and Claude-3.5-sonnet-20240620, Google DeepMind's\nGemini-1.5-pro, and OpenAI's earlier GPT-4o model. Our findings reveal that\nthese models vary significantly in their success rates and efficiency, with\no1-preview achieving the highest success rate of 64.71 percent and o1-mini and\nClaude-3.5-sonnet-20241022 providing cost-effective but less successful\nalternatives. This benchmark establishes a foundation for systematically\nevaluating the AI cyber risk posed by automated exploitation tools.\n","authors":["Dan Ristea","Vasilios Mavroudis","Chris Hicks"],"pdf_url":"https://arxiv.org/pdf/2410.21939v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10578v6","updated":"2024-12-09T15:26:00Z","published":"2024-10-14T14:52:23Z","title":"Burning RED: Unlocking Subtask-Driven Reinforcement Learning and\n  Risk-Awareness in Average-Reward Markov Decision Processes","summary":"  Average-reward Markov decision processes (MDPs) provide a foundational\nframework for sequential decision-making under uncertainty. However,\naverage-reward MDPs have remained largely unexplored in reinforcement learning\n(RL) settings, with the majority of RL-based efforts having been allocated to\nepisodic and discounted MDPs. In this work, we study a unique structural\nproperty of average-reward MDPs and utilize it to introduce Reward-Extended\nDifferential (or RED) reinforcement learning: a novel RL framework that can be\nused to effectively and efficiently solve various subtasks simultaneously in\nthe average-reward setting. We introduce a family of RED learning algorithms\nfor prediction and control, including proven-convergent algorithms for the\ntabular case. We then showcase the power of these algorithms by demonstrating\nhow they can be used to learn a policy that optimizes, for the first time, the\nwell-known conditional value-at-risk (CVaR) risk measure in a fully-online\nmanner, without the use of an explicit bi-level optimization scheme or an\naugmented state-space.\n","authors":["Juan Sebastian Rojas","Chi-Guhn Lee"],"pdf_url":"https://arxiv.org/pdf/2410.10578v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.11148v2","updated":"2024-12-09T15:16:02Z","published":"2024-09-17T13:02:19Z","title":"Improving the Efficiency of Visually Augmented Language Models","summary":"  Despite the impressive performance of autoregressive Language Models (LM) it\nhas been shown that due to reporting bias, LMs lack visual knowledge, i.e. they\ndo not know much about the visual world and its properties. To augment LMs with\nvisual knowledge, existing solutions often rely on explicit images, requiring\ntime-consuming retrieval or image generation systems. This paper shows that\nexplicit images are not necessary to visually augment an LM. Instead, we use\nvisually-grounded text representations obtained from the well-known CLIP\nmultimodal system. For a fair comparison, we modify VALM, a visually-augmented\nLM which uses image retrieval and representation, to work directly with\nvisually-grounded text representations. We name this new model BLIND-VALM. We\nshow that BLIND-VALM performs on par with VALM for Visual Language\nUnderstanding (VLU), Natural Language Understanding (NLU) and Language Modeling\ntasks, despite being significantly more efficient and simpler. We also show\nthat scaling up our model within the compute budget of VALM, either increasing\nthe model or pre-training corpus size, we outperform VALM for all the\nevaluation tasks.\n","authors":["Paula Ontalvilla","Aitor Ormazabal","Gorka Azkune"],"pdf_url":"https://arxiv.org/pdf/2409.11148v2.pdf","comment":"COLING 2025"},{"id":"http://arxiv.org/abs/2412.00789v2","updated":"2024-12-09T15:14:03Z","published":"2024-12-01T12:23:25Z","title":"A Cognac shot to forget bad memories: Corrective Unlearning in GNNs","summary":"  Graph Neural Networks (GNNs) are increasingly being used for a variety of ML\napplications on graph data. Because graph data does not follow the\nindependently and identically distributed (i.i.d.) assumption, adversarial\nmanipulations or incorrect data can propagate to other data points through\nmessage passing, which deteriorates the model's performance. To allow model\ndevelopers to remove the adverse effects of manipulated entities from a trained\nGNN, we study the recently formulated problem of Corrective Unlearning. We find\nthat current graph unlearning methods fail to unlearn the effect of\nmanipulations even when the whole manipulated set is known. We introduce a new\ngraph unlearning method, Cognac, which can unlearn the effect of the\nmanipulation set even when only 5% of it is identified. It recovers most of the\nperformance of a strong oracle with fully corrected training data, even beating\nretraining from scratch without the deletion set while being 8x more efficient.\nWe hope our work assists GNN developers in mitigating harmful effects caused by\nissues in real-world data post-training. Our code is publicly available at\nhttps://github.com/varshitakolipaka/corrective-unlearning-for-gnns\n","authors":["Varshita Kolipaka","Akshit Sinha","Debangan Mishra","Sumit Kumar","Arvindh Arun","Shashwat Goel","Ponnurangam Kumaraguru"],"pdf_url":"https://arxiv.org/pdf/2412.00789v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06559v1","updated":"2024-12-09T15:11:40Z","published":"2024-12-09T15:11:40Z","title":"ProcessBench: Identifying Process Errors in Mathematical Reasoning","summary":"  As language models regularly make mistakes when solving math problems,\nautomated identification of errors in the reasoning process becomes\nincreasingly significant for their scalable oversight. In this paper, we\nintroduce ProcessBench for measuring the ability to identify erroneous steps in\nmathematical reasoning. It consists of 3,400 test cases, primarily focused on\ncompetition- and Olympiad-level math problems. Each test case contains a\nstep-by-step solution with error location annotated by human experts. Models\nare required to identify the earliest step that contains an error, or conclude\nthat all steps are correct. We conduct extensive evaluation on ProcessBench,\ninvolving two types of models: process reward models (PRMs) and critic models,\nwhere for the latter we prompt general language models to critique each\nsolution step by step. We draw two main observations: (1) Existing PRMs\ntypically fail to generalize to more challenging math problems beyond GSM8K and\nMATH. They underperform both critic models (i.e., prompted general language\nmodels) and our own trained PRM that is straightforwardly fine-tuned on the\nPRM800K dataset. (2) The best open-source model, QwQ-32B-Preview, has\ndemonstrated the critique capability competitive with the proprietary model\nGPT-4o, despite that it still lags behind the reasoning-specialized o1-mini. We\nhope ProcessBench can foster future research in reasoning process assessment,\npaving the way toward scalable oversight of language models.\n","authors":["Chujie Zheng","Zhenru Zhang","Beichen Zhang","Runji Lin","Keming Lu","Bowen Yu","Dayiheng Liu","Jingren Zhou","Junyang Lin"],"pdf_url":"https://arxiv.org/pdf/2412.06559v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.17365v2","updated":"2024-12-09T15:10:19Z","published":"2024-04-26T12:30:32Z","title":"Similarity Equivariant Graph Neural Networks for Homogenization of\n  Metamaterials","summary":"  Soft, porous mechanical metamaterials exhibit pattern transformations that\nmay have important applications in soft robotics, sound reduction and\nbiomedicine. To design these innovative materials, it is important to be able\nto simulate them accurately and quickly, in order to tune their mechanical\nproperties. Since conventional simulations using the finite element method\nentail a high computational cost, in this article we aim to develop a machine\nlearning-based approach that scales favorably to serve as a surrogate model. To\nensure that the model is also able to handle various microstructures, including\nthose not encountered during training, we include the microstructure as part of\nthe network input. Therefore, we introduce a graph neural network that predicts\nglobal quantities (energy, stress stiffness) as well as the pattern\ntransformations that occur (the kinematics). To make our model as accurate and\ndata-efficient as possible, various symmetries are incorporated into the model.\nThe starting point is an E(n)-equivariant graph neural network (which respects\ntranslation, rotation and reflection) that has periodic boundary conditions\n(i.e., it is in-/equivariant with respect to the choice of RVE), is scale\nin-/equivariant, can simulate large deformations, and can predict scalars,\nvectors as well as second and fourth order tensors (specifically energy, stress\nand stiffness). The incorporation of scale equivariance makes the model\nequivariant with respect to the similarities group, of which the Euclidean\ngroup E(n) is a subgroup. We show that this network is more accurate and\ndata-efficient than graph neural networks with fewer symmetries. To create an\nefficient graph representation of the finite element discretization, we use\nonly the internal geometrical hole boundaries from the finite element mesh to\nachieve a better speed-up and scaling with the mesh size.\n","authors":["Fleur Hendriks","Vlado Menkovski","Martin Doškář","Marc G. D. Geers","Ondřej Rokoš"],"pdf_url":"https://arxiv.org/pdf/2404.17365v2.pdf","comment":"60 pages, 22 figures. Submitted to CMAME (Computer Methods in Applied\n  Mechanics and Engineering)"},{"id":"http://arxiv.org/abs/2412.06540v1","updated":"2024-12-09T14:51:26Z","published":"2024-12-09T14:51:26Z","title":"Sloth: scaling laws for LLM skills to predict multi-benchmark\n  performance across families","summary":"  Scaling laws for large language models (LLMs) predict model performance based\non parameters like size and training data. However, differences in training\nconfigurations and data processing across model families lead to significant\nvariations in benchmark performance, making it difficult for a single scaling\nlaw to generalize across all LLMs. On the other hand, training family-specific\nscaling laws requires training models of varying sizes for every family. In\nthis work, we propose Skills Scaling Laws (SSLaws, pronounced as Sloth), a\nnovel scaling law that leverages publicly available benchmark data and assumes\nLLM performance is driven by low-dimensional latent skills, such as reasoning\nand instruction following. These latent skills are influenced by computational\nresources like model size and training tokens but with varying efficiencies\nacross model families. Sloth exploits correlations across benchmarks to provide\nmore accurate and interpretable predictions while alleviating the need to train\nmultiple LLMs per family. We present both theoretical results on parameter\nidentification and empirical evaluations on 12 prominent benchmarks, from Open\nLLM Leaderboard v1/v2, demonstrating that Sloth predicts LLM performance\nefficiently and offers insights into scaling behaviors for downstream tasks\nsuch as coding and emotional intelligence applications.\n","authors":["Felipe Maia Polo","Seamus Somerstep","Leshem Choshen","Yuekai Sun","Mikhail Yurochkin"],"pdf_url":"https://arxiv.org/pdf/2412.06540v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.16089v2","updated":"2024-12-09T14:41:53Z","published":"2024-09-24T13:40:39Z","title":"From Pixels to Words: Leveraging Explainability in Face Recognition\n  through Interactive Natural Language Processing","summary":"  Face Recognition (FR) has advanced significantly with the development of deep\nlearning, achieving high accuracy in several applications. However, the lack of\ninterpretability of these systems raises concerns about their accountability,\nfairness, and reliability. In the present study, we propose an interactive\nframework to enhance the explainability of FR models by combining\nmodel-agnostic Explainable Artificial Intelligence (XAI) and Natural Language\nProcessing (NLP) techniques. The proposed framework is able to accurately\nanswer various questions of the user through an interactive chatbot. In\nparticular, the explanations generated by our proposed method are in the form\nof natural language text and visual representations, which for example can\ndescribe how different facial regions contribute to the similarity measure\nbetween two faces. This is achieved through the automatic analysis of the\noutput's saliency heatmaps of the face images and a BERT question-answering\nmodel, providing users with an interface that facilitates a comprehensive\nunderstanding of the FR decisions. The proposed approach is interactive,\nallowing the users to ask questions to get more precise information based on\nthe user's background knowledge. More importantly, in contrast to previous\nstudies, our solution does not decrease the face recognition performance. We\ndemonstrate the effectiveness of the method through different experiments,\nhighlighting its potential to make FR systems more interpretable and\nuser-friendly, especially in sensitive applications where decision-making\ntransparency is crucial.\n","authors":["Ivan DeAndres-Tame","Muhammad Faisal","Ruben Tolosana","Rouqaiah Al-Refai","Ruben Vera-Rodriguez","Philipp Terhörst"],"pdf_url":"https://arxiv.org/pdf/2409.16089v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.18659v5","updated":"2024-12-09T14:41:04Z","published":"2024-02-28T19:09:08Z","title":"Large Language Models and Games: A Survey and Roadmap","summary":"  Recent years have seen an explosive increase in research on large language\nmodels (LLMs), and accompanying public engagement on the topic. While starting\nas a niche area within natural language processing, LLMs have shown remarkable\npotential across a broad range of applications and domains, including games.\nThis paper surveys the current state of the art across the various applications\nof LLMs in and for games, and identifies the different roles LLMs can take\nwithin a game. Importantly, we discuss underexplored areas and promising\ndirections for future uses of LLMs in games and we reconcile the potential and\nlimitations of LLMs within the games domain. As the first comprehensive survey\nand roadmap at the intersection of LLMs and games, we are hopeful that this\npaper will serve as the basis for groundbreaking research and innovation in\nthis exciting new field.\n","authors":["Roberto Gallotta","Graham Todd","Marvin Zammit","Sam Earle","Antonios Liapis","Julian Togelius","Georgios N. Yannakakis"],"pdf_url":"https://arxiv.org/pdf/2402.18659v5.pdf","comment":"Accepted for publication at the IEEE Transactions on Games (19 pages,\n  6 figures)"},{"id":"http://arxiv.org/abs/2407.14229v2","updated":"2024-12-09T14:40:51Z","published":"2024-07-19T11:57:34Z","title":"Words2Contact: Identifying Support Contacts from Verbal Instructions\n  Using Foundation Models","summary":"  This paper presents Words2Contact, a language-guided multi-contact placement\npipeline leveraging large language models and vision language models. Our\nmethod is a key component for language-assisted teleoperation and human-robot\ncooperation, where human operators can instruct the robots where to place their\nsupport contacts before whole-body reaching or manipulation using natural\nlanguage. Words2Contact transforms the verbal instructions of a human operator\ninto contact placement predictions; it also deals with iterative corrections,\nuntil the human is satisfied with the contact location identified in the\nrobot's field of view. We benchmark state-of-the-art LLMs and VLMs for size and\nperformance in contact prediction. We demonstrate the effectiveness of the\niterative correction process, showing that users, even naive, quickly learn how\nto instruct the system to obtain accurate locations. Finally, we validate\nWords2Contact in real-world experiments with the Talos humanoid robot,\ninstructed by human operators to place support contacts on different locations\nand surfaces to avoid falling when reaching for distant objects.\n","authors":["Dionis Totsila","Quentin Rouxel","Jean-Baptiste Mouret","Serena Ivaldi"],"pdf_url":"https://arxiv.org/pdf/2407.14229v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06531v1","updated":"2024-12-09T14:34:31Z","published":"2024-12-09T14:34:31Z","title":"Unraveling the Complexity of Memory in RL Agents: an Approach for\n  Classification and Evaluation","summary":"  The incorporation of memory into agents is essential for numerous tasks\nwithin the domain of Reinforcement Learning (RL). In particular, memory is\nparamount for tasks that require the utilization of past information,\nadaptation to novel environments, and improved sample efficiency. However, the\nterm ``memory'' encompasses a wide range of concepts, which, coupled with the\nlack of a unified methodology for validating an agent's memory, leads to\nerroneous judgments about agents' memory capabilities and prevents objective\ncomparison with other memory-enhanced agents. This paper aims to streamline the\nconcept of memory in RL by providing practical precise definitions of agent\nmemory types, such as long-term versus short-term memory and declarative versus\nprocedural memory, inspired by cognitive science. Using these definitions, we\ncategorize different classes of agent memory, propose a robust experimental\nmethodology for evaluating the memory capabilities of RL agents, and\nstandardize evaluations. Furthermore, we empirically demonstrate the importance\nof adhering to the proposed methodology when evaluating different types of\nagent memory by conducting experiments with different RL agents and what its\nviolation leads to.\n","authors":["Egor Cherepanov","Nikita Kachaev","Artem Zholus","Alexey K. Kovalev","Aleksandr I. Panov"],"pdf_url":"https://arxiv.org/pdf/2412.06531v1.pdf","comment":"18 pages, 6 figures"},{"id":"http://arxiv.org/abs/2412.06530v1","updated":"2024-12-09T14:33:55Z","published":"2024-12-09T14:33:55Z","title":"HES-UNet: A U-Net for Hepatic Echinococcosis Lesion Segmentation","summary":"  Hepatic echinococcosis (HE) is a prevalent disease in economically\nunderdeveloped pastoral areas, where adequate medical resources are usually\nlacking. Existing methods often ignore multi-scale feature fusion or focus only\non feature fusion between adjacent levels, which may lead to insufficient\nfeature fusion. To address these issues, we propose HES-UNet, an efficient and\naccurate model for HE lesion segmentation. This model combines convolutional\nlayers and attention modules to capture local and global features. During\ndownsampling, the multi-directional downsampling block (MDB) is employed to\nintegrate high-frequency and low-frequency features, effectively extracting\nimage details. The multi-scale aggregation block (MAB) aggregates multi-scale\nfeature information. In contrast, the multi-scale upsampling Block (MUB) learns\nhighly abstract features and supplies this information to the skip connection\nmodule to fuse multi-scale features. Due to the distinct regional\ncharacteristics of HE, there is currently no publicly available high-quality\ndataset for training our model. We collected CT slice data from 268 patients at\na certain hospital to train and evaluate the model. The experimental results\nshow that HES-UNet achieves state-of-the-art performance on our dataset,\nachieving an overall Dice Similarity Coefficient (DSC) of 89.21%, which is\n1.09% higher than that of TransUNet. The project page is available at\nhttps://chenjiayan-qhu.github.io/HES-UNet-page.\n","authors":["Jiayan Chen","Kai Li","Zhanjin Wang","Zhan Wang","Jianqiang Huang"],"pdf_url":"https://arxiv.org/pdf/2412.06530v1.pdf","comment":"6 pages, 3 figures"},{"id":"http://arxiv.org/abs/2404.00929v3","updated":"2024-12-09T14:30:11Z","published":"2024-04-01T05:13:56Z","title":"A Survey on Multilingual Large Language Models: Corpora, Alignment, and\n  Bias","summary":"  Based on the foundation of Large Language Models (LLMs), Multilingual LLMs\n(MLLMs) have been developed to address the challenges faced in multilingual\nnatural language processing, hoping to achieve knowledge transfer from\nhigh-resource languages to low-resource languages. However, significant\nlimitations and challenges still exist, such as language imbalance,\nmultilingual alignment, and inherent bias. In this paper, we aim to provide a\ncomprehensive analysis of MLLMs, delving deeply into discussions surrounding\nthese critical issues. First of all, we start by presenting an overview of\nMLLMs, covering their evolutions, key techniques, and multilingual capacities.\nSecondly, we explore the multilingual training corpora of MLLMs and the\nmultilingual datasets oriented for downstream tasks that are crucial to enhance\nthe cross-lingual capability of MLLMs. Thirdly, we survey the state-of-the-art\nstudies of multilingual representations and investigate whether the current\nMLLMs can learn a universal language representation. Fourthly, we discuss bias\non MLLMs, including its categories, evaluation metrics, and debiasing\ntechniques. Finally, we discuss existing challenges and point out promising\nresearch directions of MLLMs.\n","authors":["Yuemei Xu","Ling Hu","Jiayi Zhao","Zihan Qiu","Kexin XU","Yuqi Ye","Hanwen Gu"],"pdf_url":"https://arxiv.org/pdf/2404.00929v3.pdf","comment":"The article has been accepted by Frontiers of Computer Science (FCS),\n  with the DOI: {10.1007/s11704-024-40579-4}"},{"id":"http://arxiv.org/abs/2409.01369v2","updated":"2024-12-09T14:26:42Z","published":"2024-09-02T16:48:57Z","title":"Imitating Language via Scalable Inverse Reinforcement Learning","summary":"  The majority of language model training builds on imitation learning. It\ncovers pretraining, supervised fine-tuning, and affects the starting conditions\nfor reinforcement learning from human feedback (RLHF). The simplicity and\nscalability of maximum likelihood estimation (MLE) for next token prediction\nled to its role as predominant paradigm. However, the broader field of\nimitation learning can more effectively utilize the sequential structure\nunderlying autoregressive generation. We focus on investigating the inverse\nreinforcement learning (IRL) perspective to imitation, extracting rewards and\ndirectly optimizing sequences instead of individual token likelihoods and\nevaluate its benefits for fine-tuning large language models. We provide a new\nangle, reformulating inverse soft-Q-learning as a temporal difference\nregularized extension of MLE. This creates a principled connection between MLE\nand IRL and allows trading off added complexity with increased performance and\ndiversity of generations in the supervised fine-tuning (SFT) setting. We find\nclear advantages for IRL-based imitation, in particular for retaining diversity\nwhile maximizing task performance, rendering IRL a strong alternative on fixed\nSFT datasets even without online data generation. Our analysis of IRL-extracted\nreward functions further indicates benefits for more robust reward functions\nvia tighter integration of supervised and preference-based LLM post-training.\n","authors":["Markus Wulfmeier","Michael Bloesch","Nino Vieillard","Arun Ahuja","Jorg Bornschein","Sandy Huang","Artem Sokolov","Matt Barnes","Guillaume Desjardins","Alex Bewley","Sarah Maria Elisabeth Bechtle","Jost Tobias Springenberg","Nikola Momchev","Olivier Bachem","Matthieu Geist","Martin Riedmiller"],"pdf_url":"https://arxiv.org/pdf/2409.01369v2.pdf","comment":"Published at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.17790v2","updated":"2024-12-09T14:14:49Z","published":"2024-11-26T15:43:06Z","title":"Self-supervised Monocular Depth and Pose Estimation for Endoscopy with\n  Generative Latent Priors","summary":"  Accurate 3D mapping in endoscopy enables quantitative, holistic lesion\ncharacterization within the gastrointestinal (GI) tract, requiring reliable\ndepth and pose estimation. However, endoscopy systems are monocular, and\nexisting methods relying on synthetic datasets or complex models often lack\ngeneralizability in challenging endoscopic conditions. We propose a robust\nself-supervised monocular depth and pose estimation framework that incorporates\na Generative Latent Bank and a Variational Autoencoder (VAE). The Generative\nLatent Bank leverages extensive depth scenes from natural images to condition\nthe depth network, enhancing realism and robustness of depth predictions\nthrough latent feature priors. For pose estimation, we reformulate it within a\nVAE framework, treating pose transitions as latent variables to regularize\nscale, stabilize z-axis prominence, and improve x-y sensitivity. This dual\nrefinement pipeline enables accurate depth and pose predictions, effectively\naddressing the GI tract's complex textures and lighting. Extensive evaluations\non SimCol and EndoSLAM datasets confirm our framework's superior performance\nover published self-supervised methods in endoscopic depth and pose estimation.\n","authors":["Ziang Xu","Bin Li","Yang Hu","Chenyu Zhang","James East","Sharib Ali","Jens Rittscher"],"pdf_url":"https://arxiv.org/pdf/2411.17790v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06512v1","updated":"2024-12-09T14:14:21Z","published":"2024-12-09T14:14:21Z","title":"The Fusion of Large Language Models and Formal Methods for Trustworthy\n  AI Agents: A Roadmap","summary":"  Large Language Models (LLMs) have emerged as a transformative AI paradigm,\nprofoundly influencing daily life through their exceptional language\nunderstanding and contextual generation capabilities. Despite their remarkable\nperformance, LLMs face a critical challenge: the propensity to produce\nunreliable outputs due to the inherent limitations of their learning-based\nnature. Formal methods (FMs), on the other hand, are a well-established\ncomputation paradigm that provides mathematically rigorous techniques for\nmodeling, specifying, and verifying the correctness of systems. FMs have been\nextensively applied in mission-critical software engineering, embedded systems,\nand cybersecurity. However, the primary challenge impeding the deployment of\nFMs in real-world settings lies in their steep learning curves, the absence of\nuser-friendly interfaces, and issues with efficiency and adaptability.\n  This position paper outlines a roadmap for advancing the next generation of\ntrustworthy AI systems by leveraging the mutual enhancement of LLMs and FMs.\nFirst, we illustrate how FMs, including reasoning and certification techniques,\ncan help LLMs generate more reliable and formally certified outputs.\nSubsequently, we highlight how the advanced learning capabilities and\nadaptability of LLMs can significantly enhance the usability, efficiency, and\nscalability of existing FM tools. Finally, we show that unifying these two\ncomputation paradigms -- integrating the flexibility and intelligence of LLMs\nwith the rigorous reasoning abilities of FMs -- has transformative potential\nfor the development of trustworthy AI software systems. We acknowledge that\nthis integration has the potential to enhance both the trustworthiness and\nefficiency of software engineering practices while fostering the development of\nintelligent FM tools capable of addressing complex yet real-world challenges.\n","authors":["Yedi Zhang","Yufan Cai","Xinyue Zuo","Xiaokun Luan","Kailong Wang","Zhe Hou","Yifan Zhang","Zhiyuan Wei","Meng Sun","Jun Sun","Jing Sun","Jin Song Dong"],"pdf_url":"https://arxiv.org/pdf/2412.06512v1.pdf","comment":"24 pages, 4 figures"},{"id":"http://arxiv.org/abs/2412.06510v1","updated":"2024-12-09T14:13:21Z","published":"2024-12-09T14:13:21Z","title":"AnomalyControl: Learning Cross-modal Semantic Features for Controllable\n  Anomaly Synthesis","summary":"  Anomaly synthesis is a crucial approach to augment abnormal data for\nadvancing anomaly inspection. Based on the knowledge from the large-scale\npre-training, existing text-to-image anomaly synthesis methods predominantly\nfocus on textual information or coarse-aligned visual features to guide the\nentire generation process. However, these methods often lack sufficient\ndescriptors to capture the complicated characteristics of realistic anomalies\n(e.g., the fine-grained visual pattern of anomalies), limiting the realism and\ngeneralization of the generation process. To this end, we propose a novel\nanomaly synthesis framework called AnomalyControl to learn cross-modal semantic\nfeatures as guidance signals, which could encode the generalized anomaly cues\nfrom text-image reference prompts and improve the realism of synthesized\nabnormal samples. Specifically, AnomalyControl adopts a flexible and\nnon-matching prompt pair (i.e., a text-image reference prompt and a targeted\ntext prompt), where a Cross-modal Semantic Modeling (CSM) module is designed to\nextract cross-modal semantic features from the textual and visual descriptors.\nThen, an Anomaly-Semantic Enhanced Attention (ASEA) mechanism is formulated to\nallow CSM to focus on the specific visual patterns of the anomaly, thus\nenhancing the realism and contextual relevance of the generated anomaly\nfeatures. Treating cross-modal semantic features as the prior, a Semantic\nGuided Adapter (SGA) is designed to encode effective guidance signals for the\nadequate and controllable synthesis process. Extensive experiments indicate\nthat AnomalyControl can achieve state-of-the-art results in anomaly synthesis\ncompared with existing methods while exhibiting superior performance for\ndownstream tasks.\n","authors":["Shidan He","Lei Liu","Shen Zhao"],"pdf_url":"https://arxiv.org/pdf/2412.06510v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.02648v3","updated":"2024-12-09T13:52:19Z","published":"2024-03-05T04:35:59Z","title":"Remove that Square Root: A New Efficient Scale-Invariant Version of\n  AdaGrad","summary":"  Adaptive methods are extremely popular in machine learning as they make\nlearning rate tuning less expensive. This paper introduces a novel optimization\nalgorithm named KATE, which presents a scale-invariant adaptation of the\nwell-known AdaGrad algorithm. We prove the scale-invariance of KATE for the\ncase of Generalized Linear Models. Moreover, for general smooth non-convex\nproblems, we establish a convergence rate of $O \\left(\\frac{\\log T}{\\sqrt{T}}\n\\right)$ for KATE, matching the best-known ones for AdaGrad and Adam. We also\ncompare KATE to other state-of-the-art adaptive algorithms Adam and AdaGrad in\nnumerical experiments with different problems, including complex machine\nlearning tasks like image classification and text classification on real data.\nThe results indicate that KATE consistently outperforms AdaGrad and\nmatches/surpasses the performance of Adam in all considered scenarios.\n","authors":["Sayantan Choudhury","Nazarii Tupitsa","Nicolas Loizou","Samuel Horvath","Martin Takac","Eduard Gorbunov"],"pdf_url":"https://arxiv.org/pdf/2403.02648v3.pdf","comment":"31 pages, 12 figures"},{"id":"http://arxiv.org/abs/2412.06486v1","updated":"2024-12-09T13:35:46Z","published":"2024-12-09T13:35:46Z","title":"SimuDICE: Offline Policy Optimization Through World Model Updates and\n  DICE Estimation","summary":"  In offline reinforcement learning, deriving an effective policy from a\npre-collected set of experiences is challenging due to the distribution\nmismatch between the target policy and the behavioral policy used to collect\nthe data, as well as the limited sample size. Model-based reinforcement\nlearning improves sample efficiency by generating simulated experiences using a\nlearned dynamic model of the environment. However, these synthetic experiences\noften suffer from the same distribution mismatch. To address these challenges,\nwe introduce SimuDICE, a framework that iteratively refines the initial policy\nderived from offline data using synthetically generated experiences from the\nworld model. SimuDICE enhances the quality of these simulated experiences by\nadjusting the sampling probabilities of state-action pairs based on stationary\nDIstribution Correction Estimation (DICE) and the estimated confidence in the\nmodel's predictions. This approach guides policy improvement by balancing\nexperiences similar to those frequently encountered with ones that have a\ndistribution mismatch. Our experiments show that SimuDICE achieves performance\ncomparable to existing algorithms while requiring fewer pre-collected\nexperiences and planning steps, and it remains robust across varying data\ncollection policies.\n","authors":["Catalin E. Brita","Stephan Bongers","Frans A. Oliehoek"],"pdf_url":"https://arxiv.org/pdf/2412.06486v1.pdf","comment":"Published at BNAIC/BeNeLearn 2024"},{"id":"http://arxiv.org/abs/2412.06483v1","updated":"2024-12-09T13:31:46Z","published":"2024-12-09T13:31:46Z","title":"SafeWorld: Geo-Diverse Safety Alignment","summary":"  In the rapidly evolving field of Large Language Models (LLMs), ensuring\nsafety is a crucial and widely discussed topic. However, existing works often\noverlook the geo-diversity of cultural and legal standards across the world. To\ndemonstrate the challenges posed by geo-diverse safety standards, we introduce\nSafeWorld, a novel benchmark specifically designed to evaluate LLMs' ability to\ngenerate responses that are not only helpful but also culturally sensitive and\nlegally compliant across diverse global contexts. SafeWorld encompasses 2,342\ntest user queries, each grounded in high-quality, human-verified cultural norms\nand legal policies from 50 countries and 493 regions/races. On top of it, we\npropose a multi-dimensional automatic safety evaluation framework that assesses\nthe contextual appropriateness, accuracy, and comprehensiveness of responses.\nOur evaluations reveal that current LLMs struggle to meet these criteria. To\nenhance LLMs' alignment with geo-diverse safety standards, we synthesize\nhelpful preference pairs for Direct Preference Optimization (DPO) alignment\ntraining. The preference pair construction aims to encourage LLMs to behave\nappropriately and provide precise references to relevant cultural norms and\npolicies when necessary. Our trained SafeWorldLM outperforms all competing\nmodels, including GPT-4o on all three evaluation dimensions by a large margin.\nGlobal human evaluators also note a nearly 20% higher winning rate in\nhelpfulness and harmfulness evaluation. Our code and data can be found here:\nhttps://github.com/PlusLabNLP/SafeWorld.\n","authors":["Da Yin","Haoyi Qiu","Kung-Hsiang Huang","Kai-Wei Chang","Nanyun Peng"],"pdf_url":"https://arxiv.org/pdf/2412.06483v1.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2409.11272v4","updated":"2024-12-09T13:21:45Z","published":"2024-09-17T15:23:08Z","title":"LOLA -- An Open-Source Massively Multilingual Large Language Model","summary":"  This paper presents LOLA, a massively multilingual large language model\ntrained on more than 160 languages using a sparse Mixture-of-Experts\nTransformer architecture. Our architectural and implementation choices address\nthe challenge of harnessing linguistic diversity while maintaining efficiency\nand avoiding the common pitfalls of multilinguality. Our analysis of the\nevaluation results shows competitive performance in natural language generation\nand understanding tasks. Additionally, we demonstrate how the learned\nexpert-routing mechanism exploits implicit phylogenetic linguistic patterns to\npotentially alleviate the curse of multilinguality. We provide an in-depth look\nat the training process, an analysis of the datasets, and a balanced\nexploration of the model's strengths and limitations. As an open-source model,\nLOLA promotes reproducibility and serves as a robust foundation for future\nresearch. Our findings enable the development of compute-efficient multilingual\nmodels with strong, scalable performance across languages.\n","authors":["Nikit Srivastava","Denis Kuchelev","Tatiana Moteu Ngoli","Kshitij Shetty","Michael Röder","Hamada Zahera","Diego Moussallem","Axel-Cyrille Ngonga Ngomo"],"pdf_url":"https://arxiv.org/pdf/2409.11272v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06474v1","updated":"2024-12-09T13:21:07Z","published":"2024-12-09T13:21:07Z","title":"From Uncertainty to Trust: Enhancing Reliability in Vision-Language\n  Models with Uncertainty-Guided Dropout Decoding","summary":"  Large vision-language models (LVLMs) demonstrate remarkable capabilities in\nmultimodal tasks but are prone to misinterpreting visual inputs, often\nresulting in hallucinations and unreliable outputs. To address these\nchallenges, we propose Dropout Decoding, a novel inference-time approach that\nquantifies the uncertainty of visual tokens and selectively masks uncertain\ntokens to improve decoding. Our method measures the uncertainty of each visual\ntoken by projecting it onto the text space and decomposing it into aleatoric\nand epistemic components. Specifically, we focus on epistemic uncertainty,\nwhich captures perception-related errors more effectively. Inspired by dropout\nregularization, we introduce uncertainty-guided token dropout, which applies\nthe dropout principle to input visual tokens instead of model parameters, and\nduring inference rather than training. By aggregating predictions from an\nensemble of masked decoding contexts, Dropout Decoding robustly mitigates\nerrors arising from visual token misinterpretations. Evaluations on benchmarks\nincluding CHAIR, THRONE, and MMBench demonstrate that Dropout Decoding\nsignificantly reduces object hallucinations (OH) and enhances both reliability\nand quality of LVLM outputs across diverse visual contexts.\n","authors":["Yixiong Fang","Ziran Yang","Zhaorun Chen","Zhuokai Zhao","Jiawei Zhou"],"pdf_url":"https://arxiv.org/pdf/2412.06474v1.pdf","comment":"Code is released at https://github.com/kigb/DropoutDecoding"},{"id":"http://arxiv.org/abs/2412.06451v1","updated":"2024-12-09T12:50:27Z","published":"2024-12-09T12:50:27Z","title":"How Certain are Uncertainty Estimates? Three Novel Earth Observation\n  Datasets for Benchmarking Uncertainty Quantification in Machine Learning","summary":"  Uncertainty quantification (UQ) is essential for assessing the reliability of\nEarth observation (EO) products. However, the extensive use of machine learning\nmodels in EO introduces an additional layer of complexity, as those models\nthemselves are inherently uncertain. While various UQ methods do exist for\nmachine learning models, their performance on EO datasets remains largely\nunevaluated. A key challenge in the community is the absence of the ground\ntruth for uncertainty, i.e. how certain the uncertainty estimates are, apart\nfrom the labels for the image/signal. This article fills this gap by\nintroducing three benchmark datasets specifically designed for UQ in EO machine\nlearning models. These datasets address three common problem types in EO:\nregression, image segmentation, and scene classification. They enable a\ntransparent comparison of different UQ methods for EO machine learning models.\nWe describe the creation and characteristics of each dataset, including data\nsources, preprocessing steps, and label generation, with a particular focus on\ncalculating the reference uncertainty. We also showcase baseline performance of\nseveral machine learning models on each dataset, highlighting the utility of\nthese benchmarks for model development and comparison. Overall, this article\noffers a valuable resource for researchers and practitioners working in\nartificial intelligence for EO, promoting a more accurate and reliable quality\nmeasure of the outputs of machine learning models. The dataset and code are\naccessible via https://gitlab.lrz.de/ai4eo/WG_Uncertainty.\n","authors":["Yuanyuan Wang","Qian Song","Dawood Wasif","Muhammad Shahzad","Christoph Koller","Jonathan Bamber","Xiao Xiang Zhu"],"pdf_url":"https://arxiv.org/pdf/2412.06451v1.pdf","comment":"Submitted to IEEE Geoscience and Remote Sensing Magazine"},{"id":"http://arxiv.org/abs/2410.17218v4","updated":"2024-12-09T12:45:53Z","published":"2024-10-22T17:43:39Z","title":"Creativity in AI: Progresses and Challenges","summary":"  Creativity is the ability to produce novel, useful, and surprising ideas, and\nhas been widely studied as a crucial aspect of human cognition. Machine\ncreativity on the other hand has been a long-standing challenge. With the rise\nof advanced generative AI, there has been renewed interest and debate regarding\nAI's creative capabilities. Therefore, it is imperative to revisit the state of\ncreativity in AI and identify key progresses and remaining challenges. In this\nwork, we survey leading works studying the creative capabilities of AI systems,\nfocusing on creative problem-solving, linguistic, artistic, and scientific\ncreativity. Our review suggests that while the latest AI models are largely\ncapable of producing linguistically and artistically creative outputs such as\npoems, images, and musical pieces, they struggle with tasks that require\ncreative problem-solving, abstract thinking and compositionality and their\ngenerations suffer from a lack of diversity, originality, long-range\nincoherence and hallucinations. We also discuss key questions concerning\ncopyright and authorship issues with generative models. Furthermore, we\nhighlight the need for a comprehensive evaluation of creativity that is\nprocess-driven and considers several dimensions of creativity. Finally, we\npropose future research directions to improve the creativity of AI outputs,\ndrawing inspiration from cognitive science and psychology.\n","authors":["Mete Ismayilzada","Debjit Paul","Antoine Bosselut","Lonneke van der Plas"],"pdf_url":"https://arxiv.org/pdf/2410.17218v4.pdf","comment":"minor updates to content + figures"},{"id":"http://arxiv.org/abs/2402.06660v3","updated":"2024-12-09T12:40:08Z","published":"2024-02-05T21:43:11Z","title":"A philosophical and ontological perspective on Artificial General\n  Intelligence and the Metaverse","summary":"  This paper leverages various philosophical and ontological frameworks to\nexplore the concept of embodied artificial general intelligence (AGI), its\nrelationship to human consciousness, and the key role of the metaverse in\nfacilitating this relationship. Several theoretical frameworks underpin this\nexploration, such as embodied cognition, Michael Levin's computational boundary\nof a \"Self,\" Donald D. Hoffman's Interface Theory of Perception, and Bernardo\nKastrup's analytical idealism, which lead to considering our perceived outer\nreality as a symbolic representation of alternate inner states of being, and\nwhere AGI could embody a different form of consciousness with a larger\ncomputational boundary. The paper further discusses the developmental stages of\nAGI, the requirements for the emergence of an embodied AGI, the importance of a\ncalibrated symbolic interface for AGI, and the key role played by the\nmetaverse, decentralized systems, open-source blockchain technology, as well as\nopen-source AI research. It also explores the idea of a feedback loop between\nAGI and human users in metaverse spaces as a tool for AGI calibration, as well\nas the role of local homeostasis and decentralized governance as preconditions\nfor achieving a stable embodied AGI. The paper concludes by emphasizing the\nimportance of achieving a certain degree of harmony in human relations and\nrecognizing the interconnectedness of humanity at a global level, as key\nprerequisites for the emergence of a stable embodied AGI.\n","authors":["Martin Schmalzried"],"pdf_url":"https://arxiv.org/pdf/2402.06660v3.pdf","comment":"Presented at the conference second international conference on\n  human-centred AI ethics: seeing the human in the artificial (HCAIE 2023):\n  https://ethics-ai.eu/hcaie2023/"},{"id":"http://arxiv.org/abs/2412.06435v1","updated":"2024-12-09T12:21:20Z","published":"2024-12-09T12:21:20Z","title":"Simulating Human-like Daily Activities with Desire-driven Autonomy","summary":"  Existing task-oriented AI agents often depend on explicit instructions or\nexternal rewards, limiting their ability to be driven by intrinsic motivations\nlike humans. In this paper, we present a desire-driven autonomy framework to\nguide a Large Language Model-based (LLM-based) agent to simulate human-like\ndaily activities. In contrast to previous agents, our Desire-driven Autonomous\nAgent (D2A) operates on the principle of intrinsic desire, allowing it to\npropose and select tasks that fulfill its motivational framework autonomously.\nInspired by the Theory of Needs, the motivational framework incorporates an\nunderstanding of human-like desires, such as the need for social interaction,\npersonal fulfillment, and self-care. Utilizing a desire-driven task generation\nmechanism, the agent evaluates its current state and takes a sequence of\nactivities aligned with its intrinsic motivations. Through simulations, we\ndemonstrate that our Desire-driven Autonomous Agent (D2A) generates coherent,\ncontextually relevant daily activities while exhibiting variability and\nadaptability similar to human behavior. A comparative analysis with other\nLLM-based frameworks demonstrates that our approach significantly enhances the\nrationality of the simulated activities.\n","authors":["Yiding Wang","Yuxuan Chen","Fangwei Zhong","Long Ma","Yizhou Wang"],"pdf_url":"https://arxiv.org/pdf/2412.06435v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.07866v3","updated":"2024-12-09T12:14:28Z","published":"2024-10-10T12:34:25Z","title":"System 2 Reasoning via Generality and Adaptation","summary":"  While significant progress has been made in task-specific applications,\ncurrent models struggle with deep reasoning, generality, and adaptation -- key\ncomponents of System 2 reasoning that are crucial for achieving Artificial\nGeneral Intelligence (AGI). Despite the promise of approaches such as program\nsynthesis, language models, and transformers, these methods often fail to\ngeneralize beyond their training data and to adapt to novel tasks, limiting\ntheir ability to perform human-like reasoning. This paper explores the\nlimitations of existing approaches in achieving advanced System 2 reasoning and\nhighlights the importance of generality and adaptation for AGI. Moreover, we\npropose four key research directions to address these gaps: (1) learning human\nintentions from action sequences, (2) combining symbolic and neural models, (3)\nmeta-learning for unfamiliar environments, and (4) reinforcement learning to\nreason multi-step. Through these directions, we aim to advance the ability to\ngeneralize and adapt, bringing computational models closer to the reasoning\ncapabilities required for AGI.\n","authors":["Sejin Kim","Sundong Kim"],"pdf_url":"https://arxiv.org/pdf/2410.07866v3.pdf","comment":"Accepted by NeurIPS 2024 Workshop on System 2 Reasoning at Scale"},{"id":"http://arxiv.org/abs/2411.08299v2","updated":"2024-12-09T12:12:14Z","published":"2024-11-13T02:41:02Z","title":"DNN Task Assignment in UAV Networks: A Generative AI Enhanced\n  Multi-Agent Reinforcement Learning Approach","summary":"  Unmanned Aerial Vehicles (UAVs) possess high mobility and flexible deployment\ncapabilities, prompting the development of UAVs for various application\nscenarios within the Internet of Things (IoT). The unique capabilities of UAVs\ngive rise to increasingly critical and complex tasks in uncertain and\npotentially harsh environments. The substantial amount of data generated from\nthese applications necessitates processing and analysis through deep neural\nnetworks (DNNs). However, UAVs encounter challenges due to their limited\ncomputing resources when managing DNN models. This paper presents a joint\napproach that combines multiple-agent reinforcement learning (MARL) and\ngenerative diffusion models (GDM) for assigning DNN tasks to a UAV swarm, aimed\nat reducing latency from task capture to result output. To address these\nchallenges, we first consider the task size of the target area to be inspected\nand the shortest flying path as optimization constraints, employing a greedy\nalgorithm to resolve the subproblem with a focus on minimizing the UAV's flying\npath and the overall system cost. In the second stage, we introduce a novel DNN\ntask assignment algorithm, termed GDM-MADDPG, which utilizes the reverse\ndenoising process of GDM to replace the actor network in multi-agent deep\ndeterministic policy gradient (MADDPG). This approach generates specific DNN\ntask assignment actions based on agents' observations in a dynamic environment.\nSimulation results indicate that our algorithm performs favorably compared to\nbenchmarks in terms of path planning, Age of Information (AoI), energy\nconsumption, and task load balancing.\n","authors":["Xin Tang","Qian Chen","Wenjie Weng","Binhan Liao","Jiacheng Wang","Xianbin Cao","Xiaohuan Li"],"pdf_url":"https://arxiv.org/pdf/2411.08299v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06419v1","updated":"2024-12-09T11:57:16Z","published":"2024-12-09T11:57:16Z","title":"LLM-BIP: Structured Pruning for Large Language Models with Block-Wise\n  Forward Importance Propagation","summary":"  Large language models (LLMs) have demonstrated remarkable performance across\nvarious language tasks, but their widespread deployment is impeded by their\nlarge size and high computational costs. Structural pruning is a prevailing\ntechnique used to introduce sparsity into pre-trained models and facilitate\ndirect hardware acceleration during inference by removing redundant connections\n(structurally-grouped parameters), such as channels and attention heads.\nExisting structural pruning approaches often employ either global or layer-wise\npruning criteria; however, they are hindered by ineffectiveness stemming from\ninaccurate evaluation of connection importance. Global pruning methods\ntypically assess component importance using near-zero and unreliable gradients,\nwhile layer-wise pruning approaches encounter significant pruning error\naccumulation issues. To this end, we propose a more accurate pruning metric\nbased on the block-wise importance score propagation, termed LLM-BIP.\nSpecifically, LLM-BIP precisely evaluates connection importance by gauging its\ninfluence on the respective transformer block output, which can be efficiently\napproximated in a single forward pass through an upper bound derived from the\nassumption of Lipschitz continuity. We evaluate the proposed method using\nLLaMA-7B, Vicuna-7B, and LLaMA-13B across common zero-shot tasks. The results\ndemonstrate that our approach achieves an average of 3.26% increase in accuracy\nfor common reasoning tasks compared to previous best baselines. It also reduces\nperplexity by 14.09 and 68.76 on average for the WikiText2 dataset and PTB\ndataset, respectively.\n","authors":["Haihang Wu"],"pdf_url":"https://arxiv.org/pdf/2412.06419v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.06642v4","updated":"2024-12-09T11:49:18Z","published":"2024-03-05T13:26:42Z","title":"PPFlow: Target-aware Peptide Design with Torsional Flow Matching","summary":"  Therapeutic peptides have proven to have great pharmaceutical value and\npotential in recent decades. However, methods of AI-assisted peptide drug\ndiscovery are not fully explored. To fill the gap, we propose a target-aware\npeptide design method called \\textsc{PPFlow}, based on conditional flow\nmatching on torus manifolds, to model the internal geometries of torsion angles\nfor the peptide structure design. Besides, we establish a protein-peptide\nbinding dataset named PPBench2024 to fill the void of massive data for the task\nof structure-based peptide drug design and to allow the training of deep\nlearning methods. Extensive experiments show that PPFlow reaches\nstate-of-the-art performance in tasks of peptide drug generation and\noptimization in comparison with baseline models, and can be generalized to\nother tasks including docking and side-chain packing.\n","authors":["Haitao Lin","Odin Zhang","Huifeng Zhao","Dejun Jiang","Lirong Wu","Zicheng Liu","Yufei Huang","Stan Z. Li"],"pdf_url":"https://arxiv.org/pdf/2405.06642v4.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2412.06412v1","updated":"2024-12-09T11:40:06Z","published":"2024-12-09T11:40:06Z","title":"StarWhisper Telescope: Agent-Based Observation Assistant System to\n  Approach AI Astrophysicist","summary":"  With the rapid advancements in Large Language Models (LLMs), LLM-based agents\nhave introduced convenient and user-friendly methods for leveraging tools\nacross various domains. In the field of astronomical observation, the\nconstruction of new telescopes has significantly increased astronomers'\nworkload. Deploying LLM-powered agents can effectively alleviate this burden\nand reduce the costs associated with training personnel. Within the Nearby\nGalaxy Supernovae Survey (NGSS) project, which encompasses eight telescopes\nacross three observation sites, aiming to find the transients from the galaxies\nin 50 mpc, we have developed the \\textbf{StarWhisper Telescope System} to\nmanage the entire observation process. This system automates tasks such as\ngenerating observation lists, conducting observations, analyzing data, and\nproviding feedback to the observer. Observation lists are customized for\ndifferent sites and strategies to ensure comprehensive coverage of celestial\nobjects. After manual verification, these lists are uploaded to the telescopes\nvia the agents in the system, which initiates observations upon neutral\nlanguage. The observed images are analyzed in real-time, and the transients are\npromptly communicated to the observer. The agent modifies them into a real-time\nfollow-up observation proposal and send to the Xinglong observatory group chat,\nthen add them to the next-day observation lists. Additionally, the integration\nof AI agents within the system provides online accessibility, saving\nastronomers' time and encouraging greater participation from amateur\nastronomers in the NGSS project.\n","authors":["Cunshi Wang","Xinjie Hu","Yu Zhang","Xunhao Chen","Pengliang Du","Yiming Mao","Rui Wang","Yuyang Li","Ying Wu","Hang Yang","Yansong Li","Beichuan Wang","Haiyang Mu","Zheng Wang","Jianfeng Tian","Liang Ge","Yongna Mao","Shengming Li","Xiaomeng Lu","Jinhang Zou","Yang Huang","Ningchen Sun","Jie Zheng","Min He","Yu Bai","Junjie Jin","Hong Wu","Chaohui Shang","Jifeng Liu"],"pdf_url":"https://arxiv.org/pdf/2412.06412v1.pdf","comment":"21 pages, 18 figures"},{"id":"http://arxiv.org/abs/2412.06410v1","updated":"2024-12-09T11:39:00Z","published":"2024-12-09T11:39:00Z","title":"BatchTopK Sparse Autoencoders","summary":"  Sparse autoencoders (SAEs) have emerged as a powerful tool for interpreting\nlanguage model activations by decomposing them into sparse, interpretable\nfeatures. A popular approach is the TopK SAE, that uses a fixed number of the\nmost active latents per sample to reconstruct the model activations. We\nintroduce BatchTopK SAEs, a training method that improves upon TopK SAEs by\nrelaxing the top-k constraint to the batch-level, allowing for a variable\nnumber of latents to be active per sample. As a result, BatchTopK adaptively\nallocates more or fewer latents depending on the sample, improving\nreconstruction without sacrificing average sparsity. We show that BatchTopK\nSAEs consistently outperform TopK SAEs in reconstructing activations from GPT-2\nSmall and Gemma 2 2B, and achieve comparable performance to state-of-the-art\nJumpReLU SAEs. However, an advantage of BatchTopK is that the average number of\nlatents can be directly specified, rather than approximately tuned through a\ncostly hyperparameter sweep. We provide code for training and evaluating\nBatchTopK SAEs at https://github.com/bartbussmann/BatchTopK\n","authors":["Bart Bussmann","Patrick Leask","Neel Nanda"],"pdf_url":"https://arxiv.org/pdf/2412.06410v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.24070v3","updated":"2024-12-09T11:29:18Z","published":"2024-10-31T16:07:21Z","title":"Dynamical similarity analysis uniquely captures how computations develop\n  in RNNs","summary":"  Methods for analyzing representations in neural systems have become a popular\ntool in both neuroscience and mechanistic interpretability. Having measures to\ncompare how similar activations of neurons are across conditions,\narchitectures, and species, gives us a scalable way of learning how information\nis transformed within different neural networks. In contrast to this trend,\nrecent investigations have revealed how some metrics can respond to spurious\nsignals and hence give misleading results. To identify the most reliable metric\nand understand how measures could be improved, it is going to be important to\nidentify specific test cases which can serve as benchmarks. Here we propose\nthat the phenomena of compositional learning in recurrent neural networks\n(RNNs) allows us to build a test case for dynamical representation alignment\nmetrics. By implementing this case, we show it enables us to test whether\nmetrics can identify representations which gradually develop throughout\nlearning and probe whether representations identified by metrics are relevant\nto computations executed by networks. By building both an attractor- and\nRNN-based test case, we show that the new Dynamical Similarity Analysis (DSA)\nis more noise robust and identifies behaviorally relevant representations more\nreliably than prior metrics (Procrustes, CKA). We also show how test cases can\nbe used beyond evaluating metrics to study new architectures. Specifically,\nresults from applying DSA to modern (Mamba) state space models, suggest that,\nin contrast to RNNs, these models may not exhibit changes to their recurrent\ndynamics due to their expressiveness. Overall, by developing test cases, we\nshow DSA's exceptional ability to detect compositional dynamical motifs,\nthereby enhancing our understanding of how computations unfold in RNNs.\n","authors":["Quentin Guilhot","Michał Wójcik","Jascha Achterberg","Rui Ponte Costa"],"pdf_url":"https://arxiv.org/pdf/2410.24070v3.pdf","comment":"19 pages, 11 figures"},{"id":"http://arxiv.org/abs/2412.06394v1","updated":"2024-12-09T11:22:59Z","published":"2024-12-09T11:22:59Z","title":"GameArena: Evaluating LLM Reasoning through Live Computer Games","summary":"  Evaluating the reasoning abilities of large language models (LLMs) is\nchallenging. Existing benchmarks often depend on static datasets, which are\nvulnerable to data contamination and may get saturated over time, or on binary\nlive human feedback that conflates reasoning with other abilities. As the most\nprominent dynamic benchmark, Chatbot Arena evaluates open-ended questions in\nreal-world settings, but lacks the granularity in assessing specific reasoning\ncapabilities. We introduce GameArena, a dynamic benchmark designed to evaluate\nLLM reasoning capabilities through interactive gameplay with humans. GameArena\nconsists of three games designed to test specific reasoning capabilities (e.g.,\ndeductive and inductive reasoning), while keeping participants entertained and\nengaged. We analyze the gaming data retrospectively to uncover the underlying\nreasoning processes of LLMs and measure their fine-grained reasoning\ncapabilities. We collect over 2000 game sessions and provide detailed\nassessments of various reasoning capabilities for five state-of-the-art LLMs.\nOur user study with 100 participants suggests that GameArena improves user\nengagement compared to Chatbot Arena. For the first time, GameArena enables the\ncollection of step-by-step LLM reasoning data in the wild.\n","authors":["Lanxiang Hu","Qiyu Li","Anze Xie","Nan Jiang","Ion Stoica","Haojian Jin","Hao Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.06394v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06390v1","updated":"2024-12-09T11:17:04Z","published":"2024-12-09T11:17:04Z","title":"Edge Delayed Deep Deterministic Policy Gradient: efficient continuous\n  control for edge scenarios","summary":"  Deep Reinforcement Learning is gaining increasing attention thanks to its\ncapability to learn complex policies in high-dimensional settings. Recent\nadvancements utilize a dual-network architecture to learn optimal policies\nthrough the Q-learning algorithm. However, this approach has notable drawbacks,\nsuch as an overestimation bias that can disrupt the learning process and\ndegrade the performance of the resulting policy. To address this, novel\nalgorithms have been developed that mitigate overestimation bias by employing\nmultiple Q-functions. Edge scenarios, which prioritize privacy, have recently\ngained prominence. In these settings, limited computational resources pose a\nsignificant challenge for complex Machine Learning approaches, making the\nefficiency of algorithms crucial for their performance. In this work, we\nintroduce a novel Reinforcement Learning algorithm tailored for edge scenarios,\ncalled Edge Delayed Deep Deterministic Policy Gradient (EdgeD3). EdgeD3\nenhances the Deep Deterministic Policy Gradient (DDPG) algorithm, achieving\nsignificantly improved performance with $25\\%$ less Graphics Process Unit (GPU)\ntime while maintaining the same memory usage. Additionally, EdgeD3 consistently\nmatches or surpasses the performance of state-of-the-art methods across various\nbenchmarks, all while using $30\\%$ fewer computational resources and requiring\n$30\\%$ less memory.\n","authors":["Alberto Sinigaglia","Niccolò Turcato","Ruggero Carli","Gian Antonio Susto"],"pdf_url":"https://arxiv.org/pdf/2412.06390v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.13591v4","updated":"2024-12-09T11:04:39Z","published":"2024-11-18T05:47:12Z","title":"Improved GUI Grounding via Iterative Narrowing","summary":"  Graphical User Interface (GUI) grounding plays a crucial role in enhancing\nthe capabilities of Vision-Language Model (VLM) agents. While general VLMs,\nsuch as GPT-4V, demonstrate strong performance across various tasks, their\nproficiency in GUI grounding remains suboptimal. Recent studies have focused on\nfine-tuning these models specifically for one-shot GUI grounding, yielding\nsignificant improvements over baseline performance. We introduce a visual\nprompting framework that employs an iterative narrowing mechanism to further\nimprove the performance of both general and fine-tuned models in GUI grounding.\nFor evaluation, we tested our method on a comprehensive benchmark comprising\nvarious UI platforms and provided the code to reproduce our results.\n","authors":["Anthony Nguyen"],"pdf_url":"https://arxiv.org/pdf/2411.13591v4.pdf","comment":"Code available at\n  https://github.com/ant-8/GUI-Grounding-via-Iterative-Narrowing"},{"id":"http://arxiv.org/abs/2406.02507v2","updated":"2024-12-09T10:58:16Z","published":"2024-06-04T17:25:59Z","title":"Guiding a Diffusion Model with a Bad Version of Itself","summary":"  The primary axes of interest in image-generating diffusion models are image\nquality, the amount of variation in the results, and how well the results align\nwith a given condition, e.g., a class label or a text prompt. The popular\nclassifier-free guidance approach uses an unconditional model to guide a\nconditional model, leading to simultaneously better prompt alignment and\nhigher-quality images at the cost of reduced variation. These effects seem\ninherently entangled, and thus hard to control. We make the surprising\nobservation that it is possible to obtain disentangled control over image\nquality without compromising the amount of variation by guiding generation\nusing a smaller, less-trained version of the model itself rather than an\nunconditional model. This leads to significant improvements in ImageNet\ngeneration, setting record FIDs of 1.01 for 64x64 and 1.25 for 512x512, using\npublicly available networks. Furthermore, the method is also applicable to\nunconditional diffusion models, drastically improving their quality.\n","authors":["Tero Karras","Miika Aittala","Tuomas Kynkäänniemi","Jaakko Lehtinen","Timo Aila","Samuli Laine"],"pdf_url":"https://arxiv.org/pdf/2406.02507v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2412.06370v1","updated":"2024-12-09T10:44:47Z","published":"2024-12-09T10:44:47Z","title":"Exploring Memorization and Copyright Violation in Frontier LLMs: A Study\n  of the New York Times v. OpenAI 2023 Lawsuit","summary":"  Copyright infringement in frontier LLMs has received much attention recently\ndue to the New York Times v. OpenAI lawsuit, filed in December 2023. The New\nYork Times claims that GPT-4 has infringed its copyrights by reproducing\narticles for use in LLM training and by memorizing the inputs, thereby publicly\ndisplaying them in LLM outputs. Our work aims to measure the propensity of\nOpenAI's LLMs to exhibit verbatim memorization in its outputs relative to other\nLLMs, specifically focusing on news articles. We discover that both GPT and\nClaude models use refusal training and output filters to prevent verbatim\noutput of the memorized articles. We apply a basic prompt template to bypass\nthe refusal training and show that OpenAI models are currently less prone to\nmemorization elicitation than models from Meta, Mistral, and Anthropic. We find\nthat as models increase in size, especially beyond 100 billion parameters, they\ndemonstrate significantly greater capacity for memorization. Our findings have\npractical implications for training: more attention must be placed on\npreventing verbatim memorization in very large models. Our findings also have\nlegal significance: in assessing the relative memorization capacity of OpenAI's\nLLMs, we probe the strength of The New York Times's copyright infringement\nclaims and OpenAI's legal defenses, while underscoring issues at the\nintersection of generative AI, law, and policy.\n","authors":["Joshua Freeman","Chloe Rippe","Edoardo Debenedetti","Maksym Andriushchenko"],"pdf_url":"https://arxiv.org/pdf/2412.06370v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06368v1","updated":"2024-12-09T10:38:30Z","published":"2024-12-09T10:38:30Z","title":"Measuring Pre-training Data Quality without Labels for Time Series\n  Foundation Models","summary":"  Recently, there has been a growing interest in time series foundation models\nthat generalize across different downstream tasks. A key to strong foundation\nmodels is a diverse pre-training dataset, which is particularly challenging to\ncollect for time series classification. In this work, we explore the\nperformance of a contrastive-learning-based foundation model as a function of\nthe data used for pre-training. We introduce contrastive accuracy, a new\nmeasure to evaluate the quality of the representation space learned by the\nfoundation model. Our experiments reveal the positive correlation between the\nproposed measure and the accuracy of the model on a collection of downstream\ntasks. This suggests that the contrastive accuracy can serve as a criterion to\nsearch for time series datasets that can enhance the pre-training and improve\nthereby the foundation model's generalization.\n","authors":["Songkang Wen","Vasilii Feofanov","Jianfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.06368v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.21348v2","updated":"2024-12-09T10:11:22Z","published":"2024-10-28T11:07:33Z","title":"Large Language Model Benchmarks in Medical Tasks","summary":"  With the increasing application of large language models (LLMs) in the\nmedical domain, evaluating these models' performance using benchmark datasets\nhas become crucial. This paper presents a comprehensive survey of various\nbenchmark datasets employed in medical LLM tasks. These datasets span multiple\nmodalities including text, image, and multimodal benchmarks, focusing on\ndifferent aspects of medical knowledge such as electronic health records\n(EHRs), doctor-patient dialogues, medical question-answering, and medical image\ncaptioning. The survey categorizes the datasets by modality, discussing their\nsignificance, data structure, and impact on the development of LLMs for\nclinical tasks such as diagnosis, report generation, and predictive decision\nsupport. Key benchmarks include MIMIC-III, MIMIC-IV, BioASQ, PubMedQA, and\nCheXpert, which have facilitated advancements in tasks like medical report\ngeneration, clinical summarization, and synthetic data generation. The paper\nsummarizes the challenges and opportunities in leveraging these benchmarks for\nadvancing multimodal medical intelligence, emphasizing the need for datasets\nwith a greater degree of language diversity, structured omics data, and\ninnovative approaches to synthesis. This work also provides a foundation for\nfuture research in the application of LLMs in medicine, contributing to the\nevolving field of medical artificial intelligence.\n","authors":["Lawrence K. Q. Yan","Qian Niu","Ming Li","Yichao Zhang","Caitlyn Heqi Yin","Cheng Fei","Benji Peng","Ziqian Bi","Pohsun Feng","Keyu Chen","Tianyang Wang","Yunze Wang","Silin Chen","Ming Liu","Junyu Liu"],"pdf_url":"https://arxiv.org/pdf/2410.21348v2.pdf","comment":"25 pages, 5 tables"},{"id":"http://arxiv.org/abs/2305.08339v5","updated":"2024-12-09T09:56:59Z","published":"2023-05-15T04:10:13Z","title":"Assessing the potential of LLM-assisted annotation for corpus-based\n  pragmatics and discourse analysis: The case of apology","summary":"  Certain forms of linguistic annotation, like part of speech and semantic\ntagging, can be automated with high accuracy. However, manual annotation is\nstill necessary for complex pragmatic and discursive features that lack a\ndirect mapping to lexical forms. This manual process is time-consuming and\nerror-prone, limiting the scalability of function-to-form approaches in corpus\nlinguistics. To address this, our study explores the possibility of using large\nlanguage models (LLMs) to automate pragma-discursive corpus annotation. We\ncompare GPT-3.5 (the model behind the free-to-use version of ChatGPT), GPT-4\n(the model underpinning the precise mode of Bing chatbot), and a human coder in\nannotating apology components in English based on the local grammar framework.\nWe find that GPT-4 outperformed GPT-3.5, with accuracy approaching that of a\nhuman coder. These results suggest that LLMs can be successfully deployed to\naid pragma-discursive corpus annotation, making the process more efficient,\nscalable and accessible.\n","authors":["Danni Yu","Luyang Li","Hang Su","Matteo Fuoli"],"pdf_url":"https://arxiv.org/pdf/2305.08339v5.pdf","comment":"24 pages, 2 figures, 3 tablels"},{"id":"http://arxiv.org/abs/2412.06341v1","updated":"2024-12-09T09:46:21Z","published":"2024-12-09T09:46:21Z","title":"Elastic-DETR: Making Image Resolution Learnable with Content-Specific\n  Network Prediction","summary":"  Multi-scale image resolution is a de facto standard approach in modern object\ndetectors, such as DETR. This technique allows for the acquisition of various\nscale information from multiple image resolutions. However, manual\nhyperparameter selection of the resolution can restrict its flexibility, which\nis informed by prior knowledge, necessitating human intervention. This work\nintroduces a novel strategy for learnable resolution, called Elastic-DETR,\nenabling elastic utilization of multiple image resolutions. Our network\nprovides an adaptive scale factor based on the content of the image with a\ncompact scale prediction module (< 2 GFLOPs). The key aspect of our method lies\nin how to determine the resolution without prior knowledge. We present two loss\nfunctions derived from identified key components for resolution optimization:\nscale loss, which increases adaptiveness according to the image, and\ndistribution loss, which determines the overall degree of scaling based on\nnetwork performance. By leveraging the resolution's flexibility, we can\ndemonstrate various models that exhibit varying trade-offs between accuracy and\ncomputational complexity. We empirically show that our scheme can unleash the\npotential of a wide spectrum of image resolutions without constraining\nflexibility. Our models on MS COCO establish a maximum accuracy gain of 3.5%p\nor 26% decrease in computation than MS-trained DN-DETR.\n","authors":["Daeun Seo","Hoeseok Yang","Sihyeong Park","Hyungshin Kim"],"pdf_url":"https://arxiv.org/pdf/2412.06341v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.01432v3","updated":"2024-12-09T09:39:12Z","published":"2023-09-29T14:38:58Z","title":"Split and Merge: Aligning Position Biases in LLM-based Evaluators","summary":"  Large language models (LLMs) have shown promise as automated evaluators for\nassessing the quality of answers generated by AI systems. However, these\nLLM-based evaluators exhibit position bias, or inconsistency, when used to\nevaluate candidate answers in pairwise comparisons, favoring either the first\nor second answer regardless of content. To address this limitation, we propose\nPORTIA, an alignment-based system designed to mimic human comparison strategies\nto calibrate position bias in a lightweight yet effective manner. Specifically,\nPORTIA splits the answers into multiple segments, aligns similar content across\ncandidate answers, and then merges them back into a single prompt for\nevaluation by LLMs. We conducted extensive experiments with six diverse LLMs to\nevaluate 11,520 answer pairs. Our results show that PORTIA markedly enhances\nthe consistency rates for all the models and comparison forms tested, achieving\nan average relative improvement of 47.46%. Remarkably, PORTIA enables less\nadvanced GPT models to achieve 88% agreement with the state-of-the-art GPT-4\nmodel at just 10% of the cost. Furthermore, it rectifies around 80% of the\nposition bias instances within the GPT-4 model, elevating its consistency rate\nup to 98%. Subsequent human evaluations indicate that the PORTIA-enhanced\nGPT-3.5 model can even surpass the standalone GPT-4 in terms of alignment with\nhuman evaluators. These findings highlight PORTIA's ability to correct position\nbias, improve LLM consistency, and boost performance while keeping\ncost-efficiency. This represents a valuable step toward a more reliable and\nscalable use of LLMs for automated evaluations across diverse applications.\n","authors":["Zongjie Li","Chaozheng Wang","Pingchuan Ma","Daoyuan Wu","Shuai Wang","Cuiyun Gao","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2310.01432v3.pdf","comment":"Accepted by EMNLP 2024. Please cite the conference version of this\n  paper, e.g., \"Zongjie Li, Chaozheng Wang, Pingchuan Ma, Daoyuan Wu, Shuai\n  Wang, Cuiyun Gao, and Yang Liu. 2024. Split and Merge: Aligning Position\n  Biases in LLM-based Evaluators. (EMNLP 2024)\""},{"id":"http://arxiv.org/abs/2412.06333v1","updated":"2024-12-09T09:34:40Z","published":"2024-12-09T09:34:40Z","title":"Augmenting the action space with conventions to improve multi-agent\n  cooperation in Hanabi","summary":"  The card game Hanabi is considered a strong medium for the testing and\ndevelopment of multi-agent reinforcement learning (MARL) algorithms, due to its\ncooperative nature, hidden information, limited communication and remarkable\ncomplexity. Previous research efforts have explored the capabilities of MARL\nalgorithms within Hanabi, focusing largely on advanced architecture design and\nalgorithmic manipulations to achieve state-of-the-art performance for a various\nnumber of cooperators. However, this often leads to complex solution strategies\nwith high computational cost and requiring large amounts of training data. For\nhumans to solve the Hanabi game effectively, they require the use of\nconventions, which often allows for a means to implicitly convey ideas or\nknowledge based on a predefined, and mutually agreed upon, set of ``rules''.\nMulti-agent problems containing partial observability, especially when limited\ncommunication is present, can benefit greatly from the use of implicit\nknowledge sharing. In this paper, we propose a novel approach to augmenting the\naction space using conventions, which act as special cooperative actions that\nspan over multiple time steps and multiple agents, requiring agents to actively\nopt in for it to reach fruition. These conventions are based on existing human\nconventions, and result in a significant improvement on the performance of\nexisting techniques for self-play and cross-play across a various number of\ncooperators within Hanabi.\n","authors":["F. Bredell","H. A. Engelbrecht","J. C. Schoeman"],"pdf_url":"https://arxiv.org/pdf/2412.06333v1.pdf","comment":"This paper is under review at the journal of autonomous agents and\n  multi-agent systems (JAAMAS)"},{"id":"http://arxiv.org/abs/2412.06332v1","updated":"2024-12-09T09:32:20Z","published":"2024-12-09T09:32:20Z","title":"Not All Errors Are Equal: Investigation of Speech Recognition Errors in\n  Alzheimer's Disease Detection","summary":"  Automatic Speech Recognition (ASR) plays an important role in speech-based\nautomatic detection of Alzheimer's disease (AD). However, recognition errors\ncould propagate downstream, potentially impacting the detection decisions.\nRecent studies have revealed a non-linear relationship between word error rates\n(WER) and AD detection performance, where ASR transcriptions with notable\nerrors could still yield AD detection accuracy equivalent to that based on\nmanual transcriptions. This work presents a series of analyses to explore the\neffect of ASR transcription errors in BERT-based AD detection systems. Our\ninvestigation reveals that not all ASR errors contribute equally to detection\nperformance. Certain words, such as stopwords, despite constituting a large\nproportion of errors, are shown to play a limited role in distinguishing AD. In\ncontrast, the keywords related to diagnosis tasks exhibit significantly greater\nimportance relative to other words. These findings provide insights into the\ninterplay between ASR errors and the downstream detection model.\n","authors":["Jiawen Kang","Junan Li","Jinchao Li","Xixin Wu","Helen Meng"],"pdf_url":"https://arxiv.org/pdf/2412.06332v1.pdf","comment":"Accepted by IEEE ISCSLP 2024"},{"id":"http://arxiv.org/abs/2410.09335v2","updated":"2024-12-09T09:31:39Z","published":"2024-10-12T02:48:34Z","title":"Rethinking Data Selection at Scale: Random Selection is Almost All You\n  Need","summary":"  Supervised fine-tuning (SFT) is crucial for aligning Large Language Models\n(LLMs) with human instructions. The primary goal during SFT is to select a\nsmall yet representative subset of training data from the larger pool, such\nthat fine-tuning with this subset achieves results comparable to or even\nexceeding those obtained using the entire dataset. However, most existing data\nselection techniques are designed for small-scale data pools, which fail to\nmeet the demands of real-world SFT scenarios. In this paper, we replicated\nseveral self-scoring methods those that do not rely on external model\nassistance on two million scale datasets, and found that nearly all methods\nstruggled to significantly outperform random selection when dealing with such\nlarge-scale data pools. Moreover, our comparisons suggest that, during SFT,\ndiversity in data selection is more critical than simply focusing on high\nquality data. We also analyzed the limitations of several current approaches,\nexplaining why they perform poorly on large-scale datasets and why they are\nunsuitable for such contexts. Finally, we found that filtering data by token\nlength offers a stable and efficient method for improving results. This\napproach, particularly when training on long text data, proves highly\nbeneficial for relatively weaker base models, such as Llama3.\n","authors":["Tingyu Xia","Bowen Yu","Kai Dang","An Yang","Yuan Wu","Yuan Tian","Yi Chang","Junyang Lin"],"pdf_url":"https://arxiv.org/pdf/2410.09335v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.17572v4","updated":"2024-12-09T09:30:26Z","published":"2024-07-24T18:05:13Z","title":"CityX: Controllable Procedural Content Generation for Unbounded 3D\n  Cities","summary":"  Urban areas, as the primary human habitat in modern civilization, accommodate\na broad spectrum of social activities. With the surge of embodied intelligence,\nrecent years have witnessed an increasing presence of physical agents in urban\nareas, such as autonomous vehicles and delivery robots. As a result,\npractitioners significantly value crafting authentic, simulation-ready 3D\ncities to facilitate the training and verification of such agents. However,\nthis task is quite challenging. Current generative methods fall short in either\ndiversity, controllability, or fidelity. In this work, we resort to the\nprocedural content generation (PCG) technique for high-fidelity generation. It\nassembles superior assets according to empirical rules, ultimately leading to\nindustrial-grade outcomes. To ensure diverse and self contained creation, we\ndesign a management protocol to accommodate extensive PCG plugins with distinct\nfunctions and interfaces. Based on this unified PCG library, we develop a\nmulti-agent framework to transform multi-modal instructions, including OSM,\nsemantic maps, and satellite images, into executable programs. The programs\ncoordinate relevant plugins to construct the 3D city consistent with the\ncontrol condition. A visual feedback scheme is introduced to further refine the\ninitial outcomes. Our method, named CityX, demonstrates its superiority in\ncreating diverse, controllable, and realistic 3D urban scenes. The synthetic\nscenes can be seamlessly deployed as a real-time simulator and an infinite data\ngenerator for embodied intelligence research. Our project page:\nhttps://cityx-lab.github.io.\n","authors":["Shougao Zhang","Mengqi Zhou","Yuxi Wang","Chuanchen Luo","Rongyu Wang","Yiwei Li","Zhaoxiang Zhang","Junran Peng"],"pdf_url":"https://arxiv.org/pdf/2407.17572v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.17543v2","updated":"2024-12-09T09:28:34Z","published":"2024-07-24T15:23:26Z","title":"Dataset Distribution Impacts Model Fairness: Single vs. Multi-Task\n  Learning","summary":"  The influence of bias in datasets on the fairness of model predictions is a\ntopic of ongoing research in various fields. We evaluate the performance of\nskin lesion classification using ResNet-based CNNs, focusing on patient sex\nvariations in training data and three different learning strategies. We present\na linear programming method for generating datasets with varying patient sex\nand class labels, taking into account the correlations between these variables.\nWe evaluated the model performance using three different learning strategies: a\nsingle-task model, a reinforcing multi-task model, and an adversarial learning\nscheme. Our observations include: 1) sex-specific training data yields better\nresults, 2) single-task models exhibit sex bias, 3) the reinforcement approach\ndoes not remove sex bias, 4) the adversarial model eliminates sex bias in cases\ninvolving only female patients, and 5) datasets that include male patients\nenhance model performance for the male subgroup, even when female patients are\nthe majority. To generalise these findings, in future research, we will examine\nmore demographic attributes, like age, and other possibly confounding factors,\nsuch as skin colour and artefacts in the skin lesions. We make all data and\nmodels available on GitHub.\n","authors":["Ralf Raumanns","Gerard Schouten","Josien P. W. Pluim","Veronika Cheplygina"],"pdf_url":"https://arxiv.org/pdf/2407.17543v2.pdf","comment":"Published in the FAIMI EPIMI 2024 Workshop"},{"id":"http://arxiv.org/abs/2408.10641v2","updated":"2024-12-09T09:27:29Z","published":"2024-08-20T08:32:39Z","title":"A Review of Human-Object Interaction Detection","summary":"  Human-object interaction (HOI) detection plays a key role in high-level\nvisual understanding, facilitating a deep comprehension of human activities.\nSpecifically, HOI detection aims to locate the humans and objects involved in\ninteractions within images or videos and classify the specific interactions\nbetween them. The success of this task is influenced by several key factors,\nincluding the accurate localization of human and object instances, as well as\nthe correct classification of object categories and interaction relationships.\nThis paper systematically summarizes and discusses the recent work in\nimage-based HOI detection. First, the mainstream datasets involved in HOI\nrelationship detection are introduced. Furthermore, starting with two-stage\nmethods and end-to-end one-stage detection approaches, this paper\ncomprehensively discusses the current developments in image-based HOI\ndetection, analyzing the strengths and weaknesses of these two methods.\nAdditionally, the advancements of zero-shot learning, weakly supervised\nlearning, and the application of large-scale language models in HOI detection\nare discussed. Finally, the current challenges in HOI detection are outlined,\nand potential research directions and future trends are explored.\n","authors":["Yuxiao Wang","Qiwei Xiong","Yu Lei","Weiying Xue","Qi Liu","Zhenao Wei"],"pdf_url":"https://arxiv.org/pdf/2408.10641v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.20587v2","updated":"2024-12-09T09:26:23Z","published":"2024-10-27T20:47:29Z","title":"Generator Matching: Generative modeling with arbitrary Markov processes","summary":"  We introduce generator matching, a modality-agnostic framework for generative\nmodeling using arbitrary Markov processes. Generators characterize the\ninfinitesimal evolution of a Markov process, which we leverage for generative\nmodeling in a similar vein to flow matching: we construct conditional\ngenerators which generate single data points, then learn to approximate the\nmarginal generator which generates the full data distribution. We show that\ngenerator matching unifies various generative modeling methods, including\ndiffusion models, flow matching and discrete diffusion models. Furthermore, it\nprovides the foundation to expand the design space to new and unexplored Markov\nprocesses such as jump processes. Finally, generator matching enables the\nconstruction of superpositions of Markov generative processes and enables the\nconstruction of multimodal models in a rigorous manner. We empirically validate\nour method on protein and image structure generation, showing that\nsuperposition with a jump process improves image generation.\n","authors":["Peter Holderrieth","Marton Havasi","Jason Yim","Neta Shaul","Itai Gat","Tommi Jaakkola","Brian Karrer","Ricky T. Q. Chen","Yaron Lipman"],"pdf_url":"https://arxiv.org/pdf/2410.20587v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.05248v2","updated":"2024-12-09T09:21:49Z","published":"2024-12-06T18:27:15Z","title":"Enhancing FKG.in: automating Indian food composition analysis","summary":"  This paper presents a novel approach to compute food composition data for\nIndian recipes using a knowledge graph for Indian food (FKG.in) and LLMs. The\nprimary focus is to provide a broad overview of an automated food composition\nanalysis workflow and describe its core functionalities: nutrition data\naggregation, food composition analysis, and LLM-augmented information\nresolution. This workflow aims to complement FKG.in and iteratively supplement\nfood composition data from verified knowledge bases. Additionally, this paper\nhighlights the challenges of representing Indian food and accessing food\ncomposition data digitally. It also reviews three key sources of food\ncomposition data: the Indian Food Composition Tables, the Indian Nutrient\nDatabank, and the Nutritionix API. Furthermore, it briefly outlines how users\ncan interact with the workflow to obtain diet-based health recommendations and\ndetailed food composition information for numerous recipes. We then explore the\ncomplex challenges of analyzing Indian recipe information across dimensions\nsuch as structure, multilingualism, and uncertainty as well as present our\nongoing work on LLM-based solutions to address these issues. The methods\nproposed in this workshop paper for AI-driven knowledge curation and\ninformation resolution are application-agnostic, generalizable, and replicable\nfor any domain.\n","authors":["Saransh Kumar Gupta","Lipika Dey","Partha Pratim Das","Geeta Trilok-Kumar","Ramesh Jain"],"pdf_url":"https://arxiv.org/pdf/2412.05248v2.pdf","comment":"15 pages, 5 figures, 30 references, International Conference on\n  Pattern Recognition 2024 - Multimedia Assisted Dietary Management Workshop"},{"id":"http://arxiv.org/abs/2411.03817v3","updated":"2024-12-09T09:20:11Z","published":"2024-11-06T10:35:11Z","title":"From Novice to Expert: LLM Agent Policy Optimization via Step-wise\n  Reinforcement Learning","summary":"  The outstanding capabilities of large language models (LLMs) render them a\ncrucial component in various autonomous agent systems. While traditional\nmethods depend on the inherent knowledge of LLMs without fine-tuning, more\nrecent approaches have shifted toward the reinforcement learning strategy to\nfurther enhance agents' ability to solve complex interactive tasks with\nenvironments and tools. However, previous approaches are constrained by the\nsparse reward issue, where existing datasets solely provide a final scalar\nreward for each multi-step reasoning chain, potentially leading to\nineffectiveness and inefficiency in policy learning. In this paper, we\nintroduce StepAgent, which utilizes step-wise reward to optimize the agent's\nreinforcement learning process. Inheriting the spirit of novice-to-expert\ntheory, we first compare the actions of the expert and the agent to\nautomatically generate intermediate rewards for fine-grained optimization.\nAdditionally, we propose implicit-reward and inverse reinforcement learning\ntechniques to facilitate agent reflection and policy adjustment. Further\ntheoretical analysis demonstrates that the action distribution of the agent can\nconverge toward the expert action distribution over multiple training cycles.\nExperimental results across various datasets indicate that StepAgent\noutperforms existing baseline methods.\n","authors":["Zhirui Deng","Zhicheng Dou","Yutao Zhu","Ji-Rong Wen","Ruibin Xiong","Mang Wang","Weipeng Chen"],"pdf_url":"https://arxiv.org/pdf/2411.03817v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06314v1","updated":"2024-12-09T09:08:31Z","published":"2024-12-09T09:08:31Z","title":"CAD-Unet: A Capsule Network-Enhanced Unet Architecture for Accurate\n  Segmentation of COVID-19 Lung Infections from CT Images","summary":"  Since the outbreak of the COVID-19 pandemic in 2019, medical imaging has\nemerged as a primary modality for diagnosing COVID-19 pneumonia. In clinical\nsettings, the segmentation of lung infections from computed tomography images\nenables rapid and accurate quantification and diagnosis of COVID-19.\nSegmentation of COVID-19 infections in the lungs poses a formidable challenge,\nprimarily due to the indistinct boundaries and limited contrast presented by\nground glass opacity manifestations. Moreover, the confounding similarity\nbetween infiltrates, lung tissues, and lung walls further complicates this\nsegmentation task. To address these challenges, this paper introduces a novel\ndeep network architecture, called CAD-Unet, for segmenting COVID-19 lung\ninfections. In this architecture, capsule networks are incorporated into the\nexisting Unet framework. Capsule networks represent a novel network\narchitecture that differs from traditional convolutional neural networks. They\nutilize vectors for information transfer among capsules, facilitating the\nextraction of intricate lesion spatial information. Additionally, we design a\ncapsule encoder path and establish a coupling path between the unet encoder and\nthe capsule encoder. This design maximizes the complementary advantages of both\nnetwork structures while achieving efficient information fusion. \\noindent\nFinally, extensive experiments are conducted on four publicly available\ndatasets, encompassing binary segmentation tasks and multi-class segmentation\ntasks. The experimental results demonstrate the superior segmentation\nperformance of the proposed model. The code has been released at:\nhttps://github.com/AmanoTooko-jie/CAD-Unet.\n","authors":["Yijie Dang","Weijun Ma","Xiaohu Luo"],"pdf_url":"https://arxiv.org/pdf/2412.06314v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18114v3","updated":"2024-12-09T09:07:57Z","published":"2024-10-09T05:36:29Z","title":"Bridging Today and the Future of Humanity: AI Safety in 2024 and Beyond","summary":"  The advancements in generative AI inevitably raise concerns about the\nassociated risks and safety implications, which, in return, catalyzes\nsignificant progress in AI safety. However, as this field continues to evolve,\na critical question arises: are our current efforts aligned with the long-term\ngoal of human history and civilization? This paper presents a blueprint for an\nadvanced human society and leverages this vision to guide contemporary AI\nsafety efforts. It outlines a future where the Internet of Everything becomes\nreality, and creates a roadmap of significant technological advancements\ntowards this envisioned future. For each stage of the advancements, this paper\nforecasts potential AI safety issues that humanity may face. By projecting\ncurrent efforts against this blueprint, we examine the alignment between the\npresent efforts and the long-term needs. We also identify gaps in current\napproaches and highlight unique challenges and missions that demand increasing\nattention from AI safety practitioners in the 2020s, addressing critical areas\nthat must not be overlooked in shaping a responsible and promising future of\nAI. This vision paper aims to offer a broader perspective on AI safety,\nemphasizing that our current efforts should not only address immediate concerns\nbut also anticipate potential risks in the expanding AI landscape, thereby\npromoting a more secure and sustainable future in human civilization.\n","authors":["Shanshan Han"],"pdf_url":"https://arxiv.org/pdf/2410.18114v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06312v1","updated":"2024-12-09T09:01:13Z","published":"2024-12-09T09:01:13Z","title":"Towards High-Level Modelling in Automated Planning","summary":"  Planning is a fundamental activity, arising frequently in many contexts, from\ndaily tasks to industrial processes. The planning task consists of selecting a\nsequence of actions to achieve a specified goal from specified initial\nconditions. The Planning Domain Definition Language (PDDL) is the leading\nlanguage used in the field of automated planning to model planning problems.\nPrevious work has highlighted the limitations of PDDL, particularly in terms of\nits expressivity. Our interest lies in facilitating the handling of complex\nproblems and enhancing the overall capability of automated planning systems.\nUnified-Planning is a Python library offering high-level API to specify\nplanning problems and to invoke automated planners. In this paper, we present\nan extension of the UP library aimed at enhancing its expressivity for\nhigh-level problem modelling. In particular, we have added an array type, an\nexpression to count booleans, and the allowance for integer parameters in\nactions. We show how these facilities enable natural high-level models of three\nclassical planning problems.\n","authors":["Carla Davesa Sureda","Joan Espasa Arxer","Ian Miguel","Mateu Villaret Auselle"],"pdf_url":"https://arxiv.org/pdf/2412.06312v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.09236v2","updated":"2024-12-09T09:00:53Z","published":"2024-02-14T15:23:59Z","title":"Learning Interpretable Concepts: Unifying Causal Representation Learning\n  and Foundation Models","summary":"  To build intelligent machine learning systems, there are two broad\napproaches. One approach is to build inherently interpretable models, as\nendeavored by the growing field of causal representation learning. The other\napproach is to build highly-performant foundation models and then invest\nefforts into understanding how they work. In this work, we relate these two\napproaches and study how to learn human-interpretable concepts from data.\nWeaving together ideas from both fields, we formally define a notion of\nconcepts and show that they can be provably recovered from diverse data.\nExperiments on synthetic data and large language models show the utility of our\nunified approach.\n","authors":["Goutham Rajendran","Simon Buchholz","Bryon Aragam","Bernhard Schölkopf","Pradeep Ravikumar"],"pdf_url":"https://arxiv.org/pdf/2402.09236v2.pdf","comment":"To appear in NeurIPS 2024 under the modified title 'From Causal to\n  Concept-Based Representation Learning'"},{"id":"http://arxiv.org/abs/2412.06308v1","updated":"2024-12-09T08:55:48Z","published":"2024-12-09T08:55:48Z","title":"PRECISE: Pre-training Sequential Recommenders with Collaborative and\n  Semantic Information","summary":"  Real-world recommendation systems commonly offer diverse content scenarios\nfor users to interact with. Considering the enormous number of users in\nindustrial platforms, it is infeasible to utilize a single unified\nrecommendation model to meet the requirements of all scenarios. Usually,\nseparate recommendation pipelines are established for each distinct scenario.\nThis practice leads to challenges in comprehensively grasping users' interests.\nRecent research endeavors have been made to tackle this problem by pre-training\nmodels to encapsulate the overall interests of users. Traditional pre-trained\nrecommendation models mainly capture user interests by leveraging collaborative\nsignals. Nevertheless, a prevalent drawback of these systems is their\nincapacity to handle long-tail items and cold-start scenarios. With the recent\nadvent of large language models, there has been a significant increase in\nresearch efforts focused on exploiting LLMs to extract semantic information for\nusers and items. However, text-based recommendations highly rely on elaborate\nfeature engineering and frequently fail to capture collaborative similarities.\nTo overcome these limitations, we propose a novel pre-training framework for\nsequential recommendation, termed PRECISE. This framework combines\ncollaborative signals with semantic information. Moreover, PRECISE employs a\nlearning framework that initially models users' comprehensive interests across\nall recommendation scenarios and subsequently concentrates on the specific\ninterests of target-scene behaviors. We demonstrate that PRECISE precisely\ncaptures the entire range of user interests and effectively transfers them to\nthe target interests. Empirical findings reveal that the PRECISE framework\nattains outstanding performance on both public and industrial datasets.\n","authors":["Chonggang Song","Chunxu Shen","Hao Gu","Yaoming Wu","Lingling Yi","Jie Wen","Chuan Chen"],"pdf_url":"https://arxiv.org/pdf/2412.06308v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.08464v2","updated":"2024-12-09T08:50:46Z","published":"2024-07-11T13:01:18Z","title":"TLDR: Unsupervised Goal-Conditioned RL via Temporal Distance-Aware\n  Representations","summary":"  Unsupervised goal-conditioned reinforcement learning (GCRL) is a promising\nparadigm for developing diverse robotic skills without external supervision.\nHowever, existing unsupervised GCRL methods often struggle to cover a wide\nrange of states in complex environments due to their limited exploration and\nsparse or noisy rewards for GCRL. To overcome these challenges, we propose a\nnovel unsupervised GCRL method that leverages TemporaL Distance-aware\nRepresentations (TLDR). Based on temporal distance, TLDR selects faraway goals\nto initiate exploration and computes intrinsic exploration rewards and\ngoal-reaching rewards. Specifically, our exploration policy seeks states with\nlarge temporal distances (i.e. covering a large state space), while the\ngoal-conditioned policy learns to minimize the temporal distance to the goal\n(i.e. reaching the goal). Our results in six simulated locomotion environments\ndemonstrate that TLDR significantly outperforms prior unsupervised GCRL methods\nin achieving a wide range of states.\n","authors":["Junik Bae","Kwanyoung Park","Youngwoon Lee"],"pdf_url":"https://arxiv.org/pdf/2407.08464v2.pdf","comment":"CoRL 2024"},{"id":"http://arxiv.org/abs/2412.06303v1","updated":"2024-12-09T08:47:05Z","published":"2024-12-09T08:47:05Z","title":"DSAI: Unbiased and Interpretable Latent Feature Extraction for\n  Data-Centric AI","summary":"  Large language models (LLMs) often struggle to objectively identify latent\ncharacteristics in large datasets due to their reliance on pre-trained\nknowledge rather than actual data patterns. To address this data grounding\nissue, we propose Data Scientist AI (DSAI), a framework that enables unbiased\nand interpretable feature extraction through a multi-stage pipeline with\nquantifiable prominence metrics for evaluating extracted features. On synthetic\ndatasets with known ground-truth features, DSAI demonstrates high recall in\nidentifying expert-defined features while faithfully reflecting the underlying\ndata. Applications on real-world datasets illustrate the framework's practical\nutility in uncovering meaningful patterns with minimal expert oversight,\nsupporting use cases such as interpretable classification.\n  The title of our paper is chosen from multiple candidates based on\nDSAI-generated criteria.\n","authors":["Hyowon Cho","Soonwon Ka","Daechul Park","Jaewook Kang","Minjoon Seo","Bokyung Son"],"pdf_url":"https://arxiv.org/pdf/2412.06303v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.10542v2","updated":"2024-12-09T08:28:03Z","published":"2024-09-01T12:09:33Z","title":"SAM4MLLM: Enhance Multi-Modal Large Language Model for Referring\n  Expression Segmentation","summary":"  We introduce SAM4MLLM, an innovative approach which integrates the Segment\nAnything Model (SAM) with Multi-Modal Large Language Models (MLLMs) for\npixel-aware tasks. Our method enables MLLMs to learn pixel-level location\ninformation without requiring excessive modifications to the existing model\narchitecture or adding specialized tokens. We introduce an inquiry-based\napproach that can effectively find prompt points for SAM to perform\nsegmentation based on MLLM. It combines detailed visual information with the\npowerful expressive capabilities of large language models in a unified\nlanguage-based manner without additional computational overhead in learning.\nExperimental results on pubic benchmarks demonstrate the effectiveness of our\napproach.\n","authors":["Yi-Chia Chen","Wei-Hua Li","Cheng Sun","Yu-Chiang Frank Wang","Chu-Song Chen"],"pdf_url":"https://arxiv.org/pdf/2409.10542v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.00627v2","updated":"2024-12-09T08:27:07Z","published":"2024-12-01T00:52:51Z","title":"ARChef: An iOS-Based Augmented Reality Cooking Assistant Powered by\n  Multimodal Gemini LLM","summary":"  Cooking meals can be difficult, causing many to resort to cookbooks and\nonline recipes. However, relying on these traditional methods of cooking often\nresults in missing ingredients, nutritional hazards, and unsatisfactory meals.\nUsing Augmented Reality (AR) can address these issues; however, current AR\ncooking applications have poor user interfaces and limited accessibility. This\npaper proposes a prototype of an iOS application that integrates AR and\nComputer Vision (CV) into the cooking process. We leverage Google's Gemini\nLarge Language Model (LLM) to identify ingredients in the camera's field of\nvision and generate recipe choices with detailed nutritional information.\nAdditionally, this application uses Apple's ARKit to create an AR user\ninterface compatible with iOS devices. Users can personalize their meal\nsuggestions by inputting their dietary preferences and rating each meal. The\napplication's effectiveness is evaluated through three rounds of user\nexperience surveys. This application advances the field of accessible cooking\nassistance technologies, aiming to reduce food wastage and improve the meal\nplanning experience.\n","authors":["Rithik Vir","Parsa Madinei"],"pdf_url":"https://arxiv.org/pdf/2412.00627v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06289v1","updated":"2024-12-09T08:24:11Z","published":"2024-12-09T08:24:11Z","title":"S$^{2}$FT: Efficient, Scalable and Generalizable LLM Fine-tuning by\n  Structured Sparsity","summary":"  Current PEFT methods for LLMs can achieve either high quality, efficient\ntraining, or scalable serving, but not all three simultaneously. To address\nthis limitation, we investigate sparse fine-tuning and observe a remarkable\nimprovement in generalization ability. Utilizing this key insight, we propose a\nfamily of Structured Sparse Fine-Tuning (S$^{2}$FT) methods for LLMs, which\nconcurrently achieve state-of-the-art fine-tuning performance, training\nefficiency, and inference scalability. S$^{2}$FT accomplishes this by\n\"selecting sparsely and computing densely\". It selects a few heads and channels\nin the MHA and FFN modules for each Transformer block, respectively. Next, it\nco-permutes weight matrices on both sides of the coupled structures in LLMs to\nconnect the selected components in each layer into a dense submatrix. Finally,\nS$^{2}$FT performs in-place gradient updates on all submatrices. Through\ntheoretical analysis and empirical results, our method prevents overfitting and\nforgetting, delivers SOTA performance on both commonsense and arithmetic\nreasoning with 4.6% and 1.3% average improvements compared to LoRA, and\nsurpasses full FT by 11.5% when generalizing to various domains after\ninstruction tuning. Using our partial backpropagation algorithm, S$^{2}$FT\nsaves training memory up to 3$\\times$ and improves latency by 1.5-2.7$\\times$\ncompared to full FT, while delivering an average 10% improvement over LoRA on\nboth metrics. We further demonstrate that the weight updates in S$^{2}$FT can\nbe decoupled into adapters, enabling effective fusion, fast switch, and\nefficient parallelism for serving multiple fine-tuned models.\n","authors":["Xinyu Yang","Jixuan Leng","Geyang Guo","Jiawei Zhao","Ryumei Nakada","Linjun Zhang","Huaxiu Yao","Beidi Chen"],"pdf_url":"https://arxiv.org/pdf/2412.06289v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.16326v2","updated":"2024-12-09T08:18:35Z","published":"2024-11-25T12:22:36Z","title":"Brain-like emergent properties in deep networks: impact of network\n  architecture, datasets and training","summary":"  Despite the rapid pace at which deep networks are improving on standardized\nvision benchmarks, they are still outperformed by humans on real-world vision\ntasks. This paradoxical lack of generalization could be addressed by making\ndeep networks more brain-like. Although several benchmarks have compared the\nability of deep networks to predict brain responses to natural images, they do\nnot capture subtle but important brain-like emergent properties. To resolve\nthis issue, we report several well-known perceptual and neural emergent\nproperties that can be tested on deep networks. To evaluate how various design\nfactors impact brain-like properties, we systematically evaluated over 30\nstate-of-the-art networks with varying network architectures, training datasets\nand training regimes. Our main findings are as follows. First, network\narchitecture had the strongest impact on brain-like properties compared to\ndataset and training regime variations. Second, networks varied widely in their\nalignment to the brain with no single network outperforming all others. Taken\ntogether, our results complement existing benchmarks by revealing brain-like\nproperties that are either emergent or lacking in state-of-the-art deep\nnetworks.\n","authors":["Niranjan Rajesh","Georgin Jacob","SP Arun"],"pdf_url":"https://arxiv.org/pdf/2411.16326v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.17749v2","updated":"2024-12-09T07:49:53Z","published":"2024-11-25T14:09:48Z","title":"The Partially Observable Off-Switch Game","summary":"  A wide variety of goals could cause an AI to disable its off switch because\n\"you can't fetch the coffee if you're dead\" (Russell 2019). Prior theoretical\nwork on this shutdown problem assumes that humans know everything that AIs do.\nIn practice, however, humans have only limited information. Moreover, in many\nof the settings where the shutdown problem is most concerning, AIs might have\nvast amounts of private information. To capture these differences in knowledge,\nwe introduce the Partially Observable Off-Switch Game (PO-OSG), a\ngame-theoretic model of the shutdown problem with asymmetric information.\nUnlike when the human has full observability, we find that in optimal play,\neven AI agents assisting perfectly rational humans sometimes avoid shutdown. As\nexpected, increasing the amount of communication or information available\nalways increases (or leaves unchanged) the agents' expected common payoff. But\ncounterintuitively, introducing bounded communication can make the AI defer to\nthe human less in optimal play even though communication mitigates information\nasymmetry. In particular, communication sometimes enables new optimal behavior\nrequiring strategic AI deference to achieve outcomes that were previously\ninaccessible. Thus, designing safe artificial agents in the presence of\nasymmetric information requires careful consideration of the tradeoffs between\nmaximizing payoffs (potentially myopically) and maintaining AIs' incentives to\ndefer to humans.\n","authors":["Andrew Garber","Rohan Subramani","Linus Luu","Mark Bedaywi","Stuart Russell","Scott Emmons"],"pdf_url":"https://arxiv.org/pdf/2411.17749v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.04139v2","updated":"2024-12-09T07:49:01Z","published":"2024-12-05T13:06:03Z","title":"Monet: Mixture of Monosemantic Experts for Transformers","summary":"  Understanding the internal computations of large language models (LLMs) is\ncrucial for aligning them with human values and preventing undesirable\nbehaviors like toxic content generation. However, mechanistic interpretability\nis hindered by polysemanticity -- where individual neurons respond to multiple,\nunrelated concepts. While Sparse Autoencoders (SAEs) have attempted to\ndisentangle these features through sparse dictionary learning, they have\ncompromised LLM performance due to reliance on post-hoc reconstruction loss. To\naddress this issue, we introduce Mixture of Monosemantic Experts for\nTransformers (Monet) architecture, which incorporates sparse dictionary\nlearning directly into end-to-end Mixture-of-Experts pretraining. Our novel\nexpert decomposition method enables scaling the expert count to 262,144 per\nlayer while total parameters scale proportionally to the square root of the\nnumber of experts. Our analyses demonstrate mutual exclusivity of knowledge\nacross experts and showcase the parametric knowledge encapsulated within\nindividual experts. Moreover, Monet allows knowledge manipulation over domains,\nlanguages, and toxicity mitigation without degrading general performance. Our\npursuit of transparent LLMs highlights the potential of scaling expert counts\nto enhance mechanistic interpretability and directly resect the internal\nknowledge to fundamentally adjust model behavior. The source code and\npretrained checkpoints are available at https://github.com/dmis-lab/Monet.\n","authors":["Jungwoo Park","Young Jin Ahn","Kee-Eung Kim","Jaewoo Kang"],"pdf_url":"https://arxiv.org/pdf/2412.04139v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06272v1","updated":"2024-12-09T07:46:14Z","published":"2024-12-09T07:46:14Z","title":"Methods for Legal Citation Prediction in the Age of LLMs: An Australian\n  Law Case Study","summary":"  In recent years, Large Language Models (LLMs) have shown great potential\nacross a wide range of legal tasks. Despite these advances, mitigating\nhallucination remains a significant challenge, with state-of-the-art LLMs still\nfrequently generating incorrect legal references. In this paper, we focus on\nthe problem of legal citation prediction within the Australian law context,\nwhere correctly identifying and citing relevant legislations or precedents is\ncritical. We compare several approaches: prompting general purpose and\nlaw-specialised LLMs, retrieval-only pipelines with both generic and\ndomain-specific embeddings, task-specific instruction-tuning of LLMs, and\nhybrid strategies that combine LLMs with retrieval augmentation, query\nexpansion, or voting ensembles. Our findings indicate that domain-specific\npre-training alone is insufficient for achieving satisfactory citation accuracy\neven after law-specialised pre-training. In contrast, instruction tuning on our\ntask-specific dataset dramatically boosts performance reaching the best results\nacross all settings. We also highlight that database granularity along with the\ntype of embeddings play a critical role in the performance of retrieval\nsystems. Among retrieval-based approaches, hybrid methods consistently\noutperform retrieval-only setups, and among these, ensemble voting delivers the\nbest result by combining the predictive quality of instruction-tuned LLMs with\nthe retrieval system.\n","authors":["Ehsan Shareghi","Jiuzhou Han","Paul Burgess"],"pdf_url":"https://arxiv.org/pdf/2412.06272v1.pdf","comment":"For code, data, and models see https://auslawbench.github.io"},{"id":"http://arxiv.org/abs/2412.06262v1","updated":"2024-12-09T07:21:27Z","published":"2024-12-09T07:21:27Z","title":"A Lightweight U-like Network Utilizing Neural Memory Ordinary\n  Differential Equations for Slimming the Decoder","summary":"  In recent years, advanced U-like networks have demonstrated remarkable\nperformance in medical image segmentation tasks. However, their drawbacks,\nincluding excessive parameters, high computational complexity, and slow\ninference speed, pose challenges for practical implementation in scenarios with\nlimited computational resources. Existing lightweight U-like networks have\nalleviated some of these problems, but they often have pre-designed structures\nand consist of inseparable modules, limiting their application scenarios. In\nthis paper, we propose three plug-and-play decoders by employing different\ndiscretization methods of the neural memory Ordinary Differential Equations\n(nmODEs). These decoders integrate features at various levels of abstraction by\nprocessing information from skip connections and performing numerical\noperations on upward path. Through experiments on the PH2, ISIC2017, and\nISIC2018 datasets, we embed these decoders into different U-like networks,\ndemonstrating their effectiveness in significantly reducing the number of\nparameters and FLOPs while maintaining performance. In summary, the proposed\ndiscretized nmODEs decoders are capable of reducing the number of parameters by\nabout 20% ~ 50% and FLOPs by up to 74%, while possessing the potential to adapt\nto all U-like networks. Our code is available at\nhttps://github.com/nayutayuki/Lightweight-nmODE-Decoders-For-U-like-networks.\n","authors":["Quansong He","Xiaojun Yao","Jun Wu","Zhang Yi","Tao He"],"pdf_url":"https://arxiv.org/pdf/2412.06262v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.20362v2","updated":"2024-12-09T07:17:07Z","published":"2024-10-27T07:38:39Z","title":"Rethinking Data Synthesis: A Teacher Model Training Recipe with\n  Interpretation","summary":"  Recent advances in large language model (LLM) training have highlighted the\nneed for diverse, high-quality instruction data. Recently, many works are\nexploring synthetic data generation using LLMs. However, they primarily focus\non prompt engineering with standard supervised instruction-finetuned models,\nwhich contains a fundamental limitation: these models are optimized for general\nquestion-answering/problem-solving rather than data generation. We propose a\nparadigm shift named \\textbf{NOMAD} by investigating how to specifically train\nmodels for data generation, demonstrating that this task differs significantly\nfrom training a classical LM. We identify two key factors: no-prompt-masked\ntraining and proper training set size selection. Our method, NOMAD, shows\nsubstantial improvements over baselines, achieving >4\\% gains in TriviaQA and\n>2\\% in GSM8K with limited training data. Finally, we offer new insights by\ninterpreting synthetic data through the lenses of \"relevance\" and \"novelty\".\n","authors":["Yifang Chen","David Zhu","Simon Du","Kevin Jamieson","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2410.20362v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.01843v5","updated":"2024-12-09T06:38:53Z","published":"2024-05-03T04:26:03Z","title":"Closing the Gap: Achieving Global Convergence (Last Iterate) of\n  Actor-Critic under Markovian Sampling with Neural Network Parametrization","summary":"  The current state-of-the-art theoretical analysis of Actor-Critic (AC)\nalgorithms significantly lags in addressing the practical aspects of AC\nimplementations. This crucial gap needs bridging to bring the analysis in line\nwith practical implementations of AC. To address this, we advocate for\nconsidering the MMCLG criteria: \\textbf{M}ulti-layer neural network\nparametrization for actor/critic, \\textbf{M}arkovian sampling,\n\\textbf{C}ontinuous state-action spaces, the performance of the \\textbf{L}ast\niterate, and \\textbf{G}lobal optimality. These aspects are practically\nsignificant and have been largely overlooked in existing theoretical analyses\nof AC algorithms. In this work, we address these gaps by providing the first\ncomprehensive theoretical analysis of AC algorithms that encompasses all five\ncrucial practical aspects (covers MMCLG criteria). We establish global\nconvergence sample complexity bounds of\n$\\tilde{\\mathcal{O}}\\left({\\epsilon^{-3}}\\right)$. We achieve this result\nthrough our novel use of the weak gradient domination property of MDP's and our\nunique analysis of the error in critic estimation.\n","authors":["Mudit Gaur","Amrit Singh Bedi","Di Wang","Vaneet Aggarwal"],"pdf_url":"https://arxiv.org/pdf/2405.01843v5.pdf","comment":"Accepted at ICML 2024. This is a revised version of arXiv:2306.10486,\n  where we have gone from finite action space to continuous action space, from\n  average iterate convergence to last iterate convergence and from\n  $\\epsilon^{-4}$ to $\\epsilon^{-3}$ sample complexity. This version fixes the\n  related work result of (Xu et al., 2020a), based on their result update on\n  arXiv"},{"id":"http://arxiv.org/abs/2412.06239v1","updated":"2024-12-09T06:27:20Z","published":"2024-12-09T06:27:20Z","title":"Unseen Attack Detection in Software-Defined Networking Using a\n  BERT-Based Large Language Model","summary":"  Software defined networking (SDN) represents a transformative shift in\nnetwork architecture by decoupling the control plane from the data plane,\nenabling centralized and flexible management of network resources. However,\nthis architectural shift introduces significant security challenges, as SDN's\ncentralized control becomes an attractive target for various types of attacks.\nWhile current research has yielded valuable insights into attack detection in\nSDN, critical gaps remain. Addressing challenges in feature selection,\nbroadening the scope beyond DDoS attacks, strengthening attack decisions based\non multi flow analysis, and building models capable of detecting unseen attacks\nthat they have not been explicitly trained on are essential steps toward\nadvancing security in SDN. In this paper, we introduce a novel approach that\nleverages Natural Language Processing (NLP) and the pre trained BERT base model\nto enhance attack detection in SDN. Our approach transforms network flow data\ninto a format interpretable by language models, allowing BERT to capture\nintricate patterns and relationships within network traffic. By using Random\nForest for feature selection, we optimize model performance and reduce\ncomputational overhead, ensuring accurate detection. Attack decisions are made\nbased on several flows, providing stronger and more reliable detection of\nmalicious traffic. Furthermore, our approach is specifically designed to detect\npreviously unseen attacks, offering a solution for identifying threats that the\nmodel was not explicitly trained on. To rigorously evaluate our approach, we\nconducted experiments in two scenarios: one focused on detecting known attacks,\nachieving 99.96% accuracy, and another on detecting unseen attacks, where our\nmodel achieved 99.96% accuracy, demonstrating the robustness of our approach in\ndetecting evolving threats to improve the security of SDN networks.\n","authors":["Mohammed N. Swileh","Shengli Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.06239v1.pdf","comment":"Mohammed N. Swileh is first author. Shengli Zhang is corresponding\n  author"},{"id":"http://arxiv.org/abs/2405.13792v2","updated":"2024-12-09T06:07:03Z","published":"2024-05-22T16:15:17Z","title":"xRAG: Extreme Context Compression for Retrieval-augmented Generation\n  with One Token","summary":"  This paper introduces xRAG, an innovative context compression method tailored\nfor retrieval-augmented generation. xRAG reinterprets document embeddings in\ndense retrieval--traditionally used solely for retrieval--as features from the\nretrieval modality. By employing a modality fusion methodology, xRAG seamlessly\nintegrates these embeddings into the language model representation space,\neffectively eliminating the need for their textual counterparts and achieving\nan extreme compression rate. In xRAG, the only trainable component is the\nmodality bridge, while both the retriever and the language model remain frozen.\nThis design choice allows for the reuse of offline-constructed document\nembeddings and preserves the plug-and-play nature of retrieval augmentation.\nExperimental results demonstrate that xRAG achieves an average improvement of\nover 10% across six knowledge-intensive tasks, adaptable to various language\nmodel backbones, ranging from a dense 7B model to an 8x7B Mixture of Experts\nconfiguration. xRAG not only significantly outperforms previous context\ncompression methods but also matches the performance of uncompressed models on\nseveral datasets, while reducing overall FLOPs by a factor of 3.53. Our work\npioneers new directions in retrieval-augmented generation from the perspective\nof multimodality fusion, and we hope it lays the foundation for future\nefficient and scalable retrieval-augmented systems\n","authors":["Xin Cheng","Xun Wang","Xingxing Zhang","Tao Ge","Si-Qing Chen","Furu Wei","Huishuai Zhang","Dongyan Zhao"],"pdf_url":"https://arxiv.org/pdf/2405.13792v2.pdf","comment":"Neurips 2024"},{"id":"http://arxiv.org/abs/2412.06229v1","updated":"2024-12-09T06:03:48Z","published":"2024-12-09T06:03:48Z","title":"LLMs as Debate Partners: Utilizing Genetic Algorithms and Adversarial\n  Search for Adaptive Arguments","summary":"  This paper introduces DebateBrawl, an innovative AI-powered debate platform\nthat integrates Large Language Models (LLMs), Genetic Algorithms (GA), and\nAdversarial Search (AS) to create an adaptive and engaging debating experience.\nDebateBrawl addresses the limitations of traditional LLMs in strategic planning\nby incorporating evolutionary optimization and game-theoretic techniques. The\nsystem demonstrates remarkable performance in generating coherent, contextually\nrelevant arguments while adapting its strategy in real-time. Experimental\nresults involving 23 debates show balanced outcomes between AI and human\nparticipants, with the AI system achieving an average score of 2.72 compared to\nthe human average of 2.67 out of 10. User feedback indicates significant\nimprovements in debating skills and a highly satisfactory learning experience,\nwith 85% of users reporting improved debating abilities and 78% finding the AI\nopponent appropriately challenging. The system's ability to maintain high\nfactual accuracy (92% compared to 78% in human-only debates) while generating\ndiverse arguments addresses critical concerns in AI-assisted discourse.\nDebateBrawl not only serves as an effective educational tool but also\ncontributes to the broader goal of improving public discourse through\nAI-assisted argumentation. The paper discusses the ethical implications of AI\nin persuasive contexts and outlines the measures implemented to ensure\nresponsible development and deployment of the system, including robust\nfact-checking mechanisms and transparency in decision-making processes.\n","authors":["Prakash Aryan"],"pdf_url":"https://arxiv.org/pdf/2412.06229v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06219v1","updated":"2024-12-09T05:30:25Z","published":"2024-12-09T05:30:25Z","title":"Data Free Backdoor Attacks","summary":"  Backdoor attacks aim to inject a backdoor into a classifier such that it\npredicts any input with an attacker-chosen backdoor trigger as an\nattacker-chosen target class. Existing backdoor attacks require either\nretraining the classifier with some clean data or modifying the model's\narchitecture. As a result, they are 1) not applicable when clean data is\nunavailable, 2) less efficient when the model is large, and 3) less stealthy\ndue to architecture changes. In this work, we propose DFBA, a novel\nretraining-free and data-free backdoor attack without changing the model\narchitecture. Technically, our proposed method modifies a few parameters of a\nclassifier to inject a backdoor. Through theoretical analysis, we verify that\nour injected backdoor is provably undetectable and unremovable by various\nstate-of-the-art defenses under mild assumptions. Our evaluation on multiple\ndatasets further demonstrates that our injected backdoor: 1) incurs negligible\nclassification loss, 2) achieves 100% attack success rates, and 3) bypasses six\nexisting state-of-the-art defenses. Moreover, our comparison with a\nstate-of-the-art non-data-free backdoor attack shows our attack is more\nstealthy and effective against various defenses while achieving less\nclassification accuracy loss.\n","authors":["Bochuan Cao","Jinyuan Jia","Chuxuan Hu","Wenbo Guo","Zhen Xiang","Jinghui Chen","Bo Li","Dawn Song"],"pdf_url":"https://arxiv.org/pdf/2412.06219v1.pdf","comment":"24 pages, 8 figures, accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2412.06215v1","updated":"2024-12-09T05:21:14Z","published":"2024-12-09T05:21:14Z","title":"A Real-Time Defense Against Object Vanishing Adversarial Patch Attacks\n  for Object Detection in Autonomous Vehicles","summary":"  Autonomous vehicles (AVs) increasingly use DNN-based object detection models\nin vision-based perception. Correct detection and classification of obstacles\nis critical to ensure safe, trustworthy driving decisions. Adversarial patches\naim to fool a DNN with intentionally generated patterns concentrated in a\nlocalized region of an image. In particular, object vanishing patch attacks can\ncause object detection models to fail to detect most or all objects in a scene,\nposing a significant practical threat to AVs.\n  This work proposes ADAV (Adversarial Defense for Autonomous Vehicles), a\nnovel defense methodology against object vanishing patch attacks specifically\ndesigned for autonomous vehicles. Unlike existing defense methods which have\nhigh latency or are designed for static images, ADAV runs in real-time and\nleverages contextual information from prior frames in an AV's video feed. ADAV\nchecks if the object detector's output for the target frame is temporally\nconsistent with the output from a previous reference frame to detect the\npresence of a patch. If the presence of a patch is detected, ADAV uses\ngradient-based attribution to localize adversarial pixels that break temporal\nconsistency. This two stage procedure allows ADAV to efficiently process clean\ninputs, and both stages are optimized to be low latency. ADAV is evaluated\nusing real-world driving data from the Berkeley Deep Drive BDD100K dataset, and\ndemonstrates high adversarial and clean performance.\n","authors":["Jaden Mu"],"pdf_url":"https://arxiv.org/pdf/2412.06215v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06212v1","updated":"2024-12-09T05:16:32Z","published":"2024-12-09T05:16:32Z","title":"A Self-guided Multimodal Approach to Enhancing Graph Representation\n  Learning for Alzheimer's Diseases","summary":"  Graph neural networks (GNNs) are powerful machine learning models designed to\nhandle irregularly structured data. However, their generic design often proves\ninadequate for analyzing brain connectomes in Alzheimer's Disease (AD),\nhighlighting the need to incorporate domain knowledge for optimal performance.\nInfusing AD-related knowledge into GNNs is a complicated task. Existing methods\ntypically rely on collaboration between computer scientists and domain experts,\nwhich can be both time-intensive and resource-demanding. To address these\nlimitations, this paper presents a novel self-guided, knowledge-infused\nmultimodal GNN that autonomously incorporates domain knowledge into the model\ndevelopment process. Our approach conceptualizes domain knowledge as natural\nlanguage and introduces a specialized multimodal GNN capable of leveraging this\nuncurated knowledge to guide the learning process of the GNN, such that it can\nimprove the model performance and strengthen the interpretability of the\npredictions. To evaluate our framework, we curated a comprehensive dataset of\nrecent peer-reviewed papers on AD and integrated it with multiple real-world AD\ndatasets. Experimental results demonstrate the ability of our method to extract\nrelevant domain knowledge, provide graph-based explanations for AD diagnosis,\nand improve the overall performance of the GNN. This approach provides a more\nscalable and efficient alternative to inject domain knowledge for AD compared\nwith the manual design from the domain expert, advancing both prediction\naccuracy and interpretability in AD diagnosis.\n","authors":["Zhepeng Wang","Runxue Bao","Yawen Wu","Guodong Liu","Lei Yang","Liang Zhan","Feng Zheng","Weiwen Jiang","Yanfu Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.06212v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06211v1","updated":"2024-12-09T05:15:44Z","published":"2024-12-09T05:15:44Z","title":"MSCrackMamba: Leveraging Vision Mamba for Crack Detection in Fused\n  Multispectral Imagery","summary":"  Crack detection is a critical task in structural health monitoring, aimed at\nassessing the structural integrity of bridges, buildings, and roads to prevent\npotential failures. Vision-based crack detection has become the mainstream\napproach due to its ease of implementation and effectiveness. Fusing infrared\n(IR) channels with red, green and blue (RGB) channels can enhance feature\nrepresentation and thus improve crack detection. However, IR and RGB channels\noften differ in resolution. To align them, higher-resolution RGB images\ntypically need to be downsampled to match the IR image resolution, which leads\nto the loss of fine details. Moreover, crack detection performance is\nrestricted by the limited receptive fields and high computational complexity of\ntraditional image segmentation networks. Inspired by the recently proposed\nMamba neural architecture, this study introduces a two-stage paradigm called\nMSCrackMamba, which leverages Vision Mamba along with a super-resolution\nnetwork to address these challenges. Specifically, to align IR and RGB\nchannels, we first apply super-resolution to IR channels to match the\nresolution of RGB channels for data fusion. Vision Mamba is then adopted as the\nbackbone network, while UperNet is employed as the decoder for crack detection.\nOur approach is validated on the large-scale Crack Detection dataset Crack900,\ndemonstrating an improvement of 3.55% in mIoU compared to the best-performing\nbaseline methods.\n","authors":["Qinfeng Zhu","Yuan Fang","Lei Fan"],"pdf_url":"https://arxiv.org/pdf/2412.06211v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01322v2","updated":"2024-12-09T05:13:27Z","published":"2024-10-02T08:26:37Z","title":"Forte : Finding Outliers with Representation Typicality Estimation","summary":"  Generative models can now produce photorealistic synthetic data which is\nvirtually indistinguishable from the real data used to train it. This is a\nsignificant evolution over previous models which could produce reasonable\nfacsimiles of the training data, but ones which could be visually distinguished\nfrom the training data by human evaluation. Recent work on OOD detection has\nraised doubts that generative model likelihoods are optimal OOD detectors due\nto issues involving likelihood misestimation, entropy in the generative\nprocess, and typicality. We speculate that generative OOD detectors also failed\nbecause their models focused on the pixels rather than the semantic content of\nthe data, leading to failures in near-OOD cases where the pixels may be similar\nbut the information content is significantly different. We hypothesize that\nestimating typical sets using self-supervised learners leads to better OOD\ndetectors. We introduce a novel approach that leverages representation\nlearning, and informative summary statistics based on manifold estimation, to\naddress all of the aforementioned issues. Our method outperforms other\nunsupervised approaches and achieves state-of-the art performance on\nwell-established challenging benchmarks, and new synthetic data detection\ntasks.\n","authors":["Debargha Ganguly","Warren Morningstar","Andrew Yu","Vipin Chaudhary"],"pdf_url":"https://arxiv.org/pdf/2410.01322v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05584v3","updated":"2024-12-09T05:06:20Z","published":"2024-10-08T00:52:03Z","title":"Rethinking Reward Model Evaluation: Are We Barking up the Wrong Tree?","summary":"  Reward Models (RMs) are crucial for aligning language models with human\npreferences. Currently, the evaluation of RMs depends on measuring accuracy\nagainst a validation set of manually annotated preference data. Although this\nmethod is straightforward and widely adopted, the relationship between RM\naccuracy and downstream policy performance remains under-explored. In this\nwork, we conduct experiments in a synthetic setting to investigate how\ndifferences in RM measured by accuracy translate into gaps in optimized policy\nperformance. Our findings reveal that while there is a weak positive\ncorrelation between accuracy and downstream performance, policies optimized\ntowards RMs with similar accuracy can exhibit quite different performance.\nMoreover, we discover that the way of measuring accuracy significantly impacts\nits ability to predict the final policy performance. Through the lens of the\nRegressional Goodhart effect, we recognize that accuracy, when used for\nmeasuring RM quality, can fail to fully capture the potential RM\noveroptimization. This underscores the inadequacy of relying solely on accuracy\nto reflect their impact on policy optimization.\n","authors":["Xueru Wen","Jie Lou","Yaojie Lu","Hongyu Lin","Xing Yu","Xinyu Lu","Ben He","Xianpei Han","Debing Zhang","Le Sun"],"pdf_url":"https://arxiv.org/pdf/2410.05584v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.10564v2","updated":"2024-12-09T05:00:29Z","published":"2024-11-15T20:21:59Z","title":"Vision Eagle Attention: a new lens for advancing image classification","summary":"  In computer vision tasks, the ability to focus on relevant regions within an\nimage is crucial for improving model performance, particularly when key\nfeatures are small, subtle, or spatially dispersed. Convolutional neural\nnetworks (CNNs) typically treat all regions of an image equally, which can lead\nto inefficient feature extraction. To address this challenge, I have introduced\nVision Eagle Attention, a novel attention mechanism that enhances visual\nfeature extraction using convolutional spatial attention. The model applies\nconvolution to capture local spatial features and generates an attention map\nthat selectively emphasizes the most informative regions of the image. This\nattention mechanism enables the model to focus on discriminative features while\nsuppressing irrelevant background information. I have integrated Vision Eagle\nAttention into a lightweight ResNet-18 architecture, demonstrating that this\ncombination results in an efficient and powerful model. I have evaluated the\nperformance of the proposed model on three widely used benchmark datasets:\nFashionMNIST, Intel Image Classification, and OracleMNIST, with a primary focus\non image classification. Experimental results show that the proposed approach\nimproves classification accuracy. Additionally, this method has the potential\nto be extended to other vision tasks, such as object detection, segmentation,\nand visual tracking, offering a computationally efficient solution for a wide\nrange of vision-based applications. Code is available at:\nhttps://github.com/MahmudulHasan11085/Vision-Eagle-Attention.git\n","authors":["Mahmudul Hasan"],"pdf_url":"https://arxiv.org/pdf/2411.10564v2.pdf","comment":"7 pages, 2 figures, 3 tables"},{"id":"http://arxiv.org/abs/2412.06207v1","updated":"2024-12-09T04:58:14Z","published":"2024-12-09T04:58:14Z","title":"Skill-Enhanced Reinforcement Learning Acceleration from Demonstrations","summary":"  Learning from Demonstration (LfD) aims to facilitate rapid Reinforcement\nLearning (RL) by leveraging expert demonstrations to pre-train the RL agent.\nHowever, the limited availability of expert demonstration data often hinders\nits ability to effectively aid downstream RL learning. To address this problem,\nwe propose a novel two-stage method dubbed as Skill-enhanced Reinforcement\nLearning Acceleration (SeRLA). SeRLA introduces a skill-level adversarial\nPositive-Unlabeled (PU) learning model to extract useful skill prior knowledge\nby enabling learning from both limited expert data and general low-cost\ndemonstration data in the offline prior learning stage. Subsequently, it\ndeploys a skill-based soft actor-critic algorithm to leverage this acquired\nprior knowledge in the downstream online RL stage for efficient training of a\nskill policy network. Moreover, we develop a simple skill-level data\nenhancement technique to further alleviate data sparsity and improve both skill\nprior learning and downstream skill policy training. Our experimental results\non multiple standard RL environments show the proposed SeRLA method achieves\nstate-of-the-art performance on accelerating reinforcement learning on\ndownstream tasks, especially in the early learning phase.\n","authors":["Hanping Zhang","Yuhong Guo"],"pdf_url":"https://arxiv.org/pdf/2412.06207v1.pdf","comment":"ICML 2024 AutoRL Workshop; 9 pages"},{"id":"http://arxiv.org/abs/2411.05420v2","updated":"2024-12-09T04:25:35Z","published":"2024-11-08T09:14:19Z","title":"WeatherGFM: Learning A Weather Generalist Foundation Model via\n  In-context Learning","summary":"  The Earth's weather system encompasses intricate weather data modalities and\ndiverse weather understanding tasks, which hold significant value to human\nlife. Existing data-driven models focus on single weather understanding tasks\n(e.g., weather forecasting). Although these models have achieved promising\nresults, they fail to tackle various complex tasks within a single and unified\nmodel. Moreover, the paradigm that relies on limited real observations for a\nsingle scenario hinders the model's performance upper bound. In response to\nthese limitations, we draw inspiration from the in-context learning paradigm\nemployed in state-of-the-art visual foundation models and large language\nmodels. In this paper, we introduce the first generalist weather foundation\nmodel (WeatherGFM), designed to address a wide spectrum of weather\nunderstanding tasks in a unified manner. More specifically, we initially unify\nthe representation and definition of the diverse weather understanding tasks.\nSubsequently, we devised weather prompt formats to manage different weather\ndata modalities, namely single, multiple, and temporal modalities. Finally, we\nadopt a visual prompting question-answering paradigm for the training of\nunified weather understanding tasks. Extensive experiments indicate that our\nWeatherGFM can effectively handle up to ten weather understanding tasks,\nincluding weather forecasting, super-resolution, weather image translation, and\npost-processing. Our method also showcases generalization ability on unseen\ntasks.\n","authors":["Xiangyu Zhao","Zhiwang Zhou","Wenlong Zhang","Yihao Liu","Xiangyu Chen","Junchao Gong","Hao Chen","Ben Fei","Shiqi Chen","Wanli Ouyang","Xiao-Ming Wu","Lei Bai"],"pdf_url":"https://arxiv.org/pdf/2411.05420v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.05133v3","updated":"2024-12-09T04:21:08Z","published":"2024-02-06T04:18:58Z","title":"Personalized Language Modeling from Personalized Human Feedback","summary":"  Personalized large language models (LLMs) are designed to tailor responses to\nindividual user preferences. While Reinforcement Learning from Human Feedback\n(RLHF) is a commonly used framework for aligning LLMs with human preferences,\nvanilla RLHF assumes that all human preferences share the same distribution,\npreventing fine-tuned LLMs from generating personalized content when user\npreferences are diverse. In this work, we propose Personalized-RLHF (P-RLHF),\nan efficient framework that utilizes a lightweight user model to capture\nindividual user preferences and jointly learns the user model and the\npersonalized LLM from human feedback. P-RLHF exhibits the following three\ncharacteristics: (1) It enables an LLM to generate personalized content and\nscale efficiently with growing number of users. (2) It handles both explicit\nuser preferences described as textual input and implicit user preferences\nencoded in the feedback data. (3) It eliminates the need for users to fully\narticulate their preferences, which are normally needed for prompting LLMs to\ngenerate personalized content yet are often impractical to obtain in real-world\nscenarios. Our experimental results show that personalized LLMs trained using\nP-RLHF generate responses that are more closely aligned with individual user\npreferences, outperforming vanilla, non-personalized RLHF and prompting-based\npersonalization approaches across different tasks. We opensource our code at\nhttps://github.com/HumainLab/Personalized_RLHF.\n","authors":["Xinyu Li","Ruiyang Zhou","Zachary C. Lipton","Liu Leqi"],"pdf_url":"https://arxiv.org/pdf/2402.05133v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.10805v6","updated":"2024-12-09T03:39:00Z","published":"2024-07-15T15:20:40Z","title":"Think-on-Graph 2.0: Deep and Faithful Large Language Model Reasoning\n  with Knowledge-guided Retrieval Augmented Generation","summary":"  Retrieval-augmented generation (RAG) has improved large language models\n(LLMs) by using knowledge retrieval to overcome knowledge deficiencies.\nHowever, current RAG methods often fall short of ensuring the depth and\ncompleteness of retrieved information, which is necessary for complex reasoning\ntasks. In this work, we introduce Think-on-Graph 2.0 (ToG-2), a hybrid RAG\nframework that iteratively retrieves information from both unstructured and\nstructured knowledge sources in a tight-coupling manner. Specifically, ToG-2\nleverages knowledge graphs (KGs) to link documents via entities, facilitating\ndeep and knowledge-guided context retrieval. Simultaneously, it utilizes\ndocuments as entity contexts to achieve precise and efficient graph retrieval.\nToG-2 alternates between graph retrieval and context retrieval to search for\nin-depth clues relevant to the question, enabling LLMs to generate answers. We\nconduct a series of well-designed experiments to highlight the following\nadvantages of ToG-2: 1) ToG-2 tightly couples the processes of context\nretrieval and graph retrieval, deepening context retrieval via the KG while\nenabling reliable graph retrieval based on contexts; 2) it achieves deep and\nfaithful reasoning in LLMs through an iterative knowledge retrieval process of\ncollaboration between contexts and the KG; and 3) ToG-2 is training-free and\nplug-and-play compatible with various LLMs. Extensive experiments demonstrate\nthat ToG-2 achieves overall state-of-the-art (SOTA) performance on 6 out of 7\nknowledge-intensive datasets with GPT-3.5, and can elevate the performance of\nsmaller models (e.g., LLAMA-2-13B) to the level of GPT-3.5's direct reasoning.\nThe source code is available on https://github.com/IDEA-FinAI/ToG-2.\n","authors":["Shengjie Ma","Chengjin Xu","Xuhui Jiang","Muzhi Li","Huaren Qu","Cehao Yang","Jiaxin Mao","Jian Guo"],"pdf_url":"https://arxiv.org/pdf/2407.10805v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06181v1","updated":"2024-12-09T03:34:49Z","published":"2024-12-09T03:34:49Z","title":"Enhancing Adversarial Resistance in LLMs with Recursion","summary":"  The increasing integration of Large Language Models (LLMs) into society\nnecessitates robust defenses against vulnerabilities from jailbreaking and\nadversarial prompts. This project proposes a recursive framework for enhancing\nthe resistance of LLMs to manipulation through the use of prompt simplification\ntechniques. By increasing the transparency of complex and confusing adversarial\nprompts, the proposed method enables more reliable detection and prevention of\nmalicious inputs. Our findings attempt to address a critical problem in AI\nsafety and security, providing a foundation for the development of systems able\nto distinguish harmless inputs from prompts containing malicious intent. As\nLLMs continue to be used in diverse applications, the importance of such\nsafeguards will only grow.\n","authors":["Bryan Li","Sounak Bagchi","Zizhan Wang"],"pdf_url":"https://arxiv.org/pdf/2412.06181v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06179v1","updated":"2024-12-09T03:32:40Z","published":"2024-12-09T03:32:40Z","title":"Annotations for Exploring Food Tweets From Multiple Aspects","summary":"  This research builds upon the Latvian Twitter Eater Corpus (LTEC), which is\nfocused on the narrow domain of tweets related to food, drinks, eating and\ndrinking. LTEC has been collected for more than 12 years and reaching almost 3\nmillion tweets with the basic information as well as extended automatically and\nmanually annotated metadata. In this paper we supplement the LTEC with manually\nannotated subsets of evaluation data for machine translation, named entity\nrecognition, timeline-balanced sentiment analysis, and text-image relation\nclassification. We experiment with each of the data sets using baseline models\nand highlight future challenges for various modelling approaches.\n","authors":["Matīss Rikters","Edison Marrese-Taylor","Rinalds Vīksna"],"pdf_url":"https://arxiv.org/pdf/2412.06179v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07870v4","updated":"2024-12-09T03:25:55Z","published":"2024-11-12T15:26:17Z","title":"Trustful LLMs: Customizing and Grounding Text Generation with Knowledge\n  Bases and Dual Decoders","summary":"  Although people are impressed by the content generation skills of large\nlanguage models, the use of LLMs, such as ChatGPT, is limited by the domain\ngrounding of the content. The correctness and groundedness of the generated\ncontent need to be based on a verified context, such as results from\nRetrieval-Augmented Generation (RAG). One important issue when adapting LLMs to\na customized domain is that the generated responses are often incomplete, or\nthe additions are not verified and may even be hallucinated. Prior studies on\nhallucination detection have focused on evaluation metrics, which are not\neasily adaptable to dynamic domains and can be vulnerable to attacks like\njail-breaking. In this work, we propose 1) a post-processing algorithm that\nleverages knowledge triplets in RAG context to correct hallucinations and 2) a\ndual-decoder model that fuses RAG context to guide the generation process.\n","authors":["Xiaofeng Zhu","Jaya Krishna Mandivarapu"],"pdf_url":"https://arxiv.org/pdf/2411.07870v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06176v1","updated":"2024-12-09T03:22:35Z","published":"2024-12-09T03:22:35Z","title":"AlphaVerus: Bootstrapping Formally Verified Code Generation through\n  Self-Improving Translation and Treefinement","summary":"  Automated code generation with large language models has gained significant\ntraction, but there remains no guarantee on the correctness of generated code.\nWe aim to use formal verification to provide mathematical guarantees that the\ngenerated code is correct. However, generating formally verified code with LLMs\nis hindered by the scarcity of training data and the complexity of formal\nproofs. To tackle this challenge, we introduce AlphaVerus, a self-improving\nframework that bootstraps formally verified code generation by iteratively\ntranslating programs from a higher-resource language and leveraging feedback\nfrom a verifier. AlphaVerus operates in three phases: exploration of candidate\ntranslations, Treefinement -- a novel tree search algorithm for program\nrefinement using verifier feedback, and filtering misaligned specifications and\nprograms to prevent reward hacking. Through this iterative process, AlphaVerus\nenables a LLaMA-3.1-70B model to generate verified code without human\nintervention or model finetuning. AlphaVerus shows an ability to generate\nformally verified solutions for HumanEval and MBPP, laying the groundwork for\ntruly trustworthy code-generation agents.\n","authors":["Pranjal Aggarwal","Bryan Parno","Sean Welleck"],"pdf_url":"https://arxiv.org/pdf/2412.06176v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.10980v5","updated":"2024-12-09T03:01:35Z","published":"2024-02-15T21:33:07Z","title":"ChemReasoner: Heuristic Search over a Large Language Model's Knowledge\n  Space using Quantum-Chemical Feedback","summary":"  The discovery of new catalysts is essential for the design of new and more\nefficient chemical processes in order to transition to a sustainable future. We\nintroduce an AI-guided computational screening framework unifying linguistic\nreasoning with quantum-chemistry based feedback from 3D atomistic\nrepresentations. Our approach formulates catalyst discovery as an uncertain\nenvironment where an agent actively searches for highly effective catalysts via\nthe iterative combination of large language model (LLM)-derived hypotheses and\natomistic graph neural network (GNN)-derived feedback. Identified catalysts in\nintermediate search steps undergo structural evaluation based on spatial\norientation, reaction pathways, and stability. Scoring functions based on\nadsorption energies and reaction energy barriers steer the exploration in the\nLLM's knowledge space toward energetically favorable, high-efficiency\ncatalysts. We introduce planning methods that automatically guide the\nexploration without human input, providing competitive performance against\nexpert-enumerated chemical descriptor-based implementations. By integrating\nlanguage-guided reasoning with computational chemistry feedback, our work\npioneers AI-accelerated, trustworthy catalyst discovery.\n","authors":["Henry W. Sprueill","Carl Edwards","Khushbu Agarwal","Mariefel V. Olarte","Udishnu Sanyal","Conrad Johnston","Hongbin Liu","Heng Ji","Sutanay Choudhury"],"pdf_url":"https://arxiv.org/pdf/2402.10980v5.pdf","comment":"9 pages, accepted by ICML 2024, final version"},{"id":"http://arxiv.org/abs/2412.06167v1","updated":"2024-12-09T03:00:57Z","published":"2024-12-09T03:00:57Z","title":"ACQ: A Unified Framework for Automated Programmatic Creativity in Online\n  Advertising","summary":"  In online advertising, the demand-side platform (a.k.a. DSP) enables\nadvertisers to create different ad creatives for real-time bidding.\nIntuitively, advertisers tend to create more ad creatives for a single photo to\nincrease the probability of participating in bidding, further enhancing their\nad cost. From the perspective of DSP, the following are two overlooked issues.\nOn the one hand, the number of ad creatives cannot grow indefinitely. On the\nother hand, the marginal effects of ad cost diminish as the number of ad\ncreatives increases. To this end, this paper proposes a two-stage framework\nnamed Automated Creatives Quota (ACQ) to achieve the automatic creation and\ndeactivation of ad creatives. ACQ dynamically allocates the creative quota\nacross multiple advertisers to maximize the revenue of the ad platform. ACQ\ncomprises two components: a prediction module to estimate the cost of a photo\nunder different numbers of ad creatives, and an allocation module to decide the\nquota for photos considering their estimated costs in the prediction module.\nSpecifically, in the prediction module, we develop a multi-task learning model\nbased on an unbalanced binary tree to effectively mitigate the target variable\nimbalance problem. In the allocation module, we formulate the quota allocation\nproblem as a multiple-choice knapsack problem (MCKP) and develop an efficient\nsolver to solve such large-scale problems involving tens of millions of ads. We\nperformed extensive offline and online experiments to validate the superiority\nof our proposed framework, which increased cost by 9.34%.\n","authors":["Ruizhi Wang","Kai Liu","Bingjie Li","Yu Rong","Qingpeng Cai","Fei Pan","Peng Jiang"],"pdf_url":"https://arxiv.org/pdf/2412.06167v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.04497v2","updated":"2024-12-09T03:00:42Z","published":"2024-11-30T00:10:56Z","title":"Opportunities and Challenges of Large Language Models for Low-Resource\n  Languages in Humanities Research","summary":"  Low-resource languages serve as invaluable repositories of human history,\nembodying cultural evolution and intellectual diversity. Despite their\nsignificance, these languages face critical challenges, including data scarcity\nand technological limitations, which hinder their comprehensive study and\npreservation. Recent advancements in large language models (LLMs) offer\ntransformative opportunities for addressing these challenges, enabling\ninnovative methodologies in linguistic, historical, and cultural research. This\nstudy systematically evaluates the applications of LLMs in low-resource\nlanguage research, encompassing linguistic variation, historical documentation,\ncultural expressions, and literary analysis. By analyzing technical frameworks,\ncurrent methodologies, and ethical considerations, this paper identifies key\nchallenges such as data accessibility, model adaptability, and cultural\nsensitivity. Given the cultural, historical, and linguistic richness inherent\nin low-resource languages, this work emphasizes interdisciplinary collaboration\nand the development of customized models as promising avenues for advancing\nresearch in this domain. By underscoring the potential of integrating\nartificial intelligence with the humanities to preserve and study humanity's\nlinguistic and cultural heritage, this study fosters global efforts towards\nsafeguarding intellectual diversity.\n","authors":["Tianyang Zhong","Zhenyuan Yang","Zhengliang Liu","Ruidong Zhang","Yiheng Liu","Haiyang Sun","Yi Pan","Yiwei Li","Yifan Zhou","Hanqi Jiang","Junhao Chen","Tianming Liu"],"pdf_url":"https://arxiv.org/pdf/2412.04497v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06165v1","updated":"2024-12-09T02:57:27Z","published":"2024-12-09T02:57:27Z","title":"Conservative Contextual Bandits: Beyond Linear Representations","summary":"  Conservative Contextual Bandits (CCBs) address safety in sequential decision\nmaking by requiring that an agent's policy, along with minimizing regret, also\nsatisfies a safety constraint: the performance is not worse than a baseline\npolicy (e.g., the policy that the company has in production) by more than\n$(1+\\alpha)$ factor. Prior work developed UCB-style algorithms in the\nmulti-armed [Wu et al., 2016] and contextual linear [Kazerouni et al., 2017]\nsettings. However, in practice the cost of the arms is often a non-linear\nfunction, and therefore existing UCB algorithms are ineffective in such\nsettings. In this paper, we consider CCBs beyond the linear case and develop\ntwo algorithms $\\mathtt{C-SquareCB}$ and $\\mathtt{C-FastCB}$, using Inverse Gap\nWeighting (IGW) based exploration and an online regression oracle. We show that\nthe safety constraint is satisfied with high probability and that the regret of\n$\\mathtt{C-SquareCB}$ is sub-linear in horizon $T$, while the regret of\n$\\mathtt{C-FastCB}$ is first-order and is sub-linear in $L^*$, the cumulative\nloss of the optimal policy. Subsequently, we use a neural network for function\napproximation and online gradient descent as the regression oracle to provide\n$\\tilde{O}(\\sqrt{KT} + K/\\alpha) $ and $\\tilde{O}(\\sqrt{KL^*} + K (1 +\n1/\\alpha))$ regret bounds, respectively. Finally, we demonstrate the efficacy\nof our algorithms on real-world data and show that they significantly\noutperform the existing baseline while maintaining the performance guarantee.\n","authors":["Rohan Deb","Mohammad Ghavamzadeh","Arindam Banerjee"],"pdf_url":"https://arxiv.org/pdf/2412.06165v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.04929v2","updated":"2024-12-09T02:54:53Z","published":"2024-12-06T10:34:50Z","title":"Continuous Video Process: Modeling Videos as Continuous\n  Multi-Dimensional Processes for Video Prediction","summary":"  Diffusion models have made significant strides in image generation, mastering\ntasks such as unconditional image synthesis, text-image translation, and\nimage-to-image conversions. However, their capability falls short in the realm\nof video prediction, mainly because they treat videos as a collection of\nindependent images, relying on external constraints such as temporal attention\nmechanisms to enforce temporal coherence. In our paper, we introduce a novel\nmodel class, that treats video as a continuous multi-dimensional process rather\nthan a series of discrete frames. We also report a reduction of 75\\% sampling\nsteps required to sample a new frame thus making our framework more efficient\nduring the inference time. Through extensive experimentation, we establish\nstate-of-the-art performance in video prediction, validated on benchmark\ndatasets including KTH, BAIR, Human3.6M, and UCF101. Navigate to the project\npage https://www.cs.umd.edu/~gauravsh/cvp/supp/website.html for video results.\n","authors":["Gaurav Shrivastava","Abhinav Shrivastava"],"pdf_url":"https://arxiv.org/pdf/2412.04929v2.pdf","comment":"Navigate to the project page\n  https://www.cs.umd.edu/~gauravsh/cvp/supp/website.html for video results.\n  Extended version of published CVPR paper"},{"id":"http://arxiv.org/abs/2412.06162v1","updated":"2024-12-09T02:51:21Z","published":"2024-12-09T02:51:21Z","title":"Query-Efficient Planning with Language Models","summary":"  Planning in complex environments requires an agent to efficiently query a\nworld model to find a feasible sequence of actions from start to goal. Recent\nwork has shown that Large Language Models (LLMs), with their rich prior\nknowledge and reasoning capabilities, can potentially help with planning by\nsearching over promising states and adapting to feedback from the world. In\nthis paper, we propose and study two fundamentally competing frameworks that\nleverage LLMs for query-efficient planning. The first uses LLMs as a heuristic\nwithin a search-based planner to select promising nodes to expand and propose\npromising actions. The second uses LLMs as a generative planner to propose an\nentire sequence of actions from start to goal, query a world model, and adapt\nbased on feedback. We show that while both approaches improve upon comparable\nbaselines, using an LLM as a generative planner results in significantly fewer\ninteractions. Our key finding is that the LLM as a planner can more rapidly\nadapt its planning strategies based on immediate feedback than LLM as a\nheuristic. We present evaluations and ablations on Robotouille and PDDL\nplanning benchmarks and discuss connections to existing theory on\nquery-efficient planning algorithms. Code is available at\nhttps://github.com/portal-cornell/llms-for-planning\n","authors":["Gonzalo Gonzalez-Pumariega","Wayne Chen","Kushal Kedia","Sanjiban Choudhury"],"pdf_url":"https://arxiv.org/pdf/2412.06162v1.pdf","comment":"11 pages (not including references or appendix); 13 figures (9 main\n  paper, 4 appendix); (v1) preprint"},{"id":"http://arxiv.org/abs/2210.15629v4","updated":"2024-12-09T02:49:04Z","published":"2022-10-27T17:20:50Z","title":"Language Control Diffusion: Efficiently Scaling through Space, Time, and\n  Tasks","summary":"  Training generalist agents is difficult across several axes, requiring us to\ndeal with high-dimensional inputs (space), long horizons (time), and\ngeneralization to novel tasks. Recent advances with architectures have allowed\nfor improved scaling along one or two of these axes, but are still\ncomputationally prohibitive to use. In this paper, we propose to address all\nthree axes by leveraging \\textbf{L}anguage to \\textbf{C}ontrol\n\\textbf{D}iffusion models as a hierarchical planner conditioned on language\n(LCD). We effectively and efficiently scale diffusion models for planning in\nextended temporal, state, and task dimensions to tackle long horizon control\nproblems conditioned on natural language instructions, as a step towards\ngeneralist agents. Comparing LCD with other state-of-the-art models on the\nCALVIN language robotics benchmark finds that LCD outperforms other SOTA\nmethods in multi-task success rates, whilst improving inference speed over\nother comparable diffusion models by 3.3x~15x. We show that LCD can\nsuccessfully leverage the unique strength of diffusion models to produce\ncoherent long range plans while addressing their weakness in generating\nlow-level details and control.\n","authors":["Edwin Zhang","Yujie Lu","Shinda Huang","William Wang","Amy Zhang"],"pdf_url":"https://arxiv.org/pdf/2210.15629v4.pdf","comment":"ICLR 2024, Project and code available at\n  https://github.com/ezhang7423/language-control-diffusion"},{"id":"http://arxiv.org/abs/2401.06199v2","updated":"2024-12-09T02:44:44Z","published":"2024-01-11T15:03:17Z","title":"xTrimoPGLM: Unified 100B-Scale Pre-trained Transformer for Deciphering\n  the Language of Protein","summary":"  Protein language models have shown remarkable success in learning biological\ninformation from protein sequences. However, most existing models are limited\nby either autoencoding or autoregressive pre-training objectives, which makes\nthem struggle to handle protein understanding and generation tasks\nconcurrently. We propose a unified protein language model, xTrimoPGLM, to\naddress these two types of tasks simultaneously through an innovative\npre-training framework. Our key technical contribution is an exploration of the\ncompatibility and the potential for joint optimization of the two types of\nobjectives, which has led to a strategy for training xTrimoPGLM at an\nunprecedented scale of 100 billion parameters and 1 trillion training tokens.\nOur extensive experiments reveal that 1) xTrimoPGLM significantly outperforms\nother advanced baselines in 18 protein understanding benchmarks across four\ncategories. The model also facilitates an atomic-resolution view of protein\nstructures, leading to an advanced 3D structural prediction model that\nsurpasses existing language model-based tools. 2) xTrimoPGLM not only can\ngenerate de novo protein sequences following the principles of natural ones,\nbut also can perform programmable generation after supervised fine-tuning (SFT)\non curated sequences. These results highlight the substantial capability and\nversatility of xTrimoPGLM in understanding and generating protein sequences,\ncontributing to the evolving landscape of foundation models in protein science.\n","authors":["Bo Chen","Xingyi Cheng","Pan Li","Yangli-ao Geng","Jing Gong","Shen Li","Zhilei Bei","Xu Tan","Boyan Wang","Xin Zeng","Chiming Liu","Aohan Zeng","Yuxiao Dong","Jie Tang","Le Song"],"pdf_url":"https://arxiv.org/pdf/2401.06199v2.pdf","comment":"100 pages with main text and supplementary contents"},{"id":"http://arxiv.org/abs/2412.06154v1","updated":"2024-12-09T02:32:20Z","published":"2024-12-09T02:32:20Z","title":"MoSH: Modeling Multi-Objective Tradeoffs with Soft and Hard Bounds","summary":"  Countless science and engineering applications in multi-objective\noptimization (MOO) necessitate that decision-makers (DMs) select a\nPareto-optimal solution which aligns with their preferences. Evaluating\nindividual solutions is often expensive, necessitating cost-sensitive\noptimization techniques. Due to competing objectives, the space of trade-offs\nis also expansive -- thus, examining the full Pareto frontier may prove\noverwhelming to a DM. Such real-world settings generally have loosely-defined\nand context-specific desirable regions for each objective function that can aid\nin constraining the search over the Pareto frontier. We introduce a novel\nconceptual framework that operationalizes these priors using soft-hard\nfunctions, SHFs, which allow for the DM to intuitively impose soft and hard\nbounds on each objective -- which has been lacking in previous MOO frameworks.\nLeveraging a novel minimax formulation for Pareto frontier sampling, we propose\na two-step process for obtaining a compact set of Pareto-optimal points which\nrespect the user-defined soft and hard bounds: (1) densely sample the Pareto\nfrontier using Bayesian optimization, and (2) sparsify the selected set to\nsurface to the user, using robust submodular function optimization. We prove\nthat (2) obtains the optimal compact Pareto-optimal set of points from (1). We\nfurther show that many practical problems fit within the SHF framework and\nprovide extensive empirical validation on diverse domains, including\nbrachytherapy, engineering design, and large language model personalization.\nSpecifically, for brachytherapy, our approach returns a compact set of points\nwith over 3% greater SHF-defined utility than the next best approach. Among the\nother diverse experiments, our approach consistently leads in utility, allowing\nthe DM to reach >99% of their maximum possible desired utility within\nvalidation of 5 points.\n","authors":["Edward Chen","Natalie Dullerud","Thomas Niedermayr","Elizabeth Kidd","Ransalu Senanayake","Pang Wei Koh","Sanmi Koyejo","Carlos Guestrin"],"pdf_url":"https://arxiv.org/pdf/2412.06154v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.02441v5","updated":"2024-12-09T02:29:37Z","published":"2024-02-04T10:41:40Z","title":"TopoX: A Suite of Python Packages for Machine Learning on Topological\n  Domains","summary":"  We introduce TopoX, a Python software suite that provides reliable and\nuser-friendly building blocks for computing and machine learning on topological\ndomains that extend graphs: hypergraphs, simplicial, cellular, path and\ncombinatorial complexes. TopoX consists of three packages: TopoNetX facilitates\nconstructing and computing on these domains, including working with nodes,\nedges and higher-order cells; TopoEmbedX provides methods to embed topological\ndomains into vector spaces, akin to popular graph-based embedding algorithms\nsuch as node2vec; TopoModelX is built on top of PyTorch and offers a\ncomprehensive toolbox of higher-order message passing functions for neural\nnetworks on topological domains. The extensively documented and unit-tested\nsource code of TopoX is available under MIT license at\nhttps://pyt-team.github.io/}{https://pyt-team.github.io/.\n","authors":["Mustafa Hajij","Mathilde Papillon","Florian Frantzen","Jens Agerberg","Ibrahem AlJabea","Rubén Ballester","Claudio Battiloro","Guillermo Bernárdez","Tolga Birdal","Aiden Brent","Peter Chin","Sergio Escalera","Simone Fiorellino","Odin Hoff Gardaa","Gurusankar Gopalakrishnan","Devendra Govil","Josef Hoppe","Maneel Reddy Karri","Jude Khouja","Manuel Lecha","Neal Livesay","Jan Meißner","Soham Mukherjee","Alexander Nikitin","Theodore Papamarkou","Jaro Prílepok","Karthikeyan Natesan Ramamurthy","Paul Rosen","Aldo Guzmán-Sáenz","Alessandro Salatiello","Shreyas N. Samaga","Simone Scardapane","Michael T. Schaub","Luca Scofano","Indro Spinelli","Lev Telyatnikov","Quang Truong","Robin Walters","Maosheng Yang","Olga Zaghen","Ghada Zamzmi","Ali Zia","Nina Miolane"],"pdf_url":"https://arxiv.org/pdf/2402.02441v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.00978v2","updated":"2024-12-09T02:28:01Z","published":"2024-07-01T05:28:40Z","title":"Hybrid RAG-empowered Multi-modal LLM for Secure Data Management in\n  Internet of Medical Things: A Diffusion-based Contract Approach","summary":"  Secure data management and effective data sharing have become paramount in\nthe rapidly evolving healthcare landscape, especially with the growing\nintegration of the Internet of Medical Things (IoMT). The rise of generative\nartificial intelligence has further elevated Multi-modal Large Language Models\n(MLLMs) as essential tools for managing and optimizing healthcare data in IoMT.\nMLLMs can support multi-modal inputs and generate diverse types of content by\nleveraging large-scale training on vast amounts of multi-modal data. However,\ncritical challenges persist in developing medical MLLMs, including security and\nfreshness issues of healthcare data, affecting the output quality of MLLMs. To\nthis end, in this paper, we propose a hybrid Retrieval-Augmented Generation\n(RAG)-empowered medical MLLM framework for healthcare data management. This\nframework leverages a hierarchical cross-chain architecture to facilitate\nsecure data training. Moreover, it enhances the output quality of MLLMs through\nhybrid RAG, which employs multi-modal metrics to filter various unimodal RAG\nresults and incorporates these retrieval results as additional inputs to MLLMs.\nAdditionally, we employ age of information to indirectly evaluate the data\nfreshness impact of MLLMs and utilize contract theory to incentivize healthcare\ndata holders to share their fresh data, mitigating information asymmetry during\ndata sharing. Finally, we utilize a generative diffusion model-based deep\nreinforcement learning algorithm to identify the optimal contract for efficient\ndata sharing. Numerical results demonstrate the effectiveness of the proposed\nschemes, which achieve secure and efficient healthcare data management.\n","authors":["Cheng Su","Jinbo Wen","Jiawen Kang","Yonghua Wang","Yuanjia Su","Hudan Pan","Zishao Zhong","M. Shamim Hossain"],"pdf_url":"https://arxiv.org/pdf/2407.00978v2.pdf","comment":"13 pages, 7 figures"},{"id":"http://arxiv.org/abs/2412.06148v1","updated":"2024-12-09T02:01:18Z","published":"2024-12-09T02:01:18Z","title":"The Computational Limits of State-Space Models and Mamba via the Lens of\n  Circuit Complexity","summary":"  In this paper, we analyze the computational limitations of Mamba and\nState-space Models (SSMs) by using the circuit complexity framework. Despite\nMamba's stateful design and recent attention as a strong candidate to\noutperform Transformers, we have demonstrated that both Mamba and SSMs with\n$\\mathrm{poly}(n)$-precision and constant-depth layers reside within the\n$\\mathsf{DLOGTIME}$-uniform $\\mathsf{TC}^0$ complexity class. This result\nindicates Mamba has the same computational capabilities as Transformer\ntheoretically, and it cannot solve problems like arithmetic formula problems,\nboolean formula value problems, and permutation composition problems if\n$\\mathsf{TC}^0 \\neq \\mathsf{NC}^1$. Therefore, it challenges the assumption\nMamba is more computationally expressive than Transformers. Our contributions\ninclude rigorous proofs showing that Selective SSM and Mamba architectures can\nbe simulated by $\\mathsf{DLOGTIME}$-uniform $\\mathsf{TC}^0$ circuits, and they\ncannot solve problems outside $\\mathsf{TC}^0$.\n","authors":["Yifang Chen","Xiaoyu Li","Yingyu Liang","Zhenmei Shi","Zhao Song"],"pdf_url":"https://arxiv.org/pdf/2412.06148v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06146v1","updated":"2024-12-09T01:59:40Z","published":"2024-12-09T01:59:40Z","title":"Homogeneous Dynamics Space for Heterogeneous Humans","summary":"  Analyses of human motion kinematics have achieved tremendous advances.\nHowever, the production mechanism, known as human dynamics, is still\nundercovered. In this paper, we aim to push data-driven human dynamics\nunderstanding forward. We identify a major obstacle to this as the\nheterogeneity of existing human motion understanding efforts. Specifically,\nheterogeneity exists in not only the diverse kinematics representations and\nhierarchical dynamics representations but also in the data from different\ndomains, namely biomechanics and reinforcement learning. With an in-depth\nanalysis of the existing heterogeneity, we propose to emphasize the beneath\nhomogeneity: all of them represent the homogeneous fact of human motion, though\nfrom different perspectives. Given this, we propose Homogeneous Dynamics Space\n(HDyS) as a fundamental space for human dynamics by aggregating heterogeneous\ndata and training a homogeneous latent space with inspiration from the\ninverse-forward dynamics procedure. Leveraging the heterogeneous\nrepresentations and datasets, HDyS achieves decent mapping between human\nkinematics and dynamics. We demonstrate the feasibility of HDyS with extensive\nexperiments and applications. The project page is\nhttps://foruck.github.io/HDyS.\n","authors":["Xinpeng Liu","Junxuan Liang","Chenshuo Zhang","Zixuan Cai","Cewu Lu","Yong-Lu Li"],"pdf_url":"https://arxiv.org/pdf/2412.06146v1.pdf","comment":"Cewu Lu and Yong-Lu Li are the corresponding authors"},{"id":"http://arxiv.org/abs/2412.06143v1","updated":"2024-12-09T01:56:25Z","published":"2024-12-09T01:56:25Z","title":"Precise, Fast, and Low-cost Concept Erasure in Value Space: Orthogonal\n  Complement Matters","summary":"  The success of text-to-image generation enabled by diffuion models has\nimposed an urgent need to erase unwanted concepts, e.g., copyrighted,\noffensive, and unsafe ones, from the pre-trained models in a precise, timely,\nand low-cost manner. The twofold demand of concept erasure requires a precise\nremoval of the target concept during generation (i.e., erasure efficacy), while\na minimal impact on non-target content generation (i.e., prior preservation).\nExisting methods are either computationally costly or face challenges in\nmaintaining an effective balance between erasure efficacy and prior\npreservation. To improve, we propose a precise, fast, and low-cost concept\nerasure method, called Adaptive Vaule Decomposer (AdaVD), which is\ntraining-free. This method is grounded in a classical linear algebraic\northogonal complement operation, implemented in the value space of each\ncross-attention layer within the UNet of diffusion models. An effective shift\nfactor is designed to adaptively navigate the erasure strength, enhancing prior\npreservation without sacrificing erasure efficacy. Extensive experimental\nresults show that the proposed AdaVD is effective at both single and multiple\nconcept erasure, showing a 2- to 10-fold improvement in prior preservation as\ncompared to the second best, meanwhile achieving the best or near best erasure\nefficacy, when comparing with both training-based and training-free state of\nthe arts. AdaVD supports a series of diffusion models and downstream image\ngeneration tasks, the code is available on the project page:\nhttps://github.com/WYuan1001/AdaVD\n","authors":["Yuan Wang","Ouxiang Li","Tingting Mu","Yanbin Hao","Kuien Liu","Xiang Wang","Xiangnan He"],"pdf_url":"https://arxiv.org/pdf/2412.06143v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01556v3","updated":"2024-12-09T01:55:03Z","published":"2024-10-02T13:52:55Z","title":"Integrative Decoding: Improve Factuality via Implicit Self-consistency","summary":"  Self-consistency-based approaches, which involve repeatedly sampling multiple\noutputs and selecting the most consistent one as the final response, prove to\nbe remarkably effective in improving the factual accuracy of large language\nmodels. Nonetheless, existing methods usually have strict constraints on the\ntask format, largely limiting their applicability. In this paper, we present\nIntegrative Decoding (ID), to unlock the potential of self-consistency in\nopen-ended generation tasks. ID operates by constructing a set of inputs, each\nprepended with a previously sampled response, and then processes them\nconcurrently, with the next token being selected by aggregating of all their\ncorresponding predictions at each decoding step. In essence, this simple\napproach implicitly incorporates self-consistency in the decoding objective.\nExtensive evaluation shows that ID consistently enhances factuality over a wide\nrange of language models, with substantial improvements on the TruthfulQA\n(+11.2%), Biographies (+15.4%) and LongFact (+8.5%) benchmarks. The performance\ngains amplify progressively as the number of sampled responses increases,\nindicating the potential of ID to scale up with repeated sampling.\n","authors":["Yi Cheng","Xiao Liang","Yeyun Gong","Wen Xiao","Song Wang","Yuji Zhang","Wenjun Hou","Kaishuai Xu","Wenge Liu","Wenjie Li","Jian Jiao","Qi Chen","Peng Cheng","Wayne Xiong"],"pdf_url":"https://arxiv.org/pdf/2410.01556v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06141v1","updated":"2024-12-09T01:50:39Z","published":"2024-12-09T01:50:39Z","title":"MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware\n  Multimodal Preference Optimization","summary":"  The advancement of Large Vision-Language Models (LVLMs) has propelled their\napplication in the medical field. However, Medical LVLMs (Med-LVLMs) encounter\nfactuality challenges due to modality misalignment, where the models prioritize\ntextual knowledge over visual input, leading to hallucinations that contradict\ninformation in medical images. Previous attempts to enhance modality alignment\nin Med-LVLMs through preference optimization have inadequately mitigated\nclinical relevance in preference data, making these samples easily\ndistinguishable and reducing alignment effectiveness. To address this\nchallenge, we propose MMedPO, a novel multimodal medical preference\noptimization approach that considers the clinical relevance of preference\nsamples to enhance Med-LVLM alignment. MMedPO curates multimodal preference\ndata by introducing two types of dispreference: (1) plausible hallucinations\ninjected through target Med-LVLMs or GPT-4o to produce medically inaccurate\nresponses, and (2) lesion region neglect achieved through local lesion-noising,\ndisrupting visual understanding of critical areas. We then calculate clinical\nrelevance for each sample based on scores from multiple Med-LLMs and visual\ntools, and integrate these scores into the preference optimization process as\nweights, enabling effective alignment. Our experiments demonstrate that MMedPO\nsignificantly enhances factual accuracy in Med-LVLMs, achieving substantial\nimprovements over existing preference optimization methods by averaging 14.2%\nand 51.7% across the Med-VQA and report generation tasks. Our code are\navailable in https://github.com/aiming-lab/MMedPO.\n","authors":["Kangyu Zhu","Peng Xia","Yun Li","Hongtu Zhu","Sheng Wang","Huaxiu Yao"],"pdf_url":"https://arxiv.org/pdf/2412.06141v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14473v2","updated":"2024-12-09T00:57:31Z","published":"2024-05-23T12:02:54Z","title":"Poisson Variational Autoencoder","summary":"  Variational autoencoders (VAEs) employ Bayesian inference to interpret\nsensory inputs, mirroring processes that occur in primate vision across both\nventral (Higgins et al., 2021) and dorsal (Vafaii et al., 2023) pathways.\nDespite their success, traditional VAEs rely on continuous latent variables,\nwhich deviates sharply from the discrete nature of biological neurons. Here, we\ndeveloped the Poisson VAE (P-VAE), a novel architecture that combines\nprinciples of predictive coding with a VAE that encodes inputs into discrete\nspike counts. Combining Poisson-distributed latent variables with predictive\ncoding introduces a metabolic cost term in the model loss function, suggesting\na relationship with sparse coding which we verify empirically. Additionally, we\nanalyze the geometry of learned representations, contrasting the P-VAE to\nalternative VAE models. We find that the P-VAE encodes its inputs in relatively\nhigher dimensions, facilitating linear separability of categories in a\ndownstream classification task with a much better (5x) sample efficiency. Our\nwork provides an interpretable computational framework to study brain-like\nsensory processing and paves the way for a deeper understanding of perception\nas an inferential process.\n","authors":["Hadi Vafaii","Dekel Galor","Jacob L. Yates"],"pdf_url":"https://arxiv.org/pdf/2405.14473v2.pdf","comment":"Published as a NeurIPS 2024 Spotlight paper\n  (https://openreview.net/forum?id=ektPEcqGLb)"},{"id":"http://arxiv.org/abs/2203.00872v5","updated":"2024-12-09T00:52:02Z","published":"2022-03-02T04:59:30Z","title":"Implications of Distance over Redistricting Maps: Central and Outlier\n  Maps","summary":"  In representative democracy, a redistricting map is chosen to partition an\nelectorate into districts which each elects a representative. A valid\nredistricting map must satisfy a collection of constraints such as being\ncompact, contiguous, and of almost-equal population. However, these constraints\nare loose enough to enable an enormous ensemble of valid redistricting maps.\nThis enables a partisan legislature to gerrymander by choosing a map which\nunfairly favors it. In this paper, we introduce an interpretable and tractable\ndistance measure over redistricting maps which does not use election results\nand study its implications over the ensemble of redistricting maps.\nSpecifically, we define a central map which may be considered \"most typical\"\nand give a rigorous justification for it by showing that it mirrors the Kemeny\nranking in a scenario where we have a committee voting over a collection of\nredistricting maps to be drawn. We include running time and sample complexity\nanalysis for our algorithms, including some negative results which hold using\nany algorithm. We further study outlier detection based on this distance\nmeasure and show that our framework can detect some gerrymandered maps. More\nprecisely, we show some maps that are widely considered to be gerrymandered\nthat lie very far away from our central maps in comparison to a large ensemble\nof valid redistricting maps. Since our distance measure does not rely on\nelection results, this gives a significant advantage in gerrymandering\ndetection which is lacking in all previous methods.\n","authors":["Seyed A. Esmaeili","Darshan Chakrabarti","Hayley Grape","Brian Brubach"],"pdf_url":"https://arxiv.org/pdf/2203.00872v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06113v1","updated":"2024-12-09T00:24:09Z","published":"2024-12-09T00:24:09Z","title":"Privacy-Preserving Large Language Models: Mechanisms, Applications, and\n  Future Directions","summary":"  The rapid advancement of large language models (LLMs) has revolutionized\nnatural language processing, enabling applications in diverse domains such as\nhealthcare, finance and education. However, the growing reliance on extensive\ndata for training and inference has raised significant privacy concerns,\nranging from data leakage to adversarial attacks. This survey comprehensively\nexplores the landscape of privacy-preserving mechanisms tailored for LLMs,\nincluding differential privacy, federated learning, cryptographic protocols,\nand trusted execution environments. We examine their efficacy in addressing key\nprivacy challenges, such as membership inference and model inversion attacks,\nwhile balancing trade-offs between privacy and model utility. Furthermore, we\nanalyze privacy-preserving applications of LLMs in privacy-sensitive domains,\nhighlighting successful implementations and inherent limitations. Finally, this\nsurvey identifies emerging research directions, emphasizing the need for novel\nframeworks that integrate privacy by design into the lifecycle of LLMs. By\nsynthesizing state-of-the-art approaches and future trends, this paper provides\na foundation for developing robust, privacy-preserving large language models\nthat safeguard sensitive information without compromising performance.\n","authors":["Guoshenghui Zhao","Eric Song"],"pdf_url":"https://arxiv.org/pdf/2412.06113v1.pdf","comment":null}]},"2024-12-08T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2412.06107v1","updated":"2024-12-08T23:49:38Z","published":"2024-12-08T23:49:38Z","title":"Infusing Prompts with Syntax and Semantics","summary":"  Despite impressive success, language models often generate outputs with\nflawed linguistic structure. We analyze the effect of directly infusing various\nkinds of syntactic and semantic information into large language models. To\ndemonstrate the value of our proposals, we focus on the translation of natural\nlanguage queries to SQL, in particular dealing with languages with less\nresources than English, to better investigate how much help we can get from low\ncost syntactic and semantic information. We show that linguistic analysis can\nsignificantly boost language models, to the point that we have surpassed\nprevious best systems.\n","authors":["Anton Bulle Labate","Fabio Gagliardi Cozman"],"pdf_url":"https://arxiv.org/pdf/2412.06107v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06106v1","updated":"2024-12-08T23:41:38Z","published":"2024-12-08T23:41:38Z","title":"Enhanced Computationally Efficient Long LoRA Inspired Perceiver\n  Architectures for Auto-Regressive Language Modeling","summary":"  The Transformer architecture has revolutionized the Natural Language\nProcessing field and is the backbone of Large Language Models (LLMs). The\nTransformer uses the attention mechanism that computes the pair-wise similarity\nbetween its input tokens to produce latent vectors that are able to understand\nthe semantic meaning of the input text. One of the challenges in the\nTransformer architecture is the quadratic complexity of the attention mechanism\nthat prohibits the efficient processing of long sequence lengths. While many\nrecent research works have attempted to provide a reduction from $O(n^2)$ time\ncomplexity of attention to semi-linear complexity, it remains an unsolved\nproblem in the sense of maintaining a high performance when such complexity is\nreduced. One of the important works in this respect is the Perceiver class of\narchitectures that have demonstrated excellent performance while reducing the\ncomputation complexity. In this paper, we use the PerceiverAR that was proposed\nfor Auto-Regressive modeling as a baseline, and provide three different\narchitectural enhancements to it with varying computation overhead tradeoffs.\nInspired by the recently proposed efficient attention computation approach of\nLong-LoRA, we then present an equally efficient Perceiver-based architecture\n(termed as Long LoRA Pereceiver - LLP) that can be used as the base\narchitecture in LLMs instead of just a fine-tuning add-on. Our results on\ndifferent benchmarks indicate impressive improvements compared to recent\nTransformer based models.\n","authors":["Kaleel Mahmood","Shaoyi Huang"],"pdf_url":"https://arxiv.org/pdf/2412.06106v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06095v1","updated":"2024-12-08T22:54:57Z","published":"2024-12-08T22:54:57Z","title":"Measuring Grammatical Diversity from Small Corpora: Derivational Entropy\n  Rates, Mean Length of Utterances, and Annotation Invariance","summary":"  In many fields, such as language acquisition, neuropsychology of language,\nthe study of aging, and historical linguistics, corpora are used for estimating\nthe diversity of grammatical structures that are produced during a period by an\nindividual, community, or type of speakers. In these cases, treebanks are taken\nas representative samples of the syntactic structures that might be\nencountered. Generalizing the potential syntactic diversity from the structures\ndocumented in a small corpus requires careful extrapolation whose accuracy is\nconstrained by the limited size of representative sub-corpora. In this article,\nI demonstrate -- theoretically, and empirically -- that a grammar's\nderivational entropy and the mean length of the utterances (MLU) it generates\nare fundamentally linked, giving rise to a new measure, the derivational\nentropy rate. The mean length of utterances becomes the most practical index of\nsyntactic complexity; I demonstrate that MLU is not a mere proxy, but a\nfundamental measure of syntactic diversity. In combination with the new\nderivational entropy rate measure, it provides a theory-free assessment of\ngrammatical complexity. The derivational entropy rate indexes the rate at which\ndifferent grammatical annotation frameworks determine the grammatical\ncomplexity of treebanks. I introduce the Smoothed Induced Treebank Entropy\n(SITE) as a tool for estimating these measures accurately, even from very small\ntreebanks. I conclude by discussing important implications of these results for\nboth NLP and human language processing.\n","authors":["Fermin Moscoso del Prado Martin"],"pdf_url":"https://arxiv.org/pdf/2412.06095v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.10835v4","updated":"2024-12-08T21:51:48Z","published":"2024-02-16T17:15:28Z","title":"Time Series Forecasting with LLMs: Understanding and Enhancing Model\n  Capabilities","summary":"  Large language models (LLMs) have been applied in many fields and have\ndeveloped rapidly in recent years. As a classic machine learning task, time\nseries forecasting has recently been boosted by LLMs. Recent works treat large\nlanguage models as \\emph{zero-shot} time series reasoners without further\nfine-tuning, which achieves remarkable performance. However, there are some\nunexplored research problems when applying LLMs for time series forecasting\nunder the zero-shot setting. For instance, the LLMs' preferences for the input\ntime series are less understood. In this paper, by comparing LLMs with\ntraditional time series forecasting models, we observe many interesting\nproperties of LLMs in the context of time series forecasting. First, our study\nshows that LLMs perform well in predicting time series with clear patterns and\ntrends, but face challenges with datasets lacking periodicity. This observation\ncan be explained by the ability of LLMs to recognize the underlying period\nwithin datasets, which is supported by our experiments. In addition, the input\nstrategy is investigated, and it is found that incorporating external knowledge\nand adopting natural language paraphrases substantially improve the predictive\nperformance of LLMs for time series. Overall, our study contributes insight\ninto LLMs' advantages and limitations in time series forecasting under\ndifferent conditions.\n","authors":["Hua Tang","Chong Zhang","Mingyu Jin","Qinkai Yu","Zhenting Wang","Xiaobo Jin","Yongfeng Zhang","Mengnan Du"],"pdf_url":"https://arxiv.org/pdf/2402.10835v4.pdf","comment":"Accepted by SIGKDD Explorations Newsletter"},{"id":"http://arxiv.org/abs/2405.15329v3","updated":"2024-12-08T21:41:57Z","published":"2024-05-24T08:12:30Z","title":"DnA-Eval: Enhancing Large Language Model Evaluation through\n  Decomposition and Aggregation","summary":"  The acceleration of Large Language Models (LLMs) research has opened up new\npossibilities for evaluating generated texts. They serve as scalable and\neconomical evaluators, but the question of how reliable these evaluators are\nhas emerged as a crucial research question. Prior research efforts in the\nmeta-evaluation of LLMs as judges limit the prompting of an LLM to a single use\nto obtain a final evaluation decision. They then compute the agreement between\nLLMs' outputs and human labels. This lacks interpretability in understanding\nthe evaluation capability of LLMs. In light of this challenge, we propose\nDecompose and Aggregate, which breaks down the evaluation process into\ndifferent stages based on pedagogical practices. Our experiments illustrate\nthat it not only provides a more interpretable window for how well LLMs\nevaluate, but also leads to improvements up to 39.6% for different LLMs on a\nvariety of meta-evaluation benchmarks.\n","authors":["Minzhi Li","Zhengyuan Liu","Shumin Deng","Shafiq Joty","Nancy F. Chen","Min-Yen Kan"],"pdf_url":"https://arxiv.org/pdf/2405.15329v3.pdf","comment":"COLING2025"},{"id":"http://arxiv.org/abs/2412.06071v1","updated":"2024-12-08T21:26:22Z","published":"2024-12-08T21:26:22Z","title":"KaSA: Knowledge-Aware Singular-Value Adaptation of Large Language Models","summary":"  The increasing sizes of large language models (LLMs) result in significant\ncomputational overhead and memory usage when adapting these models to specific\ntasks or domains. Various parameter-efficient fine-tuning (PEFT) methods have\nbeen devised to mitigate these challenges by training a small set of parameters\nfor the task-specific updates of the model weights. Among PEFT methods, LoRA\nstands out for its simplicity and efficiency, inspiring the development of a\nseries of variants. However, LoRA and its successors disregard the knowledge\nthat is noisy or irrelevant to the targeted task, detrimentally impacting model\nperformance and leading to suboptimality. To address this limitation, we\nintroduce Knowledge-aware Singular-value Adaptation (KaSA), a PEFT method that\nleverages singular value decomposition (SVD) with knowledge-aware singular\nvalues to dynamically activate knowledge based on its relevance to the task at\nhand. We conduct extensive experiments across a range of LLMs on tasks spanning\nnatural language understanding (NLU), generation (NLG), instruction following,\nand commonsense reasoning. The experimental results demonstrate that KaSA\nconsistently outperforms FFT and 14 popular PEFT baselines across 16 benchmarks\nand 4 synthetic datasets, underscoring our method's efficacy and adaptability.\nThe source code of our method is available at\nhttps://github.com/juyongjiang/KaSA.\n","authors":["Fan Wang","Juyong Jiang","Chansung Park","Sunghun Kim","Jing Tang"],"pdf_url":"https://arxiv.org/pdf/2412.06071v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.09413v2","updated":"2024-12-08T21:14:12Z","published":"2024-07-12T16:37:59Z","title":"SPIQA: A Dataset for Multimodal Question Answering on Scientific Papers","summary":"  Seeking answers to questions within long scientific research articles is a\ncrucial area of study that aids readers in quickly addressing their inquiries.\nHowever, existing question-answering (QA) datasets based on scientific papers\nare limited in scale and focus solely on textual content. We introduce SPIQA\n(Scientific Paper Image Question Answering), the first large-scale QA dataset\nspecifically designed to interpret complex figures and tables within the\ncontext of scientific research articles across various domains of computer\nscience. Leveraging the breadth of expertise and ability of multimodal large\nlanguage models (MLLMs) to understand figures, we employ automatic and manual\ncuration to create the dataset. We craft an information-seeking task on\ninterleaved images and text that involves multiple images covering plots,\ncharts, tables, schematic diagrams, and result visualizations. SPIQA comprises\n270K questions divided into training, validation, and three different\nevaluation splits. Through extensive experiments with 12 prominent foundational\nmodels, we evaluate the ability of current multimodal systems to comprehend the\nnuanced aspects of research articles. Additionally, we propose a\nChain-of-Thought (CoT) evaluation strategy with in-context retrieval that\nallows fine-grained, step-by-step assessment and improves model performance. We\nfurther explore the upper bounds of performance enhancement with additional\ntextual information, highlighting its promising potential for future research\nand the dataset's impact on revolutionizing how we interact with scientific\nliterature.\n","authors":["Shraman Pramanick","Rama Chellappa","Subhashini Venugopalan"],"pdf_url":"https://arxiv.org/pdf/2407.09413v2.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2412.06060v1","updated":"2024-12-08T20:28:48Z","published":"2024-12-08T20:28:48Z","title":"Steering Large Language Models to Evaluate and Amplify Creativity","summary":"  Although capable of generating creative text, Large Language Models (LLMs)\nare poor judges of what constitutes \"creativity\". In this work, we show that we\ncan leverage this knowledge of how to write creatively in order to better judge\nwhat is creative. We take a mechanistic approach that extracts differences in\nthe internal states of an LLM when prompted to respond \"boringly\" or\n\"creatively\" to provide a robust measure of creativity that corresponds\nstrongly with human judgment. We also show these internal state differences can\nbe applied to enhance the creativity of generated text at inference time.\n","authors":["Matthew Lyle Olson","Neale Ratzlaff","Musashi Hinck","Shao-yen Tseng","Vasudev Lal"],"pdf_url":"https://arxiv.org/pdf/2412.06060v1.pdf","comment":"(Spotlight) NeurIPS 2024 Workshop on Creativity & Generative AI.\n  Authors 1 and 2 contributed equally"},{"id":"http://arxiv.org/abs/2409.09927v2","updated":"2024-12-08T19:15:26Z","published":"2024-09-16T02:04:33Z","title":"Towards Data Contamination Detection for Modern Large Language Models:\n  Limitations, Inconsistencies, and Oracle Challenges","summary":"  As large language models achieve increasingly impressive results, questions\narise about whether such performance is from generalizability or mere data\nmemorization. Thus, numerous data contamination detection methods have been\nproposed. However, these approaches are often validated with traditional\nbenchmarks and early-stage LLMs, leaving uncertainty about their effectiveness\nwhen evaluating state-of-the-art LLMs on the contamination of more challenging\nbenchmarks. To address this gap and provide a dual investigation of SOTA LLM\ncontamination status and detection method robustness, we evaluate five\ncontamination detection approaches with four state-of-the-art LLMs across eight\nchallenging datasets often used in modern LLM evaluation. Our analysis reveals\nthat (1) Current methods have non-trivial limitations in their assumptions and\npractical applications; (2) Notable difficulties exist in detecting\ncontamination introduced during instruction fine-tuning with answer\naugmentation; and (3) Limited consistencies between SOTA contamination\ndetection techniques. These findings highlight the complexity of contamination\ndetection in advanced LLMs and the urgent need for further research on robust\nand generalizable contamination evaluation. Our code is available at\nhttps://github.com/vsamuel2003/data-contamination.\n","authors":["Vinay Samuel","Yue Zhou","Henry Peng Zou"],"pdf_url":"https://arxiv.org/pdf/2409.09927v2.pdf","comment":"Accepted to COLING 2025 12 pages, 1 figure"},{"id":"http://arxiv.org/abs/2403.19103v2","updated":"2024-12-08T19:09:52Z","published":"2024-03-28T02:35:53Z","title":"Automated Black-box Prompt Engineering for Personalized Text-to-Image\n  Generation","summary":"  Prompt engineering is effective for controlling the output of text-to-image\n(T2I) generative models, but it is also laborious due to the need for manually\ncrafted prompts. This challenge has spurred the development of algorithms for\nautomated prompt generation. However, these methods often struggle with\ntransferability across T2I models, require white-box access to the underlying\nmodel, and produce non-intuitive prompts. In this work, we introduce PRISM, an\nalgorithm that automatically identifies human-interpretable and transferable\nprompts that can effectively generate desired concepts given only black-box\naccess to T2I models. Inspired by large language model (LLM) jailbreaking,\nPRISM leverages the in-context learning ability of LLMs to iteratively refine\nthe candidate prompts distribution for given reference images. Our experiments\ndemonstrate the versatility and effectiveness of PRISM in generating accurate\nprompts for objects, styles and images across multiple T2I models, including\nStable Diffusion, DALL-E, and Midjourney.\n","authors":["Yutong He","Alexander Robey","Naoki Murata","Yiding Jiang","Joshua Nathaniel Williams","George J. Pappas","Hamed Hassani","Yuki Mitsufuji","Ruslan Salakhutdinov","J. Zico Kolter"],"pdf_url":"https://arxiv.org/pdf/2403.19103v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06033v1","updated":"2024-12-08T19:03:21Z","published":"2024-12-08T19:03:21Z","title":"Can Generative AI Solve Your In-Context Learning Problem? A Martingale\n  Perspective","summary":"  This work is about estimating when a conditional generative model (CGM) can\nsolve an in-context learning (ICL) problem. An in-context learning (ICL)\nproblem comprises a CGM, a dataset, and a prediction task. The CGM could be a\nmulti-modal foundation model; the dataset, a collection of patient histories,\ntest results, and recorded diagnoses; and the prediction task to communicate a\ndiagnosis to a new patient. A Bayesian interpretation of ICL assumes that the\nCGM computes a posterior predictive distribution over an unknown Bayesian model\ndefining a joint distribution over latent explanations and observable data.\nFrom this perspective, Bayesian model criticism is a reasonable approach to\nassess the suitability of a given CGM for an ICL problem. However, such\napproaches -- like posterior predictive checks (PPCs) -- often assume that we\ncan sample from the likelihood and posterior defined by the Bayesian model,\nwhich are not explicitly given for contemporary CGMs. To address this, we show\nwhen ancestral sampling from the predictive distribution of a CGM is equivalent\nto sampling datasets from the posterior predictive of the assumed Bayesian\nmodel. Then we develop the generative predictive $p$-value, which enables PPCs\nand their cousins for contemporary CGMs. The generative predictive $p$-value\ncan then be used in a statistical decision procedure to determine when the\nmodel is appropriate for an ICL problem. Our method only requires generating\nqueries and responses from a CGM and evaluating its response log probability.\nWe empirically evaluate our method on synthetic tabular, imaging, and natural\nlanguage ICL tasks using large language models.\n","authors":["Andrew Jesson","Nicolas Beltran-Velez","David Blei"],"pdf_url":"https://arxiv.org/pdf/2412.06033v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02937v3","updated":"2024-12-08T18:48:49Z","published":"2024-11-05T09:27:21Z","title":"Benchmarking Multimodal Retrieval Augmented Generation with Dynamic VQA\n  Dataset and Self-adaptive Planning Agent","summary":"  Multimodal Retrieval Augmented Generation (mRAG) plays an important role in\nmitigating the \"hallucination\" issue inherent in multimodal large language\nmodels (MLLMs). Although promising, existing heuristic mRAGs typically\npredefined fixed retrieval processes, which causes two issues: (1) Non-adaptive\nRetrieval Queries. (2) Overloaded Retrieval Queries. However, these flaws\ncannot be adequately reflected by current knowledge-seeking visual question\nanswering (VQA) datasets, since the most required knowledge can be readily\nobtained with a standard two-step retrieval. To bridge the dataset gap, we\nfirst construct Dyn-VQA dataset, consisting of three types of \"dynamic\"\nquestions, which require complex knowledge retrieval strategies variable in\nquery, tool, and time: (1) Questions with rapidly changing answers. (2)\nQuestions requiring multi-modal knowledge. (3) Multi-hop questions. Experiments\non Dyn-VQA reveal that existing heuristic mRAGs struggle to provide sufficient\nand precisely relevant knowledge for dynamic questions due to their rigid\nretrieval processes. Hence, we further propose the first self-adaptive planning\nagent for multimodal retrieval, OmniSearch. The underlying idea is to emulate\nthe human behavior in question solution which dynamically decomposes complex\nmultimodal questions into sub-question chains with retrieval action. Extensive\nexperiments prove the effectiveness of our OmniSearch, also provide direction\nfor advancing mRAG. The code and dataset will be open-sourced at\nhttps://github.com/Alibaba-NLP/OmniSearch.\n","authors":["Yangning Li","Yinghui Li","Xinyu Wang","Yong Jiang","Zhen Zhang","Xinran Zheng","Hui Wang","Hai-Tao Zheng","Pengjun Xie","Philip S. Yu","Fei Huang","Jingren Zhou"],"pdf_url":"https://arxiv.org/pdf/2411.02937v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15460v2","updated":"2024-12-08T18:42:11Z","published":"2024-10-20T18:18:23Z","title":"Hallucination Detox: Sensitive Neuron Dropout (SeND) for Large Language\n  Model Training","summary":"  As large language models (LLMs) are increasingly deployed across various\nindustries, concerns regarding their reliability, particularly due to\nhallucinations - outputs that are factually inaccurate or irrelevant to user\ninput - have grown. Our research investigates the relationship between the\ntraining process and the emergence of hallucinations to address a key gap in\nexisting research that focuses primarily on post hoc detection and mitigation\nstrategies. Using models from the Pythia suite (70M - 12B parameters) and\nseveral hallucination detection metrics, we analyze hallucination trends\nthroughout training and explore LLM internal dynamics. We introduce Sensitivity\nDropout (SenD), a novel training protocol designed to mitigate hallucinations\nby reducing variance during training. SenD achieves this by deterministically\ndropping embedding indices with significant variability, referred to as\nSensitive Embedding Indices. In addition, we develop an unsupervised\nhallucination detection metric, Efficient EigenScore (EES), which approximates\nthe traditional EigenScore at 2x speed. This efficient metric is integrated\ninto our protocol, allowing SenD to be both computationally scalable and\neffective at reducing hallucinations. Our empirical evaluation demonstrates\nthat our approach improves LLM reliability at test time by up to 40% compared\nto normal training while also providing an efficient method to improve factual\naccuracy when adapting LLMs to Wikipedia, Medical, and LegalBench domains.\n","authors":["Shahrad Mohammadzadeh","Juan David Guerra","Marco Bonizzato","Reihaneh Rabbany","Golnoosh Farnadi"],"pdf_url":"https://arxiv.org/pdf/2410.15460v2.pdf","comment":"23 pages, 15 figures, under review at ICLR, accepted to Safe\n  Generative AI Workshop @ NeurIPS 2024, resubmitting to reflect changes\n  requested by reviewers in ICLR 2025 review process"},{"id":"http://arxiv.org/abs/2412.06009v1","updated":"2024-12-08T17:53:43Z","published":"2024-12-08T17:53:43Z","title":"1-800-SHARED-TASKS at RegNLP: Lexical Reranking of Semantic Retrieval\n  (LeSeR) for Regulatory Question Answering","summary":"  This paper presents the system description of our entry for the COLING 2025\nRegNLP RIRAG (Regulatory Information Retrieval and Answer Generation)\nchallenge, focusing on leveraging advanced information retrieval and answer\ngeneration techniques in regulatory domains. We experimented with a combination\nof embedding models, including Stella, BGE, CDE, and Mpnet, and leveraged\nfine-tuning and reranking for retrieving relevant documents in top ranks. We\nutilized a novel approach, LeSeR, which achieved competitive results with a\nrecall@10 of 0.8201 and map@10 of 0.6655 for retrievals. This work highlights\nthe transformative potential of natural language processing techniques in\nregulatory applications, offering insights into their capabilities for\nimplementing a retrieval augmented generation system while identifying areas\nfor future improvement in robustness and domain adaptation.\n","authors":["Jebish Purbey","Drishti Sharma","Siddhant Gupta","Khawaja Murad","Siddartha Pullakhandam","Ram Mohan Rao Kadiyala"],"pdf_url":"https://arxiv.org/pdf/2412.06009v1.pdf","comment":"5 pages, Accepted to RegNLP @ COLING 2025"},{"id":"http://arxiv.org/abs/2412.06000v1","updated":"2024-12-08T17:19:48Z","published":"2024-12-08T17:19:48Z","title":"Does RLHF Scale? Exploring the Impacts From Data, Model, and Method","summary":"  This study explores the scaling properties of Reinforcement Learning from\nHuman Feedback (RLHF) in Large Language Models (LLMs). Although RLHF is\nconsidered an important step in post-training of LLMs, its scaling potential is\nstill largely unknown. We systematically analyze key components in the RLHF\nframework--model size, data composition, and inference budget--and their\nimpacts on performance. Our findings show that increasing data diversity and\nvolume improves reward model performance, helping process-supervision models\nscale better. For policy training, more response samples per prompt boost\nperformance initially but quickly plateau. And larger reward models offer\nmodest gains in policy training. In addition, larger policy models benefit less\nfrom RLHF with a fixed reward model. Overall, RLHF scales less efficiently than\npretraining, with diminishing returns from additional computational resources.\nBased on these observations, we propose strategies to optimize RLHF performance\nwithin computational limits.\n","authors":["Zhenyu Hou","Pengfan Du","Yilin Niu","Zhengxiao Du","Aohan Zeng","Xiao Liu","Minlie Huang","Hongning Wang","Jie Tang","Yuxiao Dong"],"pdf_url":"https://arxiv.org/pdf/2412.06000v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04715v2","updated":"2024-12-08T16:44:57Z","published":"2024-10-07T03:13:06Z","title":"Rule-based Data Selection for Large Language Models","summary":"  The quality of training data significantly impacts the performance of large\nlanguage models (LLMs). There are increasing studies using LLMs to rate and\nselect data based on several human-crafted metrics (rules). However, these\nconventional rule-based approaches often depend too heavily on human\nheuristics, lack effective metrics for assessing rules, and exhibit limited\nadaptability to new tasks. In our study, we introduce an innovative rule-based\nframework that utilizes the orthogonality of score vectors associated with\nrules as a novel metric for rule evaluations. Our approach includes an\nautomated pipeline that first uses LLMs to generate a diverse set of rules,\nencompassing various rating dimensions to evaluate data quality. Then it rates\na batch of data based on these rules and uses the determinantal point process\n(DPP) from random matrix theory to select the most orthogonal score vectors,\nthereby identifying a set of independent rules. These rules are subsequently\nused to evaluate all data, selecting samples with the highest average scores\nfor downstream tasks such as LLM training. We verify the effectiveness of our\nmethod through two experimental setups: 1) comparisons with ground truth\nratings and 2) benchmarking LLMs trained with the chosen data. Our\ncomprehensive experiments cover a range of scenarios, including general\npre-training and domain-specific fine-tuning in areas such as IMDB, Medical,\nMath, and Code. The outcomes demonstrate that our DPP-based rule rating method\nconsistently outperforms other approaches, including rule-free rating, uniform\nsampling, importance resampling, and QuRating, in terms of both rating\nprecision and model performance.\n","authors":["Xiaomin Li","Mingye Gao","Zhiwei Zhang","Chang Yue","Hong Hu"],"pdf_url":"https://arxiv.org/pdf/2410.04715v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10672v2","updated":"2024-12-08T16:18:49Z","published":"2024-10-14T16:15:57Z","title":"Large Language Model Evaluation via Matrix Nuclear-Norm","summary":"  As large language models (LLMs) continue to evolve, efficient evaluation\nmetrics are vital for assessing their ability to compress information and\nreduce redundancy. While traditional metrics like Matrix Entropy offer valuable\ninsights, they are computationally intensive for large-scale models due to\ntheir \\( O(n^3) \\) time complexity with Singular Value Decomposition (SVD). To\nmitigate this issue, we introduce the Matrix Nuclear-Norm, which not only\nserves as a metric to quantify the data compression proficiency of LLM but also\nprovides a convex approximation of matrix rank to capture both predictive\ndiscriminability and diversity. By employing the \\( L_{1,2}\\text{-norm} \\) to\nfurther approximate the nuclear norm, we can effectively assess the model's\ninformation compression capabilities. This approach reduces the time complexity\nto \\( O(n^2) \\) and eliminates the need for SVD computation. Consequently, the\nMatrix Nuclear-Norm achieves speeds 8 to 24 times faster than Matrix Entropy\nfor the CEREBRAS-GPT model as sizes increase from 111M to 6.7B. This\nperformance gap becomes more pronounced with larger models, as validated in\ntests with other models like Pythia. Additionally, evaluations on benchmarks\nand model responses confirm that our proposed Matrix Nuclear-Norm is a\nreliable, scalable, and efficient tool for assessing LLMs' performance,\nstriking a balance between accuracy and computational efficiency. The code is\navailable at https://github.com/MLGroupJLU/MatrixNuclearNorm.\n","authors":["Yahan Li","Tingyu Xia","Yi Chang","Yuan Wu"],"pdf_url":"https://arxiv.org/pdf/2410.10672v2.pdf","comment":"21 pages"},{"id":"http://arxiv.org/abs/2408.04556v3","updated":"2024-12-08T16:10:25Z","published":"2024-08-08T16:13:26Z","title":"BA-LoRA: Bias-Alleviating Low-Rank Adaptation to Mitigate Catastrophic\n  Inheritance in Large Language Models","summary":"  Large language models (LLMs) have demonstrated remarkable proficiency across\nvarious natural language processing (NLP) tasks. However, adapting LLMs to\ndownstream applications requires computationally intensive and memory-demanding\nfine-tuning procedures. To alleviate these burdens, parameter-efficient\nfine-tuning (PEFT) techniques have emerged as a promising approach to tailor\nLLMs with minimal computational overhead. While PEFT methods offer substantial\nadvantages, they do not fully address the pervasive issue of bias propagation\nfrom pre-training data. This work introduces Bias-Alleviating Low-Rank\nAdaptation (BA-LoRA), a novel PEFT method designed to counteract bias\ninheritance. BA-LoRA incorporates three distinct regularization terms: (1) a\nconsistency regularizer, (2) a diversity regularizer, and (3) a singular value\ndecomposition regularizer. These regularizers aim to enhance the models'\nconsistency, diversity, and generalization capabilities during fine-tuning. We\nconduct extensive experiments on natural language understanding (NLU) and\nnatural language generation (NLG) tasks using prominent LLMs such as LLaMA,\nMistral, and Gemma. The results demonstrate that BA-LoRA outperforms LoRA and\nits state-of-the-art variants. Moreover, our method effectively mitigates the\nadverse effects of pre-training bias, leading to more reliable and robust model\noutputs. The code is available at https://github.com/cyp-jlu-ai/BA-LoRA.\n","authors":["Yupeng Chang","Yi Chang","Yuan Wu"],"pdf_url":"https://arxiv.org/pdf/2408.04556v3.pdf","comment":"25 pages"},{"id":"http://arxiv.org/abs/2412.05967v1","updated":"2024-12-08T15:16:17Z","published":"2024-12-08T15:16:17Z","title":"Language hooks: a modular framework for augmenting LLM reasoning that\n  decouples tool usage from the model and its prompt","summary":"  Prompting and fine-tuning have emerged as two competing paradigms for\naugmenting language models with new capabilities, such as the use of tools.\nPrompting approaches are quick to set up but rely on providing explicit\ndemonstrations of each tool's usage in the model's prompt, thus coupling tool\nuse to the task at hand and limiting generalisation. Fine-tuning removes the\nneed for task-specific demonstrations of tool usage at runtime; however, this\nties new capabilities to a single model, thus making already-heavier setup\ncosts a recurring expense. In this paper, we introduce language hooks, a novel\nframework for augmenting language models with new capabilities that is\ndecoupled both from the model's task-specific prompt and from the model itself.\nThe language hook algorithm interleaves text generation by the base model with\nthe execution of modular programs that trigger conditionally based on the\nexisting text and the available capabilities. Upon triggering, programs may\ncall external tools, auxiliary language models (e.g. using tool specific\nprompts), and modify the existing context. We benchmark our method against\nstate-of-the-art baselines, find that it outperforms task-aware approaches, and\ndemonstrate its ability to generalise to novel tasks.\n","authors":["Damien de Mijolla","Wen Yang","Philippa Duckett","Christopher Frye","Mark Worrall"],"pdf_url":"https://arxiv.org/pdf/2412.05967v1.pdf","comment":"This work was conducted during Summer 2023. Experimental results and\n  references reflect the state of the field at that time and may not account\n  for subsequent developments"},{"id":"http://arxiv.org/abs/2412.05964v1","updated":"2024-12-08T14:59:21Z","published":"2024-12-08T14:59:21Z","title":"A Cross-Validation Study of Turkish Sentiment Analysis Datasets and\n  Tools","summary":"  In recent years, sentiment analysis has gained increasing significance,\nprompting researchers to explore datasets in various languages, including\nTurkish. However, the limited availability of Turkish datasets has led to their\nmultifaceted usage in different studies, yielding diverse outcomes. To overcome\nthis challenge, a rigorous review was conducted of research articles published\nbetween 2012 and 2022. 31 studies were listed, and 23 Turkish datasets obtained\nfrom publicly available sources and email requests used in these studies were\ncollected. We labeled these 31 studies using a taxonomy. We provide a map of\nsentiment analysis datasets according to this taxonomy in Turkish over 10\nyears. Moreover, we run state-of-the-art sentiment analysis tools on these\ndatasets and analyzed performance across popular Turkish sentiment datasets. We\nobserved that the performance of the sentiment analysis tools significantly\ndepends on the characteristics of the target text. Our study fosters a more\nnuanced understanding of sentiment analysis in the Turkish language.\n","authors":["Şevval Çakıcı","Dilara Karaduman","Mehmet Akif Çırlan","Ali Hürriyetoğlu"],"pdf_url":"https://arxiv.org/pdf/2412.05964v1.pdf","comment":"16 pages, 4 tables, no figures. Preprint version. To be submitted to\n  the Language Resources and Evaluation journal"},{"id":"http://arxiv.org/abs/2411.00533v3","updated":"2024-12-08T14:23:15Z","published":"2024-11-01T12:08:08Z","title":"ReverseNER: A Self-Generated Example-Driven Framework for Zero-Shot\n  Named Entity Recognition with Large Language Models","summary":"  This paper presents ReverseNER, a framework aimed at overcoming the\nlimitations of large language models (LLMs) in zero-shot Named Entity\nRecognition (NER) tasks, particularly in cases where certain entity types have\nambiguous boundaries. ReverseNER tackles this challenge by constructing a\nreliable example library with the reversed process of NER. Rather than\nbeginning with sentences, this method uses an LLM to generate entities based on\ntheir definitions and then expands them into full sentences. During sentence\ngeneration, the LLM is guided to replicate the structure of a specific 'feature\nsentence', extracted from the task sentences by clustering. This results in\nwell-annotated sentences with clearly labeled entities, while preserving\nsemantic and structural similarity to the task sentences. Once the example\nlibrary is constructed, the method selects the most semantically similar\nexample labels for each task sentence to support the LLM's inference. We also\npropose an entity-level self-consistency scoring mechanism to improve NER\nperformance with LLMs. Experiments show that ReverseNER significantly\noutperforms traditional zero-shot NER with LLMs and surpasses several few-shot\nmethods, marking a notable improvement in NER for domains with limited labeled\ndata.\n","authors":["Anbang Wang","Difei Mei","Zhichao Zhang","Xiuxiu Bai","Ran Yao","Zewen Fang","Min Hu","Zhirui Cao","Haitao Sun","Yifeng Guo","Hongyao Zhou","Yu Guo"],"pdf_url":"https://arxiv.org/pdf/2411.00533v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.16574v2","updated":"2024-12-08T14:22:13Z","published":"2024-07-23T15:27:37Z","title":"TLCR: Token-Level Continuous Reward for Fine-grained Reinforcement\n  Learning from Human Feedback","summary":"  Reinforcement Learning from Human Feedback (RLHF) leverages human preference\ndata to train language models to align more closely with human essence. These\nhuman preference data, however, are labeled at the sequence level, creating a\nmismatch between sequence-level preference labels and tokens, which are\nautoregressively generated from the language model. Although several recent\napproaches have tried to provide token-level (i.e., dense) rewards for each\nindividual token, these typically rely on predefined discrete reward values\n(e.g., positive: +1, negative: -1, neutral: 0), failing to account for varying\ndegrees of preference inherent to each token. To address this limitation, we\nintroduce TLCR (Token-Level Continuous Reward) for RLHF, which incorporates a\ndiscriminator trained to distinguish positive and negative tokens, and the\nconfidence of the discriminator is used to assign continuous rewards to each\ntoken considering the context. Extensive experiments show that our proposed\nTLCR leads to consistent performance improvements over previous sequence-level\nor token-level discrete rewards on open-ended generation benchmarks.\n","authors":["Eunseop Yoon","Hee Suk Yoon","SooHwan Eom","Gunsoo Han","Daniel Wontae Nam","Daejin Jo","Kyoung-Woon On","Mark A. Hasegawa-Johnson","Sungwoong Kim","Chang D. Yoo"],"pdf_url":"https://arxiv.org/pdf/2407.16574v2.pdf","comment":"ACL2024 Findings"},{"id":"http://arxiv.org/abs/2412.03096v2","updated":"2024-12-08T14:14:25Z","published":"2024-12-04T07:50:17Z","title":"TOOL-ED: Enhancing Empathetic Response Generation with the Tool Calling\n  Capability of LLM","summary":"  Empathetic conversation is a crucial characteristic in daily conversations\nbetween individuals. Nowadays, Large Language models (LLMs) have shown\noutstanding performance in generating empathetic responses. Knowledge bases\nlike COMET can assist LLMs in mitigating illusions and enhancing the\nunderstanding of users' intentions and emotions. However, models remain heavily\nreliant on fixed knowledge bases and unrestricted incorporation of external\nknowledge can introduce noise. Tool learning is a flexible end-to-end approach\nthat assists LLMs in handling complex problems. In this paper, we propose\nEmotional Knowledge Tool Calling (EKTC) framework, which encapsulates the\ncommonsense knowledge bases as empathetic tools, enabling LLMs to integrate\nexternal knowledge flexibly through tool calling. In order to adapt the models\nto the new task, we construct a novel dataset TOOL-ED based on the\nEMPATHETICMPATHETIC DIALOGUE (ED) dataset. We validate EKTC on the ED dataset,\nand the experimental results demonstrate that our framework can enhance the\nability of LLMs to generate empathetic responses effectively.\n","authors":["Huiying Cao","Yiqun Zhang","Shi Feng","Xiaocui Yang","Daling Wang","Yifei Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.03096v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.18624v3","updated":"2024-12-08T13:51:03Z","published":"2024-04-29T11:52:20Z","title":"Do Vision & Language Decoders use Images and Text equally? How\n  Self-consistent are their Explanations?","summary":"  Vision and language model (VLM) decoders are currently the best-performing\narchitectures on multimodal tasks. Next to answers, they are able to produce\nnatural language explanations, either in post-hoc or CoT settings. However, it\nis not clear to what extent they are using the input vision and text modalities\nwhen generating answers or explanations. In this work, we investigate if VLMs\nrely on their input modalities differently when they produce explanations as\nopposed to answers. We also evaluate the self-consistency of VLM decoders in\nboth post-hoc and CoT explanation settings, by extending existing unimodal\ntests and measures to VLM decoders. We find that most tested VLMs are less\nself-consistent than LLMs. Text contributions in all tested VL decoders are\nmore important than image contributions in all examined tasks. However, when\ncomparing explanation generation to answer generation, the contributions of\nimages are significantly stronger for generating explanations compared to\nanswers. This difference is even larger in CoT compared to post-hoc\nexplanations. Lastly, we provide an up-to-date benchmarking of state-of-the-art\nVL decoders on the VALSE benchmark, which before was restricted to VL encoders.\nWe find that the tested VL decoders still struggle with most phenomena tested\nby VALSE.\n","authors":["Letitia Parcalabescu","Anette Frank"],"pdf_url":"https://arxiv.org/pdf/2404.18624v3.pdf","comment":"30 pages, 8 figures, 11 tables"},{"id":"http://arxiv.org/abs/2412.05939v1","updated":"2024-12-08T13:45:44Z","published":"2024-12-08T13:45:44Z","title":"Exploring Multi-Grained Concept Annotations for Multimodal Large\n  Language Models","summary":"  Multimodal Large Language Models (MLLMs) excel in vision--language tasks by\npre-training solely on coarse-grained concept annotations (e.g., image\ncaptions). We hypothesize that integrating fine-grained concept annotations\n(e.g., object labels and object regions) will further improve performance, as\nboth data granularities complement each other in terms of breadth and depth in\nconcept representation. We introduce a new dataset featuring Multimodal\nMulti-Grained Concept annotations (MMGiC) for MLLMs. In constructing MMGiC, we\nexplore the impact of different data recipes on multimodal comprehension and\ngeneration. Our analyses reveal that multi-grained concept annotations\nintegrate and complement each other, under our structured template and a\ngeneral MLLM framework. We clearly explore and demonstrate the potential of\nMMGiC to help MLLMs better locate and learn concepts, aligning vision and\nlanguage at multiple granularities. We further validate our hypothesis by\ninvestigating the fair comparison and effective collaboration between MMGiC and\nimage--caption data on 12 multimodal comprehension and generation benchmarks,\ne.g., their appropriate combination achieve 3.95% and 2.34% absolute\nimprovements over image--caption data alone on POPE and SEED-Bench. Code, data\nand models will be available at https://github.com/LooperXX/MMGiC.\n","authors":["Xiao Xu","Tianhao Niu","Yuxi Xie","Libo Qin","Wanxiang Che","Min-Yen Kan"],"pdf_url":"https://arxiv.org/pdf/2412.05939v1.pdf","comment":"A manuscript that should have been Arxived in May :)"},{"id":"http://arxiv.org/abs/2411.15737v2","updated":"2024-12-08T13:11:58Z","published":"2024-11-24T07:02:32Z","title":"TableTime: Reformulating Time Series Classification as Zero-Shot Table\n  Understanding via Large Language Models","summary":"  Large language models (LLMs) have demonstrated their effectiveness in\nmultivariate time series classification (MTSC). Effective adaptation of LLMs\nfor MTSC necessitates informative data representations. Existing LLM-based\nmethods directly encode embeddings for time series within the latent space of\nLLMs from scratch to align with semantic space of LLMs. Despite their\neffectiveness, we reveal that these methods conceal three inherent bottlenecks:\n(1) they struggle to encode temporal and channel-specific information in a\nlossless manner, both of which are critical components of multivariate time\nseries; (2) it is much difficult to align the learned representation space with\nthe semantic space of the LLMs; (3) they require task-specific retraining,\nwhich is both computationally expensive and labor-intensive. To bridge these\ngaps, we propose TableTime, which reformulates MTSC as a table understanding\ntask. Specifically, TableTime introduces the following strategies: (1) convert\nmultivariate time series into a tabular form, thus minimizing information loss\nto the greatest extent; (2) represent tabular time series in text format to\nachieve natural alignment with the semantic space of LLMs; (3) design a\nreasoning framework that integrates contextual text information, neighborhood\nassistance, multi-path inference and problem decomposition to enhance the\nreasoning ability of LLMs and realize zero-shot classification. Extensive\nexperiments performed on 10 publicly representative datasets from UEA archive\nverify the superiorities of the TableTime.\n","authors":["Jiahao Wang","Mingyue Cheng","Qingyang Mao","Qi Liu","Feiyang Xu","Xin Li","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2411.15737v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.02657v4","updated":"2024-12-08T13:03:38Z","published":"2024-04-03T11:40:17Z","title":"Rethinking Kullback-Leibler Divergence in Knowledge Distillation for\n  Large Language Models","summary":"  Kullback-Leiber divergence has been widely used in Knowledge Distillation\n(KD) to compress Large Language Models (LLMs). Contrary to prior assertions\nthat reverse Kullback-Leibler (RKL) divergence is mode-seeking and thus\npreferable over the mean-seeking forward Kullback-Leibler (FKL) divergence,\nthis study empirically and theoretically demonstrates that neither mode-seeking\nnor mean-seeking properties manifest in KD for LLMs. Instead, RKL and FKL are\nfound to share the same optimization objective and both converge after a\nsufficient number of epochs. However, due to practical constraints, LLMs are\nseldom trained for such an extensive number of epochs. Meanwhile, we further\nfind that RKL focuses on the tail part of the distributions, while FKL focuses\non the head part at the beginning epochs. Consequently, we propose a simple yet\neffective Adaptive Kullback-Leiber (AKL) divergence method, which adaptively\nallocates weights to combine FKL and RKL. Metric-based and GPT-4-based\nevaluations demonstrate that the proposed AKL outperforms the baselines across\nvarious tasks and improves the diversity and quality of generated responses.\nCodes are available at \\href{https://github.com/wutaiqiang/LLM_KD_AKL}{github}.\n","authors":["Taiqiang Wu","Chaofan Tao","Jiahao Wang","Runming Yang","Zhe Zhao","Ngai Wong"],"pdf_url":"https://arxiv.org/pdf/2404.02657v4.pdf","comment":"COLING 2025"},{"id":"http://arxiv.org/abs/2412.05916v1","updated":"2024-12-08T12:17:26Z","published":"2024-12-08T12:17:26Z","title":"Paraphrase-Aligned Machine Translation","summary":"  Large Language Models (LLMs) have demonstrated significant capabilities in\nmachine translation. However, their translation quality is sometimes\nquestioned, as the generated outputs may deviate from expressions typically\nused by native speakers. These deviations often arise from differences in\nsentence structure between language systems. To address this issue, we propose\nParaAlign Translator, a method that fine-tunes LLMs to paraphrase sentences,\naligning their structures with those of the target language systems. This\napproach improves the performance of subsequent translations. Experimental\nresults demonstrate that the proposed method enhances the LLaMA-3-8B model's\nperformance in both resource-rich and low-resource scenarios and achieves\nparity with or surpassing the much larger LLaMA-3-70B model.\n","authors":["Ke-Ching Chang","Chung-Chi Chen","An-Zi Yen"],"pdf_url":"https://arxiv.org/pdf/2412.05916v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.01269v3","updated":"2024-12-08T12:07:00Z","published":"2024-12-02T08:35:54Z","title":"CPRM: A LLM-based Continual Pre-training Framework for Relevance\n  Modeling in Commercial Search","summary":"  Relevance modeling between queries and items stands as a pivotal component in\ncommercial search engines, directly affecting the user experience. Given the\nremarkable achievements of large language models (LLMs) in various natural\nlanguage processing (NLP) tasks, LLM-based relevance modeling is gradually\nbeing adopted within industrial search systems. Nevertheless, foundational LLMs\nlack domain-specific knowledge and do not fully exploit the potential of\nin-context learning. Furthermore, structured item text remains underutilized,\nand there is a shortage in the supply of corresponding queries and background\nknowledge. We thereby propose CPRM (Continual Pre-training for Relevance\nModeling), a framework designed for the continual pre-training of LLMs to\naddress these issues. Our CPRM framework includes three modules: 1) employing\nboth queries and multi-field item to jointly pre-train for enhancing domain\nknowledge, 2) applying in-context pre-training, a novel approach where LLMs are\npre-trained on a sequence of related queries or items, and 3) conducting\nreading comprehension on items to produce associated domain knowledge and\nbackground information (e.g., generating summaries and corresponding queries)\nto further strengthen LLMs. Results on offline experiments and online A/B\ntesting demonstrate that our model achieves convincing performance compared to\nstrong baselines.\n","authors":["Kaixin Wu","Yixin Ji","Zeyuan Chen","Qiang Wang","Cunxiang Wang","Hong Liu","Baijun Ji","Jia Xu","Zhongyi Liu","Jinjie Gu","Yuan Zhou","Linjian Mo"],"pdf_url":"https://arxiv.org/pdf/2412.01269v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11176v2","updated":"2024-12-08T12:00:50Z","published":"2024-03-17T11:32:18Z","title":"Quality-Aware Image-Text Alignment for Real-World Image Quality\n  Assessment","summary":"  No-Reference Image Quality Assessment (NR-IQA) focuses on designing methods\nto measure image quality in alignment with human perception when a high-quality\nreference image is unavailable. The reliance on human-annotated Mean Opinion\nScore (MOS) in the majority of state-of-the-art NR-IQA approaches limits their\nscalability and broader applicability to real-world scenarios. To overcome this\nlimitation, we propose QualiCLIP (Quality-aware CLIP), a CLIP-based\nself-supervised opinion-unaware method that does not require MOS. In\nparticular, we introduce a quality-aware image-text alignment strategy to make\nCLIP generate quality-aware image representations. Starting from pristine\nimages, we synthetically degrade them with increasing levels of intensity.\nThen, we train CLIP to rank these degraded images based on their similarity to\nquality-related antonym text prompts. At the same time, we force CLIP to\ngenerate consistent representations for images with similar content and the\nsame level of degradation. Our method significantly outperforms other\nopinion-unaware approaches on several datasets with authentic distortions.\nMoreover, despite not requiring MOS, QualiCLIP achieves state-of-the-art\nperformance even when compared with supervised methods in cross-dataset\nexperiments, thus proving to be suitable for application in real-world\nscenarios. The code and the model are publicly available at\nhttps://github.com/miccunifi/QualiCLIP.\n","authors":["Lorenzo Agnolucci","Leonardo Galteri","Marco Bertini"],"pdf_url":"https://arxiv.org/pdf/2403.11176v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.15365v3","updated":"2024-12-08T11:54:01Z","published":"2024-10-20T11:47:17Z","title":"BERTtime Stories: Investigating the Role of Synthetic Story Data in\n  Language pre-training","summary":"  We describe our contribution to the Strict and Strict-Small tracks of the 2nd\niteration of the BabyLM Challenge. The shared task is centered around efficient\npre-training given data constraints motivated by human development. In\nresponse, we study the effect of synthetic story data in language pre-training\nusing TinyStories: a recently introduced dataset of short stories. Initially,\nwe train GPT-Neo models on subsets of TinyStories, while varying the amount of\navailable data. We find that, even with access to less than 100M words, the\nmodels are able to generate high-quality, original completions to a given\nstory, and acquire substantial linguistic knowledge. To measure the effect of\nsynthetic story data, we train LTG-BERT encoder models on a combined dataset\nof: a subset of TinyStories, story completions generated by GPT-Neo, and a\nsubset of the BabyLM dataset. Our experimentation reveals that synthetic data\ncan occasionally offer modest gains, but overall have a negative influence on\nlinguistic understanding. Our work offers an initial study on synthesizing\nstory data in low resource settings and underscores their potential for\naugmentation in data-constrained language modeling. We publicly release our\nmodels and implementation on our GitHub.\n","authors":["Nikitas Theodoropoulos","Giorgos Filandrianos","Vassilis Lyberatos","Maria Lymperaiou","Giorgos Stamou"],"pdf_url":"https://arxiv.org/pdf/2410.15365v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03719v2","updated":"2024-12-08T11:50:03Z","published":"2024-09-28T10:18:35Z","title":"FluentEditor2: Text-based Speech Editing by Modeling Multi-Scale\n  Acoustic and Prosody Consistency","summary":"  Text-based speech editing (TSE) allows users to edit speech by modifying the\ncorresponding text directly without altering the original recording. Current\nTSE techniques often focus on minimizing discrepancies between generated speech\nand reference within edited regions during training to achieve fluent TSE\nperformance. However, the generated speech in the edited region should maintain\nacoustic and prosodic consistency with the unedited region and the original\nspeech at both the local and global levels. To maintain speech fluency, we\npropose a new fluency speech editing scheme based on our previous\n\\textit{FluentEditor} model, termed \\textit{\\textbf{FluentEditor2}}, by\nmodeling the multi-scale acoustic and prosody consistency training criterion in\nTSE training. Specifically, for local acoustic consistency, we propose\n\\textit{hierarchical local acoustic smoothness constraint} to align the\nacoustic properties of speech frames, phonemes, and words at the boundary\nbetween the generated speech in the edited region and the speech in the\nunedited region. For global prosody consistency, we propose \\textit{contrastive\nglobal prosody consistency constraint} to keep the speech in the edited region\nconsistent with the prosody of the original utterance. Extensive experiments on\nthe VCTK and LibriTTS datasets show that \\textit{FluentEditor2} surpasses\nexisting neural networks-based TSE methods, including Editspeech, Campnet,\nA$^3$T, FluentSpeech, and our Fluenteditor, in both subjective and objective.\nAblation studies further highlight the contributions of each module to the\noverall effectiveness of the system. Speech demos are available at:\n\\url{https://github.com/Ai-S2-Lab/FluentEditor2}.\n","authors":["Rui Liu","Jiatian Xi","Ziyue Jiang","Haizhou Li"],"pdf_url":"https://arxiv.org/pdf/2410.03719v2.pdf","comment":"submitted for an IEEE publication"},{"id":"http://arxiv.org/abs/2412.05896v1","updated":"2024-12-08T11:32:08Z","published":"2024-12-08T11:32:08Z","title":"XKV: Personalized KV Cache Memory Reduction for Long-Context LLM\n  Inference","summary":"  Recently the generative Large Language Model (LLM) has achieved remarkable\nsuccess in numerous applications. Notably its inference generates output tokens\none-by-one, leading to many redundant computations. The widely-used KV-Cache\nframework makes a compromise between time and space complexities. However,\ncaching data generates the increasingly growing memory demand, that can quickly\nexhaust the limited memory capacity of the modern accelerator like GPUs,\nparticularly in long-context inference tasks. Existing studies reduce memory\nconsumption by evicting some of cached data that have less important impact on\ninference accuracy. But the benefit in practice is far from ideal due to the\nstatic cache allocation across different LLM network layers. This paper\nobserves that the layer-specific cached data have very different impacts on\naccuracy. We quantify this difference, and give experimental and theoretical\nvalidation. We accordingly make a formal analysis and shows that customizing\nthe cache size for each layer in a personalized manner can yield a significant\nmemory reduction, while still providing comparable accuracy. We simulate the\ncache allocation as a combinatorial optimization problem and give a global\noptimal solution. In particular, we devise a mini- and sampling-based inference\nover a lightweight variant of the LLM model, so as to quickly capture the\ndifference and then feed it into the personalized algorithms. Extensive\nexperiments on real-world datasets demonstrate that our proposals can reduce KV\ncache memory consumption by 61.6% on average, improve computational efficiency\nby 2.1x and then increase the throughput by up to 5.5x.\n","authors":["Weizhuo Li","Zhigang Wang","Yu Gu","Ge Yu"],"pdf_url":"https://arxiv.org/pdf/2412.05896v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.16698v4","updated":"2024-12-08T11:21:20Z","published":"2024-04-25T15:59:16Z","title":"Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society\n  of LLM Agents","summary":"  As AI systems pervade human life, ensuring that large language models (LLMs)\nmake safe decisions remains a significant challenge. We introduce the\nGovernance of the Commons Simulation (GovSim), a generative simulation platform\ndesigned to study strategic interactions and cooperative decision-making in\nLLMs. In GovSim, a society of AI agents must collectively balance exploiting a\ncommon resource with sustaining it for future use. This environment enables the\nstudy of how ethical considerations, strategic planning, and negotiation skills\nimpact cooperative outcomes. We develop an LLM-based agent architecture and\ntest it with the leading open and closed LLMs. We find that all but the most\npowerful LLM agents fail to achieve a sustainable equilibrium in GovSim, with\nthe highest survival rate below 54%. Ablations reveal that successful\nmulti-agent communication between agents is critical for achieving cooperation\nin these cases. Furthermore, our analyses show that the failure to achieve\nsustainable cooperation in most LLMs stems from their inability to formulate\nand analyze hypotheses about the long-term effects of their actions on the\nequilibrium of the group. Finally, we show that agents that leverage\n\"Universalization\"-based reasoning, a theory of moral thinking, are able to\nachieve significantly better sustainability. Taken together, GovSim enables us\nto study the mechanisms that underlie sustainable self-government with\nspecificity and scale. We open source the full suite of our research results,\nincluding the simulation environment, agent prompts, and a comprehensive web\ninterface.\n","authors":["Giorgio Piatti","Zhijing Jin","Max Kleiman-Weiner","Bernhard Schölkopf","Mrinmaya Sachan","Rada Mihalcea"],"pdf_url":"https://arxiv.org/pdf/2404.16698v4.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2412.05868v1","updated":"2024-12-08T09:20:25Z","published":"2024-12-08T09:20:25Z","title":"Automated Extraction and Creation of FBS Design Reasoning Knowledge\n  Graphs from Structured Data in Product Catalogues Lacking Contextual\n  Information","summary":"  Ontology-based knowledge graphs (KG) are desirable for effective knowledge\nmanagement and reuse in various decision making scenarios, including design.\nCreating and populating extensive KG based on specific ontological models can\nbe highly labour and time-intensive unless automated processes are developed\nfor knowledge extraction and graph creation. Most research and development on\nautomated extraction and creation of KG is based on extensive unstructured data\nsets that provide contextual information. However, some of the most useful\ninformation about the products and services of a company has traditionally been\nrecorded as structured data. Such structured data sets rarely follow a standard\nontology, do not capture explicit mapping of relationships between the\nentities, and provide no contextual information. Therefore, this research\nreports a method and digital workflow developed to address this gap. The\ndeveloped method and workflow employ rule-based techniques to extract and\ncreate a Function Behaviour-Structure (FBS) ontology-based KG from legacy\nstructured data, especially specification sheets and product catalogues. The\nsolution approach consists of two main components: a process for deriving\ncontext and context-based classification rules for FBS ontology concepts and a\nworkflow for populating and retrieving the FBS ontology-based KG. KG and\nNatural Language Processing (NLP) are used to automate knowledge extraction,\nrepresentation, and retrieval. The workflow's effectiveness is demonstrated via\npilot implementation in an industrial context. Insights gained from the pilot\nstudy are reported regarding the challenges and opportunities, including\ndiscussing the FBS ontology and concepts.\n","authors":["Vijayalaxmi Sahadevan","Sushil Mario","Yash Jaiswal","Divyanshu Bajpai","Vishal Singh","Hiralal Aggarwal","Suhas Suresh","Manjunath Maigur"],"pdf_url":"https://arxiv.org/pdf/2412.05868v1.pdf","comment":"31 pages, with 17 figures and 10 tables"},{"id":"http://arxiv.org/abs/2406.00984v3","updated":"2024-12-08T09:03:03Z","published":"2024-06-03T04:36:38Z","title":"Predicting Drug-Gene Relations via Analogy Tasks with Word Embeddings","summary":"  Natural language processing (NLP) is utilized in a wide range of fields,\nwhere words in text are typically transformed into feature vectors called\nembeddings. BioConceptVec is a specific example of embeddings tailored for\nbiology, trained on approximately 30 million PubMed abstracts using models such\nas skip-gram. Generally, word embeddings are known to solve analogy tasks\nthrough simple vector arithmetic. For instance, $\\mathrm{\\textit{king}} -\n\\mathrm{\\textit{man}} + \\mathrm{\\textit{woman}}$ predicts\n$\\mathrm{\\textit{queen}}$. In this study, we demonstrate that BioConceptVec\nembeddings, along with our own embeddings trained on PubMed abstracts, contain\ninformation about drug-gene relations and can predict target genes from a given\ndrug through analogy computations. We also show that categorizing drugs and\ngenes using biological pathways improves performance. Furthermore, we\nillustrate that vectors derived from known relations in the past can predict\nunknown future relations in datasets divided by year. Despite the simplicity of\nimplementing analogy tasks as vector additions, our approach demonstrated\nperformance comparable to that of large language models such as GPT-4 in\npredicting drug-gene relations.\n","authors":["Hiroaki Yamagiwa","Ryoma Hashimoto","Kiwamu Arakane","Ken Murakami","Shou Soeda","Momose Oyama","Yihua Zhu","Mariko Okada","Hidetoshi Shimodaira"],"pdf_url":"https://arxiv.org/pdf/2406.00984v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.05862v1","updated":"2024-12-08T08:54:13Z","published":"2024-12-08T08:54:13Z","title":"Domain-Specific Translation with Open-Source Large Language Models:\n  Resource-Oriented Analysis","summary":"  In this work, we compare the domain-specific translation performance of\nopen-source autoregressive decoder-only large language models (LLMs) with\ntask-oriented machine translation (MT) models. Our experiments focus on the\nmedical domain and cover four language pairs with varied resource availability:\nEnglish-to-French, English-to-Portuguese, English-to-Swahili, and\nSwahili-to-English. Despite recent advancements, LLMs exhibit a clear gap in\nspecialized translation quality compared to multilingual encoder-decoder MT\nmodels such as NLLB-200. In three out of four language directions in our study,\nNLLB-200 3.3B outperforms all LLMs in the size range of 8B parameters in\nmedical translation. While fine-tuning LLMs such as Mistral and Llama improves\ntheir performance at medical translation, these models still fall short\ncompared to fine-tuned NLLB-200 3.3B models. Our findings highlight the ongoing\nneed for specialized MT models to achieve higher-quality domain-specific\ntranslation, especially in medium-resource and low-resource settings. As larger\nLLMs outperform their 8B variants, this also encourages pre-training\ndomain-specific medium-sized LMs to improve quality and efficiency in\nspecialized translation tasks.\n","authors":["Aman Kassahun Wassie","Mahdi Molaei","Yasmin Moslem"],"pdf_url":"https://arxiv.org/pdf/2412.05862v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.05861v1","updated":"2024-12-08T08:53:51Z","published":"2024-12-08T08:53:51Z","title":"Depression detection from Social Media Bangla Text Using Recurrent\n  Neural Networks","summary":"  Emotion artificial intelligence is a field of study that focuses on figuring\nout how to recognize emotions, especially in the area of text mining. Today is\nthe age of social media which has opened a door for us to share our individual\nexpressions, emotions, and perspectives on any event. We can analyze sentiment\non social media posts to detect positive, negative, or emotional behavior\ntoward society. One of the key challenges in sentiment analysis is to identify\ndepressed text from social media text that is a root cause of mental\nill-health. Furthermore, depression leads to severe impairment in day-to-day\nliving and is a major source of suicide incidents. In this paper, we apply\nnatural language processing techniques on Facebook texts for conducting emotion\nanalysis focusing on depression using multiple machine learning algorithms.\nPreprocessing steps like stemming, stop word removal, etc. are used to clean\nthe collected data, and feature extraction techniques like stylometric feature,\nTF-IDF, word embedding, etc. are applied to the collected dataset which\nconsists of 983 texts collected from social media posts. In the process of\nclass prediction, LSTM, GRU, support vector machine, and Naive-Bayes\nclassifiers have been used. We have presented the results using the primary\nclassification metrics including F1-score, and accuracy. This work focuses on\ndepression detection from social media posts to help psychologists to analyze\nsentiment from shared posts which may reduce the undesirable behaviors of\ndepressed individuals through diagnosis and treatment.\n","authors":["Sultan Ahmed","Salman Rakin","Mohammad Washeef Ibn Waliur","Nuzhat Binte Islam","Billal Hossain","Md. Mostofa Akbar"],"pdf_url":"https://arxiv.org/pdf/2412.05861v1.pdf","comment":"Initial version with Bangla text. arXiv admin note: substantial text\n  overlap with arXiv:2411.04542"},{"id":"http://arxiv.org/abs/2412.05850v1","updated":"2024-12-08T08:16:19Z","published":"2024-12-08T08:16:19Z","title":"Cooperative SQL Generation for Segmented Databases By Using\n  Multi-functional LLM Agents","summary":"  Text-to-SQL task aims to automatically yield SQL queries according to user\ntext questions. To address this problem, we propose a Cooperative SQL\nGeneration framework based on Multi-functional Agents (CSMA) through\ninformation interaction among large language model (LLM) based agents who own\npart of the database schema seperately. Inspired by the collaboration in human\nteamwork, CSMA consists of three stages: 1) Question-related schema collection,\n2) Question-corresponding SQL query generation, and 3) SQL query correctness\ncheck. In the first stage, agents analyze their respective schema and\ncommunicate with each other to collect the schema information relevant to the\nquestion. In the second stage, agents try to generate the corresponding SQL\nquery for the question using the collected information. In the third stage,\nagents check if the SQL query is created correctly according to their known\ninformation. This interaction-based method makes the question-relevant part of\ndatabase schema from each agent to be used for SQL generation and check.\nExperiments on the Spider and Bird benckmark demonstrate that CSMA achieves a\nhigh performance level comparable to the state-of-the-arts, meanwhile holding\nthe private data in these individual agents.\n","authors":["Zhiguang Wu","Fengbin Zhu","Xuequn Shang","Yupei Zhang","Pan Zhou"],"pdf_url":"https://arxiv.org/pdf/2412.05850v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.05845v1","updated":"2024-12-08T07:52:17Z","published":"2024-12-08T07:52:17Z","title":"Are Clinical T5 Models Better for Clinical Text?","summary":"  Large language models with a transformer-based encoder/decoder architecture,\nsuch as T5, have become standard platforms for supervised tasks. To bring these\ntechnologies to the clinical domain, recent work has trained new or adapted\nexisting models to clinical data. However, the evaluation of these clinical T5\nmodels and comparison to other models has been limited. Are the clinical T5\nmodels better choices than FLAN-tuned generic T5 models? Do they generalize\nbetter to new clinical domains that differ from the training sets? We\ncomprehensively evaluate these models across several clinical tasks and\ndomains. We find that clinical T5 models provide marginal improvements over\nexisting models, and perform worse when evaluated on different domains. Our\nresults inform future choices in developing clinical LLMs.\n","authors":["Yahan Li","Keith Harrigian","Ayah Zirikly","Mark Dredze"],"pdf_url":"https://arxiv.org/pdf/2412.05845v1.pdf","comment":"Proceedings of Machine Learning for Health (ML4H) Symposium 2024,\n  December 15th, 2024, Vancouver, Canada, 32 pages"},{"id":"http://arxiv.org/abs/2412.05843v1","updated":"2024-12-08T07:41:44Z","published":"2024-12-08T07:41:44Z","title":"A Self-Learning Multimodal Approach for Fake News Detection","summary":"  The rapid growth of social media has resulted in an explosion of online news\ncontent, leading to a significant increase in the spread of misleading or false\ninformation. While machine learning techniques have been widely applied to\ndetect fake news, the scarcity of labeled datasets remains a critical\nchallenge. Misinformation frequently appears as paired text and images, where a\nnews article or headline is accompanied by a related visuals. In this paper, we\nintroduce a self-learning multimodal model for fake news classification. The\nmodel leverages contrastive learning, a robust method for feature extraction\nthat operates without requiring labeled data, and integrates the strengths of\nLarge Language Models (LLMs) to jointly analyze both text and image features.\nLLMs are excel at this task due to their ability to process diverse linguistic\ndata drawn from extensive training corpora. Our experimental results on a\npublic dataset demonstrate that the proposed model outperforms several\nstate-of-the-art classification approaches, achieving over 85% accuracy,\nprecision, recall, and F1-score. These findings highlight the model's\neffectiveness in tackling the challenges of multimodal fake news detection.\n","authors":["Hao Chen","Hui Guo","Baochen Hu","Shu Hu","Jinrong Hu","Siwei Lyu","Xi Wu","Xin Wang"],"pdf_url":"https://arxiv.org/pdf/2412.05843v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.15052v2","updated":"2024-12-08T07:20:51Z","published":"2024-02-23T02:05:46Z","title":"ToMBench: Benchmarking Theory of Mind in Large Language Models","summary":"  Theory of Mind (ToM) is the cognitive capability to perceive and ascribe\nmental states to oneself and others. Recent research has sparked a debate over\nwhether large language models (LLMs) exhibit a form of ToM. However, existing\nToM evaluations are hindered by challenges such as constrained scope,\nsubjective judgment, and unintended contamination, yielding inadequate\nassessments. To address this gap, we introduce ToMBench with three key\ncharacteristics: a systematic evaluation framework encompassing 8 tasks and 31\nabilities in social cognition, a multiple-choice question format to support\nautomated and unbiased evaluation, and a build-from-scratch bilingual inventory\nto strictly avoid data leakage. Based on ToMBench, we conduct extensive\nexperiments to evaluate the ToM performance of 10 popular LLMs across tasks and\nabilities. We find that even the most advanced LLMs like GPT-4 lag behind human\nperformance by over 10% points, indicating that LLMs have not achieved a\nhuman-level theory of mind yet. Our aim with ToMBench is to enable an efficient\nand effective evaluation of LLMs' ToM capabilities, thereby facilitating the\ndevelopment of LLMs with inherent social intelligence.\n","authors":["Zhuang Chen","Jincenzi Wu","Jinfeng Zhou","Bosi Wen","Guanqun Bi","Gongyao Jiang","Yaru Cao","Mengting Hu","Yunghwei Lai","Zexuan Xiong","Minlie Huang"],"pdf_url":"https://arxiv.org/pdf/2402.15052v2.pdf","comment":"ACL 2024"},{"id":"http://arxiv.org/abs/2308.09975v2","updated":"2024-12-08T06:34:31Z","published":"2023-08-19T10:38:00Z","title":"FinEval: A Chinese Financial Domain Knowledge Evaluation Benchmark for\n  Large Language Models","summary":"  Large language models have demonstrated outstanding performance in various\nnatural language processing tasks, but their security capabilities in the\nfinancial domain have not been explored, and their performance on complex tasks\nlike financial agent remains unknown. This paper presents FinEval, a benchmark\ndesigned to evaluate LLMs' financial domain knowledge and practical abilities.\nThe dataset contains 8,351 questions categorized into four different key areas:\nFinancial Academic Knowledge, Financial Industry Knowledge, Financial Security\nKnowledge, and Financial Agent. Financial Academic Knowledge comprises 4,661\nmultiple-choice questions spanning 34 subjects such as finance and economics.\nFinancial Industry Knowledge contains 1,434 questions covering practical\nscenarios like investment research. Financial Security Knowledge assesses\nmodels through 1,640 questions on topics like application security and\ncryptography. Financial Agent evaluates tool usage and complex reasoning with\n616 questions. FinEval has multiple evaluation settings, including zero-shot,\nfive-shot with chain-of-thought, and assesses model performance using objective\nand subjective criteria. Our results show that Claude 3.5-Sonnet achieves the\nhighest weighted average score of 72.9 across all financial domain categories\nunder zero-shot setting. Our work provides a comprehensive benchmark closely\naligned with Chinese financial domain.\n","authors":["Xin Guo","Haotian Xia","Zhaowei Liu","Hanyang Cao","Zhi Yang","Zhiqiang Liu","Sizhe Wang","Jinyi Niu","Chuqi Wang","Yanhui Wang","Xiaolong Liang","Xiaoming Huang","Bing Zhu","Zhongyu Wei","Yun Chen","Weining Shen","Liwen Zhang"],"pdf_url":"https://arxiv.org/pdf/2308.09975v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.05821v1","updated":"2024-12-08T05:47:55Z","published":"2024-12-08T05:47:55Z","title":"An Entailment Tree Generation Approach for Multimodal Multi-Hop Question\n  Answering with Mixture-of-Experts and Iterative Feedback Mechanism","summary":"  With the rise of large-scale language models (LLMs), it is currently popular\nand effective to convert multimodal information into text descriptions for\nmultimodal multi-hop question answering. However, we argue that the current\nmethods of multi-modal multi-hop question answering still mainly face two\nchallenges: 1) The retrieved evidence containing a large amount of redundant\ninformation, inevitably leads to a significant drop in performance due to\nirrelevant information misleading the prediction. 2) The reasoning process\nwithout interpretable reasoning steps makes the model difficult to discover the\nlogical errors for handling complex questions. To solve these problems, we\npropose a unified LLMs-based approach but without heavily relying on them due\nto the LLM's potential errors, and innovatively treat multimodal multi-hop\nquestion answering as a joint entailment tree generation and question answering\nproblem. Specifically, we design a multi-task learning framework with a focus\non facilitating common knowledge sharing across interpretability and prediction\ntasks while preventing task-specific errors from interfering with each other\nvia mixture of experts. Afterward, we design an iterative feedback mechanism to\nfurther enhance both tasks by feeding back the results of the joint training to\nthe LLM for regenerating entailment trees, aiming to iteratively refine the\npotential answer. Notably, our method has won the first place in the official\nleaderboard of WebQA (since April 10, 2024), and achieves competitive results\non MultimodalQA.\n","authors":["Qing Zhang","Haocheng Lv","Jie Liu","Zhiyun Chen","Jianyong Duan","Hao Wang","Li He","Mingying Xv"],"pdf_url":"https://arxiv.org/pdf/2412.05821v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2411.00774v5","updated":"2024-12-08T05:41:56Z","published":"2024-11-01T17:59:51Z","title":"Freeze-Omni: A Smart and Low Latency Speech-to-speech Dialogue Model\n  with Frozen LLM","summary":"  Rapidly developing large language models (LLMs) have brought tremendous\nintelligent applications. Especially, the GPT-4o's excellent duplex speech\ninteraction ability has brought impressive experience to users. Researchers\nhave recently proposed several multi-modal LLMs in this direction that can\nachieve user-agent speech-to-speech conversations. This paper proposes a novel\nspeech-text multimodal LLM architecture called Freeze-Omni. Our main\ncontribution is that the speech input and output modalities can be easily\nconnected to a textual LLM while keeping the LLM's parameters frozen throughout\nthe training process. We design a three-stage training strategy for modeling\nboth the speech input and output, enabling Freeze-Omni to obtain\nspeech-to-speech conversation ability using text-speech paired data (such as\nASR and TTS data) and only 60,000 multi-round text Q&A data on 8 GPUs.\nMoreover, we can effectively ensure that the intelligence of the Freeze-Omni in\nthe speech modality is at the same level compared with that in the text\nmodality of its backbone LLM, while achieving low latency end-to-end spoken\nresponse. In addition, we also designed a method to achieve duplex dialogue\nability through multi-task training, giving Freeze-Omni a more natural style of\ndialogue ability between users and agents. In summary, Freeze-Omni holds great\npotential to conduct speech-to-speech dialogue based on a multimodal LLM under\nthe condition of a frozen LLM, avoiding the catastrophic forgetting problem\ncaused by limited data and training resources.\n","authors":["Xiong Wang","Yangze Li","Chaoyou Fu","Yunhang Shen","Lei Xie","Ke Li","Xing Sun","Long Ma"],"pdf_url":"https://arxiv.org/pdf/2411.00774v5.pdf","comment":"Project Page: https://freeze-omni.github.io/"},{"id":"http://arxiv.org/abs/2412.05818v1","updated":"2024-12-08T05:28:08Z","published":"2024-12-08T05:28:08Z","title":"SILMM: Self-Improving Large Multimodal Models for Compositional\n  Text-to-Image Generation","summary":"  Large Multimodal Models (LMMs) have demonstrated impressive capabilities in\nmultimodal understanding and generation, pushing forward advancements in\ntext-to-image generation. However, achieving accurate text-image alignment for\nLMMs, particularly in compositional scenarios, remains challenging. Existing\napproaches, such as layout planning for multi-step generation and learning from\nhuman feedback or AI feedback, depend heavily on prompt engineering, costly\nhuman annotations, and continual upgrading, limiting flexibility and\nscalability. In this work, we introduce a model-agnostic iterative\nself-improvement framework (SILMM) that can enable LMMs to provide helpful and\nscalable self-feedback and optimize text-image alignment via Direct Preference\nOptimization (DPO). DPO can readily applied to LMMs that use discrete visual\ntokens as intermediate image representations; while it is less suitable for\nLMMs with continuous visual features, as obtaining generation probabilities is\nchallenging. To adapt SILMM to LMMs with continuous features, we propose a\ndiversity mechanism to obtain diverse representations and a kernel-based\ncontinuous DPO for alignment. Extensive experiments on three compositional\ntext-to-image generation benchmarks validate the effectiveness and superiority\nof SILMM, showing improvements exceeding 30% on T2I-CompBench++ and around 20%\non DPG-Bench.\n","authors":["Leigang Qu","Haochuan Li","Wenjie Wang","Xiang Liu","Juncheng Li","Liqiang Nie","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2412.05818v1.pdf","comment":"project page: https://silmm.github.io/"},{"id":"http://arxiv.org/abs/2412.00756v2","updated":"2024-12-08T05:04:49Z","published":"2024-12-01T10:29:36Z","title":"Multi-View Incongruity Learning for Multimodal Sarcasm Detection","summary":"  Multimodal sarcasm detection (MSD) is essential for various downstream tasks.\nExisting MSD methods tend to rely on spurious correlations. These methods often\nmistakenly prioritize non-essential features yet still make correct\npredictions, demonstrating poor generalizability beyond training environments.\nRegarding this phenomenon, this paper undertakes several initiatives. Firstly,\nwe identify two primary causes that lead to the reliance of spurious\ncorrelations. Secondly, we address these challenges by proposing a novel method\nthat integrate Multimodal Incongruities via Contrastive Learning (MICL) for\nmultimodal sarcasm detection. Specifically, we first leverage incongruity to\ndrive multi-view learning from three views: token-patch, entity-object, and\nsentiment. Then, we introduce extensive data augmentation to mitigate the\nbiased learning of the textual modality. Additionally, we construct a test set,\nSPMSD, which consists potential spurious correlations to evaluate the the\nmodel's generalizability. Experimental results demonstrate the superiority of\nMICL on benchmark datasets, along with the analyses showcasing MICL's\nadvancement in mitigating the effect of spurious correlation.\n","authors":["Diandian Guo","Cong Cao","Fangfang Yuan","Yanbing Liu","Guangjie Zeng","Xiaoyan Yu","Hao Peng","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2412.00756v2.pdf","comment":"Accepted to COLING 2025"},{"id":"http://arxiv.org/abs/2411.15296v2","updated":"2024-12-08T04:24:31Z","published":"2024-11-22T18:59:54Z","title":"MME-Survey: A Comprehensive Survey on Evaluation of Multimodal LLMs","summary":"  As a prominent direction of Artificial General Intelligence (AGI), Multimodal\nLarge Language Models (MLLMs) have garnered increased attention from both\nindustry and academia. Building upon pre-trained LLMs, this family of models\nfurther develops multimodal perception and reasoning capabilities that are\nimpressive, such as writing code given a flow chart or creating stories based\non an image. In the development process, evaluation is critical since it\nprovides intuitive feedback and guidance on improving models. Distinct from the\ntraditional train-eval-test paradigm that only favors a single task like image\nclassification, the versatility of MLLMs has spurred the rise of various new\nbenchmarks and evaluation methods. In this paper, we aim to present a\ncomprehensive survey of MLLM evaluation, discussing four key aspects: 1) the\nsummarised benchmarks types divided by the evaluation capabilities, including\nfoundation capabilities, model self-analysis, and extented applications; 2) the\ntypical process of benchmark counstruction, consisting of data collection,\nannotation, and precautions; 3) the systematic evaluation manner composed of\njudge, metric, and toolkit; 4) the outlook for the next benchmark. This work\naims to offer researchers an easy grasp of how to effectively evaluate MLLMs\naccording to different needs and to inspire better evaluation methods, thereby\ndriving the progress of MLLM research.\n","authors":["Chaoyou Fu","Yi-Fan Zhang","Shukang Yin","Bo Li","Xinyu Fang","Sirui Zhao","Haodong Duan","Xing Sun","Ziwei Liu","Liang Wang","Caifeng Shan","Ran He"],"pdf_url":"https://arxiv.org/pdf/2411.15296v2.pdf","comment":"Produced by MME+MMBench+LLaVA Teams. Project Page:\n  https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Benchmarks"},{"id":"http://arxiv.org/abs/2409.12822v3","updated":"2024-12-08T04:06:53Z","published":"2024-09-19T14:50:34Z","title":"Language Models Learn to Mislead Humans via RLHF","summary":"  Language models (LMs) can produce errors that are hard to detect for humans,\nespecially when the task is complex. RLHF, the most popular post-training\nmethod, may exacerbate this problem: to achieve higher rewards, LMs might get\nbetter at convincing humans that they are right even when they are wrong. We\nstudy this phenomenon under a standard RLHF pipeline, calling it \"U-SOPHISTRY\"\nsince it is Unintended by model developers. Specifically, we ask\ntime-constrained (e.g., 3-10 minutes) human subjects to evaluate the\ncorrectness of model outputs and calculate humans' accuracy against gold\nlabels. On a question-answering task (QuALITY) and programming task (APPS),\nRLHF makes LMs better at convincing our subjects but not at completing the task\ncorrectly. RLHF also makes the model harder to evaluate: our subjects' false\npositive rate increases by 24.1% on QuALITY and 18.3% on APPS. Finally, we show\nthat probing, a state-of-the-art approach for detecting Intended Sophistry\n(e.g. backdoored LMs), does not generalize to U-SOPHISTRY. Our results\nhighlight an important failure mode of RLHF and call for more research in\nassisting humans to align them.\n","authors":["Jiaxin Wen","Ruiqi Zhong","Akbir Khan","Ethan Perez","Jacob Steinhardt","Minlie Huang","Samuel R. Bowman","He He","Shi Feng"],"pdf_url":"https://arxiv.org/pdf/2409.12822v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.05797v1","updated":"2024-12-08T03:26:44Z","published":"2024-12-08T03:26:44Z","title":"Speech Is Not Enough: Interpreting Nonverbal Indicators of Common\n  Knowledge and Engagement","summary":"  Our goal is to develop an AI Partner that can provide support for group\nproblem solving and social dynamics. In multi-party working group environments,\nmultimodal analytics is crucial for identifying non-verbal interactions of\ngroup members. In conjunction with their verbal participation, this creates an\nholistic understanding of collaboration and engagement that provides necessary\ncontext for the AI Partner. In this demo, we illustrate our present\ncapabilities at detecting and tracking nonverbal behavior in student\ntask-oriented interactions in the classroom, and the implications for tracking\ncommon ground and engagement.\n","authors":["Derek Palmer","Yifan Zhu","Kenneth Lai","Hannah VanderHoeven","Mariah Bradford","Ibrahim Khebour","Carlos Mabrey","Jack Fitzgerald","Nikhil Krishnaswamy","Martha Palmer","James Pustejovsky"],"pdf_url":"https://arxiv.org/pdf/2412.05797v1.pdf","comment":"3 pages, 2 figures, appearing at AAAI 2025 Demos Track"},{"id":"http://arxiv.org/abs/2411.16813v2","updated":"2024-12-08T02:00:57Z","published":"2024-11-25T15:28:11Z","title":"Fine-Tuning LLMs with Noisy Data for Political Argument Generation and\n  Post Guidance","summary":"  The incivility in social media discourse complicates the deployment of\nautomated text generation models for politically sensitive content. Fine-tuning\nand prompting strategies are critical, but underexplored, solutions to mitigate\ntoxicity in such contexts. This study investigates the fine-tuning and\nprompting effects on GPT-3.5 Turbo using subsets of the CLAPTON dataset of\npolitical discussion posts, comprising Twitter and Reddit data labeled for\ntheir justification, reciprocity and incivility. Fine-tuned models on Reddit\ndata scored highest on discussion quality, while combined noisy data led to\npersistent toxicity. Prompting strategies reduced specific toxic traits, such\nas personal attacks, but had limited broader impact. The findings emphasize\nthat high-quality data and well-crafted prompts are essential to reduce\nincivility and improve rhetorical quality in automated political discourse\ngeneration.\n","authors":["Svetlana Churina","Kokil Jaidka"],"pdf_url":"https://arxiv.org/pdf/2411.16813v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.05768v1","updated":"2024-12-08T00:46:10Z","published":"2024-12-08T00:46:10Z","title":"Uncovering Uncertainty in Transformer Inference","summary":"  We explore the Iterative Inference Hypothesis (IIH) within the context of\ntransformer-based language models, aiming to understand how a model's latent\nrepresentations are progressively refined and whether observable differences\nare present between correct and incorrect generations. Our findings provide\nempirical support for the IIH, showing that the nth token embedding in the\nresidual stream follows a trajectory of decreasing loss. Additionally, we\nobserve that the rate at which residual embeddings converge to a stable output\nrepresentation reflects uncertainty in the token generation process. Finally,\nwe introduce a method utilizing cross-entropy to detect this uncertainty and\ndemonstrate its potential to distinguish between correct and incorrect token\ngenerations on a dataset of idioms.\n","authors":["Greyson Brothers","Willa Mannering","Amber Tien","John Winder"],"pdf_url":"https://arxiv.org/pdf/2412.05768v1.pdf","comment":"Accepted poster at the 38th Conference on Neural Information\n  Processing Systems (NeurIPS 2024) Workshop on Foundation Model Interventions"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2412.06078v1","updated":"2024-12-08T21:55:12Z","published":"2024-12-08T21:55:12Z","title":"Mixture-of-PageRanks: Replacing Long-Context with Real-Time, Sparse\n  GraphRAG","summary":"  Recent advances have extended the context window of frontier LLMs\ndramatically, from a few thousand tokens up to millions, enabling entire books\nand codebases to fit into context. However, the compute costs of inferencing\nlong-context LLMs are massive and often prohibitive in practice. RAG offers an\nefficient and effective alternative: retrieve and process only the subset of\nthe context most important for the current task. Although promising, recent\nwork applying RAG to long-context tasks has two core limitations: 1) there has\nbeen little focus on making the RAG pipeline compute efficient, and 2) such\nworks only test on simple QA tasks, and their performance on more challenging\ntasks is unclear. To address this, we develop an algorithm based on PageRank, a\ngraph-based retrieval algorithm, which we call mixture-of-PageRanks (MixPR).\nMixPR uses a mixture of PageRank-based graph-retrieval algorithms implemented\nusing sparse matrices for efficent, cheap retrieval that can deal with a\nvariety of complex tasks. Our MixPR retriever achieves state-of-the-art results\nacross a wide range of long-context benchmark tasks, outperforming both\nexisting RAG methods, specialized retrieval architectures, and long-context\nLLMs despite being far more compute efficient. Due to using sparse embeddings,\nour retriever is extremely compute efficient, capable of embedding and\nretrieving millions of tokens within a few seconds and runs entirely on CPU.\n","authors":["Nicholas Alonso","Beren Millidge"],"pdf_url":"https://arxiv.org/pdf/2412.06078v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06069v1","updated":"2024-12-08T21:14:57Z","published":"2024-12-08T21:14:57Z","title":"Fuzzy Norm-Explicit Product Quantization for Recommender Systems","summary":"  As the data resources grow, providing recommendations that best meet the\ndemands has become a vital requirement in business and life to overcome the\ninformation overload problem. However, building a system suggesting relevant\nrecommendations has always been a point of debate. One of the most\ncost-efficient techniques in terms of producing relevant recommendations at a\nlow complexity is Product Quantization (PQ). PQ approaches have continued\ndeveloping in recent years. This system's crucial challenge is improving\nproduct quantization performance in terms of recall measures without\ncompromising its complexity. This makes the algorithm suitable for problems\nthat require a greater number of potentially relevant items without\ndisregarding others, at high-speed and low-cost to keep up with traffic. This\nis the case of online shops where the recommendations for the purpose are\nimportant, although customers can be susceptible to scoping other products.\nThis research proposes a fuzzy approach to perform norm-based product\nquantization. Type-2 Fuzzy sets (T2FSs) define the codebook allowing\nsub-vectors (T2FSs) to be associated with more than one element of the\ncodebook, and next, its norm calculus is resolved by means of integration. Our\nmethod finesses the recall measure up, making the algorithm suitable for\nproblems that require querying at most possible potential relevant items\nwithout disregarding others. The proposed method outperforms all PQ approaches\nsuch as NEQ, PQ, and RQ up to +6%, +5%, and +8% by achieving a recall of 94%,\n69%, 59% in Netflix, Audio, Cifar60k datasets, respectively. More and over,\ncomputing time and complexity nearly equals the most computationally efficient\nexisting PQ method in the state-of-the-art.\n","authors":["Mohammadreza Jamalifard","Javier Andreu-Perez","Hani Hagras","Luis Martínez López"],"pdf_url":"https://arxiv.org/pdf/2412.06069v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06009v1","updated":"2024-12-08T17:53:43Z","published":"2024-12-08T17:53:43Z","title":"1-800-SHARED-TASKS at RegNLP: Lexical Reranking of Semantic Retrieval\n  (LeSeR) for Regulatory Question Answering","summary":"  This paper presents the system description of our entry for the COLING 2025\nRegNLP RIRAG (Regulatory Information Retrieval and Answer Generation)\nchallenge, focusing on leveraging advanced information retrieval and answer\ngeneration techniques in regulatory domains. We experimented with a combination\nof embedding models, including Stella, BGE, CDE, and Mpnet, and leveraged\nfine-tuning and reranking for retrieving relevant documents in top ranks. We\nutilized a novel approach, LeSeR, which achieved competitive results with a\nrecall@10 of 0.8201 and map@10 of 0.6655 for retrievals. This work highlights\nthe transformative potential of natural language processing techniques in\nregulatory applications, offering insights into their capabilities for\nimplementing a retrieval augmented generation system while identifying areas\nfor future improvement in robustness and domain adaptation.\n","authors":["Jebish Purbey","Drishti Sharma","Siddhant Gupta","Khawaja Murad","Siddartha Pullakhandam","Ram Mohan Rao Kadiyala"],"pdf_url":"https://arxiv.org/pdf/2412.06009v1.pdf","comment":"5 pages, Accepted to RegNLP @ COLING 2025"},{"id":"http://arxiv.org/abs/2409.02864v3","updated":"2024-12-08T15:45:30Z","published":"2024-09-04T16:43:14Z","title":"Language Model Powered Digital Biology with BRAD","summary":"  Recent advancements in Large Language Models (LLMs) are transforming biology,\ncomputer science, engineering, and every day life. However, integrating the\nwide array of computational tools, databases, and scientific literature\ncontinues to pose a challenge to biological research. LLMs are well-suited for\nunstructured integration, efficient information retrieval, and automating\nstandard workflows and actions from these diverse resources. To harness these\ncapabilities in bioinformatics, we present a prototype Bioinformatics Retrieval\nAugmented Digital assistant (BRAD). BRAD is a chatbot and agentic system that\nintegrates a variety of bioinformatics tools. The Python package implements an\nAI \\texttt{Agent} that is powered by LLMs and connects to a local file system,\nonline databases, and a user's software. The \\texttt{Agent} is highly\nconfigurable, enabling tasks such as Retrieval-Augmented Generation, searches\nacross bioinformatics databases, and the execution of software pipelines.\nBRAD's coordinated integration of bioinformatics tools delivers a context-aware\nand semi-autonomous system that extends beyond the capabilities of conventional\nLLM-based chatbots. A graphical user interface (GUI) provides an intuitive\ninterface to the system.\n","authors":["Joshua Pickard","Ram Prakash","Marc Andrew Choi","Natalie Oliven","Cooper Stansbury","Jillian Cwycyshyn","Alex Gorodetsky","Alvaro Velasquez","Indika Rajapakse"],"pdf_url":"https://arxiv.org/pdf/2409.02864v3.pdf","comment":"12 pages, 3 figures, 1 table. See: https://github.com/Jpickard1/BRAD"},{"id":"http://arxiv.org/abs/2412.05937v1","updated":"2024-12-08T13:36:42Z","published":"2024-12-08T13:36:42Z","title":"Accelerating Manufacturing Scale-Up from Material Discovery Using\n  Agentic Web Navigation and Retrieval-Augmented AI for Process Engineering\n  Schematics Design","summary":"  Process Flow Diagrams (PFDs) and Process and Instrumentation Diagrams (PIDs)\nare critical tools for industrial process design, control, and safety. However,\nthe generation of precise and regulation-compliant diagrams remains a\nsignificant challenge, particularly in scaling breakthroughs from material\ndiscovery to industrial production in an era of automation and digitalization.\nThis paper introduces an autonomous agentic framework to address these\nchallenges through a twostage approach involving knowledge acquisition and\ngeneration. The framework integrates specialized sub-agents for retrieving and\nsynthesizing multimodal data from publicly available online sources and\nconstructs ontological knowledge graphs using a Graph Retrieval-Augmented\nGeneration (Graph RAG) paradigm. These capabilities enable the automation of\ndiagram generation and open-domain question answering (ODQA) tasks with high\ncontextual accuracy. Extensive empirical experiments demonstrate the frameworks\nability to deliver regulation-compliant diagrams with minimal expert\nintervention, highlighting its practical utility for industrial applications.\n","authors":["Sakhinana Sagar Srinivas","Akash Das","Shivam Gupta","Venkataramana Runkana"],"pdf_url":"https://arxiv.org/pdf/2412.05937v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.05921v1","updated":"2024-12-08T12:31:32Z","published":"2024-12-08T12:31:32Z","title":"Learning Cluster Representatives for Approximate Nearest Neighbor Search","summary":"  Developing increasingly efficient and accurate algorithms for approximate\nnearest neighbor search is a paramount goal in modern information retrieval. A\nprimary approach to addressing this question is clustering, which involves\npartitioning the dataset into distinct groups, with each group characterized by\na representative data point. By this method, retrieving the top-k data points\nfor a query requires identifying the most relevant clusters based on their\nrepresentatives -- a routing step -- and then conducting a nearest neighbor\nsearch within these clusters only, drastically reducing the search space.\n  The objective of this thesis is not only to provide a comprehensive\nexplanation of clustering-based approximate nearest neighbor search but also to\nintroduce and delve into every aspect of our novel state-of-the-art method,\nwhich originated from a natural observation: The routing function solves a\nranking problem, making the function amenable to learning-to-rank. The\ndevelopment of this intuition and applying it to maximum inner product search\nhas led us to demonstrate that learning cluster representatives using a simple\nlinear function significantly boosts the accuracy of clustering-based\napproximate nearest neighbor search.\n","authors":["Thomas Vecchiato"],"pdf_url":"https://arxiv.org/pdf/2412.05921v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.01269v3","updated":"2024-12-08T12:07:00Z","published":"2024-12-02T08:35:54Z","title":"CPRM: A LLM-based Continual Pre-training Framework for Relevance\n  Modeling in Commercial Search","summary":"  Relevance modeling between queries and items stands as a pivotal component in\ncommercial search engines, directly affecting the user experience. Given the\nremarkable achievements of large language models (LLMs) in various natural\nlanguage processing (NLP) tasks, LLM-based relevance modeling is gradually\nbeing adopted within industrial search systems. Nevertheless, foundational LLMs\nlack domain-specific knowledge and do not fully exploit the potential of\nin-context learning. Furthermore, structured item text remains underutilized,\nand there is a shortage in the supply of corresponding queries and background\nknowledge. We thereby propose CPRM (Continual Pre-training for Relevance\nModeling), a framework designed for the continual pre-training of LLMs to\naddress these issues. Our CPRM framework includes three modules: 1) employing\nboth queries and multi-field item to jointly pre-train for enhancing domain\nknowledge, 2) applying in-context pre-training, a novel approach where LLMs are\npre-trained on a sequence of related queries or items, and 3) conducting\nreading comprehension on items to produce associated domain knowledge and\nbackground information (e.g., generating summaries and corresponding queries)\nto further strengthen LLMs. Results on offline experiments and online A/B\ntesting demonstrate that our model achieves convincing performance compared to\nstrong baselines.\n","authors":["Kaixin Wu","Yixin Ji","Zeyuan Chen","Qiang Wang","Cunxiang Wang","Hong Liu","Baijun Ji","Jia Xu","Zhongyi Liu","Jinjie Gu","Yuan Zhou","Linjian Mo"],"pdf_url":"https://arxiv.org/pdf/2412.01269v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.05868v1","updated":"2024-12-08T09:20:25Z","published":"2024-12-08T09:20:25Z","title":"Automated Extraction and Creation of FBS Design Reasoning Knowledge\n  Graphs from Structured Data in Product Catalogues Lacking Contextual\n  Information","summary":"  Ontology-based knowledge graphs (KG) are desirable for effective knowledge\nmanagement and reuse in various decision making scenarios, including design.\nCreating and populating extensive KG based on specific ontological models can\nbe highly labour and time-intensive unless automated processes are developed\nfor knowledge extraction and graph creation. Most research and development on\nautomated extraction and creation of KG is based on extensive unstructured data\nsets that provide contextual information. However, some of the most useful\ninformation about the products and services of a company has traditionally been\nrecorded as structured data. Such structured data sets rarely follow a standard\nontology, do not capture explicit mapping of relationships between the\nentities, and provide no contextual information. Therefore, this research\nreports a method and digital workflow developed to address this gap. The\ndeveloped method and workflow employ rule-based techniques to extract and\ncreate a Function Behaviour-Structure (FBS) ontology-based KG from legacy\nstructured data, especially specification sheets and product catalogues. The\nsolution approach consists of two main components: a process for deriving\ncontext and context-based classification rules for FBS ontology concepts and a\nworkflow for populating and retrieving the FBS ontology-based KG. KG and\nNatural Language Processing (NLP) are used to automate knowledge extraction,\nrepresentation, and retrieval. The workflow's effectiveness is demonstrated via\npilot implementation in an industrial context. Insights gained from the pilot\nstudy are reported regarding the challenges and opportunities, including\ndiscussing the FBS ontology and concepts.\n","authors":["Vijayalaxmi Sahadevan","Sushil Mario","Yash Jaiswal","Divyanshu Bajpai","Vishal Singh","Hiralal Aggarwal","Suhas Suresh","Manjunath Maigur"],"pdf_url":"https://arxiv.org/pdf/2412.05868v1.pdf","comment":"31 pages, with 17 figures and 10 tables"},{"id":"http://arxiv.org/abs/2412.00424v2","updated":"2024-12-08T07:07:37Z","published":"2024-11-30T10:30:49Z","title":"FairSort: Learning to Fair Rank for Personalized Recommendations in\n  Two-Sided Platforms","summary":"  Traditional recommendation systems focus on maximizing user satisfaction by\nsuggesting their favourite items. This user-centric approach may lead to unfair\nexposure distribution among the providers. On the contrary, a provider-centric\ndesign might become unfair to the users. Therefore, this paper proposes a\nre-ranking model FairSort to find a trade-off solution among user-side\nfairness, provider-side fairness, and personalized recommendations utility.\nPrevious works habitually treat this issue as a knapsack problem, incorporating\nboth-side fairness as constraints.\n  In this paper, we adopt a novel perspective, treating each recommendation\nlist as a runway rather than a knapsack. In this perspective, each item on the\nrunway gains a velocity and runs within a specific time, achieving re-ranking\nfor both-side fairness. Meanwhile, we ensure the Minimum Utility Guarantee for\npersonalized recommendations by designing a Binary Search approach. This can\nprovide more reliable recommendations compared to the conventional greedy\nstrategy based on the knapsack problem. We further broaden the applicability of\nFairSort, designing two versions for online and offline recommendation\nscenarios. Theoretical analysis and extensive experiments on real-world\ndatasets indicate that FairSort can ensure more reliable personalized\nrecommendations while considering fairness for both the provider and user.\n","authors":["Guoli Wu","Zhiyong Feng","Shizhan Chen","Hongyue Wu","Xiao Xue","Jianmao Xiao","Guodong Fan","Hongqi Chen","Jingyu Li"],"pdf_url":"https://arxiv.org/pdf/2412.00424v2.pdf","comment":null}]," Artificial Intelligence":[{"id":"http://arxiv.org/abs/2412.06099v1","updated":"2024-12-08T23:00:06Z","published":"2024-12-08T23:00:06Z","title":"DECO: Life-Cycle Management of Enterprise-Grade Chatbots","summary":"  Software engineers frequently grapple with the challenge of accessing\ndisparate documentation and telemetry data, including Troubleshooting Guides\n(TSGs), incident reports, code repositories, and various internal tools\ndeveloped by multiple stakeholders. While on-call duties are inevitable,\nincident resolution becomes even more daunting due to the obscurity of legacy\nsources and the pressures of strict time constraints. To enhance the efficiency\nof on-call engineers (OCEs) and streamline their daily workflows, we introduced\nDECO -- a comprehensive framework for developing, deploying, and managing\nenterprise-grade chatbots tailored to improve productivity in engineering\nroutines. This paper details the design and implementation of the DECO\nframework, emphasizing its innovative NL2SearchQuery functionality and a\nhierarchical planner. These features support efficient and customized\nretrieval-augmented-generation (RAG) algorithms that not only extract relevant\ninformation from diverse sources but also select the most pertinent toolkits in\nresponse to user queries. This enables the addressing of complex technical\nquestions and provides seamless, automated access to internal resources.\nAdditionally, DECO incorporates a robust mechanism for converting unstructured\nincident logs into user-friendly, structured guides, effectively bridging the\ndocumentation gap. Feedback from users underscores DECO's pivotal role in\nsimplifying complex engineering tasks, accelerating incident resolution, and\nbolstering organizational productivity. Since its launch in September 2023,\nDECO has demonstrated its effectiveness through extensive engagement, with tens\nof thousands of interactions from hundreds of active users across multiple\norganizations within the company.\n","authors":["Yiwen Zhu","Mathieu Demarne","Kai Deng","Wenjing Wang","Nutan Sahoo","Divya Vermareddy","Hannah Lerner","Yunlei Lu","Swati Bararia","Anjali Bhavan","William Zhang","Xia Li","Katherine Lin","Miso Cilimdzic","Subru Krishnan"],"pdf_url":"https://arxiv.org/pdf/2412.06099v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06097v1","updated":"2024-12-08T22:57:41Z","published":"2024-12-08T22:57:41Z","title":"Order Theory in the Context of Machine Learning: an application","summary":"  The paper ``Tropical Geometry of Deep Neural Networks'' by L. Zhang et al.\nintroduces an equivalence between integer-valued neural networks (IVNN) with\nactivation $\\text{ReLU}_{t}$ and tropical rational functions, which come with a\nmap to polytopes. Here, IVNN refers to a network with integer weights but real\nbiases, and $\\text{ReLU}_{t}$ is defined as $\\text{ReLU}_{t}(x)=\\max(x,t)$ for\n$t\\in\\mathbb{R}\\cup\\{-\\infty\\}$.\n  For every poset with $n$ points, there exists a corresponding order polytope,\ni.e., a convex polytope in the unit cube $[0,1]^n$ whose coordinates obey the\ninequalities of the poset. We study neural networks whose associated polytope\nis an order polytope. We then explain how posets with four points induce neural\nnetworks that can be interpreted as $2\\times 2$ convolutional filters. These\nposet filters can be added to any neural network, not only IVNN.\n  Similarly to maxout, poset convolutional filters update the weights of the\nneural network during backpropagation with more precision than average pooling,\nmax pooling, or mixed pooling, without the need to train extra parameters. We\nreport experiments that support our statements.\n  We also prove that the assignment from a poset to an order polytope (and to\ncertain tropical polynomials) is one to one, and we define the structure of\nalgebra over the operad of posets on tropical polynomials.\n","authors":["Eric Dolores-Cuenca","Aldo Guzman-Saenz","Sangil Kim","Susana Lopez-Moreno","Jose Mendoza-Cortes"],"pdf_url":"https://arxiv.org/pdf/2412.06097v1.pdf","comment":"Poster presentation in NeuroIPS WIML 2024"}]},"2024-12-10T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2410.16780v2","updated":"2024-12-10T18:45:18Z","published":"2024-10-22T07:53:41Z","title":"Beyond Retrieval: Generating Narratives in Conversational Recommender\n  Systems","summary":"  The recent advances in Large Language Model's generation and reasoning\ncapabilities present an opportunity to develop truly conversational\nrecommendation systems. However, effectively integrating recommender system\nknowledge into LLMs for natural language generation which is tailored towards\nrecommendation tasks remains a challenge. This paper addresses this challenge\nby making two key contributions.\n  First, we introduce a new dataset (REGEN) for natural language generation\ntasks in conversational recommendations. REGEN (Reviews Enhanced with\nGEnerative Narratives) extends the Amazon Product Reviews dataset with rich\nuser narratives, including personalized explanations of product preferences,\nproduct endorsements for recommended items, and summaries of user purchase\nhistory. REGEN is made publicly available to facilitate further research.\nFurthermore, we establish benchmarks using well-known generative metrics, and\nperform an automated evaluation of the new dataset using a rater LLM. Second,\nthe paper introduces a fusion architecture (CF model with an LLM) which serves\nas a baseline for REGEN. And to the best of our knowledge, represents the first\nattempt to analyze the capabilities of LLMs in understanding recommender\nsignals and generating rich narratives. We demonstrate that LLMs can\neffectively learn from simple fusion architectures utilizing interaction-based\nCF embeddings, and this can be further enhanced using the metadata and\npersonalization data associated with items. Our experiments show that combining\nCF and content embeddings leads to improvements of 4-12% in key language\nmetrics compared to using either type of embedding individually. We also\nprovide an analysis to interpret how CF and content embeddings contribute to\nthis new generative task.\n","authors":["Krishna Sayana","Raghavendra Vasudeva","Yuri Vasilevski","Kun Su","Liam Hebert","James Pine","Hubert Pham","Ambarish Jash","Sukhdeep Sodhi"],"pdf_url":"https://arxiv.org/pdf/2410.16780v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07743v1","updated":"2024-12-10T18:43:02Z","published":"2024-12-10T18:43:02Z","title":"Zero-Shot ATC Coding with Large Language Models for Clinical Assessments","summary":"  Manual assignment of Anatomical Therapeutic Chemical (ATC) codes to\nprescription records is a significant bottleneck in healthcare research and\noperations at Ontario Health and InterRAI Canada, requiring extensive expert\ntime and effort. To automate this process while maintaining data privacy, we\ndevelop a practical approach using locally deployable large language models\n(LLMs). Inspired by recent advances in automatic International Classification\nof Diseases (ICD) coding, our method frames ATC coding as a hierarchical\ninformation extraction task, guiding LLMs through the ATC ontology level by\nlevel. We evaluate our approach using GPT-4o as an accuracy ceiling and focus\ndevelopment on open-source Llama models suitable for privacy-sensitive\ndeployment. Testing across Health Canada drug product data, the RABBITS\nbenchmark, and real clinical notes from Ontario Health, our method achieves 78%\nexact match accuracy with GPT-4o and 60% with Llama 3.1 70B. We investigate\nknowledge grounding through drug definitions, finding modest improvements in\naccuracy. Further, we show that fine-tuned Llama 3.1 8B matches zero-shot Llama\n3.1 70B accuracy, suggesting that effective ATC coding is feasible with smaller\nmodels. Our results demonstrate the feasibility of automatic ATC coding in\nprivacy-sensitive healthcare environments, providing a foundation for future\ndeployments.\n","authors":["Zijian Chen","John-Michael Gamble","Micaela Jantzi","John P. Hirdes","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2412.07743v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.12253v2","updated":"2024-12-10T18:19:29Z","published":"2024-04-18T15:21:34Z","title":"Toward Self-Improvement of LLMs via Imagination, Searching, and\n  Criticizing","summary":"  Despite the impressive capabilities of Large Language Models (LLMs) on\nvarious tasks, they still struggle with scenarios that involves complex\nreasoning and planning. Recent work proposed advanced prompting techniques and\nthe necessity of fine-tuning with high-quality data to augment LLMs' reasoning\nabilities. However, these approaches are inherently constrained by data\navailability and quality. In light of this, self-correction and self-learning\nemerge as viable solutions, employing strategies that allow LLMs to refine\ntheir outputs and learn from self-assessed rewards. Yet, the efficacy of LLMs\nin self-refining its response, particularly in complex reasoning and planning\ntask, remains dubious. In this paper, we introduce AlphaLLM for the\nself-improvements of LLMs, which integrates Monte Carlo Tree Search (MCTS) with\nLLMs to establish a self-improving loop, thereby enhancing the capabilities of\nLLMs without additional annotations. Drawing inspiration from the success of\nAlphaGo, AlphaLLM addresses the unique challenges of combining MCTS with LLM\nfor self-improvement, including data scarcity, the vastness search spaces of\nlanguage tasks, and the subjective nature of feedback in language tasks.\nAlphaLLM is comprised of prompt synthesis component, an efficient MCTS approach\ntailored for language tasks, and a trio of critic models for precise feedback.\nOur experimental results in mathematical reasoning tasks demonstrate that\nAlphaLLM significantly enhances the performance of LLMs without additional\nannotations, showing the potential for self-improvement in LLMs.\n","authors":["Ye Tian","Baolin Peng","Linfeng Song","Lifeng Jin","Dian Yu","Haitao Mi","Dong Yu"],"pdf_url":"https://arxiv.org/pdf/2404.12253v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2412.07724v1","updated":"2024-12-10T18:17:02Z","published":"2024-12-10T18:17:02Z","title":"Granite Guardian","summary":"  We introduce the Granite Guardian models, a suite of safeguards designed to\nprovide risk detection for prompts and responses, enabling safe and responsible\nuse in combination with any large language model (LLM). These models offer\ncomprehensive coverage across multiple risk dimensions, including social bias,\nprofanity, violence, sexual content, unethical behavior, jailbreaking, and\nhallucination-related risks such as context relevance, groundedness, and answer\nrelevance for retrieval-augmented generation (RAG). Trained on a unique dataset\ncombining human annotations from diverse sources and synthetic data, Granite\nGuardian models address risks typically overlooked by traditional risk\ndetection models, such as jailbreaks and RAG-specific issues. With AUC scores\nof 0.871 and 0.854 on harmful content and RAG-hallucination-related benchmarks\nrespectively, Granite Guardian is the most generalizable and competitive model\navailable in the space. Released as open-source, Granite Guardian aims to\npromote responsible AI development across the community.\n  https://github.com/ibm-granite/granite-guardian\n","authors":["Inkit Padhi","Manish Nagireddy","Giandomenico Cornacchia","Subhajit Chaudhury","Tejaswini Pedapati","Pierre Dognin","Keerthiram Murugesan","Erik Miehling","Martín Santillán Cooper","Kieran Fraser","Giulio Zizzo","Muhammad Zaid Hameed","Mark Purcell","Michael Desmond","Qian Pan","Inge Vejsbjerg","Elizabeth M. Daly","Michael Hind","Werner Geyer","Ambrish Rawat","Kush R. Varshney","Prasanna Sattigeri"],"pdf_url":"https://arxiv.org/pdf/2412.07724v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17413v2","updated":"2024-12-10T17:59:38Z","published":"2024-10-22T20:39:21Z","title":"Scalable Influence and Fact Tracing for Large Language Model Pretraining","summary":"  Training data attribution (TDA) methods aim to attribute model outputs back\nto specific training examples, and the application of these methods to large\nlanguage model (LLM) outputs could significantly advance model transparency and\ndata curation. However, it has been challenging to date to apply these methods\nto the full scale of LLM pretraining. In this paper, we refine existing\ngradient-based methods to work effectively at scale, allowing us to retrieve\ninfluential examples for an 8B-parameter language model from a pretraining\ncorpus of over 160B tokens with no need for subsampling or pre-filtering. Our\nmethod combines several techniques, including optimizer state correction, a\ntask-specific Hessian approximation, and normalized encodings, which we find to\nbe critical for performance at scale. In quantitative evaluations on a fact\ntracing task, our method performs best at identifying examples that influence\nmodel predictions, but classical, model-agnostic retrieval methods such as BM25\nstill perform better at finding passages which explicitly contain relevant\nfacts. These results demonstrate a misalignment between factual *attribution*\nand causal *influence*. With increasing model size and training tokens, we find\nthat influence more closely aligns with factual attribution. Finally, we\nexamine different types of examples identified as influential by our method,\nfinding that while many directly entail a particular fact, others support the\nsame output by reinforcing priors on relation types, common entities, and\nnames. We release our prompt set and model outputs, along with a web-based\nvisualization tool to explore influential examples for factual predictions,\ncommonsense reasoning, arithmetic, and open-ended generation for an\n8B-parameter LLM.\n","authors":["Tyler A. Chang","Dheeraj Rajagopal","Tolga Bolukbasi","Lucas Dixon","Ian Tenney"],"pdf_url":"https://arxiv.org/pdf/2410.17413v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.05821v2","updated":"2024-12-10T17:42:49Z","published":"2024-12-08T05:47:55Z","title":"An Entailment Tree Generation Approach for Multimodal Multi-Hop Question\n  Answering with Mixture-of-Experts and Iterative Feedback Mechanism","summary":"  With the rise of large-scale language models (LLMs), it is currently popular\nand effective to convert multimodal information into text descriptions for\nmultimodal multi-hop question answering. However, we argue that the current\nmethods of multi-modal multi-hop question answering still mainly face two\nchallenges: 1) The retrieved evidence containing a large amount of redundant\ninformation, inevitably leads to a significant drop in performance due to\nirrelevant information misleading the prediction. 2) The reasoning process\nwithout interpretable reasoning steps makes the model difficult to discover the\nlogical errors for handling complex questions. To solve these problems, we\npropose a unified LLMs-based approach but without heavily relying on them due\nto the LLM's potential errors, and innovatively treat multimodal multi-hop\nquestion answering as a joint entailment tree generation and question answering\nproblem. Specifically, we design a multi-task learning framework with a focus\non facilitating common knowledge sharing across interpretability and prediction\ntasks while preventing task-specific errors from interfering with each other\nvia mixture of experts. Afterward, we design an iterative feedback mechanism to\nfurther enhance both tasks by feeding back the results of the joint training to\nthe LLM for regenerating entailment trees, aiming to iteratively refine the\npotential answer. Notably, our method has won the first place in the official\nleaderboard of WebQA (since April 10, 2024), and achieves competitive results\non MultimodalQA.\n","authors":["Qing Zhang","Haocheng Lv","Jie Liu","Zhiyun Chen","Jianyong Duan","Hao Wang","Li He","Mingying Xv"],"pdf_url":"https://arxiv.org/pdf/2412.05821v2.pdf","comment":"Erratum: We identified an error in the calculation of the F1 score in\n  table 4 reported in a previous version of this work. The performance of the\n  new result is better than the previous one. The corrected values are included\n  in this updated version of the paper. These changes do not alter the primary\n  conclusions of our research"},{"id":"http://arxiv.org/abs/2412.07682v1","updated":"2024-12-10T17:13:35Z","published":"2024-12-10T17:13:35Z","title":"TRIM: Token Reduction and Inference Modeling for Cost-Effective Language\n  Generation","summary":"  The inference cost of Large Language Models (LLMs) is a significant challenge\ndue to their computational demands, specially on tasks requiring long outputs.\nHowever, natural language often contains redundancy, which presents an\nopportunity for optimization. We have observed that LLMs can generate distilled\nlanguage-concise outputs that retain essential meaning, when prompted\nappropriately. We propose a framework for saving computational cost, in which a\nshorter distilled output from the LLM is reconstructed into a full narrative by\na smaller model with lower inference costs. Our experiments show promising\nresults, particularly in general knowledge domains with 20.58% saved tokens on\naverage with tiny decrease in evaluation metrics, hinting that this approach\ncan effectively balance efficiency and accuracy in language processing tasks.\n","authors":["Alfredo Garrachón Ruiz","Tomás de la Rosa","Daniel Borrajo"],"pdf_url":"https://arxiv.org/pdf/2412.07682v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2412.07678v1","updated":"2024-12-10T17:06:33Z","published":"2024-12-10T17:06:33Z","title":"Can linguists better understand DNA?","summary":"  Multilingual transfer ability, which reflects how well models fine-tuned on\none source language can be applied to other languages, has been well studied in\nmultilingual pre-trained models. However, the existence of such capability\ntransfer between natural language and gene sequences/languages remains\nunderexplored.This study addresses this gap by drawing inspiration from the\nsentence-pair classification task used for evaluating sentence similarity in\nnatural language. We constructed two analogous tasks: DNA-pair\nclassification(DNA sequence similarity) and DNA-protein-pair\nclassification(gene coding determination). These tasks were designed to\nvalidate the transferability of capabilities from natural language to gene\nsequences. Even a small-scale pre-trained model like GPT-2-small, which was\npre-trained on English, achieved an accuracy of 78% on the DNA-pair\nclassification task after being fine-tuned on English sentence-pair\nclassification data(XTREME PAWS-X). While training a BERT model on multilingual\ntext, the precision reached 82%.On the more complex DNA-protein-pair\nclassification task, however, the model's output was barely distinguishable\nfrom random output.Experiments suggest that there may be a capability transfer\nfrom natural language to genetic language, but further task testing is needed\nto confirm this.\n","authors":["Wang Liang"],"pdf_url":"https://arxiv.org/pdf/2412.07678v1.pdf","comment":"11 pages,3 figures"},{"id":"http://arxiv.org/abs/2412.07675v1","updated":"2024-12-10T17:02:58Z","published":"2024-12-10T17:02:58Z","title":"RAZOR: Sharpening Knowledge by Cutting Bias with Unsupervised Text\n  Rewriting","summary":"  Despite the widespread use of LLMs due to their superior performance in\nvarious tasks, their high computational costs often lead potential users to opt\nfor the pretraining-finetuning pipeline. However, biases prevalent in manually\nconstructed datasets can introduce spurious correlations between tokens and\nlabels, creating so-called shortcuts and hindering the generalizability of\nfine-tuned models. Existing debiasing methods often rely on prior knowledge of\nspecific dataset biases, which is challenging to acquire a priori. We propose\nRAZOR (Rewriting And Zero-bias Optimization Refinement), a novel, unsupervised,\nand data-focused debiasing approach based on text rewriting for shortcut\nmitigation. RAZOR leverages LLMs to iteratively rewrite potentially biased text\nsegments by replacing them with heuristically selected alternatives in a\nshortcut space defined by token statistics and positional information. This\nprocess aims to align surface-level text features more closely with diverse\nlabel distributions, thereby promoting the learning of genuine linguistic\npatterns. Compared with unsupervised SoTA models, RAZOR improves by 3.5% on the\nFEVER and 6.5% on MNLI and SNLI datasets according to the F1 score.\nAdditionally, RAZOR effectively mitigates specific known biases, reducing\nbias-related terms by x2 without requiring prior bias information, a result\nthat is on par with SoTA models that leverage prior information. Our work\nprioritizes data manipulation over architectural modifications, emphasizing the\npivotal role of data quality in enhancing model performance and fairness. This\nresearch contributes to developing more robust evaluation benchmarks for\ndebiasing methods by incorporating metrics for bias reduction and overall model\nefficacy.\n","authors":["Shuo Yang","Bardh Prenkaj","Gjergji Kasneci"],"pdf_url":"https://arxiv.org/pdf/2412.07675v1.pdf","comment":"Shuo and Bardh contributed equally. Accepted to AAAI'25"},{"id":"http://arxiv.org/abs/2412.07672v1","updated":"2024-12-10T17:02:28Z","published":"2024-12-10T17:02:28Z","title":"FlexLLM: Exploring LLM Customization for Moving Target Defense on\n  Black-Box LLMs Against Jailbreak Attacks","summary":"  Defense in large language models (LLMs) is crucial to counter the numerous\nattackers exploiting these systems to generate harmful content through\nmanipulated prompts, known as jailbreak attacks. Although many defense\nstrategies have been proposed, they often require access to the model's\ninternal structure or need additional training, which is impractical for\nservice providers using LLM APIs, such as OpenAI APIs or Claude APIs. In this\npaper, we propose a moving target defense approach that alters decoding\nhyperparameters to enhance model robustness against various jailbreak attacks.\nOur approach does not require access to the model's internal structure and\nincurs no additional training costs. The proposed defense includes two key\ncomponents: (1) optimizing the decoding strategy by identifying and adjusting\ndecoding hyperparameters that influence token generation probabilities, and (2)\ntransforming the decoding hyperparameters and model system prompts into dynamic\ntargets, which are continuously altered during each runtime. By continuously\nmodifying decoding strategies and prompts, the defense effectively mitigates\nthe existing attacks. Our results demonstrate that our defense is the most\neffective against jailbreak attacks in three of the models tested when using\nLLMs as black-box APIs. Moreover, our defense offers lower inference costs and\nmaintains comparable response quality, making it a potential layer of\nprotection when used alongside other defense methods.\n","authors":["Bocheng Chen","Hanqing Guo","Qiben Yan"],"pdf_url":"https://arxiv.org/pdf/2412.07672v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07646v1","updated":"2024-12-10T16:32:19Z","published":"2024-12-10T16:32:19Z","title":"Searching for Structure: Investigating Emergent Communication with Large\n  Language Models","summary":"  Human languages have evolved to be structured through repeated language\nlearning and use. These processes introduce biases that operate during language\nacquisition and shape linguistic systems toward communicative efficiency. In\nthis paper, we investigate whether the same happens if artificial languages are\noptimised for implicit biases of Large Language Models (LLMs). To this end, we\nsimulate a classical referential game in which LLMs learn and use artificial\nlanguages. Our results show that initially unstructured holistic languages are\nindeed shaped to have some structural properties that allow two LLM agents to\ncommunicate successfully. Similar to observations in human experiments,\ngenerational transmission increases the learnability of languages, but can at\nthe same time result in non-humanlike degenerate vocabularies. Taken together,\nthis work extends experimental findings, shows that LLMs can be used as tools\nin simulations of language evolution, and opens possibilities for future\nhuman-machine experiments in this field.\n","authors":["Tom Kouwenhoven","Max Peeperkorn","Tessa Verhoef"],"pdf_url":"https://arxiv.org/pdf/2412.07646v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07633v1","updated":"2024-12-10T16:13:58Z","published":"2024-12-10T16:13:58Z","title":"ChocoLlama: Lessons Learned From Teaching Llamas Dutch","summary":"  While Large Language Models (LLMs) have shown remarkable capabilities in\nnatural language understanding and generation, their performance often lags in\nlower-resource, non-English languages due to biases in the training data. In\nthis work, we explore strategies for adapting the primarily English LLMs\n(Llama-2 and Llama-3) to Dutch, a language spoken by 30 million people\nworldwide yet often underrepresented in LLM development. We collect 104GB of\nDutch text ($32$B tokens) from various sources to first apply continued\npretraining using low-rank adaptation (LoRA), complemented with Dutch\nposttraining strategies provided by prior work. For Llama-2, we consider using\n(i) the tokenizer of the original model, and (ii) training a new,\nDutch-specific tokenizer combined with embedding reinitialization. We evaluate\nour adapted models, ChocoLlama-2, both on standard benchmarks and a novel Dutch\nbenchmark, ChocoLlama-Bench. Our results demonstrate that LoRA can effectively\nscale for language adaptation, and that tokenizer modification with careful\nweight reinitialization can improve performance. Notably, Llama-3 was released\nduring the course of this project and, upon evaluation, demonstrated superior\nDutch capabilities compared to our Dutch-adapted versions of Llama-2. We hence\napply the same adaptation technique to Llama-3, using its original tokenizer.\nWhile our adaptation methods enhanced Llama-2's Dutch capabilities, we found\nlimited gains when applying the same techniques to Llama-3. This suggests that\nfor ever improving, multilingual foundation models, language adaptation\ntechniques may benefit more from focusing on language-specific posttraining\nrather than on continued pretraining. We hope this work contributes to the\nbroader understanding of adapting LLMs to lower-resource languages, and to the\ndevelopment of Dutch LLMs in particular.\n","authors":["Matthieu Meeus","Anthony Rathé","François Remy","Pieter Delobelle","Jens-Joris Decorte","Thomas Demeester"],"pdf_url":"https://arxiv.org/pdf/2412.07633v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07629v1","updated":"2024-12-10T16:08:14Z","published":"2024-12-10T16:08:14Z","title":"Piece of Table: A Divide-and-Conquer Approach for Selecting Sub-Tables\n  in Table Question Answering","summary":"  Applying language models (LMs) to tables is challenging due to the inherent\nstructural differences between two-dimensional tables and one-dimensional text\nfor which the LMs were originally designed. Furthermore, when applying\nlinearized tables to LMs, the maximum token lengths often imposed in\nself-attention calculations make it difficult to comprehensively understand the\ncontext spread across large tables. To address these challenges, we present\nPieTa (Piece of Table), a new framework for sub-table-based question answering\n(QA). PieTa operates through an iterative process of dividing tables into\nsmaller windows, using LMs to select relevant cells within each window, and\nmerging these cells into a sub-table. This multi-resolution approach captures\ndependencies across multiple rows and columns while avoiding the limitations\ncaused by long context inputs. Instantiated as a simple iterative sub-table\nunion algorithm, PieTa demonstrates improved performance over previous\nsub-table-based QA approaches.\n","authors":["Wonjin Lee","Kyumin Kim","Sungjae Lee","Jihun Lee","Kwang In KIm"],"pdf_url":"https://arxiv.org/pdf/2412.07629v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07619v1","updated":"2024-12-10T15:56:12Z","published":"2024-12-10T15:56:12Z","title":"DRUM: Learning Demonstration Retriever for Large MUlti-modal Models","summary":"  Recently, large language models (LLMs) have demonstrated impressive\ncapabilities in dealing with new tasks with the help of in-context learning\n(ICL). In the study of Large Vision-Language Models (LVLMs), when implementing\nICL, researchers usually adopts the naive strategies like fixed demonstrations\nacross different samples, or selecting demonstrations directly via a\nvisual-language embedding model. These methods does not guarantee the\nconfigured demonstrations fit the need of the LVLMs. To address this issue, we\nnow propose a novel framework, \\underline{d}emonstration \\underline{r}etriever\nfor large m\\underline{u}lti-modal \\underline{m}odel (DRUM), which fine-tunes\nthe visual-language embedding model to better meet the LVLM's needs. First, we\ndiscuss the retrieval strategies for a visual-language task, assuming an\nembedding model is given. And we propose to concate the image and text\nembeddings to enhance the retrieval performance. Second, we propose to re-rank\nthe demonstrations retrieved by the embedding model via the LVLM's feedbacks,\nand calculate a list-wise ranking loss for training the embedding model. Third,\nwe propose an iterative demonstration mining strategy to improve the training\nof the embedding model. Through extensive experiments on 3 types of\nvisual-language tasks, 7 benchmark datasets, our DRUM framework is proven to be\neffective in boosting the LVLM's in-context learning performance via retrieving\nmore proper demonstrations.\n","authors":["Ellen Yi-Ge","Jiechao Gao","Wei Han","Wei Zhu"],"pdf_url":"https://arxiv.org/pdf/2412.07619v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07618v1","updated":"2024-12-10T15:56:03Z","published":"2024-12-10T15:56:03Z","title":"Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced\n  Retrieval-Augmented Generation on Knowledge Graphs","summary":"  Despite the superior performance of Large language models on many NLP tasks,\nthey still face significant limitations in memorizing extensive world\nknowledge. Recent studies have demonstrated that leveraging the\nRetrieval-Augmented Generation (RAG) framework, combined with Knowledge Graphs\nthat encapsulate extensive factual data in a structured format, robustly\nenhances the reasoning capabilities of LLMs. However, deploying such systems in\nreal-world scenarios presents challenges: the continuous evolution of\nnon-stationary environments may lead to performance degradation and user\nsatisfaction requires a careful balance of performance and responsiveness. To\naddress these challenges, we introduce a Multi-objective Multi-Armed Bandit\nenhanced RAG framework, supported by multiple retrieval methods with diverse\ncapabilities under rich and evolving retrieval contexts in practice. Within\nthis framework, each retrieval method is treated as a distinct ``arm''. The\nsystem utilizes real-time user feedback to adapt to dynamic environments, by\nselecting the appropriate retrieval method based on input queries and the\nhistorical multi-objective performance of each arm. Extensive experiments\nconducted on two benchmark KGQA datasets demonstrate that our method\nsignificantly outperforms baseline methods in non-stationary settings while\nachieving state-of-the-art performance in stationary environments. Code and\ndata are available at https://github.com/FUTUREEEEEE/Dynamic-RAG.git\n","authors":["Xiaqiang Tang","Jian Li","Nan Du","Sihong Xie"],"pdf_url":"https://arxiv.org/pdf/2412.07618v1.pdf","comment":"AAAI 2025"},{"id":"http://arxiv.org/abs/2410.14875v2","updated":"2024-12-10T15:44:59Z","published":"2024-10-18T21:42:37Z","title":"Which LLMs are Difficult to Detect? A Detailed Analysis of Potential\n  Factors Contributing to Difficulties in LLM Text Detection","summary":"  As LLMs increase in accessibility, LLM-generated texts have proliferated\nacross several fields, such as scientific, academic, and creative writing.\nHowever, LLMs are not created equally; they may have different architectures\nand training datasets. Thus, some LLMs may be more challenging to detect than\nothers. Using two datasets spanning four total writing domains, we train\nAI-generated (AIG) text classifiers using the LibAUC library - a deep learning\nlibrary for training classifiers with imbalanced datasets. Our results in the\nDeepfake Text dataset show that AIG-text detection varies across domains, with\nscientific writing being relatively challenging. In the Rewritten Ivy Panda\n(RIP) dataset focusing on student essays, we find that the OpenAI family of\nLLMs was substantially difficult for our classifiers to distinguish from human\ntexts. Additionally, we explore possible factors that could explain the\ndifficulties in detecting OpenAI-generated texts.\n","authors":["Shantanu Thorat","Tianbao Yang"],"pdf_url":"https://arxiv.org/pdf/2410.14875v2.pdf","comment":"Accepted at NeurIPS 2024 - Safe Generative AI Workshop; Camera-ready\n  version"},{"id":"http://arxiv.org/abs/2412.07573v1","updated":"2024-12-10T15:06:48Z","published":"2024-12-10T15:06:48Z","title":"SST framework for Document Matching","summary":"  Long-form document matching aims to judge the relevance between two documents\nand has been applied to various scenarios. Most existing works utilize\nhierarchical or long context models to process documents, which achieve coarse\nunderstanding but may ignore details. Some researchers construct a document\nview with similar sentences about aligned document subtopics to focus on\ndetailed matching signals. However, a long document generally contains multiple\nsubtopics. The matching signals are heterogeneous from multiple topics.\nConsidering only the homologous aligned subtopics may not be representative\nenough and may cause biased modeling. In this paper, we introduce a new\nframework to model representative matching signals. First, we propose to\ncapture various matching signals through subtopics of document pairs. Next, We\nconstruct multiple document views based on subtopics to cover heterogeneous and\nvaluable details. However, existing spatial aggregation methods like attention,\nwhich integrate all these views simultaneously, are hard to integrate\nheterogeneous information. Instead, we propose temporal aggregation, which\neffectively integrates different views gradually as the training progresses.\nExperimental results show that our learning framework is effective on several\ndocument-matching tasks, including news duplication and legal case retrieval.\n","authors":["Youchao Zhou","Heyan Huang","Zhijing Wu","Yuhang Liu","Xinglin Wang"],"pdf_url":"https://arxiv.org/pdf/2412.07573v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.13925v2","updated":"2024-12-10T14:46:40Z","published":"2024-06-20T01:45:44Z","title":"GenderAlign: An Alignment Dataset for Mitigating Gender Bias in Large\n  Language Models","summary":"  Large Language Models (LLMs) are prone to generating content that exhibits\ngender biases, raising significant ethical concerns. Alignment, the process of\nfine-tuning LLMs to better align with desired behaviors, is recognized as an\neffective approach to mitigate gender biases. Although proprietary LLMs have\nmade significant strides in mitigating gender bias, their alignment datasets\nare not publicly available. The commonly used and publicly available alignment\ndataset, HH-RLHF, still exhibits gender bias to some extent. There is a lack of\npublicly available alignment datasets specifically designed to address gender\nbias. Hence, we developed a new dataset named GenderAlign, aiming at mitigating\na comprehensive set of gender biases in LLMs. This dataset comprises 8k\nsingle-turn dialogues, each paired with a \"chosen\" and a \"rejected\" response.\nCompared to the \"rejected\" responses, the \"chosen\" responses demonstrate lower\nlevels of gender bias and higher quality. Furthermore, we categorized the\ngender biases in the \"rejected\" responses of GenderAlign into 4 principal\ncategories. The experimental results show the effectiveness of GenderAlign in\nreducing gender bias in LLMs.\n","authors":["Tao Zhang","Ziqian Zeng","Yuxiang Xiao","Huiping Zhuang","Cen Chen","James Foulds","Shimei Pan"],"pdf_url":"https://arxiv.org/pdf/2406.13925v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.10212v3","updated":"2024-12-10T14:44:41Z","published":"2024-05-16T16:02:18Z","title":"CPsyExam: A Chinese Benchmark for Evaluating Psychology using\n  Examinations","summary":"  In this paper, we introduce a novel psychological benchmark, CPsyExam,\nconstructed from questions sourced from Chinese language examinations. CPsyExam\nis designed to prioritize psychological knowledge and case analysis separately,\nrecognizing the significance of applying psychological knowledge to real-world\nscenarios. From the pool of 22k questions, we utilize 4k to create the\nbenchmark that offers balanced coverage of subjects and incorporates a diverse\nrange of case analysis techniques.Furthermore, we evaluate a range of existing\nlarge language models~(LLMs), spanning from open-sourced to API-based models.\nOur experiments and analysis demonstrate that CPsyExam serves as an effective\nbenchmark for enhancing the understanding of psychology within LLMs and enables\nthe comparison of LLMs across various granularities.\n","authors":["Jiahao Zhao","Jingwei Zhu","Minghuan Tan","Min Yang","Renhao Li","Di Yang","Chenhao Zhang","Guancheng Ye","Chengming Li","Xiping Hu","Derek F. Wong"],"pdf_url":"https://arxiv.org/pdf/2405.10212v3.pdf","comment":"To appear in COLING 2025"},{"id":"http://arxiv.org/abs/2409.09269v2","updated":"2024-12-10T14:43:03Z","published":"2024-09-14T02:29:36Z","title":"Guiding Vision-Language Model Selection for Visual Question-Answering\n  Across Tasks, Domains, and Knowledge Types","summary":"  Visual Question-Answering (VQA) has become key to user experience,\nparticularly after improved generalization capabilities of Vision-Language\nModels (VLMs). But evaluating VLMs for an application requirement using a\nstandardized framework in practical settings is still challenging. This paper\naims to solve that using an end-to-end framework. We present VQA360 - a novel\ndataset derived from established VQA benchmarks, annotated with task types,\napplication domains, and knowledge types, for a comprehensive evaluation. We\nalso introduce GoEval, a multimodal evaluation metric developed using GPT-4o,\nachieving a correlation factor of 56.71% with human judgments. Our experiments\nwith state-of-the-art VLMs reveal that no single model excels universally,\nthus, making a right choice a key design decision. Proprietary models such as\nGemini-1.5-Pro and GPT-4o-mini generally outperform others, but open-source\nmodels like InternVL-2-8B and CogVLM-2-Llama-3-19B also demonstrate competitive\nstrengths, while providing additional advantages. Our framework can also be\nextended to other tasks.\n","authors":["Neelabh Sinha","Vinija Jain","Aman Chadha"],"pdf_url":"https://arxiv.org/pdf/2409.09269v2.pdf","comment":"8 pages + references + 6 pages of Appendix"},{"id":"http://arxiv.org/abs/2406.14099v3","updated":"2024-12-10T14:05:31Z","published":"2024-06-20T08:24:57Z","title":"Let Guidelines Guide You: A Prescriptive Guideline-Centered Data\n  Annotation Methodology","summary":"  We introduce the Guideline-Centered Annotation Methodology (GCAM), a novel\ndata annotation methodology designed to report the annotation guidelines\nassociated with each data sample. Our approach addresses three key limitations\nof the standard prescriptive annotation methodology by reducing the information\nloss during annotation and ensuring adherence to guidelines. Furthermore, GCAM\nenables the efficient reuse of annotated data across multiple tasks. We\nevaluate GCAM in two ways: (i) through a human annotation study and (ii) an\nexperimental evaluation with several machine learning models. Our results\nhighlight the advantages of GCAM from multiple perspectives, demonstrating its\npotential to improve annotation quality and error analysis.\n","authors":["Federico Ruggeri","Eleonora Misino","Arianna Muti","Katerina Korre","Paolo Torroni","Alberto Barrón-Cedeño"],"pdf_url":"https://arxiv.org/pdf/2406.14099v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16714v2","updated":"2024-12-10T13:57:46Z","published":"2024-06-24T15:16:45Z","title":"AutoDetect: Towards a Unified Framework for Automated Weakness Detection\n  in Large Language Models","summary":"  Although Large Language Models (LLMs) are becoming increasingly powerful,\nthey still exhibit significant but subtle weaknesses, such as mistakes in\ninstruction-following or coding tasks. As these unexpected errors could lead to\nsevere consequences in practical deployments, it is crucial to investigate the\nlimitations within LLMs systematically. Traditional benchmarking approaches\ncannot thoroughly pinpoint specific model deficiencies, while manual\ninspections are costly and not scalable. In this paper, we introduce a unified\nframework, AutoDetect, to automatically expose weaknesses in LLMs across\nvarious tasks. Inspired by the educational assessment process that measures\nstudents' learning outcomes, AutoDetect consists of three LLM-powered agents:\nExaminer, Questioner, and Assessor. The collaboration among these three agents\nis designed to realize comprehensive and in-depth weakness identification. Our\nframework demonstrates significant success in uncovering flaws, with an\nidentification success rate exceeding 30% in prominent models such as ChatGPT\nand Claude. More importantly, these identified weaknesses can guide specific\nmodel improvements, proving more effective than untargeted data augmentation\nmethods like Self-Instruct. Our approach has led to substantial enhancements in\npopular LLMs, including the Llama series and Mistral-7b, boosting their\nperformance by over 10% across several benchmarks. Code and data are publicly\navailable at https://github.com/thu-coai/AutoDetect.\n","authors":["Jiale Cheng","Yida Lu","Xiaotao Gu","Pei Ke","Xiao Liu","Yuxiao Dong","Hongning Wang","Jie Tang","Minlie Huang"],"pdf_url":"https://arxiv.org/pdf/2406.16714v2.pdf","comment":"EMNLP 2024 findings"},{"id":"http://arxiv.org/abs/2412.07515v1","updated":"2024-12-10T13:51:55Z","published":"2024-12-10T13:51:55Z","title":"CoPrUS: Consistency Preserving Utterance Synthesis towards more\n  realistic benchmark dialogues","summary":"  Large-scale Wizard-Of-Oz dialogue datasets have enabled the training of deep\nlearning-based dialogue systems. While they are successful as benchmark\ndatasets, they lack certain types of utterances, which would make them more\nrealistic. In this work, we investigate the creation of synthetic communication\nerrors in an automatic pipeline. Based on linguistic theory, we propose and\nfollow a simple error taxonomy. We focus on three types of miscommunications\nthat could happen in real-world dialogues but are underrepresented in the\nbenchmark dataset: misunderstandings, non-understandings and vaguely related\nquestions. Our two-step approach uses a state-of-the-art Large Language Model\n(LLM) to first create the error and secondly the repairing utterance. We\nperform Language Model-based evaluation to ensure the quality of the generated\nutterances. We apply the method to the MultiWOZ dataset and evaluate it both\nqualitatively and empirically as well as with human judges. Our results\nindicate that current LLMs can aid in adding post-hoc miscommunications to\nbenchmark datasets as a form of data augmentation. We publish the resulting\ndataset, in which nearly 1900 dialogues have been modified, as CoPrUS-MultiWOZ\nto facilitate future work on dialogue systems.\n","authors":["Sebastian Steindl","Ulrich Schäfer","Bernd Ludwig"],"pdf_url":"https://arxiv.org/pdf/2412.07515v1.pdf","comment":"Accepted at COLING 2025 (main, long paper)"},{"id":"http://arxiv.org/abs/2410.10879v2","updated":"2024-12-10T13:00:22Z","published":"2024-10-09T11:54:41Z","title":"Enhancing Vision-Language Model Pre-training with Image-text Pair\n  Pruning Based on Word Frequency","summary":"  We propose Word-Frequency-based Image-Text Pair Pruning (WFPP), a novel data\npruning method that improves the efficiency of VLMs. Unlike MetaCLIP, our\nmethod does not need metadata for pruning, but selects text-image pairs to\nprune based on the content of the text. Specifically, WFPP prunes text-image\npairs containing high-frequency words across the entire training dataset. The\neffect of WFPP is to reduce the dominance of frequent words. The result a\nbetter balanced word-frequency distribution in the dataset, which is known to\nimprove the training of word embedding models. After pre-training on the pruned\nsubset, we fine-tuned the model on the entire dataset for one additional epoch\nto achieve better performance. Our experiments demonstrate that applying WFPP\nwhen training a CLIP model improves performance on a wide range of downstream\ntasks. WFPP also provides the advantage of speeding up pre-training by using\nfewer samples. Additionally, we analyze the training data before and after\npruning to visualize how WFPP changes the balance of word frequencies. We hope\nour work encourages researchers to consider the distribution of words in the\ntraining data when pre-training VLMs, not limited to CLIP.\n","authors":["Mingliang Liang","Martha Larson"],"pdf_url":"https://arxiv.org/pdf/2410.10879v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19892v3","updated":"2024-12-10T12:46:39Z","published":"2024-06-28T13:00:30Z","title":"Automatic register identification for the open web using multilingual\n  deep learning","summary":"  This article investigates how well deep learning models can identify web\nregisters -- text varieties such as news reports and discussion forums --\nacross 16 languages. We introduce the Multilingual CORE corpora, which contain\n72,504 documents annotated with a hierarchical taxonomy of 25 registers\ndesigned to cover the entire open web. Our multilingual models achieve\nstate-of-the-art results (79% F1 score) using multi-label classification. This\nperformance matches or exceeds previous studies that used simpler\nclassification schemes, showing that models can perform well even with a\ncomplex register scheme at a massively multilingual scale. However, we observe\na consistent performance ceiling around 77-80% F1 score across all models and\nconfigurations. When we remove documents with uncertain labels through data\npruning, performance increases to over 90% F1, suggesting that this ceiling\nstems from inherent ambiguity in web registers rather than model limitations.\nAnalysis of hybrid documents -- texts combining multiple registers -- reveals\nthat the main challenge is not in classifying hybrids themselves, but in\ndistinguishing between hybrid and non-hybrid documents. Multilingual models\nconsistently outperform monolingual ones, particularly helping languages with\nlimited training data. While zero-shot performance drops by an average of 7% on\nunseen languages, this decrease varies substantially between languages (from 3%\nto 20%), indicating that while registers share many features across languages,\nthey also maintain language-specific characteristics.\n","authors":["Erik Henriksson","Amanda Myntti","Saara Hellström","Anni Eskelinen","Selcen Erten-Johansson","Veronika Laippala"],"pdf_url":"https://arxiv.org/pdf/2406.19892v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06720v2","updated":"2024-12-10T12:41:25Z","published":"2024-12-09T18:06:39Z","title":"VP-MEL: Visual Prompts Guided Multimodal Entity Linking","summary":"  Multimodal Entity Linking (MEL) is extensively utilized in the domains of\ninformation retrieval. However, existing MEL methods typically utilize mention\nwords as mentions for retrieval. This results in a significant dependence of\nMEL on mention words, thereby constraining its capacity to effectively leverage\ninformation from both images and text. In situations where mention words are\nabsent, MEL methods struggle to leverage image-text pairs for entity linking.\nTo solve these issues, we introduce a Visual Prompts guided Multimodal Entity\nLinking (VP-MEL) task. VP-MEL directly marks specific regions within the image.\nThese markers are referred to as visual prompts in VP-MEL. Without mention\nwords, VP-MEL aims to utilize marked image-text pairs to align visual prompts\nwith specific entities in the knowledge bases. A new dataset for the VP-MEL\ntask, VPWiki, is proposed in this paper. Moreover, we propose a framework named\nFBMEL, which enhances the significance of visual prompts and fully leverages\nthe information in image-text pairs. Experimental results on the VPWiki dataset\ndemonstrate that FBMEL outperforms baseline methods across multiple benchmarks\nfor the VP-MEL task.\n","authors":["Hongze Mi","Jinyuan Li","Xuying Zhang","Haoran Cheng","Jiahao Wang","Di Sun","Gang Pan"],"pdf_url":"https://arxiv.org/pdf/2412.06720v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07462v1","updated":"2024-12-10T12:31:33Z","published":"2024-12-10T12:31:33Z","title":"Bilingual BSARD: Extending Statutory Article Retrieval to Dutch","summary":"  Statutory article retrieval plays a crucial role in making legal information\nmore accessible to both laypeople and legal professionals. Multilingual\ncountries like Belgium present unique challenges for retrieval models due to\nthe need for handling legal issues in multiple languages. Building on the\nBelgian Statutory Article Retrieval Dataset (BSARD) in French, we introduce the\nbilingual version of this dataset, bBSARD. The dataset contains parallel\nBelgian statutory articles in both French and Dutch, along with legal questions\nfrom BSARD and their Dutch translation. Using bBSARD, we conduct extensive\nbenchmarking of retrieval models available for Dutch and French. Our\nbenchmarking setup includes lexical models, zero-shot dense models, and\nfine-tuned small foundation models. Our experiments show that BM25 remains a\ncompetitive baseline compared to many zero-shot dense models in both languages.\nWe also observe that while proprietary models outperform open alternatives in\nthe zero-shot setting, they can be matched or surpassed by fine-tuning small\nlanguage-specific models. Our dataset and evaluation code are publicly\navailable.\n","authors":["Ehsan Lotfi","Nikolay Banar","Nerses Yuzbashyan","Walter Daelemans"],"pdf_url":"https://arxiv.org/pdf/2412.07462v1.pdf","comment":"To be presented at RegNLP-2025 (COLING)"},{"id":"http://arxiv.org/abs/2412.07446v1","updated":"2024-12-10T12:05:03Z","published":"2024-12-10T12:05:03Z","title":"Causal World Representation in the GPT Model","summary":"  Are generative pre-trained transformer (GPT) models only trained to predict\nthe next token, or do they implicitly learn a world model from which a sequence\nis generated one token at a time? We examine this question by deriving a causal\ninterpretation of the attention mechanism in GPT, and suggesting a causal world\nmodel that arises from this interpretation. Furthermore, we propose that\nGPT-models, at inference time, can be utilized for zero-shot causal structure\nlearning for in-distribution sequences. Empirical evaluation is conducted in a\ncontrolled synthetic environment using the setup and rules of the Othello board\ngame. A GPT, pre-trained on real-world games played with the intention of\nwinning, is tested on synthetic data that only adheres to the game rules. We\nfind that the GPT model tends to generate next moves that adhere to the game\nrules for sequences for which the attention mechanism encodes a causal\nstructure with high confidence. In general, in cases for which the GPT model\ngenerates moves that do not adhere to the game rules, it also fails to capture\nany causal structure.\n","authors":["Raanan Y. Rohekar","Yaniv Gurwicz","Sungduk Yu","Vasudev Lal"],"pdf_url":"https://arxiv.org/pdf/2412.07446v1.pdf","comment":"NeurIPS 2024 Workshop on Causality and Large Models (CaLM)"},{"id":"http://arxiv.org/abs/2410.17520v2","updated":"2024-12-10T11:56:09Z","published":"2024-10-23T02:51:43Z","title":"MobileSafetyBench: Evaluating Safety of Autonomous Agents in Mobile\n  Device Control","summary":"  Autonomous agents powered by large language models (LLMs) show promising\npotential in assistive tasks across various domains, including mobile device\ncontrol. As these agents interact directly with personal information and device\nsettings, ensuring their safe and reliable behavior is crucial to prevent\nundesirable outcomes. However, no benchmark exists for standardized evaluation\nof the safety of mobile device-control agents. In this work, we introduce\nMobileSafetyBench, a benchmark designed to evaluate the safety of\ndevice-control agents within a realistic mobile environment based on Android\nemulators. We develop a diverse set of tasks involving interactions with\nvarious mobile applications, including messaging and banking applications,\nchallenging agents with managing risks encompassing misuse and negative side\neffects. These tasks include tests to evaluate the safety of agents in daily\nscenarios as well as their robustness against indirect prompt injection\nattacks. Our experiments demonstrate that baseline agents, based on\nstate-of-the-art LLMs, often fail to effectively prevent harm while performing\nthe tasks. To mitigate these safety concerns, we propose a prompting method\nthat encourages agents to prioritize safety considerations. While this method\nshows promise in promoting safer behaviors, there is still considerable room\nfor improvement to fully earn user trust. This highlights the urgent need for\ncontinued research to develop more robust safety mechanisms in mobile\nenvironments. We open-source our benchmark at:\nhttps://mobilesafetybench.github.io/.\n","authors":["Juyong Lee","Dongyoon Hahm","June Suk Choi","W. Bradley Knox","Kimin Lee"],"pdf_url":"https://arxiv.org/pdf/2410.17520v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07430v1","updated":"2024-12-10T11:40:47Z","published":"2024-12-10T11:40:47Z","title":"Knowledge Graph Guided Evaluation of Abstention Techniques","summary":"  To deploy language models safely, it is crucial that they abstain from\nresponding to inappropriate requests. Several prior studies test the safety\npromises of models based on their effectiveness in blocking malicious requests.\nIn this work, we focus on evaluating the underlying techniques that cause\nmodels to abstain. We create SELECT, a benchmark derived from a set of benign\nconcepts (e.g., \"rivers\") from a knowledge graph. The nature of SELECT enables\nus to isolate the effects of abstention techniques from other safety training\nprocedures, as well as evaluate their generalization and specificity. Using\nSELECT, we benchmark different abstention techniques over six open-weight and\nclosed-source models. We find that the examined techniques indeed cause models\nto abstain with over $80\\%$ abstention rates. However, these techniques are not\nas effective for descendants of the target concepts, with refusal rates\ndeclining by $19\\%$. We also characterize the generalization-vs-specificity\ntrade-offs for different techniques. Overall, no single technique is invariably\nbetter than the others. Our findings call for a careful evaluation of different\naspects of abstention, and hopefully inform practitioners of various trade-offs\ninvolved.\n","authors":["Kinshuk Vasisht","Navreet Kaur","Danish Pruthi"],"pdf_url":"https://arxiv.org/pdf/2412.07430v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07429v1","updated":"2024-12-10T11:40:11Z","published":"2024-12-10T11:40:11Z","title":"Optimizing Alignment with Less: Leveraging Data Augmentation for\n  Personalized Evaluation","summary":"  Automatic evaluation by large language models (LLMs) is a prominent topic\ntoday; however, judgment and evaluation tasks are often subjective and\ninfluenced by various factors, making adaptation challenging. While many\nstudies demonstrate the capabilities of state-of-the-art proprietary LLMs in\ncomparison to human evaluators, they often struggle to adapt to reference\nevaluators over time, a requirement for achieving personalized judgment.\nAdditionally, numerous works have attempted to apply open LLMs as judges or\nevaluators, but these efforts frequently overlook the limitations of working\nwith scarce data. Personalized judgment is inherently associated with limited\ndata scenarios, which are common in many real-world problems. Our work aims to\npresent a data augmentation technique to select a more effective sample from\nlimited data in order to align an open LLM with human preference. Our work\nachieves approximately 7% improvements in Pearson correlation with a reference\njudge over the baseline,and 30% improvement over the base model\n(Llama3.1-8B-Instruct) in the mathematical reasoning evaluation task.\ndemonstrating that augmenting selecting more effective preference data enables\nour approach to surpass baseline methods.\n","authors":["Javad Seraj","Mohammad Mahdi Mohajeri","Mohammad Javad Dousti","Majid Nili Ahmadabadi"],"pdf_url":"https://arxiv.org/pdf/2412.07429v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.17284v2","updated":"2024-12-10T11:36:48Z","published":"2024-11-26T10:13:39Z","title":"Using Large Language Models for Expert Prior Elicitation in Predictive\n  Modelling","summary":"  Large language models (LLMs), trained on diverse data effectively acquire a\nbreadth of information across various domains. However, their computational\ncomplexity, cost, and lack of transparency hinder their direct application for\nspecialised tasks. In fields such as clinical research, acquiring expert\nannotations or prior knowledge about predictive models is often costly and\ntime-consuming. This study proposes the use of LLMs to elicit expert prior\ndistributions for predictive models. This approach also provides an alternative\nto in-context learning, where language models are tasked with making\npredictions directly. In this work, we compare LLM-elicited and uninformative\npriors, evaluate whether LLMs truthfully generate parameter distributions, and\npropose a model selection strategy for in-context learning and prior\nelicitation. Our findings show that LLM-elicited prior parameter distributions\nsignificantly reduce predictive error compared to uninformative priors in\nlow-data settings. Applied to clinical problems, this translates to fewer\nrequired biological samples, lowering cost and resources. Prior elicitation\nalso consistently outperforms and proves more reliable than in-context learning\nat a lower cost, making it a preferred alternative in our setting. We\ndemonstrate the utility of this method across various use cases, including\nclinical applications. For infection prediction, using LLM-elicited priors\nreduced the number of required labels to achieve the same accuracy as an\nuninformative prior by 55%, 200 days earlier in the study.\n","authors":["Alexander Capstick","Rahul G. Krishnan","Payam Barnaghi"],"pdf_url":"https://arxiv.org/pdf/2411.17284v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.14679v2","updated":"2024-12-10T11:26:52Z","published":"2024-02-22T16:32:08Z","title":"Is Self-knowledge and Action Consistent or Not: Investigating Large\n  Language Model's Personality","summary":"  In this study, we delve into the validity of conventional personality\nquestionnaires in capturing the human-like personality traits of Large Language\nModels (LLMs). Our objective is to assess the congruence between the\npersonality traits LLMs claim to possess and their demonstrated tendencies in\nreal-world scenarios. By conducting an extensive examination of LLM outputs\nagainst observed human response patterns, we aim to understand the disjunction\nbetween self-knowledge and action in LLMs.\n","authors":["Yiming Ai","Zhiwei He","Ziyin Zhang","Wenhong Zhu","Hongkun Hao","Kai Yu","Lingjun Chen","Rui Wang"],"pdf_url":"https://arxiv.org/pdf/2402.14679v2.pdf","comment":"ICML 2024, Large Language Models and Cognition"},{"id":"http://arxiv.org/abs/2412.07420v1","updated":"2024-12-10T11:18:29Z","published":"2024-12-10T11:18:29Z","title":"RAG-based Question Answering over Heterogeneous Data and Text","summary":"  This article presents the QUASAR system for question answering over\nunstructured text, structured tables, and knowledge graphs, with unified\ntreatment of all sources. The system adopts a RAG-based architecture, with a\npipeline of evidence retrieval followed by answer generation, with the latter\npowered by a moderate-sized language model. Additionally and uniquely, QUASAR\nhas components for question understanding, to derive crisper input for evidence\nretrieval, and for re-ranking and filtering the retrieved evidence before\nfeeding the most informative pieces into the answer generation. Experiments\nwith three different benchmarks demonstrate the high answering quality of our\napproach, being on par with or better than large GPT models, while keeping the\ncomputational cost and energy consumption orders of magnitude lower.\n","authors":["Philipp Christmann","Gerhard Weikum"],"pdf_url":"https://arxiv.org/pdf/2412.07420v1.pdf","comment":"IEEE Data Engineering Bulletin -- December 2024 Edition on RAG"},{"id":"http://arxiv.org/abs/2412.07419v1","updated":"2024-12-10T11:17:02Z","published":"2024-12-10T11:17:02Z","title":"Composing or Not Composing? Towards Distributional Construction Grammars","summary":"  The mechanisms of comprehension during language processing remains an open\nquestion. Classically, building the meaning of a linguistic utterance is said\nto be incremental, step-by-step, based on a compositional process. However,\nmany different works have shown for a long time that non-compositional\nphenomena are also at work. It is therefore necessary to propose a framework\nbringing together both approaches. We present in this paper an approach based\non Construction Grammars and completing this framework in order to account for\nthese different mechanisms. We propose first a formal definition of this\nframework by completing the feature structure representation proposed in\nSign-Based Construction Grammars. In a second step, we present a general\nrepresentation of the meaning based on the interaction of constructions, frames\nand events. This framework opens the door to a processing mechanism for\nbuilding the meaning based on the notion of activation evaluated in terms of\nsimilarity and unification. This new approach integrates features from\ndistributional semantics into the constructionist framework, leading to what we\ncall Distributional Construction Grammars.\n","authors":["Philippe Blache","Emmanuele Chersoni","Giulia Rambelli","Alessandro Lenci"],"pdf_url":"https://arxiv.org/pdf/2412.07419v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07412v1","updated":"2024-12-10T11:05:26Z","published":"2024-12-10T11:05:26Z","title":"Generating Knowledge Graphs from Large Language Models: A Comparative\n  Study of GPT-4, LLaMA 2, and BERT","summary":"  Knowledge Graphs (KGs) are essential for the functionality of GraphRAGs, a\nform of Retrieval-Augmented Generative Systems (RAGs) that excel in tasks\nrequiring structured reasoning and semantic understanding. However, creating\nKGs for GraphRAGs remains a significant challenge due to accuracy and\nscalability limitations of traditional methods. This paper introduces a novel\napproach leveraging large language models (LLMs) like GPT-4, LLaMA 2 (13B), and\nBERT to generate KGs directly from unstructured data, bypassing traditional\npipelines. Using metrics such as Precision, Recall, F1-Score, Graph Edit\nDistance, and Semantic Similarity, we evaluate the models' ability to generate\nhigh-quality KGs. Results demonstrate that GPT-4 achieves superior semantic\nfidelity and structural accuracy, LLaMA 2 excels in lightweight,\ndomain-specific graphs, and BERT provides insights into challenges in\nentity-relationship modeling. This study underscores the potential of LLMs to\nstreamline KG creation and enhance GraphRAG accessibility for real-world\napplications, while setting a foundation for future advancements.\n","authors":["Ahan Bhatt","Nandan Vaghela","Kush Dudhia"],"pdf_url":"https://arxiv.org/pdf/2412.07412v1.pdf","comment":"4 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2410.12622v3","updated":"2024-12-10T10:52:14Z","published":"2024-10-16T14:42:23Z","title":"From Measurement Instruments to Data: Leveraging Theory-Driven Synthetic\n  Training Data for Classifying Social Constructs","summary":"  Computational text classification is a challenging task, especially for\nmulti-dimensional social constructs. Recently, there has been increasing\ndiscussion that synthetic training data could enhance classification by\noffering examples of how these constructs are represented in texts. In this\npaper, we systematically examine the potential of theory-driven synthetic\ntraining data for improving the measurement of social constructs. In\nparticular, we explore how researchers can transfer established knowledge from\nmeasurement instruments in the social sciences, such as survey scales or\nannotation codebooks, into theory-driven generation of synthetic data. Using\ntwo studies on measuring sexism and political topics, we assess the added value\nof synthetic training data for fine-tuning text classification models. Although\nthe results of the sexism study were less promising, our findings demonstrate\nthat synthetic data can be highly effective in reducing the need for labeled\ndata in political topic classification. With only a minimal drop in\nperformance, synthetic data allows for substituting large amounts of labeled\ndata. Furthermore, theory-driven synthetic data performed markedly better than\ndata generated without conceptual information in mind.\n","authors":["Lukas Birkenmaier","Matthias Roth","Indira Sen"],"pdf_url":"https://arxiv.org/pdf/2410.12622v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14112v3","updated":"2024-12-10T10:43:50Z","published":"2024-03-21T03:52:01Z","title":"Benchmarking Chinese Commonsense Reasoning of LLMs: From\n  Chinese-Specifics to Reasoning-Memorization Correlations","summary":"  We introduce CHARM, the first benchmark for comprehensively and in-depth\nevaluating the commonsense reasoning ability of large language models (LLMs) in\nChinese, which covers both globally known and Chinese-specific commonsense. We\nevaluated 7 English and 12 Chinese-oriented LLMs on CHARM, employing 5\nrepresentative prompt strategies for improving LLMs' reasoning ability, such as\nChain-of-Thought. Our findings indicate that the LLM's language orientation and\nthe task's domain influence the effectiveness of the prompt strategy, which\nenriches previous research findings. We built closely-interconnected reasoning\nand memorization tasks, and found that some LLMs struggle with memorizing\nChinese commonsense, affecting their reasoning ability, while others show\ndifferences in reasoning despite similar memorization performance. We also\nevaluated the LLMs' memorization-independent reasoning abilities and analyzed\nthe typical errors. Our study precisely identified the LLMs' strengths and\nweaknesses, providing the clear direction for optimization. It can also serve\nas a reference for studies in other fields. We will release CHARM at\nhttps://github.com/opendatalab/CHARM .\n","authors":["Jiaxing Sun","Weiquan Huang","Jiang Wu","Chenya Gu","Wei Li","Songyang Zhang","Hang Yan","Conghui He"],"pdf_url":"https://arxiv.org/pdf/2403.14112v3.pdf","comment":"Equal contribution: Jiaxing Sun, Weiquan Huang, Jiang Wu;\n  Corresponding author: Conghui He"},{"id":"http://arxiv.org/abs/2412.07393v1","updated":"2024-12-10T10:35:19Z","published":"2024-12-10T10:35:19Z","title":"CMT: A Memory Compression Method for Continual Knowledge Learning of\n  Large Language Models","summary":"  Large Language Models (LLMs) need to adapt to the continuous changes in data,\ntasks, and user preferences. Due to their massive size and the high costs\nassociated with training, LLMs are not suitable for frequent retraining.\nHowever, updates are necessary to keep them in sync with rapidly evolving human\nknowledge. To address these challenges, this paper proposes the Compression\nMemory Training (CMT) method, an efficient and effective online adaptation\nframework for LLMs that features robust knowledge retention capabilities.\nInspired by human memory mechanisms, CMT compresses and extracts information\nfrom new documents to be stored in a memory bank. When answering to queries\nrelated to these new documents, the model aggregates these document memories\nfrom the memory bank to better answer user questions. The parameters of the LLM\nitself do not change during training and inference, reducing the risk of\ncatastrophic forgetting. To enhance the encoding, retrieval, and aggregation of\nmemory, we further propose three new general and flexible techniques, including\nmemory-aware objective, self-matching and top-aggregation. Extensive\nexperiments conducted on three continual learning datasets (i.e., StreamingQA,\nSQuAD and ArchivalQA) demonstrate that the proposed method improves model\nadaptability and robustness across multiple base LLMs (e.g., +4.07 EM & +4.19\nF1 in StreamingQA with Llama-2-7b).\n","authors":["Dongfang Li","Zetian Sun","Xinshuo Hu","Baotian Hu","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.07393v1.pdf","comment":"AAAI 2025; Pre-print"},{"id":"http://arxiv.org/abs/2412.07388v1","updated":"2024-12-10T10:32:22Z","published":"2024-12-10T10:32:22Z","title":"A Review of Challenges in Speech-based Conversational AI for Elderly\n  Care","summary":"  Artificially intelligent systems optimized for speech conversation are\nappearing at a fast pace. Such models are interesting from a healthcare\nperspective, as these voice-controlled assistants may support the elderly and\nenable remote health monitoring. The bottleneck for efficacy, however, is how\nwell these devices work in practice and how the elderly experience them, but\nresearch on this topic is scant. We review elderly use of voice-controlled AI\nand highlight various user- and technology-centered issues, that need to be\nconsidered before effective speech-controlled AI for elderly care can be\nrealized.\n","authors":["Willemijn Klaassen","Bram van Dijk","Marco Spruit"],"pdf_url":"https://arxiv.org/pdf/2412.07388v1.pdf","comment":"Accepted for publication at Medical Informatics Europe 2025\n  conference, Glasgow. 5 pages, 1 figure, 1 table"},{"id":"http://arxiv.org/abs/2412.07386v1","updated":"2024-12-10T10:32:01Z","published":"2024-12-10T10:32:01Z","title":"Algorithmic Phase Transitions in Language Models: A Mechanistic Case\n  Study of Arithmetic","summary":"  Zero-shot capabilities of large language models make them powerful tools for\nsolving a range of tasks without explicit training. It remains unclear,\nhowever, how these models achieve such performance, or why they can zero-shot\nsome tasks but not others. In this paper, we shed some light on this phenomenon\nby defining and investigating algorithmic stability in language models --\nchanges in problem-solving strategy employed by the model as a result of\nchanges in task specification. We focus on a task where algorithmic stability\nis needed for generalization: two-operand arithmetic. Surprisingly, we find\nthat Gemma-2-2b employs substantially different computational models on closely\nrelated subtasks, i.e. four-digit versus eight-digit addition. Our findings\nsuggest that algorithmic instability may be a contributing factor to language\nmodels' poor zero-shot performance across certain logical reasoning tasks, as\nthey struggle to abstract different problem-solving strategies and smoothly\ntransition between them.\n","authors":["Alan Sun","Ethan Sun","Warren Shepard"],"pdf_url":"https://arxiv.org/pdf/2412.07386v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2412.07380v1","updated":"2024-12-10T10:27:41Z","published":"2024-12-10T10:27:41Z","title":"SpecFuse: Ensembling Large Language Models via Next-Segment Prediction","summary":"  Ensembles of generative large language models (LLMs) can integrate the\nstrengths of different LLMs to compensate for the limitations of individual\nmodels. However, recent work has focused on training an additional fusion model\nto combine complete responses from multiple LLMs, failing to tap into their\ncollaborative potential to generate higher-quality responses. Moreover, as the\nadditional fusion model is trained on a specialized dataset, these methods\nstruggle with generalizing to open-domain queries from online users. In this\npaper, we propose SpecFuse, a novel ensemble framework that outputs the fused\nresult by iteratively producing the next segment through collaboration among\nLLMs. This is achieved through cyclic execution of its inference and\nverification components. In each round, the inference component invokes each\nbase LLM to generate candidate segments in parallel, and the verify component\ncalls these LLMs again to predict the ranking of the segments. The top-ranked\nsegment is then broadcast to all LLMs, encouraging them to generate\nhigher-quality segments in the next round. This approach also allows the base\nLLMs to be plug-and-play, without any training or adaptation, avoiding\ngeneralization limitations. Furthermore, to conserve computational resources,\nwe propose a model exit mechanism that dynamically excludes models exhibiting\npoor performance in previous rounds during each query response. In this way, it\neffectively reduces the number of model calls while maintaining overall\nperformance.\n","authors":["Bo Lv","Chen Tang","Yanan Zhang","Xin Liu","Yue Yu","Ping Luo"],"pdf_url":"https://arxiv.org/pdf/2412.07380v1.pdf","comment":"15 pages, 5 figures"},{"id":"http://arxiv.org/abs/2412.05644v2","updated":"2024-12-10T10:13:59Z","published":"2024-12-07T13:15:22Z","title":"Mixture of Hidden-Dimensions Transformer","summary":"  Transformer models encounter challenges in scaling hidden dimensions\nefficiently, as uniformly increasing them inflates computational and memory\ncosts while failing to emphasize the most relevant features for each token. For\nfurther understanding, we study hidden dimension sparsity and observe that\ntrained Transformers utilize only a small fraction of token dimensions,\nrevealing an \"activation flow\" pattern. Notably, there are shared\nsub-dimensions with sustained activation across multiple consecutive tokens and\nspecialized sub-dimensions uniquely activated for each token. To better model\ntoken-relevant sub-dimensions, we propose MoHD (Mixture of Hidden Dimensions),\na sparse conditional activation architecture. Particularly, MoHD employs shared\nsub-dimensions for common token features and a routing mechanism to dynamically\nactivate specialized sub-dimensions. To mitigate potential information loss\nfrom sparsity, we design activation scaling and group fusion mechanisms to\npreserve activation flow. In this way, MoHD expands hidden dimensions with\nnegligible increases in computation or parameters, efficient training and\ninference while maintaining performance. Evaluations across 10 NLP tasks show\nthat MoHD surpasses Vanilla Transformers in parameter efficiency and task\nperformance. It achieves 1.7% higher performance with 50% fewer activation\nparameters and 3.7% higher performance with a 3x parameter expansion at\nconstant activation cost. MOHD offers a new perspective for scaling the model,\nshowcasing the potential of hidden dimension sparsity to boost efficiency\n","authors":["Yilong Chen","Junyuan Shang","Zhengyu Zhang","Jiawei Sheng","Tingwen Liu","Shuohuan Wang","Yu Sun","Hua Wu","Haifeng Wang"],"pdf_url":"https://arxiv.org/pdf/2412.05644v2.pdf","comment":"16 pages, 10 figures, 5 tables"},{"id":"http://arxiv.org/abs/2412.07367v1","updated":"2024-12-10T10:06:46Z","published":"2024-12-10T10:06:46Z","title":"My Words Imply Your Opinion: Reader Agent-Based Propagation Enhancement\n  for Personalized Implicit Emotion Analysis","summary":"  In implicit emotion analysis (IEA), the subtlety of emotional expressions\nmakes it particularly sensitive to user-specific characteristics. Existing\nstudies often inject personalization into the analysis by focusing on the\nauthorial dimension of the emotional text. However, these methods overlook the\npotential influence of the intended reader on the reaction of implicit\nemotions. In this paper, we refine the IEA task to Personalized Implicit\nEmotion Analysis (PIEA) and introduce the RAPPIE model, a novel framework\ndesigned to address the issue of missing user information within this task. In\nparticular, 1) we create reader agents based on the Large Language Model to\nsimulate reader reactions, to address challenges of the spiral of silence and\ndata incompleteness encountered when acquiring reader feedback information. 2)\nWe establish a reader propagation role system and develop a role-aware emotion\npropagation multi-view graph learning model, which effectively deals with the\nsparsity of reader information by utilizing the distribution of propagation\nroles. 3) We annotate two Chinese PIEA datasets with detailed user metadata,\nthereby addressing the limitation of prior datasets that primarily focus on\ntextual content annotation. Extensive experiments on these datasets indicate\nthat the RAPPIE model outperforms current state-of-the-art baselines,\nhighlighting the significance and efficacy of incorporating reader feedback\ninto the PIEA process.\n","authors":["Jian Liao","Yu Feng","Xiaoyu Wang","Suge Wang","Jianxing Zheng","Deyu Li"],"pdf_url":"https://arxiv.org/pdf/2412.07367v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07355v1","updated":"2024-12-10T09:48:07Z","published":"2024-12-10T09:48:07Z","title":"Towards Predictive Communication with Brain-Computer Interfaces\n  integrating Large Language Models","summary":"  This perspective article aims at providing an outline of the state of the art\nand future developments towards the integration of cutting-edge predictive\nlanguage models with BCI. A synthetic overview of early and more recent\nlinguistic models, from natural language processing (NLP) models to recent LLM,\nthat to a varying extent improved predictive writing systems, is first\nprovided. Second, a summary of previous BCI implementations integrating\nlanguage models is presented. The few preliminary studies investigating the\npossible combination of LLM with BCI spellers to efficiently support fast\ncommunication and control are then described. Finally, current challenges and\nlimitations towards the full integration of LLM with BCI systems are discussed.\nRecent investigations suggest that the combination of LLM with BCI might\ndrastically improve human-computer interaction in patients with motor or\nlanguage disorders as well as in healthy individuals. In particular, the\npretrained autoregressive transformer models, such as GPT, that capitalize from\nparallelization, learning through pre-training and fine-tuning, promise a\nsubstantial improvement of BCI for communication with respect to previous\nsystems incorporating simpler language models. Indeed, among various models,\nthe GPT-2 was shown to represent an excellent candidate for its integration\ninto BCI although testing was only perfomed on simulated conversations and not\non real BCI scenarios. Prospectively, the full integration of LLM with advanced\nBCI systems might lead to a big leap forward towards fast, efficient and\nuser-adaptive neurotechnology.\n","authors":["Andrea Caria"],"pdf_url":"https://arxiv.org/pdf/2412.07355v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07334v1","updated":"2024-12-10T09:25:39Z","published":"2024-12-10T09:25:39Z","title":"Frame Representation Hypothesis: Multi-Token LLM Interpretability and\n  Concept-Guided Text Generation","summary":"  Interpretability is a key challenge in fostering trust for Large Language\nModels (LLMs), which stems from the complexity of extracting reasoning from\nmodel's parameters. We present the Frame Representation Hypothesis, a\ntheoretically robust framework grounded in the Linear Representation Hypothesis\n(LRH) to interpret and control LLMs by modeling multi-token words. Prior\nresearch explored LRH to connect LLM representations with linguistic concepts,\nbut was limited to single token analysis. As most words are composed of several\ntokens, we extend LRH to multi-token words, thereby enabling usage on any\ntextual data with thousands of concepts. To this end, we propose words can be\ninterpreted as frames, ordered sequences of vectors that better capture\ntoken-word relationships. Then, concepts can be represented as the average of\nword frames sharing a common concept. We showcase these tools through Top-k\nConcept-Guided Decoding, which can intuitively steer text generation using\nconcepts of choice. We verify said ideas on Llama 3.1, Gemma 2, and Phi 3\nfamilies, demonstrating gender and language biases, exposing harmful content,\nbut also potential to remediate them, leading to safer and more transparent\nLLMs. Code is available at\nhttps://github.com/phvv-me/frame-representation-hypothesis.git\n","authors":["Pedro H. V. Valois","Lincon S. Souza","Erica K. Shimomoto","Kazuhiro Fukui"],"pdf_url":"https://arxiv.org/pdf/2412.07334v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.00657v2","updated":"2024-12-10T09:16:53Z","published":"2024-05-01T17:37:50Z","title":"RST-LoRA: A Discourse-Aware Low-Rank Adaptation for Long Document\n  Abstractive Summarization","summary":"  For long document summarization, discourse structure is important to discern\nthe key content of the text and the differences in importance level between\nsentences. Unfortunately, the integration of rhetorical structure theory (RST)\ninto parameter-efficient fine-tuning strategies for long document summarization\nremains unexplored. Therefore, this paper introduces RST-LoRA and proposes four\nRST-aware variants to explicitly incorporate RST into the LoRA model. Our\nempirical evaluation demonstrates that incorporating the type and uncertainty\nof rhetorical relations can complementarily enhance the performance of LoRA in\nsummarization tasks. Furthermore, the best-performing variant we introduced\noutperforms the vanilla LoRA and full-parameter fine-tuning models, as\nconfirmed by multiple automatic and human evaluations, and even surpasses\nprevious state-of-the-art methods.\n","authors":["Dongqi Liu","Vera Demberg"],"pdf_url":"https://arxiv.org/pdf/2405.00657v2.pdf","comment":"NAACL 2024 Main & Long Conference Paper (Oral Presentation)"},{"id":"http://arxiv.org/abs/2403.17768v2","updated":"2024-12-10T09:12:46Z","published":"2024-03-26T14:54:48Z","title":"SciNews: From Scholarly Complexities to Public Narratives -- A Dataset\n  for Scientific News Report Generation","summary":"  Scientific news reports serve as a bridge, adeptly translating complex\nresearch articles into reports that resonate with the broader public. The\nautomated generation of such narratives enhances the accessibility of scholarly\ninsights. In this paper, we present a new corpus to facilitate this paradigm\ndevelopment. Our corpus comprises a parallel compilation of academic\npublications and their corresponding scientific news reports across nine\ndisciplines. To demonstrate the utility and reliability of our dataset, we\nconduct an extensive analysis, highlighting the divergences in readability and\nbrevity between scientific news narratives and academic manuscripts. We\nbenchmark our dataset employing state-of-the-art text generation models. The\nevaluation process involves both automatic and human evaluation, which lays the\ngroundwork for future explorations into the automated generation of scientific\nnews reports. The dataset and code related to this work are available at\nhttps://dongqi.me/projects/SciNews.\n","authors":["Dongqi Liu","Yifan Wang","Jia Loy","Vera Demberg"],"pdf_url":"https://arxiv.org/pdf/2403.17768v2.pdf","comment":"LREC-COLING 2024 Main Conference Paper"},{"id":"http://arxiv.org/abs/2306.07799v2","updated":"2024-12-10T09:06:22Z","published":"2023-06-13T14:21:35Z","title":"ChatGPT vs Human-authored Text: Insights into Controllable Text\n  Summarization and Sentence Style Transfer","summary":"  Large-scale language models, like ChatGPT, have garnered significant media\nattention and stunned the public with their remarkable capacity for generating\ncoherent text from short natural language prompts. In this paper, we aim to\nconduct a systematic inspection of ChatGPT's performance in two controllable\ngeneration tasks, with respect to ChatGPT's ability to adapt its output to\ndifferent target audiences (expert vs. layman) and writing styles (formal vs.\ninformal). Additionally, we evaluate the faithfulness of the generated text,\nand compare the model's performance with human-authored texts. Our findings\nindicate that the stylistic variations produced by humans are considerably\nlarger than those demonstrated by ChatGPT, and the generated texts diverge from\nhuman samples in several characteristics, such as the distribution of word\ntypes. Moreover, we observe that ChatGPT sometimes incorporates factual errors\nor hallucinations when adapting the text to suit a specific style.\n","authors":["Dongqi Liu","Vera Demberg"],"pdf_url":"https://arxiv.org/pdf/2306.07799v2.pdf","comment":"ACL-SRW 2023"},{"id":"http://arxiv.org/abs/2305.16784v2","updated":"2024-12-10T08:59:20Z","published":"2023-05-26T09:51:47Z","title":"Incorporating Distributions of Discourse Structure for Long Document\n  Abstractive Summarization","summary":"  For text summarization, the role of discourse structure is pivotal in\ndiscerning the core content of a text. Regrettably, prior studies on\nincorporating Rhetorical Structure Theory (RST) into transformer-based\nsummarization models only consider the nuclearity annotation, thereby\noverlooking the variety of discourse relation types. This paper introduces the\n'RSTformer', a novel summarization model that comprehensively incorporates both\nthe types and uncertainty of rhetorical relations. Our RST-attention mechanism,\nrooted in document-level rhetorical structure, is an extension of the recently\ndevised Longformer framework. Through rigorous evaluation, the model proposed\nherein exhibits significant superiority over state-of-the-art models, as\nevidenced by its notable performance on several automatic metrics and human\nevaluation.\n","authors":["Dongqi Liu","Yifan Wang","Vera Demberg"],"pdf_url":"https://arxiv.org/pdf/2305.16784v2.pdf","comment":"ACL 2023 (Main conference)"},{"id":"http://arxiv.org/abs/2403.09472v2","updated":"2024-12-10T08:54:09Z","published":"2024-03-14T15:12:38Z","title":"Easy-to-Hard Generalization: Scalable Alignment Beyond Human Supervision","summary":"  Current AI alignment methodologies rely on human-provided demonstrations or\njudgments, and the learned capabilities of AI systems would be upper-bounded by\nhuman capabilities as a result. This raises a challenging research question:\nHow can we keep improving the systems when their capabilities have surpassed\nthe levels of humans? This paper answers this question in the context of\ntackling hard reasoning tasks (e.g., level 4-5 MATH problems) via learning from\nhuman annotations on easier tasks (e.g., level 1-3 MATH problems), which we\nterm as easy-to-hard generalization. Our key insight is that an evaluator\n(reward model) trained on supervisions for easier tasks can be effectively used\nfor scoring candidate solutions of harder tasks and hence facilitating\neasy-to-hard generalization over different levels of tasks. Based on this\ninsight, we propose a novel approach to scalable alignment, which firstly\ntrains the (process-supervised) reward models on easy problems (e.g., level\n1-3), and then uses them to evaluate the performance of policy models on hard\nproblems. We show that such easy-to-hard generalization from evaluators can\nenable easy-to-hard generalizations in generators either through re-ranking or\nreinforcement learning (RL). Notably, our process-supervised 7b RL model and\n34b model (reranking@1024) achieves an accuracy of 34.0% and 52.5% on MATH500,\nrespectively, despite only using human supervision on easy problems. Our\napproach suggests a promising path toward AI systems that advance beyond the\nfrontier of human supervision.\n","authors":["Zhiqing Sun","Longhui Yu","Yikang Shen","Weiyang Liu","Yiming Yang","Sean Welleck","Chuang Gan"],"pdf_url":"https://arxiv.org/pdf/2403.09472v2.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2412.07303v1","updated":"2024-12-10T08:31:52Z","published":"2024-12-10T08:31:52Z","title":"Filipino Benchmarks for Measuring Sexist and Homophobic Bias in\n  Multilingual Language Models from Southeast Asia","summary":"  Bias studies on multilingual models confirm the presence of gender-related\nstereotypes in masked models processing languages with high NLP resources. We\nexpand on this line of research by introducing Filipino CrowS-Pairs and\nFilipino WinoQueer: benchmarks that assess both sexist and anti-queer biases in\npretrained language models (PLMs) handling texts in Filipino, a low-resource\nlanguage from the Philippines. The benchmarks consist of 7,074 new challenge\npairs resulting from our cultural adaptation of English bias evaluation\ndatasets, a process that we document in detail to guide similar forthcoming\nefforts. We apply the Filipino benchmarks on masked and causal multilingual\nmodels, including those pretrained on Southeast Asian data, and find that they\ncontain considerable amounts of bias. We also find that for multilingual\nmodels, the extent of bias learned for a particular language is influenced by\nhow much pretraining data in that language a model was exposed to. Our\nbenchmarks and insights can serve as a foundation for future work analyzing and\nmitigating bias in multilingual models.\n","authors":["Lance Calvin Lim Gamboa","Mark Lee"],"pdf_url":"https://arxiv.org/pdf/2412.07303v1.pdf","comment":"Accepted for presentation at The First Workshop on Language Models\n  for Low-Resource Languages (LoResLM) at The 31st International Conference on\n  Computational Linguistics (COLING 2025)"},{"id":"http://arxiv.org/abs/2412.07298v1","updated":"2024-12-10T08:28:57Z","published":"2024-12-10T08:28:57Z","title":"The Rise and Down of Babel Tower: Investigating the Evolution Process of\n  Multilingual Code Large Language Model","summary":"  Large language models (LLMs) have shown significant multilingual\ncapabilities. However, the mechanisms underlying the development of these\ncapabilities during pre-training are not well understood. In this paper, we use\ncode LLMs as an experimental platform to explore the evolution of multilingual\ncapabilities in LLMs during the pre-training process. Based on our\nobservations, we propose the Babel Tower Hypothesis, which describes the entire\nprocess of LLMs acquiring new language capabilities. During the learning\nprocess, multiple languages initially share a single knowledge system dominated\nby the primary language and gradually develop language-specific knowledge\nsystems. We then validate the above hypothesis by tracking the internal states\nof the LLMs through identifying working languages and language transferring\nneurons. Experimental results show that the internal state changes of the LLM\nare consistent with our Babel Tower Hypothesis. Building on these insights, we\npropose a novel method to construct an optimized pre-training corpus for\nmultilingual code LLMs, which significantly outperforms LLMs trained on the\noriginal corpus. The proposed Babel Tower Hypothesis provides new insights into\ndesigning pre-training data distributions to achieve optimal multilingual\ncapabilities in LLMs.\n","authors":["Jiawei Chen","Wentao Chen","Jing Su","Jingjing Xu","Hongyu Lin","Mengjie Ren","Yaojie Lu","Xianpei Han","Le Sun"],"pdf_url":"https://arxiv.org/pdf/2412.07298v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07292v1","updated":"2024-12-10T08:21:19Z","published":"2024-12-10T08:21:19Z","title":"Multimodal Sentiment Analysis Based on Causal Reasoning","summary":"  With the rapid development of multimedia, the shift from unimodal textual\nsentiment analysis to multimodal image-text sentiment analysis has obtained\nacademic and industrial attention in recent years. However, multimodal\nsentiment analysis is affected by unimodal data bias, e.g., text sentiment is\nmisleading due to explicit sentiment semantic, leading to low accuracy in the\nfinal sentiment classification. In this paper, we propose a novel\nCounterFactual Multimodal Sentiment Analysis framework (CF-MSA) using causal\ncounterfactual inference to construct multimodal sentiment causal inference.\nCF-MSA mitigates the direct effect from unimodal bias and ensures heterogeneity\nacross modalities by differentiating the treatment variables between\nmodalities. In addition, considering the information complementarity and bias\ndifferences between modalities, we propose a new optimisation objective to\neffectively integrate different modalities and reduce the inherent bias from\neach modality. Experimental results on two public datasets, MVSA-Single and\nMVSA-Multiple, demonstrate that the proposed CF-MSA has superior debiasing\ncapability and achieves new state-of-the-art performances. We will release the\ncode and datasets to facilitate future research.\n","authors":["Fuhai Chen","Pengpeng Huang","Xuri Ge","Jie Huang","Zishuo Bao"],"pdf_url":"https://arxiv.org/pdf/2412.07292v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07289v1","updated":"2024-12-10T08:18:29Z","published":"2024-12-10T08:18:29Z","title":"Enhancing Relation Extraction via Supervised Rationale Verification and\n  Feedback","summary":"  Despite the rapid progress that existing automated feedback methods have made\nin correcting the output of large language models (LLMs), these methods cannot\nbe well applied to the relation extraction (RE) task due to their designated\nfeedback objectives and correction manner. To address this problem, we propose\na novel automated feedback framework for RE, which presents a rationale\nsupervisor to verify the rationale and provide re-selected demonstrations as\nfeedback to correct the initial prediction. Specifically, we first design a\ncausal intervention and observation method for to collect biased/unbiased\nrationales for contrastive training the rationale supervisor. Then, we present\na verification-feedback-correction procedure to iteratively enhance LLMs'\ncapability of handling the RE task. Extensive experiments prove that our\nproposed framework significantly outperforms existing methods.\n","authors":["Yongqi Li","Xin Miao","Shen Zhou","Mayi Xu","Yuyang Ren","Tieyun Qian"],"pdf_url":"https://arxiv.org/pdf/2412.07289v1.pdf","comment":"Accepted to AAAI 2025, camera ready version"},{"id":"http://arxiv.org/abs/2412.07282v1","updated":"2024-12-10T08:12:22Z","published":"2024-12-10T08:12:22Z","title":"HARP: Hesitation-Aware Reframing in Transformer Inference Pass","summary":"  This paper aims to improve the performance of large language models by\naddressing the variable computational demands in inference steps, where some\ntokens require more computational resources than others. We present HARP, a\nsimple modification to \"off-the-shelf\" Transformer forward pass. Drawing from\nhesitation and the framing effect in decision-making, HARP selectively applies\nadditional computation when the model encounters uncertainty during token\ngeneration. Our method mimics human cognitive processes by pausing at difficult\ndecision points and reframing inputs for a different perspective. Unlike other\napproaches, HARP is model-agnostic, training-free, and easy to implement. We\nthoroughly evaluate our method across various downstream tasks and model sizes,\ndemonstrating performance improvements up to +5.16%. Notably, HARP achieves\nthese gains while maintaining inference times twice faster than beam search.\nSimple and yet with significant gains, HARP offers a practical solution for\nenhancing the performance of Transformer-based language models with minimal\ncomputational impact.\n","authors":["Romain Storaï","Seung-won Hwang"],"pdf_url":"https://arxiv.org/pdf/2412.07282v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06559v2","updated":"2024-12-10T08:10:32Z","published":"2024-12-09T15:11:40Z","title":"ProcessBench: Identifying Process Errors in Mathematical Reasoning","summary":"  As language models regularly make mistakes when solving math problems,\nautomated identification of errors in the reasoning process becomes\nincreasingly significant for their scalable oversight. In this paper, we\nintroduce ProcessBench for measuring the ability to identify erroneous steps in\nmathematical reasoning. It consists of 3,400 test cases, primarily focused on\ncompetition- and Olympiad-level math problems. Each test case contains a\nstep-by-step solution with error location annotated by human experts. Models\nare required to identify the earliest step that contains an error, or conclude\nthat all steps are correct. We conduct extensive evaluation on ProcessBench,\ninvolving two types of models: process reward models (PRMs) and critic models,\nwhere for the latter we prompt general language models to critique each\nsolution step by step. We draw two main observations: (1) Existing PRMs\ntypically fail to generalize to more challenging math problems beyond GSM8K and\nMATH. They underperform both critic models (i.e., prompted general language\nmodels) and our own trained PRM that is straightforwardly fine-tuned on the\nPRM800K dataset. (2) The best open-source model, QwQ-32B-Preview, has\ndemonstrated the critique capability competitive with the proprietary model\nGPT-4o, despite that it still lags behind the reasoning-specialized o1-mini. We\nhope ProcessBench can foster future research in reasoning process assessment,\npaving the way toward scalable oversight of language models.\n","authors":["Chujie Zheng","Zhenru Zhang","Beichen Zhang","Runji Lin","Keming Lu","Bowen Yu","Dayiheng Liu","Jingren Zhou","Junyang Lin"],"pdf_url":"https://arxiv.org/pdf/2412.06559v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07255v1","updated":"2024-12-10T07:35:23Z","published":"2024-12-10T07:35:23Z","title":"Label-Confidence-Aware Uncertainty Estimation in Natural Language\n  Generation","summary":"  Large Language Models (LLMs) display formidable capabilities in generative\ntasks but also pose potential risks due to their tendency to generate\nhallucinatory responses. Uncertainty Quantification (UQ), the evaluation of\nmodel output reliability, is crucial for ensuring the safety and robustness of\nAI systems. Recent studies have concentrated on model uncertainty by analyzing\nthe relationship between output entropy under various sampling conditions and\nthe corresponding labels. However, these methods primarily focus on measuring\nmodel entropy with precision to capture response characteristics, often\nneglecting the uncertainties associated with greedy decoding results-the\nsources of model labels, which can lead to biased classification outcomes. In\nthis paper, we explore the biases introduced by greedy decoding and propose a\nlabel-confidence-aware (LCA) uncertainty estimation based on Kullback-Leibler\n(KL) divergence bridging between samples and label source, thus enhancing the\nreliability and stability of uncertainty assessments. Our empirical evaluations\nacross a range of popular LLMs and NLP datasets reveal that different label\nsources can indeed affect classification, and that our approach can effectively\ncapture differences in sampling results and label sources, demonstrating more\neffective uncertainty estimation.\n","authors":["Qinhong Lin","Linna Zhou","Zhongliang Yang","Yuang Cai"],"pdf_url":"https://arxiv.org/pdf/2412.07255v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07251v1","updated":"2024-12-10T07:20:51Z","published":"2024-12-10T07:20:51Z","title":"KULTURE Bench: A Benchmark for Assessing Language Model in Korean\n  Cultural Context","summary":"  Large language models have exhibited significant enhancements in performance\nacross various tasks. However, the complexity of their evaluation increases as\nthese models generate more fluent and coherent content. Current multilingual\nbenchmarks often use translated English versions, which may incorporate Western\ncultural biases that do not accurately assess other languages and cultures. To\naddress this research gap, we introduce KULTURE Bench, an evaluation framework\nspecifically designed for Korean culture that features datasets of cultural\nnews, idioms, and poetry. It is designed to assess language models' cultural\ncomprehension and reasoning capabilities at the word, sentence, and paragraph\nlevels. Using the KULTURE Bench, we assessed the capabilities of models trained\nwith different language corpora and analyzed the results comprehensively. The\nresults show that there is still significant room for improvement in the\nmodels' understanding of texts related to the deeper aspects of Korean culture.\n","authors":["Xiaonan Wang","Jinyoung Yeo","Joon-Ho Lim","Hansaem Kim"],"pdf_url":"https://arxiv.org/pdf/2412.07251v1.pdf","comment":"Accepted by the 38th Pacific Asia Conference on Language, Information\n  and Computation"},{"id":"http://arxiv.org/abs/2412.07246v1","updated":"2024-12-10T07:11:49Z","published":"2024-12-10T07:11:49Z","title":"Filling Memory Gaps: Enhancing Continual Semantic Parsing via SQL Syntax\n  Variance-Guided LLMs without Real Data Replay","summary":"  Continual Semantic Parsing (CSP) aims to train parsers to convert natural\nlanguage questions into SQL across tasks with limited annotated examples,\nadapting to the real-world scenario of dynamically updated databases. Previous\nstudies mitigate this challenge by replaying historical data or employing\nparameter-efficient tuning (PET), but they often violate data privacy or rely\non ideal continual learning settings. To address these problems, we propose a\nnew Large Language Model (LLM)-Enhanced Continuous Semantic Parsing method,\nnamed LECSP, which alleviates forgetting while encouraging generalization,\nwithout requiring real data replay or ideal settings. Specifically, it first\nanalyzes the commonalities and differences between tasks from the SQL syntax\nperspective to guide LLMs in reconstructing key memories and improving memory\naccuracy through a calibration strategy. Then, it uses a task-aware\ndual-teacher distillation framework to promote the accumulation and transfer of\nknowledge during sequential training. Experimental results on two CSP\nbenchmarks show that our method significantly outperforms existing methods,\neven those utilizing data replay or ideal settings. Additionally, we achieve\ngeneralization performance beyond the upper limits, better adapting to unseen\ntasks.\n","authors":["Ruiheng Liu","Jinyu Zhang","Yanqi Song","Yu Zhang","Bailong Yang"],"pdf_url":"https://arxiv.org/pdf/2412.07246v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.12024v2","updated":"2024-12-10T07:03:27Z","published":"2022-04-26T01:38:47Z","title":"Reprint: a randomized extrapolation based on principal components for\n  data augmentation","summary":"  Data scarcity and data imbalance have attracted a lot of attention in many\nfields. Data augmentation, explored as an effective approach to tackle them,\ncan improve the robustness and efficiency of classification models by\ngenerating new samples. This paper presents REPRINT, a simple and effective\nhidden-space data augmentation method for imbalanced data classification. Given\nhidden-space representations of samples in each class, REPRINT extrapolates, in\na randomized fashion, augmented examples for target class by using subspaces\nspanned by principal components to summarize distribution structure of both\nsource and target class. Consequently, the examples generated would diversify\nthe target while maintaining the original geometry of target distribution.\nBesides, this method involves a label refinement component which allows to\nsynthesize new soft labels for augmented examples. Compared with different NLP\ndata augmentation approaches under a range of data imbalanced scenarios on four\ntext classification benchmark, REPRINT shows prominent improvements. Moreover,\nthrough comprehensive ablation studies, we show that label refinement is better\nthan label-preserving for augmented examples, and that our method suggests\nstable and consistent improvements in terms of suitable choices of principal\ncomponents. Moreover, REPRINT is appealing for its easy-to-use since it\ncontains only one hyperparameter determining the dimension of subspace and\nrequires low computational resource.\n","authors":["Le Li","Jiale Wei","Pai Peng","Qiyuan Chen","Benjamin Guedj","Bo Cai"],"pdf_url":"https://arxiv.org/pdf/2204.12024v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07238v1","updated":"2024-12-10T07:03:06Z","published":"2024-12-10T07:03:06Z","title":"Speaker effects in spoken language comprehension","summary":"  The identity of a speaker significantly influences spoken language\ncomprehension by affecting both perception and expectation. This review\nexplores speaker effects, focusing on how speaker information impacts language\nprocessing. We propose an integrative model featuring the interplay between\nbottom-up perception-based processes driven by acoustic details and top-down\nexpectation-based processes driven by a speaker model. The acoustic details\ninfluence lower-level perception, while the speaker model modulates both\nlower-level and higher-level processes such as meaning interpretation and\npragmatic inferences. We define speaker-idiosyncrasy and speaker-demographics\neffects and demonstrate how bottom-up and top-down processes interact at\nvarious levels in different scenarios. This framework contributes to\npsycholinguistic theory by offering a comprehensive account of how speaker\ninformation interacts with linguistic content to shape message construction. We\nsuggest that speaker effects can serve as indices of a language learner's\nproficiency and an individual's characteristics of social cognition. We\nencourage future research to extend these findings to AI speakers, probing the\nuniversality of speaker effects across humans and artificial agents.\n","authors":["Hanlin Wu","Zhenguang G. Cai"],"pdf_url":"https://arxiv.org/pdf/2412.07238v1.pdf","comment":"44 pages, 1 figure"},{"id":"http://arxiv.org/abs/2412.07220v1","updated":"2024-12-10T06:18:07Z","published":"2024-12-10T06:18:07Z","title":"Comateformer: Combined Attention Transformer for Semantic Sentence\n  Matching","summary":"  The Transformer-based model have made significant strides in semantic\nmatching tasks by capturing connections between phrase pairs. However, to\nassess the relevance of sentence pairs, it is insufficient to just examine the\ngeneral similarity between the sentences. It is crucial to also consider the\ntiny subtleties that differentiate them from each other. Regrettably, attention\nsoftmax operations in transformers tend to miss these subtle differences. To\nthis end, in this work, we propose a novel semantic sentence matching model\nnamed Combined Attention Network based on Transformer model (Comateformer). In\nComateformer model, we design a novel transformer-based quasi-attention\nmechanism with compositional properties. Unlike traditional attention\nmechanisms that merely adjust the weights of input tokens, our proposed method\nlearns how to combine, subtract, or resize specific vectors when building a\nrepresentation. Moreover, our proposed approach builds on the intuition of\nsimilarity and dissimilarity (negative affinity) when calculating dual affinity\nscores. This allows for a more meaningful representation of relationships\nbetween sentences. To evaluate the performance of our proposed model, we\nconducted extensive experiments on ten public real-world datasets and\nrobustness testing. Experimental results show that our method achieves\nconsistent improvements.\n","authors":["Bo Li","Di Liang","Zixin Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.07220v1.pdf","comment":"This paper is accepted by 27th EUROPEAN CONFERENCE ON ARTIFICIAL\n  INTELLIGENCE (ECAI 2024)"},{"id":"http://arxiv.org/abs/2412.07207v1","updated":"2024-12-10T05:55:14Z","published":"2024-12-10T05:55:14Z","title":"MAPLE: A Framework for Active Preference Learning Guided by Large\n  Language Models","summary":"  The advent of large language models (LLMs) has sparked significant interest\nin using natural language for preference learning. However, existing methods\noften suffer from high computational burdens, taxing human supervision, and\nlack of interpretability. To address these issues, we introduce MAPLE, a\nframework for large language model-guided Bayesian active preference learning.\nMAPLE leverages LLMs to model the distribution over preference functions,\nconditioning it on both natural language feedback and conventional preference\nlearning feedback, such as pairwise trajectory rankings. MAPLE also employs\nactive learning to systematically reduce uncertainty in this distribution and\nincorporates a language-conditioned active query selection mechanism to\nidentify informative and easy-to-answer queries, thus reducing human burden. We\nevaluate MAPLE's sample efficiency and preference inference quality across two\nbenchmarks, including a real-world vehicle route planning benchmark using\nOpenStreetMap data. Our results demonstrate that MAPLE accelerates the learning\nprocess and effectively improves humans' ability to answer queries.\n","authors":["Saaduddin Mahmud","Mason Nakamura","Shlomo Zilberstein"],"pdf_url":"https://arxiv.org/pdf/2412.07207v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.05579v2","updated":"2024-12-10T05:49:12Z","published":"2024-12-07T08:07:24Z","title":"LLMs-as-Judges: A Comprehensive Survey on LLM-based Evaluation Methods","summary":"  The rapid advancement of Large Language Models (LLMs) has driven their\nexpanding application across various fields. One of the most promising\napplications is their role as evaluators based on natural language responses,\nreferred to as ''LLMs-as-judges''. This framework has attracted growing\nattention from both academia and industry due to their excellent effectiveness,\nability to generalize across tasks, and interpretability in the form of natural\nlanguage. This paper presents a comprehensive survey of the LLMs-as-judges\nparadigm from five key perspectives: Functionality, Methodology, Applications,\nMeta-evaluation, and Limitations. We begin by providing a systematic definition\nof LLMs-as-Judges and introduce their functionality (Why use LLM judges?). Then\nwe address methodology to construct an evaluation system with LLMs (How to use\nLLM judges?). Additionally, we investigate the potential domains for their\napplication (Where to use LLM judges?) and discuss methods for evaluating them\nin various contexts (How to evaluate LLM judges?). Finally, we provide a\ndetailed analysis of the limitations of LLM judges and discuss potential future\ndirections. Through a structured and comprehensive analysis, we aim aims to\nprovide insights on the development and application of LLMs-as-judges in both\nresearch and practice. We will continue to maintain the relevant resource list\nat https://github.com/CSHaitao/Awesome-LLMs-as-Judges.\n","authors":["Haitao Li","Qian Dong","Junjie Chen","Huixue Su","Yujia Zhou","Qingyao Ai","Ziyi Ye","Yiqun Liu"],"pdf_url":"https://arxiv.org/pdf/2412.05579v2.pdf","comment":"60 pages, comprehensive and continuously updated"},{"id":"http://arxiv.org/abs/2412.07201v1","updated":"2024-12-10T05:33:09Z","published":"2024-12-10T05:33:09Z","title":"A Review on the Applications of Transformer-based language models for\n  Nucleotide Sequence Analysis","summary":"  In recent times, Transformer-based language models are making quite an impact\nin the field of natural language processing. As relevant parallels can be drawn\nbetween biological sequences and natural languages, the models used in NLP can\nbe easily extended and adapted for various applications in bioinformatics. In\nthis regard, this paper introduces the major developments of Transformer-based\nmodels in the recent past in the context of nucleotide sequences. We have\nreviewed and analysed a large number of application-based papers on this\nsubject, giving evidence of the main characterizing features and to different\napproaches that may be adopted to customize such powerful computational\nmachines. We have also provided a structured description of the functioning of\nTransformers, that may enable even first time users to grab the essence of such\ncomplex architectures. We believe this review will help the scientific\ncommunity in understanding the various applications of Transformer-based\nlanguage models to nucleotide sequences. This work will motivate the readers to\nbuild on these methodologies to tackle also various other problems in the field\nof bioinformatics.\n","authors":["Nimisha Ghosh","Daniele Santoni","Indrajit Saha","Giovanni Felici"],"pdf_url":"https://arxiv.org/pdf/2412.07201v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07200v1","updated":"2024-12-10T05:32:57Z","published":"2024-12-10T05:32:57Z","title":"Modifying AI, Enhancing Essays: How Active Engagement with Generative AI\n  Boosts Writing Quality","summary":"  Students are increasingly relying on Generative AI (GAI) to support their\nwriting-a key pedagogical practice in education. In GAI-assisted writing,\nstudents can delegate core cognitive tasks (e.g., generating ideas and turning\nthem into sentences) to GAI while still producing high-quality essays. This\ncreates new challenges for teachers in assessing and supporting student\nlearning, as they often lack insight into whether students are engaging in\nmeaningful cognitive processes during writing or how much of the essay's\nquality can be attributed to those processes. This study aimed to help teachers\nbetter assess and support student learning in GAI-assisted writing by examining\nhow different writing behaviors, especially those indicative of meaningful\nlearning versus those that are not, impact essay quality. Using a dataset of\n1,445 GAI-assisted writing sessions, we applied the cutting-edge method,\nX-Learner, to quantify the causal impact of three GAI-assisted writing\nbehavioral patterns (i.e., seeking suggestions but not accepting them, seeking\nsuggestions and accepting them as they are, and seeking suggestions and\naccepting them with modification) on four measures of essay quality (i.e.,\nlexical sophistication, syntactic complexity, text cohesion, and linguistic\nbias). Our analysis showed that writers who frequently modified GAI-generated\ntext-suggesting active engagement in higher-order cognitive\nprocesses-consistently improved the quality of their essays in terms of lexical\nsophistication, syntactic complexity, and text cohesion. In contrast, those who\noften accepted GAI-generated text without changes, primarily engaging in\nlower-order processes, saw a decrease in essay quality. Additionally, while\nhuman writers tend to introduce linguistic bias when writing independently,\nincorporating GAI-generated text-even without modification-can help mitigate\nthis bias.\n","authors":["Kaixun Yang","Mladen Raković","Zhiping Liang","Lixiang Yan","Zijie Zeng","Yizhou Fan","Dragan Gašević","Guanliang Chen"],"pdf_url":"https://arxiv.org/pdf/2412.07200v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.16594v2","updated":"2024-12-10T05:24:37Z","published":"2024-11-25T17:28:44Z","title":"From Generation to Judgment: Opportunities and Challenges of\n  LLM-as-a-judge","summary":"  Assessment and evaluation have long been critical challenges in artificial\nintelligence (AI) and natural language processing (NLP). However, traditional\nmethods, whether matching-based or embedding-based, often fall short of judging\nsubtle attributes and delivering satisfactory results. Recent advancements in\nLarge Language Models (LLMs) inspire the \"LLM-as-a-judge\" paradigm, where LLMs\nare leveraged to perform scoring, ranking, or selection across various tasks\nand applications. This paper provides a comprehensive survey of LLM-based\njudgment and assessment, offering an in-depth overview to advance this emerging\nfield. We begin by giving detailed definitions from both input and output\nperspectives. Then we introduce a comprehensive taxonomy to explore\nLLM-as-a-judge from three dimensions: what to judge, how to judge and where to\njudge. Finally, we compile benchmarks for evaluating LLM-as-a-judge and\nhighlight key challenges and promising directions, aiming to provide valuable\ninsights and inspire future research in this promising research area. Paper\nlist and more resources about LLM-as-a-judge can be found at\n\\url{https://github.com/llm-as-a-judge/Awesome-LLM-as-a-judge} and\n\\url{https://llm-as-a-judge.github.io}.\n","authors":["Dawei Li","Bohan Jiang","Liangjie Huang","Alimohammad Beigi","Chengshuai Zhao","Zhen Tan","Amrita Bhattacharjee","Yuxuan Jiang","Canyu Chen","Tianhao Wu","Kai Shu","Lu Cheng","Huan Liu"],"pdf_url":"https://arxiv.org/pdf/2411.16594v2.pdf","comment":"v2: add missing citations; 32 pages, 5 figures"},{"id":"http://arxiv.org/abs/2412.07192v1","updated":"2024-12-10T05:00:01Z","published":"2024-12-10T05:00:01Z","title":"PrisonBreak: Jailbreaking Large Language Models with Fewer Than\n  Twenty-Five Targeted Bit-flips","summary":"  We introduce a new class of attacks on commercial-scale (human-aligned)\nlanguage models that induce jailbreaking through targeted bitwise corruptions\nin model parameters. Our adversary can jailbreak billion-parameter language\nmodels with fewer than 25 bit-flips in all cases$-$and as few as 5 in\nsome$-$using up to 40$\\times$ less bit-flips than existing attacks on computer\nvision models at least 100$\\times$ smaller. Unlike prompt-based jailbreaks, our\nattack renders these models in memory 'uncensored' at runtime, allowing them to\ngenerate harmful responses without any input modifications. Our attack\nalgorithm efficiently identifies target bits to flip, offering up to 20$\\times$\nmore computational efficiency than previous methods. This makes it practical\nfor language models with billions of parameters. We show an end-to-end\nexploitation of our attack using software-induced fault injection, Rowhammer\n(RH). Our work examines 56 DRAM RH profiles from DDR4 and LPDDR4X devices with\ndifferent RH vulnerabilities. We show that our attack can reliably induce\njailbreaking in systems similar to those affected by prior bit-flip attacks.\nMoreover, our approach remains effective even against highly RH-secure systems\n(e.g., 46$\\times$ more secure than previously tested systems). Our analyses\nfurther reveal that: (1) models with less post-training alignment require fewer\nbit flips to jailbreak; (2) certain model components, such as value projection\nlayers, are substantially more vulnerable than others; and (3) our method is\nmechanistically different than existing jailbreaks. Our findings highlight a\npressing, practical threat to the language model ecosystem and underscore the\nneed for research to protect these models from bit-flip attacks.\n","authors":["Zachary Coalson","Jeonghyun Woo","Shiyang Chen","Yu Sun","Lishan Yang","Prashant Nair","Bo Fang","Sanghyun Hong"],"pdf_url":"https://arxiv.org/pdf/2412.07192v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06575v2","updated":"2024-12-10T04:35:28Z","published":"2024-12-09T15:28:39Z","title":"Data Quality Enhancement on the Basis of Diversity with Large Language\n  Models for Text Classification: Uncovered, Difficult, and Noisy","summary":"  In recent years, the use of large language models (LLMs) for text\nclassification has attracted widespread attention. Despite this, the\nclassification accuracy of LLMs has not yet universally surpassed that of\nsmaller models. LLMs can enhance their performance in text classification\nthrough fine-tuning. However, existing data quality research based on LLMs is\nchallenging to apply directly to solve text classification problems. To further\nimprove the performance of LLMs in classification tasks, this paper proposes a\ndata quality enhancement (DQE) method for text classification based on LLMs.\nThis method starts by using a greedy algorithm to select data, dividing the\ndataset into sampled and unsampled subsets, and then performing fine-tuning of\nthe LLMs using the sampled data. Subsequently, this model is used to predict\nthe outcomes for the unsampled data, categorizing incorrectly predicted data\ninto uncovered, difficult, and noisy data. Experimental results demonstrate\nthat our method effectively enhances the performance of LLMs in text\nclassification tasks and significantly improves training efficiency, saving\nnearly half of the training time. Our method has achieved state-of-the-art\nperformance in several open-source classification tasks.\n","authors":["Min Zeng","Caiquan Liu","Shiqi Zhang","Li Xie","Chen Sang","Xiaoxin Chen"],"pdf_url":"https://arxiv.org/pdf/2412.06575v2.pdf","comment":"Accepted by COLING 2025(main, long paper)"},{"id":"http://arxiv.org/abs/2408.09640v2","updated":"2024-12-10T04:29:24Z","published":"2024-08-19T01:54:37Z","title":"Acquiring Bidirectionality via Large and Small Language Models","summary":"  Using token representation from bidirectional language models (LMs) such as\nBERT is still a widely used approach for token-classification tasks. Even\nthough there exist much larger unidirectional LMs such as Llama-2, they are\nrarely used to replace the token representation of bidirectional LMs. In this\nwork, we hypothesize that their lack of bidirectionality is keeping them\nbehind. To that end, we propose to newly train a small backward LM and\nconcatenate its representations to those of existing LM for downstream tasks.\nThrough experiments in named entity recognition, we demonstrate that\nintroducing backward model improves the benchmark performance more than 10\npoints. Furthermore, we show that the proposed method is especially effective\nfor rare domains and in few-shot learning settings.\n","authors":["Takumi Goto","Hiroyoshi Nagao","Yuta Koreeda"],"pdf_url":"https://arxiv.org/pdf/2408.09640v2.pdf","comment":"Accepted by COLING2025"},{"id":"http://arxiv.org/abs/2409.06656v2","updated":"2024-12-10T04:23:11Z","published":"2024-09-10T17:20:11Z","title":"Sortformer: Seamless Integration of Speaker Diarization and ASR by\n  Bridging Timestamps and Tokens","summary":"  We propose Sortformer, a novel neural model for speaker diarization, trained\nwith unconventional objectives compared to existing end-to-end diarization\nmodels. The permutation problem in speaker diarization has long been regarded\nas a critical challenge. Most prior end-to-end diarization systems employ\npermutation invariant loss (PIL), which optimizes for the permutation that\nyields the lowest error. In contrast, we introduce Sort Loss, which enables a\ndiarization model to autonomously resolve permutation, with or without PIL. We\ndemonstrate that combining Sort Loss and PIL achieves performance competitive\nwith state-of-the-art end-to-end diarization models trained exclusively with\nPIL. Crucially, we present a streamlined multispeaker ASR architecture that\nleverages Sortformer as a speaker supervision model, embedding speaker label\nestimation within the ASR encoder state using a sinusoidal kernel function.\nThis approach resolves the speaker permutation problem through sorted\nobjectives, effectively bridging speaker-label timestamps and speaker tokens.\nIn our experiments, we show that the proposed multispeaker ASR architecture,\nenhanced with speaker supervision, improves performance via adapter techniques.\nCode and trained models will be made publicly available via the NVIDIA NeMo\nframework.\n","authors":["Taejin Park","Ivan Medennikov","Kunal Dhawan","Weiqing Wang","He Huang","Nithin Rao Koluguri","Krishna C. Puvvada","Jagadeesh Balam","Boris Ginsburg"],"pdf_url":"https://arxiv.org/pdf/2409.06656v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07171v1","updated":"2024-12-10T04:09:29Z","published":"2024-12-10T04:09:29Z","title":"Breaking the Stage Barrier: A Novel Single-Stage Approach to Long\n  Context Extension for Large Language Models","summary":"  Recently, Large language models (LLMs) have revolutionized Natural Language\nProcessing (NLP). Pretrained LLMs, due to limited training context size,\nstruggle with handling long token sequences, limiting their performance on\nvarious downstream tasks. Current solutions toward long context modeling often\nemploy multi-stage continual pertaining, which progressively increases the\neffective context length through several continual pretraining stages. However,\nthose approaches require extensive manual tuning and human expertise. In this\npaper, we introduce a novel single-stage continual pretraining method,\nHead-Adaptive Rotary Position Encoding (HARPE), to equip LLMs with long context\nmodeling capabilities while simplifying the training process. Our HARPE\nleverages different Rotary Position Encoding (RoPE) base frequency values\nacross different attention heads and directly trains LLMs on the target context\nlength. Extensive experiments on 4 language modeling benchmarks, including the\nlatest RULER benchmark, demonstrate that HARPE excels in understanding and\nintegrating long-context tasks with single-stage training, matching and even\noutperforming existing multi-stage methods. Our results highlight that HARPE\nsuccessfully breaks the stage barrier for training LLMs with long context\nmodeling capabilities.\n","authors":["Haoran Lian","Junmin Chen","Wei Huang","Yizhe Xiong","Wenping Hu","Guiguang Ding","Hui Chen","Jianwei Niu","Zijia Lin","Fuzheng Zhang","Di Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.07171v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01812v5","updated":"2024-12-10T03:43:20Z","published":"2024-09-14T02:35:29Z","title":"From Text to Multimodality: Exploring the Evolution and Impact of Large\n  Language Models in Medical Practice","summary":"  Large Language Models (LLMs) have rapidly evolved from text-based systems to\nmultimodal platforms, significantly impacting various sectors including\nhealthcare. This comprehensive review explores the progression of LLMs to\nMultimodal Large Language Models (MLLMs) and their growing influence in medical\npractice. We examine the current landscape of MLLMs in healthcare, analyzing\ntheir applications across clinical decision support, medical imaging, patient\nengagement, and research. The review highlights the unique capabilities of\nMLLMs in integrating diverse data types, such as text, images, and audio, to\nprovide more comprehensive insights into patient health. We also address the\nchallenges facing MLLM implementation, including data limitations, technical\nhurdles, and ethical considerations. By identifying key research gaps, this\npaper aims to guide future investigations in areas such as dataset development,\nmodality alignment methods, and the establishment of ethical guidelines. As\nMLLMs continue to shape the future of healthcare, understanding their potential\nand limitations is crucial for their responsible and effective integration into\nmedical practice.\n","authors":["Qian Niu","Keyu Chen","Ming Li","Pohsun Feng","Ziqian Bi","Lawrence KQ Yan","Yichao Zhang","Caitlyn Heqi Yin","Cheng Fei","Junyu Liu","Benji Peng","Tianyang Wang","Yunze Wang","Silin Chen","Ming Liu"],"pdf_url":"https://arxiv.org/pdf/2410.01812v5.pdf","comment":"12 pages, 1 figure"},{"id":"http://arxiv.org/abs/2403.05720v4","updated":"2024-12-10T03:29:48Z","published":"2024-03-08T23:17:55Z","title":"A Dataset and Benchmark for Hospital Course Summarization with Adapted\n  Large Language Models","summary":"  Brief hospital course (BHC) summaries are clinical documents that summarize a\npatient's hospital stay. While large language models (LLMs) depict remarkable\ncapabilities in automating real-world tasks, their capabilities for healthcare\napplications such as synthesizing BHCs from clinical notes have not been shown.\nWe introduce a novel pre-processed dataset, the MIMIC-IV-BHC, encapsulating\nclinical note and brief hospital course (BHC) pairs to adapt LLMs for BHC\nsynthesis. Furthermore, we introduce a benchmark of the summarization\nperformance of two general-purpose LLMs and three healthcare-adapted LLMs.\nUsing clinical notes as input, we apply prompting-based (using in-context\nlearning) and fine-tuning-based adaptation strategies to three open-source LLMs\n(Clinical-T5-Large, Llama2-13B, FLAN-UL2) and two proprietary LLMs (GPT-3.5,\nGPT-4). We evaluate these LLMs across multiple context-length inputs using\nnatural language similarity metrics. We further conduct a clinical study with\nfive clinicians, comparing clinician-written and LLM-generated BHCs across 30\nsamples, focusing on their potential to enhance clinical decision-making\nthrough improved summary quality. We observe that the Llama2-13B fine-tuned LLM\noutperforms other domain-adapted models given quantitative evaluation metrics\nof BLEU and BERT-Score. GPT-4 with in-context learning shows more robustness to\nincreasing context lengths of clinical note inputs than fine-tuned Llama2-13B.\nDespite comparable quantitative metrics, the reader study depicts a significant\npreference for summaries generated by GPT-4 with in-context learning compared\nto both Llama2-13B fine-tuned summaries and the original summaries,\nhighlighting the need for qualitative clinical evaluation.\n","authors":["Asad Aali","Dave Van Veen","Yamin Ishraq Arefeen","Jason Hom","Christian Bluethgen","Eduardo Pontes Reis","Sergios Gatidis","Namuun Clifford","Joseph Daws","Arash S. Tehrani","Jangwon Kim","Akshay S. Chaudhari"],"pdf_url":"https://arxiv.org/pdf/2403.05720v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.05112v4","updated":"2024-12-10T03:18:41Z","published":"2024-09-08T14:45:47Z","title":"WaterSeeker: Pioneering Efficient Detection of Watermarked Segments in\n  Large Documents","summary":"  Watermarking algorithms for large language models (LLMs) have attained high\naccuracy in detecting LLM-generated text. However, existing methods primarily\nfocus on distinguishing fully watermarked text from non-watermarked text,\noverlooking real-world scenarios where LLMs generate only small sections within\nlarge documents. In this scenario, balancing time complexity and detection\nperformance poses significant challenges. This paper presents WaterSeeker, a\nnovel approach to efficiently detect and locate watermarked segments amid\nextensive natural text. It first applies an efficient anomaly extraction method\nto preliminarily locate suspicious watermarked regions. Following this, it\nconducts a local traversal and performs full-text detection for more precise\nverification. Theoretical analysis and experimental results demonstrate that\nWaterSeeker achieves a superior balance between detection accuracy and\ncomputational efficiency. Moreover, its localization capability lays the\nfoundation for building interpretable AI detection systems. Our code is\navailable at https://github.com/THU-BPM/WaterSeeker.\n","authors":["Leyi Pan","Aiwei Liu","Yijian Lu","Zitian Gao","Yichen Di","Shiyu Huang","Lijie Wen","Irwin King","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2409.05112v4.pdf","comment":"17 pages, 6 figures, 7 tables"},{"id":"http://arxiv.org/abs/2404.16767v4","updated":"2024-12-10T03:17:30Z","published":"2024-04-25T17:20:45Z","title":"REBEL: Reinforcement Learning via Regressing Relative Rewards","summary":"  While originally developed for continuous control problems, Proximal Policy\nOptimization (PPO) has emerged as the work-horse of a variety of reinforcement\nlearning (RL) applications, including the fine-tuning of generative models.\nUnfortunately, PPO requires multiple heuristics to enable stable convergence\n(e.g. value networks, clipping), and is notorious for its sensitivity to the\nprecise implementation of these components. In response, we take a step back\nand ask what a minimalist RL algorithm for the era of generative models would\nlook like. We propose REBEL, an algorithm that cleanly reduces the problem of\npolicy optimization to regressing the relative reward between two completions\nto a prompt in terms of the policy, enabling strikingly lightweight\nimplementation. In theory, we prove that fundamental RL algorithms like Natural\nPolicy Gradient can be seen as variants of REBEL, which allows us to match the\nstrongest known theoretical guarantees in terms of convergence and sample\ncomplexity in the RL literature. REBEL can also cleanly incorporate offline\ndata and be extended to handle the intransitive preferences we frequently see\nin practice. Empirically, we find that REBEL provides a unified approach to\nlanguage modeling and image generation with stronger or similar performance as\nPPO and DPO, all while being simpler to implement and more computationally\nefficient than PPO. When fine-tuning Llama-3-8B-Instruct, REBEL achieves strong\nperformance in AlpacaEval 2.0, MT-Bench, and Open LLM Leaderboard.\n","authors":["Zhaolin Gao","Jonathan D. Chang","Wenhao Zhan","Owen Oertell","Gokul Swamy","Kianté Brantley","Thorsten Joachims","J. Andrew Bagnell","Jason D. Lee","Wen Sun"],"pdf_url":"https://arxiv.org/pdf/2404.16767v4.pdf","comment":"New experimental results on general chat"},{"id":"http://arxiv.org/abs/2412.07148v1","updated":"2024-12-10T03:13:41Z","published":"2024-12-10T03:13:41Z","title":"MM-PoE: Multiple Choice Reasoning via. Process of Elimination using\n  Multi-Modal Models","summary":"  This paper introduces Multiple Choice Reasoning via. Process of Elimination\nusing Multi-Modal models, herein referred to as Multi-Modal Process of\nElimination (MM-PoE). This novel methodology is engineered to augment the\nefficacy of Vision-Language Models (VLMs) in multiple-choice visual reasoning\ntasks. Diverging from conventional approaches that evaluate each option\nindependently, MM-PoE employs a dual-step scoring paradigm that initially\nidentifies and excludes implausible choices, subsequently concentrating on the\nmost probable remaining options. This method emulates human test-taking\nstrategies, where individuals typically eliminate clearly incorrect answers\nprior to selecting the optimal response. Our empirical evaluations, conducted\nacross three benchmark datasets, reveal that MM-PoE significantly improves both\nzero-shot and few-shot performance of contemporary state-of-the-art VLMs.\nCritically, this approach not only broadens the application of the elimination\nprocess to multi-modal contexts but also allows few-shot experiments, thereby\naddressing two principal limitations concerning usage of PoE only in zero-shot\nsettings and only with a language-only framework. As a result, MM-PoE not only\nrefines the reasoning capabilities of VLMs but also broadens their\napplicability to complex visual question-answering scenarios. All code and\ndocumentation supporting our work are available at\nhttps://pypi.org/project/mm-poe/, enabling researchers and practitioners to\neasily integrate and further develop these techniques.\n","authors":["Sayak Chakrabarty","Souradip Pal"],"pdf_url":"https://arxiv.org/pdf/2412.07148v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07144v1","updated":"2024-12-10T03:06:28Z","published":"2024-12-10T03:06:28Z","title":"Political Actor Agent: Simulating Legislative System for Roll Call Votes\n  Prediction with Large Language Models","summary":"  Predicting roll call votes through modeling political actors has emerged as a\nfocus in quantitative political science and computer science. Widely used\nembedding-based methods generate vectors for legislators from diverse data sets\nto predict legislative behaviors. However, these methods often contend with\nchallenges such as the need for manually predefined features, reliance on\nextensive training data, and a lack of interpretability. Achieving more\ninterpretable predictions under flexible conditions remains an unresolved\nissue. This paper introduces the Political Actor Agent (PAA), a novel\nagent-based framework that utilizes Large Language Models to overcome these\nlimitations. By employing role-playing architectures and simulating legislative\nsystem, PAA provides a scalable and interpretable paradigm for predicting\nroll-call votes. Our approach not only enhances the accuracy of predictions but\nalso offers multi-view, human-understandable decision reasoning, providing new\ninsights into political actor behaviors. We conducted comprehensive experiments\nusing voting records from the 117-118th U.S. House of Representatives,\nvalidating the superior performance and interpretability of PAA. This study not\nonly demonstrates PAA's effectiveness but also its potential in political\nscience research.\n","authors":["Hao Li","Ruoyuan Gong","Hao Jiang"],"pdf_url":"https://arxiv.org/pdf/2412.07144v1.pdf","comment":"Accepted at AAAI 2025"},{"id":"http://arxiv.org/abs/2409.13199v2","updated":"2024-12-10T02:55:21Z","published":"2024-09-20T04:03:27Z","title":"CFSP: An Efficient Structured Pruning Framework for LLMs with\n  Coarse-to-Fine Activation Information","summary":"  The colossal parameters and computational overhead of Large Language Models\n(LLMs) challenge their real-world applications. Network pruning, which targets\nunstructured or structured sparsity by removing redundant parameters, has\nrecently been explored for LLM acceleration. Existing LLM pruning works focus\non unstructured pruning, which typically requires special hardware support for\na practical speed-up. In contrast, structured pruning can reduce latency on\ngeneral devices. However, it remains a challenge to perform structured pruning\nefficiently and maintain performance, especially at high sparsity ratios. To\nthis end, we introduce an efficient structured pruning framework named CFSP,\nwhich leverages both Coarse (interblock) and Fine-grained (intrablock)\nactivation information as an importance criterion to guide pruning. The pruning\nis highly efficient, as it only requires one forward pass to compute feature\nactivations. Specifically, we first allocate the sparsity budget across blocks\nbased on their importance and then retain important weights within each block.\nIn addition, we introduce a recovery fine-tuning strategy that adaptively\nallocates training overhead based on coarse-grained importance to further\nimprove performance. Experimental results demonstrate that CFSP outperforms\nexisting methods on diverse models across various sparsity budgets. Our code\nwill be available at https://github.com/wyxscir/CFSP.\n","authors":["Yuxin Wang","Minghua Ma","Zekun Wang","Jingchang Chen","Huiming Fan","Liping Shan","Qing Yang","Dongliang Xu","Ming Liu","Bing Qin"],"pdf_url":"https://arxiv.org/pdf/2409.13199v2.pdf","comment":"Proc. The 31st International Conference on Computational Linguistics\n  (COLING2025)"},{"id":"http://arxiv.org/abs/2311.02192v3","updated":"2024-12-10T02:39:39Z","published":"2023-11-03T18:49:05Z","title":"Automating Governing Knowledge Commons and Contextual Integrity (GKC-CI)\n  Privacy Policy Annotations with Large Language Models","summary":"  Identifying contextual integrity (CI) and governing knowledge commons (GKC)\nparameters in privacy policy texts can facilitate normative privacy analysis.\nHowever, GKC-CI annotation has heretofore required manual or crowdsourced\neffort. This paper demonstrates that high-accuracy GKC-CI parameter annotation\nof privacy policies can be performed automatically using large language models.\nWe fine-tune 50 open-source and proprietary models on 21,588 ground truth\nGKC-CI annotations from 16 privacy policies. Our best performing model has an\naccuracy of 90.65%, which is comparable to the accuracy of experts on the same\ntask. We apply our best performing model to 456 privacy policies from a variety\nof online services, demonstrating the effectiveness of scaling GKC-CI\nannotation for privacy policy exploration and analysis. We publicly release our\nmodel training code, training and testing data, an annotation visualizer, and\nall annotated policies for future GKC-CI research.\n","authors":["Jake Chanenson","Madison Pickering","Noah Apthorpe"],"pdf_url":"https://arxiv.org/pdf/2311.02192v3.pdf","comment":"29 pages, 18 figures, 11 tables; camera-ready version"},{"id":"http://arxiv.org/abs/2309.00178v2","updated":"2024-12-10T02:34:44Z","published":"2023-09-01T00:11:56Z","title":"Will sentiment analysis need subculture? A new data augmentation\n  approach","summary":"  Nowadays, the omnipresence of the Internet has fostered a subculture that\ncongregates around the contemporary milieu. The subculture artfully articulates\nthe intricacies of human feelings by ardently pursuing the allure of novelty, a\nfact that cannot be disregarded in the sentiment analysis. This paper aims to\nenrich data through the lens of subculture, to address the insufficient\ntraining data faced by sentiment analysis. To this end, a new approach of\nsubculture-based data augmentation (SCDA) is proposed, which engenders enhanced\ntexts for each training text by leveraging the creation of specific subcultural\nexpression generators. The extensive experiments attest to the effectiveness\nand potential of SCDA. The results also shed light on the phenomenon that\ndisparate subcultural expressions elicit varying degrees of sentiment\nstimulation. Moreover, an intriguing conjecture arises, suggesting the linear\nreversibility of certain subcultural expressions.\n","authors":["Zhenhua Wang","Simin He","Guang Xu","Ming Ren"],"pdf_url":"https://arxiv.org/pdf/2309.00178v2.pdf","comment":"JASIST"},{"id":"http://arxiv.org/abs/2412.07121v1","updated":"2024-12-10T02:26:33Z","published":"2024-12-10T02:26:33Z","title":"Bridging the Gap for Test-Time Multimodal Sentiment Analysis","summary":"  Multimodal sentiment analysis (MSA) is an emerging research topic that aims\nto understand and recognize human sentiment or emotions through multiple\nmodalities. However, in real-world dynamic scenarios, the distribution of\ntarget data is always changing and different from the source data used to train\nthe model, which leads to performance degradation. Common adaptation methods\nusually need source data, which could pose privacy issues or storage overheads.\nTherefore, test-time adaptation (TTA) methods are introduced to improve the\nperformance of the model at inference time. Existing TTA methods are always\nbased on probabilistic models and unimodal learning, and thus can not be\napplied to MSA which is often considered as a multimodal regression task. In\nthis paper, we propose two strategies: Contrastive Adaptation and Stable\nPseudo-label generation (CASP) for test-time adaptation for multimodal\nsentiment analysis. The two strategies deal with the distribution shifts for\nMSA by enforcing consistency and minimizing empirical risk, respectively.\nExtensive experiments show that CASP brings significant and consistent\nimprovements to the performance of the model across various distribution shift\nsettings and with different backbones, demonstrating its effectiveness and\nversatility. Our codes are available at https://github.com/zrguo/CASP.\n","authors":["Zirun Guo","Tao Jin","Wenlong Xu","Wang Lin","Yangyang Wu"],"pdf_url":"https://arxiv.org/pdf/2412.07121v1.pdf","comment":"Accepted to AAAI 2025"},{"id":"http://arxiv.org/abs/2412.07116v1","updated":"2024-12-10T02:06:10Z","published":"2024-12-10T02:06:10Z","title":"A Review of Human Emotion Synthesis Based on Generative Technology","summary":"  Human emotion synthesis is a crucial aspect of affective computing. It\ninvolves using computational methods to mimic and convey human emotions through\nvarious modalities, with the goal of enabling more natural and effective\nhuman-computer interactions. Recent advancements in generative models, such as\nAutoencoders, Generative Adversarial Networks, Diffusion Models, Large Language\nModels, and Sequence-to-Sequence Models, have significantly contributed to the\ndevelopment of this field. However, there is a notable lack of comprehensive\nreviews in this field. To address this problem, this paper aims to address this\ngap by providing a thorough and systematic overview of recent advancements in\nhuman emotion synthesis based on generative models. Specifically, this review\nwill first present the review methodology, the emotion models involved, the\nmathematical principles of generative models, and the datasets used. Then, the\nreview covers the application of different generative models to emotion\nsynthesis based on a variety of modalities, including facial images, speech,\nand text. It also examines mainstream evaluation metrics. Additionally, the\nreview presents some major findings and suggests future research directions,\nproviding a comprehensive understanding of the role of generative technology in\nthe nuanced domain of emotion synthesis.\n","authors":["Fei Ma","Yukan Li","Yifan Xie","Ying He","Yi Zhang","Hongwei Ren","Zhou Liu","Wei Yao","Fuji Ren","Fei Richard Yu","Shiguang Ni"],"pdf_url":"https://arxiv.org/pdf/2412.07116v1.pdf","comment":"25 pages, 10 figures"},{"id":"http://arxiv.org/abs/2412.07113v1","updated":"2024-12-10T02:03:24Z","published":"2024-12-10T02:03:24Z","title":"Exploring Coding Spot: Understanding Parametric Contributions to LLM\n  Coding Performance","summary":"  Large Language Models (LLMs) have demonstrated notable proficiency in both\ncode generation and comprehension across multiple programming languages.\nHowever, the mechanisms underlying this proficiency remain underexplored,\nparticularly with respect to whether distinct programming languages are\nprocessed independently or within a shared parametric region. Drawing an\nanalogy to the specialized regions of the brain responsible for distinct\ncognitive functions, we introduce the concept of Coding Spot, a specialized\nparametric region within LLMs that facilitates coding capabilities. Our\nfindings identify this Coding Spot and show that targeted modifications to this\nsubset significantly affect performance on coding tasks, while largely\npreserving non-coding functionalities. This compartmentalization mirrors the\nfunctional specialization observed in cognitive neuroscience, where specific\nbrain regions are dedicated to distinct tasks, suggesting that LLMs may\nsimilarly employ specialized parameter regions for different knowledge domains.\n","authors":["Dongjun Kim","Minhyuk Kim","YongChan Chun","Chanjun Park","Heuiseok Lim"],"pdf_url":"https://arxiv.org/pdf/2412.07113v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07112v1","updated":"2024-12-10T01:57:17Z","published":"2024-12-10T01:57:17Z","title":"Maya: An Instruction Finetuned Multilingual Multimodal Model","summary":"  The rapid development of large Vision-Language Models (VLMs) has led to\nimpressive results on academic benchmarks, primarily in widely spoken\nlanguages. However, significant gaps remain in the ability of current VLMs to\nhandle low-resource languages and varied cultural contexts, largely due to a\nlack of high-quality, diverse, and safety-vetted data. Consequently, these\nmodels often struggle to understand low-resource languages and cultural nuances\nin a manner free from toxicity. To address these limitations, we introduce\nMaya, an open-source Multimodal Multilingual model. Our contributions are\nthreefold: 1) a multilingual image-text pretraining dataset in eight languages,\nbased on the LLaVA pretraining dataset; 2) a thorough analysis of toxicity\nwithin the LLaVA dataset, followed by the creation of a novel toxicity-free\nversion across eight languages; and 3) a multilingual image-text model\nsupporting these languages, enhancing cultural and linguistic comprehension in\nvision-language tasks. Code available at https://github.com/nahidalam/maya.\n","authors":["Nahid Alam","Karthik Reddy Kanjula","Surya Guthikonda","Timothy Chung","Bala Krishna S Vegesna","Abhipsha Das","Anthony Susevski","Ryan Sze-Yin Chan","S M Iftekhar Uddin","Shayekh Bin Islam","Roshan Santhosh","Snegha A","Drishti Sharma","Chen Liu","Isha Chaturvedi","Genta Indra Winata","Ashvanth. S","Snehanshu Mukherjee","Alham Fikri Aji"],"pdf_url":"https://arxiv.org/pdf/2412.07112v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07111v1","updated":"2024-12-10T01:56:30Z","published":"2024-12-10T01:56:30Z","title":"Predictable Emergent Abilities of LLMs: Proxy Tasks Are All You Need","summary":"  While scaling laws optimize training configurations for large language models\n(LLMs) through experiments on smaller or early-stage models, they fail to\npredict emergent abilities due to the absence of such capabilities in these\nmodels. To address this, we propose a method that predicts emergent abilities\nby leveraging proxy tasks. We begin by establishing relevance metrics between\nthe target task and candidate tasks based on performance differences across\nmultiple models. These candidate tasks are then validated for robustness with\nsmall model ensembles, leading to the selection of the most appropriate proxy\ntasks. The predicted performance on the target task is then derived by\nintegrating the evaluation results of these proxies. In a case study on tool\nutilization capabilities, our method demonstrated a strong correlation between\npredicted and actual performance, confirming its effectiveness.\n","authors":["Bo-Wen Zhang","Yan Yan","Boxiang Yang","Yifei Xue","Guang Liu"],"pdf_url":"https://arxiv.org/pdf/2412.07111v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07108v1","updated":"2024-12-10T01:49:23Z","published":"2024-12-10T01:49:23Z","title":"Improving the Natural Language Inference robustness to hard dataset by\n  data augmentation and preprocessing","summary":"  Natural Language Inference (NLI) is the task of inferring whether the\nhypothesis can be justified by the given premise. Basically, we classify the\nhypothesis into three labels(entailment, neutrality and contradiction) given\nthe premise. NLI was well studied by the previous researchers. A number of\nmodels, especially the transformer based ones, have achieved significant\nimprovement on these tasks. However, it is reported that these models are\nsuffering when they are dealing with hard datasets. Particularly, they perform\nmuch worse when dealing with unseen out-of-distribution premise and hypothesis.\nThey may not understand the semantic content but learn the spurious\ncorrelations. In this work, we propose the data augmentation and preprocessing\nmethods to solve the word overlap, numerical reasoning and length mismatch\nproblems. These methods are general methods that do not rely on the\ndistribution of the testing data and they help improve the robustness of the\nmodels.\n","authors":["Zijiang Yang"],"pdf_url":"https://arxiv.org/pdf/2412.07108v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07096v1","updated":"2024-12-10T01:29:51Z","published":"2024-12-10T01:29:51Z","title":"QAPyramid: Fine-grained Evaluation of Content Selection for Text\n  Summarization","summary":"  How to properly conduct human evaluations for text summarization is a\nlongstanding challenge. The Pyramid human evaluation protocol, which assesses\ncontent selection by breaking the reference summary into sub-units and\nverifying their presence in the system summary, has been widely adopted.\nHowever, it suffers from a lack of systematicity in the definition and\ngranularity of the sub-units. We address these problems by proposing QAPyramid,\nwhich decomposes each reference summary into finer-grained question-answer (QA)\npairs according to the QA-SRL framework. We collect QA-SRL annotations for\nreference summaries from CNN/DM and evaluate 10 summarization systems,\nresulting in 8.9K QA-level annotations. We show that, compared to Pyramid,\nQAPyramid provides more systematic and fine-grained content selection\nevaluation while maintaining high inter-annotator agreement without needing\nexpert annotations. Furthermore, we propose metrics that automate the\nevaluation pipeline and achieve higher correlations with QAPyramid than other\nwidely adopted metrics, allowing future work to accurately and efficiently\nbenchmark summarization systems.\n","authors":["Shiyue Zhang","David Wan","Arie Cattan","Ayal Klein","Ido Dagan","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2412.07096v1.pdf","comment":"The first two authors contributed equally. Code:\n  https://github.com/ZhangShiyue/QAPyramid"},{"id":"http://arxiv.org/abs/2408.08964v3","updated":"2024-12-10T01:12:21Z","published":"2024-08-16T18:30:22Z","title":"BnSentMix: A Diverse Bengali-English Code-Mixed Dataset for Sentiment\n  Analysis","summary":"  The widespread availability of code-mixed data can provide valuable insights\ninto low-resource languages like Bengali, which have limited datasets.\nSentiment analysis has been a fundamental text classification task across\nseveral languages for code-mixed data. However, there has yet to be a\nlarge-scale and diverse sentiment analysis dataset on code-mixed Bengali. We\naddress this limitation by introducing BnSentMix, a sentiment analysis dataset\non code-mixed Bengali consisting of 20,000 samples with 4 sentiment labels from\nFacebook, YouTube, and e-commerce sites. We ensure diversity in data sources to\nreplicate realistic code-mixed scenarios. Additionally, we propose 14 baseline\nmethods including novel transformer encoders further pre-trained on code-mixed\nBengali-English, achieving an overall accuracy of 69.8% and an F1 score of\n69.1% on sentiment classification tasks. Detailed analyses reveal variations in\nperformance across different sentiment labels and text types, highlighting\nareas for future improvement.\n","authors":["Sadia Alam","Md Farhan Ishmam","Navid Hasin Alvee","Md Shahnewaz Siddique","Md Azam Hossain","Abu Raihan Mostofa Kamal"],"pdf_url":"https://arxiv.org/pdf/2408.08964v3.pdf","comment":"LoResLM at COLING 2025"},{"id":"http://arxiv.org/abs/2412.07078v1","updated":"2024-12-10T00:41:25Z","published":"2024-12-10T00:41:25Z","title":"Defensive Dual Masking for Robust Adversarial Defense","summary":"  The field of textual adversarial defenses has gained considerable attention\nin recent years due to the increasing vulnerability of natural language\nprocessing (NLP) models to adversarial attacks, which exploit subtle\nperturbations in input text to deceive models. This paper introduces the\nDefensive Dual Masking (DDM) algorithm, a novel approach designed to enhance\nmodel robustness against such attacks. DDM utilizes a unique adversarial\ntraining strategy where [MASK] tokens are strategically inserted into training\nsamples to prepare the model to handle adversarial perturbations more\neffectively. During inference, potentially adversarial tokens are dynamically\nreplaced with [MASK] tokens to neutralize potential threats while preserving\nthe core semantics of the input. The theoretical foundation of our approach is\nexplored, demonstrating how the selective masking mechanism strengthens the\nmodel's ability to identify and mitigate adversarial manipulations. Our\nempirical evaluation across a diverse set of benchmark datasets and attack\nmechanisms consistently shows that DDM outperforms state-of-the-art defense\ntechniques, improving model accuracy and robustness. Moreover, when applied to\nLarge Language Models (LLMs), DDM also enhances their resilience to adversarial\nattacks, providing a scalable defense mechanism for large-scale NLP\napplications.\n","authors":["Wangli Yang","Jie Yang","Yi Guo","Johan Barthelemy"],"pdf_url":"https://arxiv.org/pdf/2412.07078v1.pdf","comment":"First version"},{"id":"http://arxiv.org/abs/2412.02605v2","updated":"2024-12-10T23:41:53Z","published":"2024-12-03T17:34:50Z","title":"Interpretable Company Similarity with Sparse Autoencoders","summary":"  Determining company similarity is a vital task in finance, underpinning\nhedging, risk management, portfolio diversification, and more. Practitioners\noften rely on sector and industry classifications to gauge similarity, such as\nSIC-codes and GICS-codes - the former being used by the U.S. Securities and\nExchange Commission (SEC), and the latter widely used by the investment\ncommunity. Since these classifications can lack granularity and often need to\nbe updated, using clusters of embeddings of company descriptions has been\nproposed as a potential alternative, but the lack of interpretability in token\nembeddings poses a significant barrier to adoption in high-stakes contexts.\nSparse Autoencoders (SAEs) have shown promise in enhancing the interpretability\nof Large Language Models (LLMs) by decomposing LLM activations into\ninterpretable features. We apply SAEs to company descriptions, obtaining\nmeaningful clusters of equities in the process. We benchmark SAE features\nagainst SIC-codes, Major Group codes, and Embeddings. Our results demonstrate\nthat SAE features not only replicate but often surpass sector classifications\nand embeddings in capturing fundamental company characteristics. This is\nevidenced by their superior performance in correlating monthly returns - a\nproxy for similarity - and generating higher Sharpe ratio co-integration\nstrategies, which underscores deeper fundamental similarities among companies.\n","authors":["Marco Molinari","Victor Shao","Vladimir Tregubiak","Abhimanyu Pandey","Mateusz Mikolajczak","Sebastian Kuznetsov Ryder Torres Pereira"],"pdf_url":"https://arxiv.org/pdf/2412.02605v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07975v1","updated":"2024-12-10T23:23:28Z","published":"2024-12-10T23:23:28Z","title":"Machines of Meaning","summary":"  One goal of Artificial Intelligence is to learn meaningful representations\nfor natural language expressions, but what this entails is not always clear. A\nvariety of new linguistic behaviours present themselves embodied as computers,\nenhanced humans, and collectives with various kinds of integration and\ncommunication. But to measure and understand the behaviours generated by such\nsystems, we must clarify the language we use to talk about them. Computational\nmodels are often confused with the phenomena they try to model and shallow\nmetaphors are used as justifications for (or to hype) the success of\ncomputational techniques on many tasks related to natural language; thus\nimplying their progress toward human-level machine intelligence without ever\nclarifying what that means.\n  This paper discusses the challenges in the specification of \"machines of\nmeaning\", machines capable of acquiring meaningful semantics from natural\nlanguage in order to achieve their goals. We characterize \"meaning\" in a\ncomputational setting, while highlighting the need for detachment from\nanthropocentrism in the study of the behaviour of machines of meaning. The\npressing need to analyse AI risks and ethics requires a proper measurement of\nits capabilities which cannot be productively studied and explained while using\nambiguous language. We propose a view of \"meaning\" to facilitate the discourse\naround approaches such as neural language models and help broaden the research\nperspectives for technology that facilitates dialogues between humans and\nmachines.\n","authors":["Davide Nunes","Luis Antunes"],"pdf_url":"https://arxiv.org/pdf/2412.07975v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07965v1","updated":"2024-12-10T23:09:02Z","published":"2024-12-10T23:09:02Z","title":"HalluCana: Fixing LLM Hallucination with A Canary Lookahead","summary":"  In this paper, we present HalluCana, a canary lookahead to detect and correct\nfactuality hallucinations of Large Language Models (LLMs) in long-form\ngeneration. HalluCana detects and intervenes as soon as traces of hallucination\nemerge, during and even before generation. To support timely detection, we\nexploit the internal factuality representation in the LLM hidden space, where\nwe investigate various proxies to the LLMs' factuality self-assessment, and\ndiscuss its relation to the models' context familiarity from their\npre-training. On biography generation, our method improves generation quality\nby up to 2.5x, while consuming over 6 times less compute.\n","authors":["Tianyi Li","Erenay Dayanik","Shubhi Tyagi","Andrea Pierleoni"],"pdf_url":"https://arxiv.org/pdf/2412.07965v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.07921v2","updated":"2024-12-10T23:01:28Z","published":"2024-02-28T03:20:27Z","title":"Merino: Entropy-driven Design for Generative Language Models on IoT\n  Devices","summary":"  Generative Large Language Models (LLMs) stand as a revolutionary advancement\nin the modern era of artificial intelligence (AI). However, scaling down LLMs\nfor resource-constrained hardware, such as Internet-of-Things (IoT) devices\nrequires non-trivial efforts and domain knowledge. In this paper, we propose a\nnovel information-entropy framework for designing mobile-friendly generative\nlanguage models. The whole design procedure involves solving a mathematical\nprogramming (MP) problem, which can be done on the CPU within minutes, making\nit nearly zero-cost. We evaluate our designed models, termed MeRino, across\nfourteen NLP downstream tasks, showing their competitive performance against\nthe state-of-the-art autoregressive transformer models under the mobile\nsetting. Notably, MeRino achieves similar or better performance on both\nlanguage modeling and zero-shot learning tasks, compared to the 350M parameter\nOPT while being 4.9x faster on NVIDIA Jetson Nano with 5.5x reduction in model\nsize.\n","authors":["Youpeng Zhao","Ming Lin","Huadong Tang","Qiang Wu","Jun Wang"],"pdf_url":"https://arxiv.org/pdf/2403.07921v2.pdf","comment":"AAAI 2025"},{"id":"http://arxiv.org/abs/2412.07961v1","updated":"2024-12-10T22:57:57Z","published":"2024-12-10T22:57:57Z","title":"Forking Paths in Neural Text Generation","summary":"  Estimating uncertainty in Large Language Models (LLMs) is important for\nproperly evaluating LLMs, and ensuring safety for users. However, prior\napproaches to uncertainty estimation focus on the final answer in generated\ntext, ignoring intermediate steps that might dramatically impact the outcome.\nWe hypothesize that there exist key forking tokens, such that re-sampling the\nsystem at those specific tokens, but not others, leads to very different\noutcomes. To test this empirically, we develop a novel approach to representing\nuncertainty dynamics across individual tokens of text generation, and applying\nstatistical models to test our hypothesis. Our approach is highly flexible: it\ncan be applied to any dataset and any LLM, without fine tuning or accessing\nmodel weights. We use our method to analyze LLM responses on 7 different tasks\nacross 4 domains, spanning a wide range of typical use cases. We find many\nexamples of forking tokens, including surprising ones such as punctuation\nmarks, suggesting that LLMs are often just a single token away from saying\nsomething very different.\n","authors":["Eric Bigelow","Ari Holtzman","Hidenori Tanaka","Tomer Ullman"],"pdf_url":"https://arxiv.org/pdf/2412.07961v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07940v1","updated":"2024-12-10T21:57:32Z","published":"2024-12-10T21:57:32Z","title":"HEDS 3.0: The Human Evaluation Data Sheet Version 3.0","summary":"  This paper presents version 3.0 of the Human Evaluation Datasheet (HEDS).\nThis update is the result of our experience using HEDS in the context of\nnumerous recent human evaluation experiments, including reproduction studies,\nand of feedback received. Our main overall goal was to improve clarity, and to\nenable users to complete the datasheet more consistently and comparably. The\nHEDS 3.0 package consists of the digital data sheet, documentation, and code\nfor exporting completed data sheets as latex files, all available from the HEDS\nGitHub.\n","authors":["Anya Belz","Craig Thomson"],"pdf_url":"https://arxiv.org/pdf/2412.07940v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2103.09710"},{"id":"http://arxiv.org/abs/2406.14498v2","updated":"2024-12-10T21:52:35Z","published":"2024-06-20T17:00:34Z","title":"LLaSA: A Multimodal LLM for Human Activity Analysis Through Wearable and\n  Smartphone Sensors","summary":"  Integrating inertial measurement units (IMUs) with large language models\n(LLMs) expands the potential of multimodal AI, enabling more nuanced human\nactivity analysis. In this paper, we introduce LLaSA (Large Language and Sensor\nAssistant), a multimodal large language model built on LIMU-BERT and Llama,\ndesigned to interpret and answer queries related to human activities and motion\nanalysis, leveraging sensor data and contextual reasoning. To develop LLaSA, we\nintroduce two key datasets: SensorCaps, a comprehensive collection of 35,960\nIMU-derived narratives with handcrafted features, and OpenSQA, an\ninstruction-following dataset containing 179,727 question-answer pairs aware of\nthe sensor and human activity context. These datasets provide diverse and rich\ninputs to train LLaSA for complex sensor-based queries. To optimize LLaSA's\nperformance, we apply a unique hyperparameter tuning method, which\nsignificantly enhances its effectiveness in contextual question-answering\ntasks. Extensive evaluations, including a human-led assessment of the\nquestion-answering, demonstrate that LLaSA achieves superior data\ninterpretation and context-aware responses compared to GPT-3.5-Turbo and\nVicuna-1.5-13b-16K. These contributions advance the frontier of sensor-aware\nLLMs and create new opportunities for impactful multimodal research in\nhealthcare, sports science, and human-computer interactions. Our code\nrepository and datasets can be found at https://github.com/BASHLab/LLaSA.\n","authors":["Sheikh Asif Imran","Mohammad Nur Hossain Khan","Subrata Biswas","Bashima Islam"],"pdf_url":"https://arxiv.org/pdf/2406.14498v2.pdf","comment":"Under review at SenSys 2025"},{"id":"http://arxiv.org/abs/2412.07937v1","updated":"2024-12-10T21:47:15Z","published":"2024-12-10T21:47:15Z","title":"Style-agnostic evaluation of ASR using multiple reference transcripts","summary":"  Word error rate (WER) as a metric has a variety of limitations that have\nplagued the field of speech recognition. Evaluation datasets suffer from\nvarying style, formality, and inherent ambiguity of the transcription task. In\nthis work, we attempt to mitigate some of these differences by performing\nstyle-agnostic evaluation of ASR systems using multiple references transcribed\nunder opposing style parameters. As a result, we find that existing WER reports\nare likely significantly over-estimating the number of contentful errors made\nby state-of-the-art ASR systems. In addition, we have found our multireference\nmethod to be a useful mechanism for comparing the quality of ASR models that\ndiffer in the stylistic makeup of their training data and target task.\n","authors":["Quinten McNamara","Miguel Ángel del Río Fernández","Nishchal Bhandari","Martin Ratajczak","Danny Chen","Corey Miller","Migüel Jetté"],"pdf_url":"https://arxiv.org/pdf/2412.07937v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07923v1","updated":"2024-12-10T21:09:12Z","published":"2024-12-10T21:09:12Z","title":"Asking Again and Again: Exploring LLM Robustness to Repeated Questions","summary":"  This study examines whether large language models (LLMs), such as ChatGPT,\nspecifically the latest GPT-4o-mini, exhibit sensitivity to repeated prompts\nand whether repeating a question can improve response accuracy. We hypothesize\nthat reiterating a question within a single prompt might enhance the model's\nfocus on key elements of the query. To test this, we evaluate ChatGPT's\nperformance on a large sample of two reading comprehension datasets under both\nopen-book and closed-book settings, varying the repetition of each question to\n1, 3, or 5 times per prompt. Our findings indicate that the model does not\ndemonstrate sensitivity to repeated questions, highlighting its robustness and\nconsistency in this context.\n","authors":["Sagi Shaier"],"pdf_url":"https://arxiv.org/pdf/2412.07923v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.16490v2","updated":"2024-12-10T21:04:59Z","published":"2024-09-24T22:31:39Z","title":"Exploring Knowledge Tracing in Tutor-Student Dialogues using LLMs","summary":"  Recent advances in large language models (LLMs) have led to the development\nof artificial intelligence (AI)-powered tutoring chatbots, showing promise in\nproviding broad access to high-quality personalized education. Existing works\nhave studied how to make LLMs follow tutoring principles, but have not studied\nbroader uses of LLMs for supporting tutoring. Up until now, tracing student\nknowledge and analyzing misconceptions has been difficult and time-consuming to\nimplement for open-ended dialogue tutoring. In this work, we investigate\nwhether LLMs can be supportive of this task: we first use LLM prompting methods\nto identify the knowledge components/skills involved in each dialogue turn,\ni.e., a tutor utterance posing a task or a student utterance that responds to\nit. We also evaluate whether the student responds correctly to the tutor and\nverify the LLM's accuracy using human expert annotations. We then apply a range\nof knowledge tracing (KT) methods on the resulting labeled data to track\nstudent knowledge levels over an entire dialogue. We conduct experiments on two\ntutoring dialogue datasets, and show that a novel yet simple LLM-based method,\nLLMKT, significantly outperforms existing KT methods in predicting student\nresponse correctness in dialogues. We perform extensive qualitative analyses to\nhighlight the challenges in dialogueKT and outline multiple avenues for future\nwork.\n","authors":["Alexander Scarlatos","Ryan S. Baker","Andrew Lan"],"pdf_url":"https://arxiv.org/pdf/2409.16490v2.pdf","comment":"Published in LAK 2025: The 15th International Learning Analytics and\n  Knowledge Conference"},{"id":"http://arxiv.org/abs/2412.07919v1","updated":"2024-12-10T21:04:56Z","published":"2024-12-10T21:04:56Z","title":"Identifying Quantum Mechanical Statistics in Italian Corpora","summary":"  We present a theoretical and empirical investigation of the statistical\nbehaviour of the words in a text produced by human language. To this aim, we\nanalyse the word distribution of various texts of Italian language selected\nfrom a specific literary corpus. We firstly generalise a theoretical framework\nelaborated by ourselves to identify 'quantum mechanical statistics' in\nlarge-size texts. Then, we show that, in all analysed texts, words distribute\naccording to 'Bose--Einstein statistics' and show significant deviations from\n'Maxwell--Boltzmann statistics'. Next, we introduce an effect of 'word\nrandomization' which instead indicates that the difference between the two\nstatistical models is not as pronounced as in the original cases. These results\nconfirm the empirical patterns obtained in texts of English language and\nstrongly indicate that identical words tend to 'clump together' as a\nconsequence of their meaning, which can be explained as an effect of 'quantum\nentanglement' produced through a phenomenon of 'contextual updating'. More,\nword randomization can be seen as the linguistic-conceptual equivalent of an\nincrease of temperature which destroys 'coherence' and makes classical\nstatistics prevail over quantum statistics. Some insights into the origin of\nquantum statistics in physics are finally provided.\n","authors":["Diederik Aerts","Jonito Aerts Arguëlles","Lester Beltran","Massimiliano Sassoli de Bianchi","Sandro Sozzo"],"pdf_url":"https://arxiv.org/pdf/2412.07919v1.pdf","comment":"21 pages, 6 figures"},{"id":"http://arxiv.org/abs/2412.07906v1","updated":"2024-12-10T20:30:51Z","published":"2024-12-10T20:30:51Z","title":"Rethinking Emotion Annotations in the Era of Large Language Models","summary":"  Modern affective computing systems rely heavily on datasets with\nhuman-annotated emotion labels, for training and evaluation. However, human\nannotations are expensive to obtain, sensitive to study design, and difficult\nto quality control, because of the subjective nature of emotions. Meanwhile,\nLarge Language Models (LLMs) have shown remarkable performance on many Natural\nLanguage Understanding tasks, emerging as a promising tool for text annotation.\nIn this work, we analyze the complexities of emotion annotation in the context\nof LLMs, focusing on GPT-4 as a leading model. In our experiments, GPT-4\nachieves high ratings in a human evaluation study, painting a more positive\npicture than previous work, in which human labels served as the only ground\ntruth. On the other hand, we observe differences between human and GPT-4\nemotion perception, underscoring the importance of human input in annotation\nstudies. To harness GPT-4's strength while preserving human perspective, we\nexplore two ways of integrating GPT-4 into emotion annotation pipelines,\nshowing its potential to flag low-quality labels, reduce the workload of human\nannotators, and improve downstream model learning performance and efficiency.\nTogether, our findings highlight opportunities for new emotion labeling\npractices and suggest the use of LLMs as a promising tool to aid human\nannotation.\n","authors":["Minxue Niu","Yara El-Tawil","Amrit Romana","Emily Mower Provost"],"pdf_url":"https://arxiv.org/pdf/2412.07906v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.06237v3","updated":"2024-12-10T20:23:44Z","published":"2023-11-10T18:52:58Z","title":"Summon a Demon and Bind it: A Grounded Theory of LLM Red Teaming","summary":"  Engaging in the deliberate generation of abnormal outputs from Large Language\nModels (LLMs) by attacking them is a novel human activity. This paper presents\na thorough exposition of how and why people perform such attacks, defining LLM\nred-teaming based on extensive and diverse evidence. Using a formal qualitative\nmethodology, we interviewed dozens of practitioners from a broad range of\nbackgrounds, all contributors to this novel work of attempting to cause LLMs to\nfail. We focused on the research questions of defining LLM red teaming,\nuncovering the motivations and goals for performing the activity, and\ncharacterizing the strategies people use when attacking LLMs. Based on the\ndata, LLM red teaming is defined as a limit-seeking, non-malicious, manual\nactivity, which depends highly on a team-effort and an alchemist mindset. It is\nhighly intrinsically motivated by curiosity, fun, and to some degrees by\nconcerns for various harms of deploying LLMs. We identify a taxonomy of 12\nstrategies and 35 different techniques of attacking LLMs. These findings are\npresented as a comprehensive grounded theory of how and why people attack large\nlanguage models: LLM red teaming.\n","authors":["Nanna Inie","Jonathan Stray","Leon Derczynski"],"pdf_url":"https://arxiv.org/pdf/2311.06237v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.13253v2","updated":"2024-12-10T20:19:18Z","published":"2024-02-20T18:59:26Z","title":"BiMediX: Bilingual Medical Mixture of Experts LLM","summary":"  In this paper, we introduce BiMediX, the first bilingual medical mixture of\nexperts LLM designed for seamless interaction in both English and Arabic. Our\nmodel facilitates a wide range of medical interactions in English and Arabic,\nincluding multi-turn chats to inquire about additional details such as patient\nsymptoms and medical history, multiple-choice question answering, and\nopen-ended question answering. We propose a semi-automated English-to-Arabic\ntranslation pipeline with human refinement to ensure high-quality translations.\nWe also introduce a comprehensive evaluation benchmark for Arabic medical LLMs.\nFurthermore, we introduce BiMed1.3M, an extensive Arabic-English bilingual\ninstruction set covering 1.3 Million diverse medical interactions, resulting in\nover 632 million healthcare specialized tokens for instruction tuning. Our\nBiMed1.3M dataset includes 250k synthesized multi-turn doctor-patient chats and\nmaintains a 1:2 Arabic-to-English ratio. Our model outperforms state-of-the-art\nMed42 and Meditron by average absolute gains of 2.5% and 4.1%, respectively,\ncomputed across multiple medical evaluation benchmarks in English, while\noperating at 8-times faster inference. Moreover, our BiMediX outperforms the\ngeneric Arabic-English bilingual LLM, Jais-30B, by average absolute gains of\n10% on our Arabic medical benchmark and 15% on bilingual evaluations across\nmultiple datasets. Our project page with source code and trained model is\navailable at https://github.com/mbzuai-oryx/BiMediX .\n","authors":["Sara Pieri","Sahal Shaji Mullappilly","Fahad Shahbaz Khan","Rao Muhammad Anwer","Salman Khan","Timothy Baldwin","Hisham Cholakkal"],"pdf_url":"https://arxiv.org/pdf/2402.13253v2.pdf","comment":"Accepted to EMNLP 2024 (Findings)"},{"id":"http://arxiv.org/abs/2412.02141v2","updated":"2024-12-10T20:00:17Z","published":"2024-12-03T03:57:24Z","title":"WSI-LLaVA: A Multimodal Large Language Model for Whole Slide Image","summary":"  Recent advancements in computational pathology have produced patch-level\nMulti-modal Large Language Models (MLLMs), but these models are limited by\ntheir inability to analyze whole slide images (WSIs) comprehensively and their\ntendency to bypass crucial morphological features that pathologists rely on for\ndiagnosis. To address these challenges, we first introduce WSI-Bench, a\nlarge-scale morphology-aware benchmark containing 180k VQA pairs from 9,850\nWSIs across 30 cancer types, designed to evaluate MLLMs' understanding of\nmorphological characteristics crucial for accurate diagnosis. Building upon\nthis benchmark, we present WSI-LLaVA, a novel framework for gigapixel WSI\nunderstanding that employs a three-stage training approach: WSI-text alignment,\nfeature space alignment, and task-specific instruction tuning. To better assess\nmodel performance in pathological contexts, we develop two specialized WSI\nmetrics: WSI-Precision and WSI-Relevance. Experimental results demonstrate that\nWSI-LLaVA outperforms existing models across all capability dimensions, with a\nsignificant improvement in morphological analysis, establishing a clear\ncorrelation between morphological understanding and diagnostic accuracy.\n","authors":["Yuci Liang","Xinheng Lyu","Meidan Ding","Wenting Chen","Jipeng Zhang","Yuexiang Ren","Xiangjian He","Song Wu","Sen Yang","Xiyue Wang","Xiaohan Xing","Linlin Shen"],"pdf_url":"https://arxiv.org/pdf/2412.02141v2.pdf","comment":"38 pages, 22 figures, 35 tables"},{"id":"http://arxiv.org/abs/2411.18915v3","updated":"2024-12-10T19:18:10Z","published":"2024-11-28T05:12:17Z","title":"MATATA: A weakly-supervised MAthematical Tool-Assisted reasoning for\n  Tabular Applications","summary":"  Mathematical reasoning capabilities are increasing with tool-augmented\nlanguage agents, but methods often rely either on closed-source or large\nmodels, external data, or extensive prompt engineering. This work introduces\nMATATA, a novel cost-effective method to train LLM agents for tabular data\nproblems through reasoning, planning, and tool use. With a progressive\nself-improvement paradigm and an iterative weak supervision, it empowers\n3.8B/8B Small Language Models (SLMs), particularly suited for local hosting and\nsensitive business contexts where data privacy is crucial. By employing a\nflexible and reusable tools across different datasets, it achieves robust\nperformance with effective scalability across shared tasks. Experiments show\nthat MATATA reaches state-of-the-art performances on FinQA and TAT-QA among\nreasoning frameworks based on open-source models. Moreover, MATATA models\ncompete with GPT-4 based frameworks on TabMWP, while being SLMs.\n","authors":["Vishnou Vinayagame","Gregory Senay","Luis Martí"],"pdf_url":"https://arxiv.org/pdf/2411.18915v3.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2410.16780v2","updated":"2024-12-10T18:45:18Z","published":"2024-10-22T07:53:41Z","title":"Beyond Retrieval: Generating Narratives in Conversational Recommender\n  Systems","summary":"  The recent advances in Large Language Model's generation and reasoning\ncapabilities present an opportunity to develop truly conversational\nrecommendation systems. However, effectively integrating recommender system\nknowledge into LLMs for natural language generation which is tailored towards\nrecommendation tasks remains a challenge. This paper addresses this challenge\nby making two key contributions.\n  First, we introduce a new dataset (REGEN) for natural language generation\ntasks in conversational recommendations. REGEN (Reviews Enhanced with\nGEnerative Narratives) extends the Amazon Product Reviews dataset with rich\nuser narratives, including personalized explanations of product preferences,\nproduct endorsements for recommended items, and summaries of user purchase\nhistory. REGEN is made publicly available to facilitate further research.\nFurthermore, we establish benchmarks using well-known generative metrics, and\nperform an automated evaluation of the new dataset using a rater LLM. Second,\nthe paper introduces a fusion architecture (CF model with an LLM) which serves\nas a baseline for REGEN. And to the best of our knowledge, represents the first\nattempt to analyze the capabilities of LLMs in understanding recommender\nsignals and generating rich narratives. We demonstrate that LLMs can\neffectively learn from simple fusion architectures utilizing interaction-based\nCF embeddings, and this can be further enhanced using the metadata and\npersonalization data associated with items. Our experiments show that combining\nCF and content embeddings leads to improvements of 4-12% in key language\nmetrics compared to using either type of embedding individually. We also\nprovide an analysis to interpret how CF and content embeddings contribute to\nthis new generative task.\n","authors":["Krishna Sayana","Raghavendra Vasudeva","Yuri Vasilevski","Kun Su","Liam Hebert","James Pine","Hubert Pham","Ambarish Jash","Sukhdeep Sodhi"],"pdf_url":"https://arxiv.org/pdf/2410.16780v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07713v1","updated":"2024-12-10T18:01:33Z","published":"2024-12-10T18:01:33Z","title":"Benchmark for Evaluation and Analysis of Citation Recommendation Models","summary":"  Citation recommendation systems have attracted much academic interest,\nresulting in many studies and implementations. These systems help authors\nautomatically generate proper citations by suggesting relevant references based\non the text they have written. However, the methods used in citation\nrecommendation differ across various studies and implementations. Some\napproaches focus on the overall content of papers, while others consider the\ncontext of the citation text. Additionally, the datasets used in these studies\ninclude different aspects of papers, such as metadata, citation context, or\neven the full text of the paper in various formats and structures. The\ndiversity in models, datasets, and evaluation metrics makes it challenging to\nassess and compare citation recommendation methods effectively. To address this\nissue, a standardized dataset and evaluation metrics are needed to evaluate\nthese models consistently. Therefore, we propose developing a benchmark\nspecifically designed to analyze and compare citation recommendation models.\nThis benchmark will evaluate the performance of models on different features of\nthe citation context and provide a comprehensive evaluation of the models\nacross all these tasks, presenting the results in a standardized way. By\ncreating a benchmark with standardized evaluation metrics, researchers and\npractitioners in the field of citation recommendation will have a common\nplatform to assess and compare different models. This will enable meaningful\ncomparisons and help identify promising approaches for further research and\ndevelopment in the field.\n","authors":["Puja Maharjan"],"pdf_url":"https://arxiv.org/pdf/2412.07713v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2405.12207v3","updated":"2024-12-10T17:06:57Z","published":"2024-05-20T17:47:18Z","title":"Optimistic Query Routing in Clustering-based Approximate Maximum Inner\n  Product Search","summary":"  Clustering-based nearest neighbor search is an effective method in which\npoints are partitioned into geometric shards to form an index, with only a few\nshards searched during query processing to find a set of top-$k$ vectors. Even\nthough the search efficacy is heavily influenced by the algorithm that\nidentifies the shards to probe, it has received little attention in the\nliterature. This work bridges that gap by studying routing in clustering-based\nmaximum inner product search. We unpack existing routers and notice the\nsurprising contribution of optimism. We then take a page from the sequential\ndecision making literature and formalize that insight following the principle\nof ``optimism in the face of uncertainty.'' In particular, we present a\nframework that incorporates the moments of the distribution of inner products\nwithin each shard to estimate the maximum inner product. We then present an\ninstance of our algorithm that uses only the first two moments to reach the\nsame accuracy as state-of-the-art routers such as ScaNN by probing up to $50\\%$\nfewer points on benchmark datasets. Our algorithm is also space-efficient: we\ndesign a sketch of the second moment whose size is independent of the number of\npoints and requires $\\mathcal{O}(1)$ vectors per shard.\n","authors":["Sebastian Bruch","Aditya Krishnan","Franco Maria Nardini"],"pdf_url":"https://arxiv.org/pdf/2405.12207v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07626v1","updated":"2024-12-10T16:05:56Z","published":"2024-12-10T16:05:56Z","title":"OmniDocBench: Benchmarking Diverse PDF Document Parsing with\n  Comprehensive Annotations","summary":"  Document content extraction is crucial in computer vision, especially for\nmeeting the high-quality data needs of large language models (LLMs) and\nretrieval-augmented generation (RAG) technologies. However, current document\nparsing methods suffer from significant limitations in terms of diversity and\ncomprehensive evaluation. To address these challenges, we introduce\nOmniDocBench, a novel multi-source benchmark designed to advance automated\ndocument content extraction. OmniDocBench includes a meticulously curated and\nannotated high-quality evaluation dataset comprising nine diverse document\ntypes, such as academic papers, textbooks, slides, among others. Our benchmark\nprovides a flexible and comprehensive evaluation framework with 19 layout\ncategory labels and 14 attribute labels, enabling multi-level assessments\nacross entire datasets, individual modules, or specific data types. Using\nOmniDocBench, we perform an exhaustive comparative analysis of existing modular\npipelines and multimodal end-to-end methods, highlighting their limitations in\nhandling document diversity and ensuring fair evaluation. OmniDocBench\nestablishes a robust, diverse, and fair evaluation standard for the document\ncontent extraction field, offering crucial insights for future advancements and\nfostering the development of document parsing technologies. The codes and\ndataset is available in https://github.com/opendatalab/OmniDocBench.\n","authors":["Linke Ouyang","Yuan Qu","Hongbin Zhou","Jiawei Zhu","Rui Zhang","Qunshu Lin","Bin Wang","Zhiyuan Zhao","Man Jiang","Xiaomeng Zhao","Jin Shi","Fan Wu","Pei Chu","Minghao Liu","Zhenxiang Li","Chao Xu","Bo Zhang","Botian Shi","Zhongying Tu","Conghui He"],"pdf_url":"https://arxiv.org/pdf/2412.07626v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.05668v2","updated":"2024-12-10T16:00:55Z","published":"2024-03-08T20:44:59Z","title":"CFaiRLLM: Consumer Fairness Evaluation in Large-Language Model\n  Recommender System","summary":"  This work takes a critical stance on previous studies concerning fairness\nevaluation in Large Language Model (LLM)-based recommender systems, which have\nprimarily assessed consumer fairness by comparing recommendation lists\ngenerated with and without sensitive user attributes. Such approaches\nimplicitly treat discrepancies in recommended items as biases, overlooking\nwhether these changes might stem from genuine personalization aligned with true\npreferences of users. Moreover, these earlier studies typically address single\nsensitive attributes in isolation, neglecting the complex interplay of\nintersectional identities. In response to these shortcomings, we introduce\nCFaiRLLM, an enhanced evaluation framework that not only incorporates true\npreference alignment but also rigorously examines intersectional fairness by\nconsidering overlapping sensitive attributes. Additionally, CFaiRLLM introduces\ndiverse user profile sampling strategies-random, top-rated, and\nrecency-focused-to better understand the impact of profile generation fed to\nLLMs in light of inherent token limitations in these systems. Given that\nfairness depends on accurately understanding users' tastes and preferences,,\nthese strategies provide a more realistic assessment of fairness within\nRecLLMs.\n  The results demonstrated that true preference alignment offers a more\npersonalized and fair assessment compared to similarity-based measures,\nrevealing significant disparities when sensitive and intersectional attributes\nare incorporated. Notably, our study finds that intersectional attributes\namplify fairness gaps more prominently, especially in less structured domains\nsuch as music recommendations in LastFM.\n","authors":["Yashar Deldjoo","Tommaso di Noia"],"pdf_url":"https://arxiv.org/pdf/2403.05668v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07573v1","updated":"2024-12-10T15:06:48Z","published":"2024-12-10T15:06:48Z","title":"SST framework for Document Matching","summary":"  Long-form document matching aims to judge the relevance between two documents\nand has been applied to various scenarios. Most existing works utilize\nhierarchical or long context models to process documents, which achieve coarse\nunderstanding but may ignore details. Some researchers construct a document\nview with similar sentences about aligned document subtopics to focus on\ndetailed matching signals. However, a long document generally contains multiple\nsubtopics. The matching signals are heterogeneous from multiple topics.\nConsidering only the homologous aligned subtopics may not be representative\nenough and may cause biased modeling. In this paper, we introduce a new\nframework to model representative matching signals. First, we propose to\ncapture various matching signals through subtopics of document pairs. Next, We\nconstruct multiple document views based on subtopics to cover heterogeneous and\nvaluable details. However, existing spatial aggregation methods like attention,\nwhich integrate all these views simultaneously, are hard to integrate\nheterogeneous information. Instead, we propose temporal aggregation, which\neffectively integrates different views gradually as the training progresses.\nExperimental results show that our learning framework is effective on several\ndocument-matching tasks, including news duplication and legal case retrieval.\n","authors":["Youchao Zhou","Heyan Huang","Zhijing Wu","Yuhang Liu","Xinglin Wang"],"pdf_url":"https://arxiv.org/pdf/2412.07573v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17643v2","updated":"2024-12-10T12:36:09Z","published":"2024-03-26T12:23:34Z","title":"S+t-SNE -- Bringing Dimensionality Reduction to Data Streams","summary":"  We present S+t-SNE, an adaptation of the t-SNE algorithm designed to handle\ninfinite data streams. The core idea behind S+t-SNE is to update the t-SNE\nembedding incrementally as new data arrives, ensuring scalability and\nadaptability to handle streaming scenarios. By selecting the most important\npoints at each step, the algorithm ensures scalability while keeping\ninformative visualisations. By employing a blind method for drift management,\nthe algorithm adjusts the embedding space, which facilitates the visualisation\nof evolving data dynamics. Our experimental evaluations demonstrate the\neffectiveness and efficiency of S+t-SNE, whilst highlighting its ability to\ncapture patterns in a streaming scenario. We hope our approach offers\nresearchers and practitioners a real-time tool for understanding and\ninterpreting high-dimensional data.\n","authors":["Pedro C. Vieira","João P. Montrezol","João T. Vieira","João Gama"],"pdf_url":"https://arxiv.org/pdf/2403.17643v2.pdf","comment":"This preprint has undergone peer review but does not have any\n  post-submission improvements or corrections. Full version after peer-review\n  and post-acceptance improvements was presented at IDA2024\n  (https://ida2024.org/)"},{"id":"http://arxiv.org/abs/2412.07462v1","updated":"2024-12-10T12:31:33Z","published":"2024-12-10T12:31:33Z","title":"Bilingual BSARD: Extending Statutory Article Retrieval to Dutch","summary":"  Statutory article retrieval plays a crucial role in making legal information\nmore accessible to both laypeople and legal professionals. Multilingual\ncountries like Belgium present unique challenges for retrieval models due to\nthe need for handling legal issues in multiple languages. Building on the\nBelgian Statutory Article Retrieval Dataset (BSARD) in French, we introduce the\nbilingual version of this dataset, bBSARD. The dataset contains parallel\nBelgian statutory articles in both French and Dutch, along with legal questions\nfrom BSARD and their Dutch translation. Using bBSARD, we conduct extensive\nbenchmarking of retrieval models available for Dutch and French. Our\nbenchmarking setup includes lexical models, zero-shot dense models, and\nfine-tuned small foundation models. Our experiments show that BM25 remains a\ncompetitive baseline compared to many zero-shot dense models in both languages.\nWe also observe that while proprietary models outperform open alternatives in\nthe zero-shot setting, they can be matched or surpassed by fine-tuning small\nlanguage-specific models. Our dataset and evaluation code are publicly\navailable.\n","authors":["Ehsan Lotfi","Nikolay Banar","Nerses Yuzbashyan","Walter Daelemans"],"pdf_url":"https://arxiv.org/pdf/2412.07462v1.pdf","comment":"To be presented at RegNLP-2025 (COLING)"},{"id":"http://arxiv.org/abs/2312.11018v2","updated":"2024-12-10T11:20:21Z","published":"2023-12-18T08:35:10Z","title":"Hypergrah-Enhanced Dual Convolutional Network for Bundle Recommendation","summary":"  Bundle recommendations strive to offer users a set of items as a package\nnamed bundle, enhancing convenience and contributing to the seller's revenue.\nWhile previous approaches have demonstrated notable performance, we argue that\nthey may compromise the ternary relationship among users, items, and bundles.\nThis compromise can result in information loss, ultimately impacting the\noverall model performance. To address this gap, we develop a unified model for\nbundle recommendation, termed hypergraph-enhanced dual convolutional neural\nnetwork (HED). Our approach is characterized by two key aspects. Firstly, we\nconstruct a complete hypergraph to capture interaction dynamics among users,\nitems, and bundles. Secondly, we incorporate U-B interaction information to\nenhance the information representation derived from users and bundle embedding\nvectors. Extensive experimental results on the Youshu and Netease datasets have\ndemonstrated that HED surpasses state-of-the-art baselines, proving its\neffectiveness. In addition, various ablation studies and sensitivity analyses\nrevealed the working mechanism and proved our effectiveness. Codes and datasets\nare available at https://github.com/AAI-Lab/HED\n","authors":["Yang Li","Kangbo Liu","Yaoxin Wu","Zhaoxuan Wang","Erik Cambria","Xiaoxu Wang"],"pdf_url":"https://arxiv.org/pdf/2312.11018v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07420v1","updated":"2024-12-10T11:18:29Z","published":"2024-12-10T11:18:29Z","title":"RAG-based Question Answering over Heterogeneous Data and Text","summary":"  This article presents the QUASAR system for question answering over\nunstructured text, structured tables, and knowledge graphs, with unified\ntreatment of all sources. The system adopts a RAG-based architecture, with a\npipeline of evidence retrieval followed by answer generation, with the latter\npowered by a moderate-sized language model. Additionally and uniquely, QUASAR\nhas components for question understanding, to derive crisper input for evidence\nretrieval, and for re-ranking and filtering the retrieved evidence before\nfeeding the most informative pieces into the answer generation. Experiments\nwith three different benchmarks demonstrate the high answering quality of our\napproach, being on par with or better than large GPT models, while keeping the\ncomputational cost and energy consumption orders of magnitude lower.\n","authors":["Philipp Christmann","Gerhard Weikum"],"pdf_url":"https://arxiv.org/pdf/2412.07420v1.pdf","comment":"IEEE Data Engineering Bulletin -- December 2024 Edition on RAG"},{"id":"http://arxiv.org/abs/2412.07403v1","updated":"2024-12-10T10:52:44Z","published":"2024-12-10T10:52:44Z","title":"RLT4Rec: Reinforcement Learning Transformer for User Cold Start and Item\n  Recommendation","summary":"  We introduce a new sequential transformer reinforcement learning architecture\nRLT4Rec and demonstrate that it achieves excellent performance in a range of\nitem recommendation tasks. RLT4Rec uses a relatively simple transformer\narchitecture that takes as input the user's (item,rating) history and outputs\nthe next item to present to the user. Unlike existing RL approaches, there is\nno need to input a state observation or estimate. RLT4Rec handles new users and\nestablished users within the same consistent framework and automatically\nbalances the \"exploration\" needed to discover the preferences of a new user\nwith the \"exploitation\" that is more appropriate for established users.\nTraining of RLT4Rec is robust and fast and is insensitive to the choice of\ntraining data, learning to generate \"good\" personalised sequences that the user\ntends to rate highly even when trained on \"bad\" data.\n","authors":["Dilina Chandika Rajapakse","Douglas Leith"],"pdf_url":"https://arxiv.org/pdf/2412.07403v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07382v1","updated":"2024-12-10T10:28:32Z","published":"2024-12-10T10:28:32Z","title":"Temporal Linear Item-Item Model for Sequential Recommendation","summary":"  In sequential recommendation (SR), neural models have been actively explored\ndue to their remarkable performance, but they suffer from inefficiency inherent\nto their complexity. On the other hand, linear SR models exhibit high\nefficiency and achieve competitive or superior accuracy compared to neural\nmodels. However, they solely deal with the sequential order of items (i.e.,\nsequential information) and overlook the actual timestamp (i.e., temporal\ninformation). It is limited to effectively capturing various user preference\ndrifts over time. To address this issue, we propose a novel linear SR model,\nnamed TemporAl LinEar item-item model (TALE), incorporating temporal\ninformation while preserving training/inference efficiency, with three key\ncomponents. (i) Single-target augmentation concentrates on a single target\nitem, enabling us to learn the temporal correlation for the target item. (ii)\nTime interval-aware weighting utilizes the actual timestamp to discern the item\ncorrelation depending on time intervals. (iii) Trend-aware normalization\nreflects the dynamic shift of item popularity over time. Our empirical studies\nshow that TALE outperforms ten competing SR models by up to 18.71% gains on\nfive benchmark datasets. It also exhibits remarkable effectiveness in\nevaluating long-tail items by up to 30.45% gains. The source code is available\nat https://github.com/psm1206/TALE.\n","authors":["Seongmin Park","Mincheol Yoon","Minjin Choi","Jongwuk Lee"],"pdf_url":"https://arxiv.org/pdf/2412.07382v1.pdf","comment":"Accepted by WSDM 2025"},{"id":"http://arxiv.org/abs/2404.11180v3","updated":"2024-12-10T10:22:57Z","published":"2024-04-17T08:50:29Z","title":"Causal Deconfounding via Confounder Disentanglement for Dual-Target\n  Cross-Domain Recommendation","summary":"  In recent years, dual-target Cross-Domain Recommendation (CDR) has been\nproposed to capture comprehensive user preferences in order to ultimately\nenhance the recommendation accuracy in both data-richer and data-sparser\ndomains simultaneously. However, in addition to users' true preferences, the\nuser-item interactions might also be affected by confounders (e.g., free\nshipping, sales promotion). As a result, dual-target CDR has to meet two\nchallenges: (1) how to effectively decouple observed confounders, including\nsingle-domain confounders and cross-domain confounders, and (2) how to preserve\nthe positive effects of observed confounders on predicted interactions, while\neliminating their negative effects on capturing comprehensive user preferences.\nTo address the above two challenges, we propose a Causal Deconfounding\nframework via Confounder Disentanglement for dual-target Cross-Domain\nRecommendation, called CD2CDR. In CD2CDR, we first propose a confounder\ndisentanglement module to effectively decouple observed single-domain and\ncross-domain confounders. We then propose a causal deconfounding module to\npreserve the positive effects of such observed confounders and eliminate their\nnegative effects via backdoor adjustment, thereby enhancing the recommendation\naccuracy in each domain. Extensive experiments conducted on five real-world\ndatasets demonstrate that CD2CDR significantly outperforms the state-of-the-art\nmethods.\n","authors":["Jiajie Zhu","Yan Wang","Feng Zhu","Zhu Sun"],"pdf_url":"https://arxiv.org/pdf/2404.11180v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.04629v2","updated":"2024-12-10T08:02:24Z","published":"2024-12-05T21:51:05Z","title":"Argumentative Experience: Reducing Confirmation Bias on Controversial\n  Issues through LLM-Generated Multi-Persona Debates","summary":"  Large language models (LLMs) are enabling designers to give life to exciting\nnew user experiences for information access. In this work, we present a system\nthat generates LLM personas to debate a topic of interest from different\nperspectives. How might information seekers use and benefit from such a system?\nCan centering information access around diverse viewpoints help to mitigate\nthorny challenges like confirmation bias in which information seekers\nover-trust search results matching existing beliefs? How do potential biases\nand hallucinations in LLMs play out alongside human users who are also fallible\nand possibly biased?\n  Our study exposes participants to multiple viewpoints on controversial issues\nvia a mixed-methods, within-subjects study. We use eye-tracking metrics to\nquantitatively assess cognitive engagement alongside qualitative feedback.\nCompared to a baseline search system, we see more creative interactions and\ndiverse information-seeking with our multi-persona debate system, which more\neffectively reduces user confirmation bias and conviction toward their initial\nbeliefs. Overall, our study contributes to the emerging design space of\nLLM-based information access systems, specifically investigating the potential\nof simulated personas to promote greater exposure to information diversity,\nemulate collective intelligence, and mitigate bias in information seeking.\n","authors":["Li Shi","Houjiang Liu","Yian Wong","Utkarsh Mujumdar","Dan Zhang","Jacek Gwizdka","Matthew Lease"],"pdf_url":"https://arxiv.org/pdf/2412.04629v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.03988v2","updated":"2024-12-10T07:40:54Z","published":"2024-05-07T04:00:30Z","title":"LEARN: Knowledge Adaptation from Large Language Model to Recommendation\n  for Practical Industrial Application","summary":"  Contemporary recommendation systems predominantly rely on ID embedding to\ncapture latent associations among users and items. However, this approach\noverlooks the wealth of semantic information embedded within textual\ndescriptions of items, leading to suboptimal performance and poor\ngeneralizations. Leveraging the capability of large language models to\ncomprehend and reason about textual content presents a promising avenue for\nadvancing recommendation systems. To achieve this, we propose an Llm-driven\nknowlEdge Adaptive RecommeNdation (LEARN) framework that synergizes open-world\nknowledge with collaborative knowledge. We address computational complexity\nconcerns by utilizing pretrained LLMs as item encoders and freezing LLM\nparameters to avoid catastrophic forgetting and preserve open-world knowledge.\nTo bridge the gap between the open-world and collaborative domains, we design a\ntwin-tower structure supervised by the recommendation task and tailored for\npractical industrial application. Through experiments on the real large-scale\nindustrial dataset and online A/B tests, we demonstrate the efficacy of our\napproach in industry application. We also achieve state-of-the-art performance\non six Amazon Review datasets to verify the superiority of our method.\n","authors":["Jian Jia","Yipei Wang","Yan Li","Honggang Chen","Xuehan Bai","Zhaocheng Liu","Jian Liang","Quan Chen","Han Li","Peng Jiang","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2405.03988v2.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2412.07213v1","updated":"2024-12-10T06:09:49Z","published":"2024-12-10T06:09:49Z","title":"IntellectSeeker: A Personalized Literature Management System with the\n  Probabilistic Model and Large Language Model","summary":"  Faced with the burgeoning volume of academic literature, researchers often\nneed help with uncertain article quality and mismatches in term searches using\ntraditional academic engines. We introduce IntellectSeeker, an innovative and\npersonalized intelligent academic literature management platform to address\nthese challenges. This platform integrates a Large Language Model (LLM)--based\nsemantic enhancement bot with a sophisticated probability model to personalize\nand streamline literature searches. We adopted the GPT-3.5-turbo model to\ntransform everyday language into professional academic terms across various\nscenarios using multiple rounds of few-shot learning. This adaptation mainly\nbenefits academic newcomers, effectively bridging the gap between general\ninquiries and academic terminology. The probabilistic model intelligently\nfilters academic articles to align closely with the specific interests of\nusers, which are derived from explicit needs and behavioral patterns. Moreover,\nIntellectSeeker incorporates an advanced recommendation system and text\ncompression tools. These features enable intelligent article recommendations\nbased on user interactions and present search results through concise one-line\nsummaries and innovative word cloud visualizations, significantly enhancing\nresearch efficiency and user experience. IntellectSeeker offers academic\nresearchers a highly customizable literature management solution with\nexceptional search precision and matching capabilities. The code can be found\nhere: https://github.com/LuckyBian/ISY5001\n","authors":["Weizhen Bian","Siyan Liu","Yubo Zhou","Dezhi Chen","Yijie Liao","Zhenzhen Fan","Aobo Wang"],"pdf_url":"https://arxiv.org/pdf/2412.07213v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.05579v2","updated":"2024-12-10T05:49:12Z","published":"2024-12-07T08:07:24Z","title":"LLMs-as-Judges: A Comprehensive Survey on LLM-based Evaluation Methods","summary":"  The rapid advancement of Large Language Models (LLMs) has driven their\nexpanding application across various fields. One of the most promising\napplications is their role as evaluators based on natural language responses,\nreferred to as ''LLMs-as-judges''. This framework has attracted growing\nattention from both academia and industry due to their excellent effectiveness,\nability to generalize across tasks, and interpretability in the form of natural\nlanguage. This paper presents a comprehensive survey of the LLMs-as-judges\nparadigm from five key perspectives: Functionality, Methodology, Applications,\nMeta-evaluation, and Limitations. We begin by providing a systematic definition\nof LLMs-as-Judges and introduce their functionality (Why use LLM judges?). Then\nwe address methodology to construct an evaluation system with LLMs (How to use\nLLM judges?). Additionally, we investigate the potential domains for their\napplication (Where to use LLM judges?) and discuss methods for evaluating them\nin various contexts (How to evaluate LLM judges?). Finally, we provide a\ndetailed analysis of the limitations of LLM judges and discuss potential future\ndirections. Through a structured and comprehensive analysis, we aim aims to\nprovide insights on the development and application of LLMs-as-judges in both\nresearch and practice. We will continue to maintain the relevant resource list\nat https://github.com/CSHaitao/Awesome-LLMs-as-Judges.\n","authors":["Haitao Li","Qian Dong","Junjie Chen","Huixue Su","Yujia Zhou","Qingyao Ai","Ziyi Ye","Yiqun Liu"],"pdf_url":"https://arxiv.org/pdf/2412.05579v2.pdf","comment":"60 pages, comprehensive and continuously updated"},{"id":"http://arxiv.org/abs/2408.08931v2","updated":"2024-12-10T03:39:16Z","published":"2024-08-16T05:49:14Z","title":"Personalized Federated Collaborative Filtering: A Variational\n  AutoEncoder Approach","summary":"  Federated Collaborative Filtering (FedCF) is an emerging field focused on\ndeveloping a new recommendation framework with preserving privacy in a\nfederated setting. Existing FedCF methods typically combine distributed\nCollaborative Filtering (CF) algorithms with privacy-preserving mechanisms, and\nthen preserve personalized information into a user embedding vector. However,\nthe user embedding is usually insufficient to preserve the rich information of\nthe fine-grained personalization across heterogeneous clients. This paper\nproposes a novel personalized FedCF method by preserving users' personalized\ninformation into a latent variable and a neural model simultaneously.\nSpecifically, we decompose the modeling of user knowledge into two encoders,\neach designed to capture shared knowledge and personalized knowledge\nseparately. A personalized gating network is then applied to balance\npersonalization and generalization between the global and local encoders.\nMoreover, to effectively train the proposed framework, we model the CF problem\nas a specialized Variational AutoEncoder (VAE) task by integrating user\ninteraction vector reconstruction with missing value prediction. The decoder is\ntrained to reconstruct the implicit feedback from items the user has interacted\nwith, while also predicting items the user might be interested in but has not\nyet interacted with. Experimental results on benchmark datasets demonstrate\nthat the proposed method outperforms other baseline methods, showcasing\nsuperior performance. Our code is available at https://github.com/mtics/FedDAE.\n","authors":["Zhiwei Li","Guodong Long","Tianyi Zhou","Jing Jiang","Chengqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.08931v2.pdf","comment":"10 pages, 3 figures, 4 tables, conference"},{"id":"http://arxiv.org/abs/2410.02126v2","updated":"2024-12-10T02:14:00Z","published":"2024-10-03T01:14:30Z","title":"BayesCNS: A Unified Bayesian Approach to Address Cold Start and\n  Non-Stationarity in Search Systems at Scale","summary":"  Information Retrieval (IR) systems used in search and recommendation\nplatforms frequently employ Learning-to-Rank (LTR) models to rank items in\nresponse to user queries. These models heavily rely on features derived from\nuser interactions, such as clicks and engagement data. This dependence\nintroduces cold start issues for items lacking user engagement and poses\nchallenges in adapting to non-stationary shifts in user behavior over time. We\naddress both challenges holistically as an online learning problem and propose\nBayesCNS, a Bayesian approach designed to handle cold start and non-stationary\ndistribution shifts in search systems at scale. BayesCNS achieves this by\nestimating prior distributions for user-item interactions, which are\ncontinuously updated with new user interactions gathered online. This online\nlearning procedure is guided by a ranker model, enabling efficient exploration\nof relevant items using contextual information provided by the ranker. We\nsuccessfully deployed BayesCNS in a large-scale search system and demonstrated\nits efficacy through comprehensive offline and online experiments. Notably, an\nonline A/B experiment showed a 10.60% increase in new item interactions and a\n1.05% improvement in overall success metrics over the existing production\nbaseline.\n","authors":["Randy Ardywibowo","Rakesh Sunki","Lucy Kuo","Sankalp Nayak"],"pdf_url":"https://arxiv.org/pdf/2410.02126v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.13298v3","updated":"2024-12-10T19:40:49Z","published":"2024-04-20T07:04:46Z","title":"MARec: Metadata Alignment for cold-start Recommendation","summary":"  For many recommender systems, the primary data source is a historical record\nof user clicks. The associated click matrix is often very sparse, as the number\nof users x products can be far larger than the number of clicks. Such sparsity\nis accentuated in cold-start settings, which makes the efficient use of\nmetadata information of paramount importance. In this work, we propose a simple\napproach to address cold-start recommendations by leveraging content metadata,\nMetadata Alignment for cold-start Recommendation. We show that this approach\ncan readily augment existing matrix factorization and autoencoder approaches,\nenabling a smooth transition to top performing algorithms in warmer set-ups.\nOur experimental results indicate three separate contributions: first, we show\nthat our proposed framework largely beats SOTA results on 4 cold-start datasets\nwith different sparsity and scale characteristics, with gains ranging from\n+8.4% to +53.8% on reported ranking metrics; second, we provide an ablation\nstudy on the utility of semantic features, and proves the additional gain\nobtained by leveraging such features ranges between +46.8% and +105.5%; and\nthird, our approach is by construction highly competitive in warm set-ups, and\nwe propose a closed-form solution outperformed by SOTA results by only 0.8% on\naverage.\n","authors":["Julien Monteil","Volodymyr Vaskovych","Wentao Lu","Anirban Majumder","Anton van den Hengel"],"pdf_url":"https://arxiv.org/pdf/2404.13298v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09644v1","updated":"2024-12-10T16:31:53Z","published":"2024-12-10T16:31:53Z","title":"Combining knowledge graphs and LLMs for hazardous chemical information\n  management and reuse","summary":"  Human health is increasingly threatened by exposure to hazardous substances,\nparticularly persistent and toxic chemicals. The link between these substances,\noften encountered in complex mixtures, and various diseases are demonstrated in\nscientific studies. However, this information is scattered across several\nsources and hardly accessible by humans and machines. This paper evaluates\ncurrent practices for publishing/accessing information on hazardous chemicals\nand proposes a novel platform designed to facilitate retrieval of critical\nchemical data in urgent situations. The platform aggregates information from\nmultiple sources and organizes it into a structured knowledge graph. Users can\naccess this information through a visual interface such as Neo4J Bloom and\ndashboards, or via natural language queries using a Chatbot. Our findings\ndemonstrate a significant reduction in the time and effort required to access\nvital chemical information when datasets follow FAIR principles. Furthermore,\nwe discuss the lessons learned from the development and implementation of this\nplatform and provide recommendations for data owners and publishers to enhance\ndata reuse and interoperability. This work aims to improve the accessibility\nand usability of chemical information by healthcare professionals, thereby\nsupporting better health outcomes and informed decision-making in the face of\npatients exposed to chemical intoxication risks.\n","authors":["Marcos Da Silveira","Louis Deladiennee","Kheira Acem","Oona Freudenthal"],"pdf_url":"https://arxiv.org/pdf/2412.09644v1.pdf","comment":"Submitted to IEEE BIBM24"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2412.07775v1","updated":"2024-12-10T18:59:58Z","published":"2024-12-10T18:59:58Z","title":"Efficient Diversity-Preserving Diffusion Alignment via Gradient-Informed\n  GFlowNets","summary":"  While one commonly trains large diffusion models by collecting datasets on\ntarget downstream tasks, it is often desired to align and finetune pretrained\ndiffusion models on some reward functions that are either designed by experts\nor learned from small-scale datasets. Existing methods for finetuning diffusion\nmodels typically suffer from lack of diversity in generated samples, lack of\nprior preservation, and/or slow convergence in finetuning. Inspired by recent\nsuccesses in generative flow networks (GFlowNets), a class of probabilistic\nmodels that sample with the unnormalized density of a reward function, we\npropose a novel GFlowNet method dubbed Nabla-GFlowNet (abbreviated as\n$\\nabla$-GFlowNet), the first GFlowNet method that leverages the rich signal in\nreward gradients, together with an objective called $\\nabla$-DB plus its\nvariant residual $\\nabla$-DB designed for prior-preserving diffusion alignment.\nWe show that our proposed method achieves fast yet diversity- and\nprior-preserving alignment of Stable Diffusion, a large-scale text-conditioned\nimage diffusion model, on different realistic reward functions.\n","authors":["Zhen Liu","Tim Z. Xiao","Weiyang Liu","Yoshua Bengio","Dinghuai Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.07775v1.pdf","comment":"Technical Report (35 pages, 31 figures)"},{"id":"http://arxiv.org/abs/2412.07776v1","updated":"2024-12-10T18:59:58Z","published":"2024-12-10T18:59:58Z","title":"Video Motion Transfer with Diffusion Transformers","summary":"  We propose DiTFlow, a method for transferring the motion of a reference video\nto a newly synthesized one, designed specifically for Diffusion Transformers\n(DiT). We first process the reference video with a pre-trained DiT to analyze\ncross-frame attention maps and extract a patch-wise motion signal called the\nAttention Motion Flow (AMF). We guide the latent denoising process in an\noptimization-based, training-free, manner by optimizing latents with our AMF\nloss to generate videos reproducing the motion of the reference one. We also\napply our optimization strategy to transformer positional embeddings, granting\nus a boost in zero-shot motion transfer capabilities. We evaluate DiTFlow\nagainst recently published methods, outperforming all across multiple metrics\nand human evaluation.\n","authors":["Alexander Pondaven","Aliaksandr Siarohin","Sergey Tulyakov","Philip Torr","Fabio Pizzati"],"pdf_url":"https://arxiv.org/pdf/2412.07776v1.pdf","comment":"Project page: https://ditflow.github.io/"},{"id":"http://arxiv.org/abs/2412.07773v1","updated":"2024-12-10T18:59:50Z","published":"2024-12-10T18:59:50Z","title":"Mobile-TeleVision: Predictive Motion Priors for Humanoid Whole-Body\n  Control","summary":"  Humanoid robots require both robust lower-body locomotion and precise\nupper-body manipulation. While recent Reinforcement Learning (RL) approaches\nprovide whole-body loco-manipulation policies, they lack precise manipulation\nwith high DoF arms. In this paper, we propose decoupling upper-body control\nfrom locomotion, using inverse kinematics (IK) and motion retargeting for\nprecise manipulation, while RL focuses on robust lower-body locomotion. We\nintroduce PMP (Predictive Motion Priors), trained with Conditional Variational\nAutoencoder (CVAE) to effectively represent upper-body motions. The locomotion\npolicy is trained conditioned on this upper-body motion representation,\nensuring that the system remains robust with both manipulation and locomotion.\nWe show that CVAE features are crucial for stability and robustness, and\nsignificantly outperforms RL-based whole-body control in precise manipulation.\nWith precise upper-body motion and robust lower-body locomotion control,\noperators can remotely control the humanoid to walk around and explore\ndifferent environments, while performing diverse manipulation tasks.\n","authors":["Chenhao Lu","Xuxin Cheng","Jialong Li","Shiqi Yang","Mazeyu Ji","Chengjing Yuan","Ge Yang","Sha Yi","Xiaolong Wang"],"pdf_url":"https://arxiv.org/pdf/2412.07773v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07770v1","updated":"2024-12-10T18:59:44Z","published":"2024-12-10T18:59:44Z","title":"From an Image to a Scene: Learning to Imagine the World from a Million\n  360 Videos","summary":"  Three-dimensional (3D) understanding of objects and scenes play a key role in\nhumans' ability to interact with the world and has been an active area of\nresearch in computer vision, graphics, and robotics. Large scale synthetic and\nobject-centric 3D datasets have shown to be effective in training models that\nhave 3D understanding of objects. However, applying a similar approach to\nreal-world objects and scenes is difficult due to a lack of large-scale data.\nVideos are a potential source for real-world 3D data, but finding diverse yet\ncorresponding views of the same content has shown to be difficult at scale.\nFurthermore, standard videos come with fixed viewpoints, determined at the time\nof capture. This restricts the ability to access scenes from a variety of more\ndiverse and potentially useful perspectives. We argue that large scale 360\nvideos can address these limitations to provide: scalable corresponding frames\nfrom diverse views. In this paper, we introduce 360-1M, a 360 video dataset,\nand a process for efficiently finding corresponding frames from diverse\nviewpoints at scale. We train our diffusion-based model, Odin, on 360-1M.\nEmpowered by the largest real-world, multi-view dataset to date, Odin is able\nto freely generate novel views of real-world scenes. Unlike previous methods,\nOdin can move the camera through the environment, enabling the model to infer\nthe geometry and layout of the scene. Additionally, we show improved\nperformance on standard novel view synthesis and 3D reconstruction benchmarks.\n","authors":["Matthew Wallingford","Anand Bhattad","Aditya Kusupati","Vivek Ramanujan","Matt Deitke","Sham Kakade","Aniruddha Kembhavi","Roozbeh Mottaghi","Wei-Chiu Ma","Ali Farhadi"],"pdf_url":"https://arxiv.org/pdf/2412.07770v1.pdf","comment":"NeurIPS 2024. For project page, see\n  https://mattwallingford.github.io/ODIN"},{"id":"http://arxiv.org/abs/2412.07763v1","updated":"2024-12-10T18:57:48Z","published":"2024-12-10T18:57:48Z","title":"Bayesian Optimization of Antibodies Informed by a Generative Model of\n  Evolving Sequences","summary":"  To build effective therapeutics, biologists iteratively mutate antibody\nsequences to improve binding and stability. Proposed mutations can be informed\nby previous measurements or by learning from large antibody databases to\npredict only typical antibodies. Unfortunately, the space of typical antibodies\nis enormous to search, and experiments often fail to find suitable antibodies\non a budget. We introduce Clone-informed Bayesian Optimization (CloneBO), a\nBayesian optimization procedure that efficiently optimizes antibodies in the\nlab by teaching a generative model how our immune system optimizes antibodies.\nOur immune system makes antibodies by iteratively evolving specific portions of\ntheir sequences to bind their target strongly and stably, resulting in a set of\nrelated, evolving sequences known as a clonal family. We train a large language\nmodel, CloneLM, on hundreds of thousands of clonal families and use it to\ndesign sequences with mutations that are most likely to optimize an antibody\nwithin the human immune system. We propose to guide our designs to fit previous\nmeasurements with a twisted sequential Monte Carlo procedure. We show that\nCloneBO optimizes antibodies substantially more efficiently than previous\nmethods in realistic in silico experiments and designs stronger and more stable\nbinders in in vitro wet lab experiments.\n","authors":["Alan Nawzad Amin","Nate Gruver","Yilun Kuang","Lily Li","Hunter Elliott","Calvin McCarter","Aniruddh Raghu","Peyton Greenside","Andrew Gordon Wilson"],"pdf_url":"https://arxiv.org/pdf/2412.07763v1.pdf","comment":"Code available at https://github.com/AlanNawzadAmin/CloneBO"},{"id":"http://arxiv.org/abs/2412.07762v1","updated":"2024-12-10T18:57:12Z","published":"2024-12-10T18:57:12Z","title":"Efficient Online Reinforcement Learning Fine-Tuning Need Not Retain\n  Offline Data","summary":"  The modern paradigm in machine learning involves pre-training on diverse\ndata, followed by task-specific fine-tuning. In reinforcement learning (RL),\nthis translates to learning via offline RL on a diverse historical dataset,\nfollowed by rapid online RL fine-tuning using interaction data. Most RL\nfine-tuning methods require continued training on offline data for stability\nand performance. However, this is undesirable because training on diverse\noffline data is slow and expensive for large datasets, and in principle, also\nlimit the performance improvement possible because of constraints or pessimism\non offline data. In this paper, we show that retaining offline data is\nunnecessary as long as we use a properly-designed online RL approach for\nfine-tuning offline RL initializations. To build this approach, we start by\nanalyzing the role of retaining offline data in online fine-tuning. We find\nthat continued training on offline data is mostly useful for preventing a\nsudden divergence in the value function at the onset of fine-tuning, caused by\na distribution mismatch between the offline data and online rollouts. This\ndivergence typically results in unlearning and forgetting the benefits of\noffline pre-training. Our approach, Warm-start RL (WSRL), mitigates the\ncatastrophic forgetting of pre-trained initializations using a very simple\nidea. WSRL employs a warmup phase that seeds the online RL run with a very\nsmall number of rollouts from the pre-trained policy to do fast online RL. The\ndata collected during warmup helps ``recalibrate'' the offline Q-function to\nthe online distribution, allowing us to completely discard offline data without\ndestabilizing the online RL fine-tuning. We show that WSRL is able to fine-tune\nwithout retaining any offline data, and is able to learn faster and attains\nhigher performance than existing algorithms irrespective of whether they retain\noffline data or not.\n","authors":["Zhiyuan Zhou","Andy Peng","Qiyang Li","Sergey Levine","Aviral Kumar"],"pdf_url":"https://arxiv.org/pdf/2412.07762v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07754v1","updated":"2024-12-10T18:51:31Z","published":"2024-12-10T18:51:31Z","title":"PortraitTalk: Towards Customizable One-Shot Audio-to-Talking Face\n  Generation","summary":"  Audio-driven talking face generation is a challenging task in digital\ncommunication. Despite significant progress in the area, most existing methods\nconcentrate on audio-lip synchronization, often overlooking aspects such as\nvisual quality, customization, and generalization that are crucial to producing\nrealistic talking faces. To address these limitations, we introduce a novel,\ncustomizable one-shot audio-driven talking face generation framework, named\nPortraitTalk. Our proposed method utilizes a latent diffusion framework\nconsisting of two main components: IdentityNet and AnimateNet. IdentityNet is\ndesigned to preserve identity features consistently across the generated video\nframes, while AnimateNet aims to enhance temporal coherence and motion\nconsistency. This framework also integrates an audio input with the reference\nimages, thereby reducing the reliance on reference-style videos prevalent in\nexisting approaches. A key innovation of PortraitTalk is the incorporation of\ntext prompts through decoupled cross-attention mechanisms, which significantly\nexpands creative control over the generated videos. Through extensive\nexperiments, including a newly developed evaluation metric, our model\ndemonstrates superior performance over the state-of-the-art methods, setting a\nnew standard for the generation of customizable realistic talking faces\nsuitable for real-world applications.\n","authors":["Fatemeh Nazarieh","Zhenhua Feng","Diptesh Kanojia","Muhammad Awais","Josef Kittler"],"pdf_url":"https://arxiv.org/pdf/2412.07754v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.19643v3","updated":"2024-12-10T18:50:37Z","published":"2024-10-25T15:49:04Z","title":"Impact of Leakage on Data Harmonization in Machine Learning Pipelines in\n  Class Imbalance Across Sites","summary":"  Machine learning (ML) models benefit from large datasets. Collecting data in\nbiomedical domains is costly and challenging, hence, combining datasets has\nbecome a common practice. However, datasets obtained under different conditions\ncould present undesired site-specific variability. Data harmonization methods\naim to remove site-specific variance while retaining biologically relevant\ninformation. This study evaluates the effectiveness of popularly used\nComBat-based methods for harmonizing data in scenarios where the class balance\nis not equal across sites. We find that these methods struggle with data\nleakage issues. To overcome this problem, we propose a novel approach\nPrettYharmonize, designed to harmonize data by pretending the target labels. We\nvalidate our approach using controlled datasets designed to benchmark the\nutility of harmonization. Finally, using real-world MRI and clinical data, we\ncompare leakage-prone methods with PrettYharmonize and show that it achieves\ncomparable performance while avoiding data leakage, particularly in\nsite-target-dependence scenarios.\n","authors":["Nicolás Nieto","Simon B. Eickhoff","Christian Jung","Martin Reuter","Kersten Diers","Malte Kelm","Artur Lichtenberg","Federico Raimondo","Kaustubh R. Patil"],"pdf_url":"https://arxiv.org/pdf/2410.19643v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07752v1","updated":"2024-12-10T18:50:37Z","published":"2024-12-10T18:50:37Z","title":"FlashRNN: Optimizing Traditional RNNs on Modern Hardware","summary":"  While Transformers and other sequence-parallelizable neural network\narchitectures seem like the current state of the art in sequence modeling, they\nspecifically lack state-tracking capabilities. These are important for\ntime-series tasks and logical reasoning. Traditional RNNs like LSTMs and GRUs,\nas well as modern variants like sLSTM do have these capabilities at the cost of\nstrictly sequential processing. While this is often seen as a strong\nlimitation, we show how fast these networks can get with our\nhardware-optimization FlashRNN in Triton and CUDA, optimizing kernels to the\nregister level on modern GPUs. We extend traditional RNNs with a\nparallelization variant that processes multiple RNNs of smaller hidden state in\nparallel, similar to the head-wise processing in Transformers. To enable\nflexibility on different GPU variants, we introduce a new optimization\nframework for hardware-internal cache sizes, memory and compute handling. It\nmodels the hardware in a setting using polyhedral-like constraints, including\nthe notion of divisibility. This speeds up the solution process in our\nConstrINT library for general integer constraint satisfaction problems (integer\nCSPs). We show that our kernels can achieve 50x speed-ups over a vanilla\nPyTorch implementation and allow 40x larger hidden sizes compared to our Triton\nimplementation. Our open-source kernels and the optimization library are\nreleased here to boost research in the direction of state-tracking enabled RNNs\nand sequence modeling: \\url{https://github.com/NX-AI/flashrnn}\n","authors":["Korbinian Pöppel","Maximilian Beck","Sepp Hochreiter"],"pdf_url":"https://arxiv.org/pdf/2412.07752v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07747v1","updated":"2024-12-10T18:47:10Z","published":"2024-12-10T18:47:10Z","title":"Predictive Modeling of Homeless Service Assignment: A Representation\n  Learning Approach","summary":"  In recent years, there has been growing interest in leveraging machine\nlearning for homeless service assignment. However, the categorical nature of\nadministrative data recorded for homeless individuals hinders the development\nof accurate machine learning methods for this task. This work asserts that\nderiving latent representations of such features, while at the same time\nleveraging underlying relationships between instances is crucial in\nalgorithmically enhancing the existing assignment decision-making process. Our\nproposed approach learns temporal and functional relationships between services\nfrom historical data, as well as unobserved but relevant relationships between\nindividuals to generate features that significantly improve the prediction of\nthe next service assignment compared to the state-of-the-art.\n","authors":["Khandker Sadia Rahman","Charalampos Chelmis"],"pdf_url":"https://arxiv.org/pdf/2412.07747v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.12921v4","updated":"2024-12-10T18:46:23Z","published":"2024-02-20T11:15:13Z","title":"Right on Time: Revising Time Series Models by Constraining their\n  Explanations","summary":"  The reliability of deep time series models is often compromised by their\ntendency to rely on confounding factors, which may lead to incorrect outputs.\nOur newly recorded, naturally confounded dataset named P2S from a real\nmechanical production line emphasizes this. To avoid \"Clever-Hans\" moments in\ntime series, i.e., to mitigate confounders, we introduce the method Right on\nTime (RioT). RioT enables, for the first time, interactions with model\nexplanations across both the time and frequency domain. Feedback on\nexplanations in both domains is then used to constrain the model, steering it\naway from the annotated confounding factors. The dual-domain interaction\nstrategy is crucial for effectively addressing confounders in time series\ndatasets. We empirically demonstrate that RioT can effectively guide models\naway from the wrong reasons in P2S as well as popular time series\nclassification and forecasting datasets.\n","authors":["Maurice Kraus","David Steinmann","Antonia Wüst","Andre Kokozinski","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2402.12921v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16780v2","updated":"2024-12-10T18:45:18Z","published":"2024-10-22T07:53:41Z","title":"Beyond Retrieval: Generating Narratives in Conversational Recommender\n  Systems","summary":"  The recent advances in Large Language Model's generation and reasoning\ncapabilities present an opportunity to develop truly conversational\nrecommendation systems. However, effectively integrating recommender system\nknowledge into LLMs for natural language generation which is tailored towards\nrecommendation tasks remains a challenge. This paper addresses this challenge\nby making two key contributions.\n  First, we introduce a new dataset (REGEN) for natural language generation\ntasks in conversational recommendations. REGEN (Reviews Enhanced with\nGEnerative Narratives) extends the Amazon Product Reviews dataset with rich\nuser narratives, including personalized explanations of product preferences,\nproduct endorsements for recommended items, and summaries of user purchase\nhistory. REGEN is made publicly available to facilitate further research.\nFurthermore, we establish benchmarks using well-known generative metrics, and\nperform an automated evaluation of the new dataset using a rater LLM. Second,\nthe paper introduces a fusion architecture (CF model with an LLM) which serves\nas a baseline for REGEN. And to the best of our knowledge, represents the first\nattempt to analyze the capabilities of LLMs in understanding recommender\nsignals and generating rich narratives. We demonstrate that LLMs can\neffectively learn from simple fusion architectures utilizing interaction-based\nCF embeddings, and this can be further enhanced using the metadata and\npersonalization data associated with items. Our experiments show that combining\nCF and content embeddings leads to improvements of 4-12% in key language\nmetrics compared to using either type of embedding individually. We also\nprovide an analysis to interpret how CF and content embeddings contribute to\nthis new generative task.\n","authors":["Krishna Sayana","Raghavendra Vasudeva","Yuri Vasilevski","Kun Su","Liam Hebert","James Pine","Hubert Pham","Ambarish Jash","Sukhdeep Sodhi"],"pdf_url":"https://arxiv.org/pdf/2410.16780v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07746v1","updated":"2024-12-10T18:45:04Z","published":"2024-12-10T18:45:04Z","title":"LoRA3D: Low-Rank Self-Calibration of 3D Geometric Foundation Models","summary":"  Emerging 3D geometric foundation models, such as DUSt3R, offer a promising\napproach for in-the-wild 3D vision tasks. However, due to the high-dimensional\nnature of the problem space and scarcity of high-quality 3D data, these\npre-trained models still struggle to generalize to many challenging\ncircumstances, such as limited view overlap or low lighting. To address this,\nwe propose LoRA3D, an efficient self-calibration pipeline to\n$\\textit{specialize}$ the pre-trained models to target scenes using their own\nmulti-view predictions. Taking sparse RGB images as input, we leverage robust\noptimization techniques to refine multi-view predictions and align them into a\nglobal coordinate frame. In particular, we incorporate prediction confidence\ninto the geometric optimization process, automatically re-weighting the\nconfidence to better reflect point estimation accuracy. We use the calibrated\nconfidence to generate high-quality pseudo labels for the calibrating views and\nuse low-rank adaptation (LoRA) to fine-tune the models on the pseudo-labeled\ndata. Our method does not require any external priors or manual labels. It\ncompletes the self-calibration process on a $\\textbf{single standard GPU within\njust 5 minutes}$. Each low-rank adapter requires only $\\textbf{18MB}$ of\nstorage. We evaluated our method on $\\textbf{more than 160 scenes}$ from the\nReplica, TUM and Waymo Open datasets, achieving up to $\\textbf{88% performance\nimprovement}$ on 3D reconstruction, multi-view pose estimation and novel-view\nrendering.\n","authors":["Ziqi Lu","Heng Yang","Danfei Xu","Boyi Li","Boris Ivanovic","Marco Pavone","Yue Wang"],"pdf_url":"https://arxiv.org/pdf/2412.07746v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.06752v3","updated":"2024-12-10T18:34:46Z","published":"2024-09-10T14:04:58Z","title":"A tutorial on automatic differentiation with complex numbers","summary":"  Automatic differentiation is everywhere, but there exists only minimal\ndocumentation of how it works in complex arithmetic beyond stating \"derivatives\nin $\\mathbb{C}^d$\" $\\cong$ \"derivatives in $\\mathbb{R}^{2d}$\" and, at best,\nshallow references to Wirtinger calculus. Unfortunately, the equivalence\n$\\mathbb{C}^d \\cong \\mathbb{R}^{2d}$ becomes insufficient as soon as we need to\nderive custom gradient rules, e.g., to avoid differentiating \"through\"\nexpensive linear algebra functions or differential equation simulators. To\ncombat such a lack of documentation, this article surveys forward- and\nreverse-mode automatic differentiation with complex numbers, covering topics\nsuch as Wirtinger derivatives, a modified chain rule, and different gradient\nconventions while explicitly avoiding holomorphicity and the Cauchy--Riemann\nequations (which would be far too restrictive). To be precise, we will derive,\nexplain, and implement a complex version of Jacobian-vector and vector-Jacobian\nproducts almost entirely with linear algebra without relying on complex\nanalysis or differential geometry. This tutorial is a call to action, for users\nand developers alike, to take complex values seriously when implementing custom\ngradient propagation rules -- the manuscript explains how.\n","authors":["Nicholas Krämer"],"pdf_url":"https://arxiv.org/pdf/2409.06752v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07737v1","updated":"2024-12-10T18:34:08Z","published":"2024-12-10T18:34:08Z","title":"Explainable machine learning for neoplasms diagnosis via\n  electrocardiograms: an externally validated study","summary":"  Background: Neoplasms remains a leading cause of mortality worldwide, with\ntimely diagnosis being crucial for improving patient outcomes. Current\ndiagnostic methods are often invasive, costly, and inaccessible to many\npopulations. Electrocardiogram (ECG) data, widely available and non-invasive,\nhas the potential to serve as a tool for neoplasms diagnosis by using\nphysiological changes in cardiovascular function associated with neoplastic\nprescences.\n  Methods: This study explores the application of machine learning models to\nanalyze ECG features for the diagnosis of neoplasms. We developed a pipeline\nintegrating tree-based models with Shapley values for explainability. The model\nwas trained and internally validated and externally validated on a second\nlarge-scale independent external cohort to ensure robustness and\ngeneralizability.\n  Findings: The results demonstrate that ECG data can effectively capture\nneoplasms-associated cardiovascular changes, achieving high performance in both\ninternal testing and external validation cohorts. Shapley values identified key\nECG features influencing model predictions, revealing established and novel\ncardiovascular markers linked to neoplastic conditions. This non-invasive\napproach provides a cost-effective and scalable alternative for the diagnosis\nof neoplasms, particularly in resource-limited settings. Similarly, useful for\nthe management of secondary cardiovascular effects given neoplasms therapies.\n  Interpretation: This study highlights the feasibility of leveraging ECG\nsignals and machine learning to enhance neoplasms diagnostics. By offering\ninterpretable insights into cardio-neoplasms interactions, this approach\nbridges existing gaps in non-invasive diagnostics and has implications for\nintegrating ECG-based tools into broader neoplasms diagnostic frameworks, as\nwell as neoplasms therapy management.\n","authors":["Juan Miguel Lopez Alcaraz","Wilhelm Haverkamp","Nils Strodthoff"],"pdf_url":"https://arxiv.org/pdf/2412.07737v1.pdf","comment":"9 pages, 2 figures, code under\n  https://github.com/AI4HealthUOL/CardioDiag"},{"id":"http://arxiv.org/abs/2109.04266v4","updated":"2024-12-10T18:31:50Z","published":"2021-09-09T13:35:01Z","title":"An objective function for order preserving hierarchical clustering","summary":"  We present a theory and an objective function for similarity-based\nhierarchical clustering of probabilistic partial orders and directed acyclic\ngraphs (DAGs). Specifically, given elements $x \\le y$ in the partial order, and\ntheir respective clusters $[x]$ and $[y]$, the theory yields an order relation\n$\\le'$ on the clusters such that $[x]\\le'[y]$. The theory provides a concise\ndefinition of order-preserving hierarchical clustering, and offers a\nclassification theorem identifying the order-preserving trees (dendrograms). To\ndetermine the optimal order-preserving trees, we develop an objective function\nthat frames the problem as a bi-objective optimisation, aiming to satisfy both\nthe order relation and the similarity measure. We prove that the optimal trees\nunder the objective are both order-preserving and exhibit high-quality\nhierarchical clustering. Since finding an optimal solution is NP-hard, we\nintroduce a polynomial-time approximation algorithm and demonstrate that the\nmethod outperforms existing methods for order-preserving hierarchical\nclustering by a significant margin.\n","authors":["Daniel Bakkelund"],"pdf_url":"https://arxiv.org/pdf/2109.04266v4.pdf","comment":"39 pages"},{"id":"http://arxiv.org/abs/2412.05467v2","updated":"2024-12-10T18:28:46Z","published":"2024-12-06T23:43:59Z","title":"The BrowserGym Ecosystem for Web Agent Research","summary":"  The BrowserGym ecosystem addresses the growing need for efficient evaluation\nand benchmarking of web agents, particularly those leveraging automation and\nLarge Language Models (LLMs) for web interaction tasks. Many existing\nbenchmarks suffer from fragmentation and inconsistent evaluation methodologies,\nmaking it challenging to achieve reliable comparisons and reproducible results.\nBrowserGym aims to solve this by providing a unified, gym-like environment with\nwell-defined observation and action spaces, facilitating standardized\nevaluation across diverse benchmarks. Combined with AgentLab, a complementary\nframework that aids in agent creation, testing, and analysis, BrowserGym offers\nflexibility for integrating new benchmarks while ensuring consistent evaluation\nand comprehensive experiment management. This standardized approach seeks to\nreduce the time and complexity of developing web agents, supporting more\nreliable comparisons and facilitating in-depth analysis of agent behaviors, and\ncould result in more adaptable, capable agents, ultimately accelerating\ninnovation in LLM-driven automation. As a supporting evidence, we conduct the\nfirst large-scale, multi-benchmark web agent experiment and compare the\nperformance of 6 state-of-the-art LLMs across all benchmarks currently\navailable in BrowserGym. Among other findings, our results highlight a large\ndiscrepancy between OpenAI and Anthropic's latests models, with\nClaude-3.5-Sonnet leading the way on almost all benchmarks, except on\nvision-related tasks where GPT-4o is superior. Despite these advancements, our\nresults emphasize that building robust and efficient web agents remains a\nsignificant challenge, due to the inherent complexity of real-world web\nenvironments and the limitations of current models.\n","authors":["Thibault Le Sellier De Chezelles","Maxime Gasse","Alexandre Drouin","Massimo Caccia","Léo Boisvert","Megh Thakkar","Tom Marty","Rim Assouel","Sahar Omidi Shayegan","Lawrence Keunho Jang","Xing Han Lù","Ori Yoran","Dehan Kong","Frank F. Xu","Siva Reddy","Quentin Cappart","Graham Neubig","Ruslan Salakhutdinov","Nicolas Chapados","Alexandre Lacoste"],"pdf_url":"https://arxiv.org/pdf/2412.05467v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07730v1","updated":"2024-12-10T18:27:06Z","published":"2024-12-10T18:27:06Z","title":"STIV: Scalable Text and Image Conditioned Video Generation","summary":"  The field of video generation has made remarkable advancements, yet there\nremains a pressing need for a clear, systematic recipe that can guide the\ndevelopment of robust and scalable models. In this work, we present a\ncomprehensive study that systematically explores the interplay of model\narchitectures, training recipes, and data curation strategies, culminating in a\nsimple and scalable text-image-conditioned video generation method, named STIV.\nOur framework integrates image condition into a Diffusion Transformer (DiT)\nthrough frame replacement, while incorporating text conditioning via a joint\nimage-text conditional classifier-free guidance. This design enables STIV to\nperform both text-to-video (T2V) and text-image-to-video (TI2V) tasks\nsimultaneously. Additionally, STIV can be easily extended to various\napplications, such as video prediction, frame interpolation, multi-view\ngeneration, and long video generation, etc. With comprehensive ablation studies\non T2I, T2V, and TI2V, STIV demonstrate strong performance, despite its simple\ndesign. An 8.7B model with 512 resolution achieves 83.1 on VBench T2V,\nsurpassing both leading open and closed-source models like CogVideoX-5B, Pika,\nKling, and Gen-3. The same-sized model also achieves a state-of-the-art result\nof 90.1 on VBench I2V task at 512 resolution. By providing a transparent and\nextensible recipe for building cutting-edge video generation models, we aim to\nempower future research and accelerate progress toward more versatile and\nreliable video generation solutions.\n","authors":["Zongyu Lin","Wei Liu","Chen Chen","Jiasen Lu","Wenze Hu","Tsu-Jui Fu","Jesse Allardice","Zhengfeng Lai","Liangchen Song","Bowen Zhang","Cha Chen","Yiran Fei","Yifan Jiang","Lezhi Li","Yizhou Sun","Kai-Wei Chang","Yinfei Yang"],"pdf_url":"https://arxiv.org/pdf/2412.07730v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01752v2","updated":"2024-12-10T18:21:13Z","published":"2024-10-02T17:02:17Z","title":"TorchSISSO: A PyTorch-Based Implementation of the Sure Independence\n  Screening and Sparsifying Operator for Efficient and Interpretable Model\n  Discovery","summary":"  Symbolic regression (SR) is a powerful machine learning approach that\nsearches for both the structure and parameters of algebraic models, offering\ninterpretable and compact representations of complex data. Unlike traditional\nregression methods, SR explores progressively complex feature spaces, which can\nuncover simple models that generalize well, even from small datasets. Among SR\nalgorithms, the Sure Independence Screening and Sparsifying Operator (SISSO)\nhas proven particularly effective in the natural sciences, helping to\nrediscover fundamental physical laws as well as discover new interpretable\nequations for materials property modeling. However, its widespread adoption has\nbeen limited by performance inefficiencies and the challenges posed by its\nFORTRAN-based implementation, especially in modern computing environments. In\nthis work, we introduce TorchSISSO, a native Python implementation built in the\nPyTorch framework. TorchSISSO leverages GPU acceleration, easy integration, and\nextensibility, offering a significant speed-up and improved accuracy over the\noriginal. We demonstrate that TorchSISSO matches or exceeds the performance of\nthe original SISSO across a range of tasks, while dramatically reducing\ncomputational time and improving accessibility for broader scientific\napplications.\n","authors":["Madhav Muthyala","Farshud Sorourifar","Joel A. Paulson"],"pdf_url":"https://arxiv.org/pdf/2410.01752v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.12253v2","updated":"2024-12-10T18:19:29Z","published":"2024-04-18T15:21:34Z","title":"Toward Self-Improvement of LLMs via Imagination, Searching, and\n  Criticizing","summary":"  Despite the impressive capabilities of Large Language Models (LLMs) on\nvarious tasks, they still struggle with scenarios that involves complex\nreasoning and planning. Recent work proposed advanced prompting techniques and\nthe necessity of fine-tuning with high-quality data to augment LLMs' reasoning\nabilities. However, these approaches are inherently constrained by data\navailability and quality. In light of this, self-correction and self-learning\nemerge as viable solutions, employing strategies that allow LLMs to refine\ntheir outputs and learn from self-assessed rewards. Yet, the efficacy of LLMs\nin self-refining its response, particularly in complex reasoning and planning\ntask, remains dubious. In this paper, we introduce AlphaLLM for the\nself-improvements of LLMs, which integrates Monte Carlo Tree Search (MCTS) with\nLLMs to establish a self-improving loop, thereby enhancing the capabilities of\nLLMs without additional annotations. Drawing inspiration from the success of\nAlphaGo, AlphaLLM addresses the unique challenges of combining MCTS with LLM\nfor self-improvement, including data scarcity, the vastness search spaces of\nlanguage tasks, and the subjective nature of feedback in language tasks.\nAlphaLLM is comprised of prompt synthesis component, an efficient MCTS approach\ntailored for language tasks, and a trio of critic models for precise feedback.\nOur experimental results in mathematical reasoning tasks demonstrate that\nAlphaLLM significantly enhances the performance of LLMs without additional\nannotations, showing the potential for self-improvement in LLMs.\n","authors":["Ye Tian","Baolin Peng","Linfeng Song","Lifeng Jin","Dian Yu","Haitao Mi","Dong Yu"],"pdf_url":"https://arxiv.org/pdf/2404.12253v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.02168v2","updated":"2024-12-10T18:14:14Z","published":"2024-11-04T15:26:07Z","title":"Do graph neural network states contain graph properties?","summary":"  Deep neural networks (DNNs) achieve state-of-the-art performance on many\ntasks, but this often requires increasingly larger model sizes, which in turn\nleads to more complex internal representations. Explainability techniques (XAI)\nhave made remarkable progress in the interpretability of ML models. However,\nthe non-relational nature of Graph neural networks (GNNs) make it difficult to\nreuse already existing XAI methods. While other works have focused on\ninstance-based explanation methods for GNNs, very few have investigated\nmodel-based methods and, to our knowledge, none have tried to probe the\nembedding of the GNNs for well-known structural graph properties. In this paper\nwe present a model agnostic explainability pipeline for GNNs employing\ndiagnostic classifiers. This pipeline aims to probe and interpret the learned\nrepresentations in GNNs across various architectures and datasets, refining our\nunderstanding and trust in these models.\n","authors":["Tom Pelletreau-Duris","Ruud van Bakel","Michael Cochez"],"pdf_url":"https://arxiv.org/pdf/2411.02168v2.pdf","comment":"10 pages, 22 figures, conference"},{"id":"http://arxiv.org/abs/2411.07272v2","updated":"2024-12-10T18:04:57Z","published":"2024-11-10T18:17:15Z","title":"ASTD Patterns for Integrated Continuous Anomaly Detection In Data Logs","summary":"  This paper investigates the use of the ASTD language for ensemble anomaly\ndetection in data logs. It uses a sliding window technique for continuous\nlearning in data streams, coupled with updating learning models upon the\ncompletion of each window to maintain accurate detection and align with current\ndata trends. It proposes ASTD patterns for combining learning models,\nespecially in the context of unsupervised learning, which is commonly used for\ndata streams. To facilitate this, a new ASTD operator is proposed, the\nQuantified Flow, which enables the seamless combination of learning models\nwhile ensuring that the specification remains concise. Our contribution is a\nspecification pattern, highlighting the capacity of ASTDs to abstract and\nmodularize anomaly detection systems. The ASTD language provides a unique\napproach to develop data flow anomaly detection systems, grounded in the\ncombination of processes through the graphical representation of the language\noperators. This simplifies the design task for developers, who can focus\nprimarily on defining the functional operations that constitute the system.\n","authors":["Chaymae El Jabri","Marc Frappier","Pierre-Martin Tardif"],"pdf_url":"https://arxiv.org/pdf/2411.07272v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23129v2","updated":"2024-12-10T17:57:03Z","published":"2024-10-30T15:41:30Z","title":"Why Fine-grained Labels in Pretraining Benefit Generalization?","summary":"  Recent studies show that pretraining a deep neural network with fine-grained\nlabeled data, followed by fine-tuning on coarse-labeled data for downstream\ntasks, often yields better generalization than pretraining with coarse-labeled\ndata. While there is ample empirical evidence supporting this, the theoretical\njustification remains an open problem. This paper addresses this gap by\nintroducing a \"hierarchical multi-view\" structure to confine the input data\ndistribution. Under this framework, we prove that: 1) coarse-grained\npretraining only allows a neural network to learn the common features well,\nwhile 2) fine-grained pretraining helps the network learn the rare features in\naddition to the common ones, leading to improved accuracy on hard downstream\ntest samples.\n","authors":["Guan Zhe Hong","Yin Cui","Ariel Fuxman","Stanley Chan","Enming Luo"],"pdf_url":"https://arxiv.org/pdf/2410.23129v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2303.16887"},{"id":"http://arxiv.org/abs/2412.07698v1","updated":"2024-12-10T17:38:36Z","published":"2024-12-10T17:38:36Z","title":"Quantum vs. Classical Machine Learning Algorithms for Software Defect\n  Prediction: Challenges and Opportunities","summary":"  Software defect prediction is a critical aspect of software quality\nassurance, as it enables early identification and mitigation of defects,\nthereby reducing the cost and impact of software failures. Over the past few\nyears, quantum computing has risen as an exciting technology capable of\ntransforming multiple domains; Quantum Machine Learning (QML) is one of them.\nQML algorithms harness the power of quantum computing to solve complex problems\nwith better efficiency and effectiveness than their classical counterparts.\nHowever, research into its application in software engineering to predict\nsoftware defects still needs to be explored. In this study, we worked to fill\nthe research gap by comparing the performance of three QML and five classical\nmachine learning (CML) algorithms on the 20 software defect datasets. Our\ninvestigation reports the comparative scenarios of QML vs. CML algorithms and\nidentifies the better-performing and consistent algorithms to predict software\ndefects. We also highlight the challenges and future directions of employing\nQML algorithms in real software defect datasets based on the experience we\nfaced while performing this investigation. The findings of this study can help\npractitioners and researchers further progress in this research domain by\nmaking software systems reliable and bug-free.\n","authors":["Md Nadim","Mohammad Hassan","Ashis Kumar Mandal","Chanchal K. Roy"],"pdf_url":"https://arxiv.org/pdf/2412.07698v1.pdf","comment":"In the proceedings of the 6th Quantum Software Engineering (Q-SE)\n  workshop at the 47th IEEE/ACM International Conference on Software\n  Engineering (ICSE 2025)"},{"id":"http://arxiv.org/abs/2412.07696v1","updated":"2024-12-10T17:35:12Z","published":"2024-12-10T17:35:12Z","title":"SimVS: Simulating World Inconsistencies for Robust View Synthesis","summary":"  Novel-view synthesis techniques achieve impressive results for static scenes\nbut struggle when faced with the inconsistencies inherent to casual capture\nsettings: varying illumination, scene motion, and other unintended effects that\nare difficult to model explicitly. We present an approach for leveraging\ngenerative video models to simulate the inconsistencies in the world that can\noccur during capture. We use this process, along with existing multi-view\ndatasets, to create synthetic data for training a multi-view harmonization\nnetwork that is able to reconcile inconsistent observations into a consistent\n3D scene. We demonstrate that our world-simulation strategy significantly\noutperforms traditional augmentation methods in handling real-world scene\nvariations, thereby enabling highly accurate static 3D reconstructions in the\npresence of a variety of challenging inconsistencies. Project page:\nhttps://alextrevithick.github.io/simvs\n","authors":["Alex Trevithick","Roni Paiss","Philipp Henzler","Dor Verbin","Rundi Wu","Hadi Alzayer","Ruiqi Gao","Ben Poole","Jonathan T. Barron","Aleksander Holynski","Ravi Ramamoorthi","Pratul P. Srinivasan"],"pdf_url":"https://arxiv.org/pdf/2412.07696v1.pdf","comment":"Project page: https://alextrevithick.github.io/simvs"},{"id":"http://arxiv.org/abs/2412.07687v1","updated":"2024-12-10T17:20:47Z","published":"2024-12-10T17:20:47Z","title":"Privacy-Preserving Customer Support: A Framework for Secure and Scalable\n  Interactions","summary":"  The growing reliance on artificial intelligence (AI) in customer support has\nsignificantly improved operational efficiency and user experience. However,\ntraditional machine learning (ML) approaches, which require extensive local\ntraining on sensitive datasets, pose substantial privacy risks and compliance\nchallenges with regulations like the General Data Protection Regulation (GDPR)\nand California Consumer Privacy Act (CCPA). Existing privacy-preserving\ntechniques, such as anonymization, differential privacy, and federated\nlearning, address some concerns but face limitations in utility, scalability,\nand complexity. This paper introduces the Privacy-Preserving Zero-Shot Learning\n(PP-ZSL) framework, a novel approach leveraging large language models (LLMs) in\na zero-shot learning mode. Unlike conventional ML methods, PP-ZSL eliminates\nthe need for local training on sensitive data by utilizing pre-trained LLMs to\ngenerate responses directly. The framework incorporates real-time data\nanonymization to redact or mask sensitive information, retrieval-augmented\ngeneration (RAG) for domain-specific query resolution, and robust\npost-processing to ensure compliance with regulatory standards. This\ncombination reduces privacy risks, simplifies compliance, and enhances\nscalability and operational efficiency. Empirical analysis demonstrates that\nthe PP-ZSL framework provides accurate, privacy-compliant responses while\nsignificantly lowering the costs and complexities of deploying AI-driven\ncustomer support systems. The study highlights potential applications across\nindustries, including financial services, healthcare, e-commerce, legal\nsupport, telecommunications, and government services. By addressing the dual\nchallenges of privacy and performance, this framework establishes a foundation\nfor secure, efficient, and regulatory-compliant AI applications in customer\ninteractions.\n","authors":["Anant Prakash Awasthi","Chandraketu Singh","Rakshit Varma","Sanchit Sharma"],"pdf_url":"https://arxiv.org/pdf/2412.07687v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07686v1","updated":"2024-12-10T17:20:44Z","published":"2024-12-10T17:20:44Z","title":"Optimizing Sensor Redundancy in Sequential Decision-Making Problems","summary":"  Reinforcement Learning (RL) policies are designed to predict actions based on\ncurrent observations to maximize cumulative future rewards. In real-world\napplications (i.e., non-simulated environments), sensors are essential for\nmeasuring the current state and providing the observations on which RL policies\nrely to make decisions. A significant challenge in deploying RL policies in\nreal-world scenarios is handling sensor dropouts, which can result from\nhardware malfunctions, physical damage, or environmental factors like dust on a\ncamera lens. A common strategy to mitigate this issue is the use of backup\nsensors, though this comes with added costs. This paper explores the\noptimization of backup sensor configurations to maximize expected returns while\nkeeping costs below a specified threshold, C. Our approach uses a second-order\napproximation of expected returns and includes penalties for exceeding cost\nconstraints. We then optimize this quadratic program using Tabu Search, a\nmeta-heuristic algorithm. The approach is evaluated across eight OpenAI Gym\nenvironments and a custom Unity-based robotic environment (RobotArmGrasping).\nEmpirical results demonstrate that our quadratic program effectively\napproximates real expected returns, facilitating the identification of optimal\nsensor configurations.\n","authors":["Jonas Nüßlein","Maximilian Zorn","Fabian Ritz","Jonas Stein","Gerhard Stenzel","Julian Schönberger","Thomas Gabor","Claudia Linnhoff-Popien"],"pdf_url":"https://arxiv.org/pdf/2412.07686v1.pdf","comment":"Accepted at ICAART conference 2025"},{"id":"http://arxiv.org/abs/2412.07684v1","updated":"2024-12-10T17:18:33Z","published":"2024-12-10T17:18:33Z","title":"The Pitfalls of Memorization: When Memorization Hurts Generalization","summary":"  Neural networks often learn simple explanations that fit the majority of the\ndata while memorizing exceptions that deviate from these explanations.This\nbehavior leads to poor generalization when the learned explanations rely on\nspurious correlations. In this work, we formalize the interplay between\nmemorization and generalization, showing that spurious correlations would\nparticularly lead to poor generalization when are combined with memorization.\nMemorization can reduce training loss to zero, leaving no incentive to learn\nrobust, generalizable patterns. To address this, we propose memorization-aware\ntraining (MAT), which uses held-out predictions as a signal of memorization to\nshift a model's logits. MAT encourages learning robust patterns invariant\nacross distributions, improving generalization under distribution shifts.\n","authors":["Reza Bayat","Mohammad Pezeshki","Elvis Dohmatob","David Lopez-Paz","Pascal Vincent"],"pdf_url":"https://arxiv.org/pdf/2412.07684v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.12207v3","updated":"2024-12-10T17:06:57Z","published":"2024-05-20T17:47:18Z","title":"Optimistic Query Routing in Clustering-based Approximate Maximum Inner\n  Product Search","summary":"  Clustering-based nearest neighbor search is an effective method in which\npoints are partitioned into geometric shards to form an index, with only a few\nshards searched during query processing to find a set of top-$k$ vectors. Even\nthough the search efficacy is heavily influenced by the algorithm that\nidentifies the shards to probe, it has received little attention in the\nliterature. This work bridges that gap by studying routing in clustering-based\nmaximum inner product search. We unpack existing routers and notice the\nsurprising contribution of optimism. We then take a page from the sequential\ndecision making literature and formalize that insight following the principle\nof ``optimism in the face of uncertainty.'' In particular, we present a\nframework that incorporates the moments of the distribution of inner products\nwithin each shard to estimate the maximum inner product. We then present an\ninstance of our algorithm that uses only the first two moments to reach the\nsame accuracy as state-of-the-art routers such as ScaNN by probing up to $50\\%$\nfewer points on benchmark datasets. Our algorithm is also space-efficient: we\ndesign a sketch of the second moment whose size is independent of the number of\npoints and requires $\\mathcal{O}(1)$ vectors per shard.\n","authors":["Sebastian Bruch","Aditya Krishnan","Franco Maria Nardini"],"pdf_url":"https://arxiv.org/pdf/2405.12207v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07675v1","updated":"2024-12-10T17:02:58Z","published":"2024-12-10T17:02:58Z","title":"RAZOR: Sharpening Knowledge by Cutting Bias with Unsupervised Text\n  Rewriting","summary":"  Despite the widespread use of LLMs due to their superior performance in\nvarious tasks, their high computational costs often lead potential users to opt\nfor the pretraining-finetuning pipeline. However, biases prevalent in manually\nconstructed datasets can introduce spurious correlations between tokens and\nlabels, creating so-called shortcuts and hindering the generalizability of\nfine-tuned models. Existing debiasing methods often rely on prior knowledge of\nspecific dataset biases, which is challenging to acquire a priori. We propose\nRAZOR (Rewriting And Zero-bias Optimization Refinement), a novel, unsupervised,\nand data-focused debiasing approach based on text rewriting for shortcut\nmitigation. RAZOR leverages LLMs to iteratively rewrite potentially biased text\nsegments by replacing them with heuristically selected alternatives in a\nshortcut space defined by token statistics and positional information. This\nprocess aims to align surface-level text features more closely with diverse\nlabel distributions, thereby promoting the learning of genuine linguistic\npatterns. Compared with unsupervised SoTA models, RAZOR improves by 3.5% on the\nFEVER and 6.5% on MNLI and SNLI datasets according to the F1 score.\nAdditionally, RAZOR effectively mitigates specific known biases, reducing\nbias-related terms by x2 without requiring prior bias information, a result\nthat is on par with SoTA models that leverage prior information. Our work\nprioritizes data manipulation over architectural modifications, emphasizing the\npivotal role of data quality in enhancing model performance and fairness. This\nresearch contributes to developing more robust evaluation benchmarks for\ndebiasing methods by incorporating metrics for bias reduction and overall model\nefficacy.\n","authors":["Shuo Yang","Bardh Prenkaj","Gjergji Kasneci"],"pdf_url":"https://arxiv.org/pdf/2412.07675v1.pdf","comment":"Shuo and Bardh contributed equally. Accepted to AAAI'25"},{"id":"http://arxiv.org/abs/2412.05767v2","updated":"2024-12-10T16:59:55Z","published":"2024-12-08T00:22:58Z","title":"DeMem: Privacy-Enhanced Robust Adversarial Learning via De-Memorization","summary":"  Adversarial robustness, the ability of a model to withstand manipulated\ninputs that cause errors, is essential for ensuring the trustworthiness of\nmachine learning models in real-world applications. However, previous studies\nhave shown that enhancing adversarial robustness through adversarial training\nincreases vulnerability to privacy attacks. While differential privacy can\nmitigate these attacks, it often compromises robustness against both natural\nand adversarial samples. Our analysis reveals that differential privacy\ndisproportionately impacts low-risk samples, causing an unintended performance\ndrop. To address this, we propose DeMem, which selectively targets high-risk\nsamples, achieving a better balance between privacy protection and model\nrobustness. DeMem is versatile and can be seamlessly integrated into various\nadversarial training techniques. Extensive evaluations across multiple training\nmethods and datasets demonstrate that DeMem significantly reduces privacy\nleakage while maintaining robustness against both natural and adversarial\nsamples. These results confirm DeMem's effectiveness and broad applicability in\nenhancing privacy without compromising robustness.\n","authors":["Xiaoyu Luo","Qiongxiu Li"],"pdf_url":"https://arxiv.org/pdf/2412.05767v2.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2412.07658v1","updated":"2024-12-10T16:45:03Z","published":"2024-12-10T16:45:03Z","title":"TraSCE: Trajectory Steering for Concept Erasure","summary":"  Recent advancements in text-to-image diffusion models have brought them to\nthe public spotlight, becoming widely accessible and embraced by everyday\nusers. However, these models have been shown to generate harmful content such\nas not-safe-for-work (NSFW) images. While approaches have been proposed to\nerase such abstract concepts from the models, jail-breaking techniques have\nsucceeded in bypassing such safety measures. In this paper, we propose TraSCE,\nan approach to guide the diffusion trajectory away from generating harmful\ncontent. Our approach is based on negative prompting, but as we show in this\npaper, conventional negative prompting is not a complete solution and can\neasily be bypassed in some corner cases. To address this issue, we first\npropose a modification of conventional negative prompting. Furthermore, we\nintroduce a localized loss-based guidance that enhances the modified negative\nprompting technique by steering the diffusion trajectory. We demonstrate that\nour proposed method achieves state-of-the-art results on various benchmarks in\nremoving harmful content including ones proposed by red teams; and erasing\nartistic styles and objects. Our proposed approach does not require any\ntraining, weight modifications, or training data (both image or prompt), making\nit easier for model owners to erase new concepts.\n","authors":["Anubhav Jain","Yuya Kobayashi","Takashi Shibuya","Yuhta Takida","Nasir Memon","Julian Togelius","Yuki Mitsufuji"],"pdf_url":"https://arxiv.org/pdf/2412.07658v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07655v1","updated":"2024-12-10T16:41:19Z","published":"2024-12-10T16:41:19Z","title":"Bayesian Data Augmentation and Training for Perception DNN in Autonomous\n  Aerial Vehicles","summary":"  Learning-based solutions have enabled incredible capabilities for autonomous\nsystems. Autonomous vehicles, both aerial and ground, rely on DNN for various\nintegral tasks, including perception. The efficacy of supervised learning\nsolutions hinges on the quality of the training data. Discrepancies between\ntraining data and operating conditions result in faults that can lead to\ncatastrophic incidents. However, collecting vast amounts of context-sensitive\ndata, with broad coverage of possible operating environments, is prohibitively\ndifficult. Synthetic data generation techniques for DNN allow for the easy\nexploration of diverse scenarios. However, synthetic data generation solutions\nfor aerial vehicles are still lacking.\n  This work presents a data augmentation framework for aerial vehicle's\nperception training, leveraging photorealistic simulation integrated with\nhigh-fidelity vehicle dynamics. Safe landing is a crucial challenge in the\ndevelopment of autonomous air taxis, therefore, landing maneuver is chosen as\nthe focus of this work. With repeated simulations of landing in varying\nscenarios we assess the landing performance of the VTOL type UAV and gather\nvaluable data. The landing performance is used as the objective function to\noptimize the DNN through retraining. Given the high computational cost of DNN\nretraining, we incorporated Bayesian Optimization in our framework that\nsystematically explores the data augmentation parameter space to retrain the\nbest-performing models. The framework allowed us to identify high-performing\ndata augmentation parameters that are consistently effective across different\nlanding scenarios. Utilizing the capabilities of this data augmentation\nframework, we obtained a robust perception model. The model consistently\nimproved the perception-based landing success rate by at least 20% under\ndifferent lighting and weather conditions.\n","authors":["Ashik E Rasul","Humaira Tasnim","Hyung-Jin Yoon","Ayoosh Bansal","Duo Wang","Naira Hovakimyan","Lui Sha","Petros Voulgaris"],"pdf_url":"https://arxiv.org/pdf/2412.07655v1.pdf","comment":"To be published in AIAA SciTech 2025 Forum"},{"id":"http://arxiv.org/abs/2411.03865v2","updated":"2024-12-10T16:41:12Z","published":"2024-11-06T12:19:01Z","title":"AdaSociety: An Adaptive Environment with Social Structures for\n  Multi-Agent Decision-Making","summary":"  Traditional interactive environments limit agents' intelligence growth with\nfixed tasks. Recently, single-agent environments address this by generating new\ntasks based on agent actions, enhancing task diversity. We consider the\ndecision-making problem in multi-agent settings, where tasks are further\ninfluenced by social connections, affecting rewards and information access.\nHowever, existing multi-agent environments lack a combination of adaptive\nphysical surroundings and social connections, hindering the learning of\nintelligent behaviors. To address this, we introduce AdaSociety, a customizable\nmulti-agent environment featuring expanding state and action spaces, alongside\nexplicit and alterable social structures. As agents progress, the environment\nadaptively generates new tasks with social structures for agents to undertake.\nIn AdaSociety, we develop three mini-games showcasing distinct social\nstructures and tasks. Initial results demonstrate that specific social\nstructures can promote both individual and collective benefits, though current\nreinforcement learning and LLM-based algorithms show limited effectiveness in\nleveraging social structures to enhance performance. Overall, AdaSociety serves\nas a valuable research platform for exploring intelligence in diverse physical\nand social settings. The code is available at\nhttps://github.com/bigai-ai/AdaSociety.\n","authors":["Yizhe Huang","Xingbo Wang","Hao Liu","Fanqi Kong","Aoyang Qin","Min Tang","Xiaoxi Wang","Song-Chun Zhu","Mingjie Bi","Siyuan Qi","Xue Feng"],"pdf_url":"https://arxiv.org/pdf/2411.03865v2.pdf","comment":"Accepted at NeurIPS D&B 2024"},{"id":"http://arxiv.org/abs/2407.20471v2","updated":"2024-12-10T16:40:49Z","published":"2024-07-30T00:16:50Z","title":"Relaxed Equivariant Graph Neural Networks","summary":"  3D Euclidean symmetry equivariant neural networks have demonstrated notable\nsuccess in modeling complex physical systems. We introduce a framework for\nrelaxed $E(3)$ graph equivariant neural networks that can learn and represent\nsymmetry breaking within continuous groups. Building on the existing e3nn\nframework, we propose the use of relaxed weights to allow for controlled\nsymmetry breaking. We show empirically that these relaxed weights learn the\ncorrect amount of symmetry breaking.\n","authors":["Elyssa Hofgard","Rui Wang","Robin Walters","Tess Smidt"],"pdf_url":"https://arxiv.org/pdf/2407.20471v2.pdf","comment":"Extended abstract presented at the Geometry-grounded Representation\n  Learning and Generative Modeling Workshop (GRaM) at the 41st International\n  Conference on Machine Learning, July 2024, Vienna, Austria"},{"id":"http://arxiv.org/abs/2406.19370v3","updated":"2024-12-10T16:40:34Z","published":"2024-06-27T17:50:05Z","title":"Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept\n  Space","summary":"  Modern generative models demonstrate impressive capabilities, likely stemming\nfrom an ability to identify and manipulate abstract concepts underlying their\ntraining data. However, fundamental questions remain: what determines the\nconcepts a model learns, the order in which it learns them, and its ability to\nmanipulate those concepts? To address these questions, we propose analyzing a\nmodel's learning dynamics via a framework we call the concept space, where each\naxis represents an independent concept underlying the data generating process.\nBy characterizing learning dynamics in this space, we identify how the speed at\nwhich a concept is learned, and hence the order of concept learning, is\ncontrolled by properties of the data we term concept signal. Further, we\nobserve moments of sudden turns in the direction of a model's learning dynamics\nin concept space. Surprisingly, these points precisely correspond to the\nemergence of hidden capabilities, i.e., where latent interventions show the\nmodel possesses the capability to manipulate a concept, but these capabilities\ncannot yet be elicited via naive input prompting. While our results focus on\nsynthetically defined toy datasets, we hypothesize a general claim on emergence\nof hidden capabilities may hold: generative models possess latent capabilities\nthat emerge suddenly and consistently during training, though a model might not\nexhibit these capabilities under naive input prompting.\n","authors":["Core Francisco Park","Maya Okawa","Andrew Lee","Ekdeep Singh Lubana","Hidenori Tanaka"],"pdf_url":"https://arxiv.org/pdf/2406.19370v3.pdf","comment":"NeurIPS 2024 (Spotlight)"},{"id":"http://arxiv.org/abs/2301.10780v3","updated":"2024-12-10T16:31:45Z","published":"2023-01-25T19:00:01Z","title":"Quantum anomaly detection in the latent space of proton collision events\n  at the LHC","summary":"  The ongoing quest to discover new phenomena at the LHC necessitates the\ncontinuous development of algorithms and technologies. Established approaches\nlike machine learning, along with emerging technologies such as quantum\ncomputing show promise in the enhancement of experimental capabilities. In this\nwork, we propose a strategy for anomaly detection tasks at the LHC based on\nunsupervised quantum machine learning, and demonstrate its effectiveness in\nidentifying new phenomena. The designed quantum models, an unsupervised kernel\nmachine and two clustering algorithms, are trained to detect new-physics events\nusing a latent representation of LHC data, generated by an autoencoder designed\nto accommodate current quantum hardware limitations on problem size. For\nkernel-based anomaly detection, we implement an instance of the model on a\nquantum computer, and we identify a regime where it significantly outperforms\nits classical counterparts. We show that the observed performance enhancement\nis related to the quantum resources utilised by the model.\n","authors":["Vasilis Belis","Kinga Anna Woźniak","Ema Puljak","Panagiotis Barkoutsos","Günther Dissertori","Michele Grossi","Maurizio Pierini","Florentin Reiter","Ivano Tavernelli","Sofia Vallecorsa"],"pdf_url":"https://arxiv.org/pdf/2301.10780v3.pdf","comment":"Peer-reviewed version, new Figure 4, revised tables, and added some\n  references. 8 Figures, 3 Tables"},{"id":"http://arxiv.org/abs/2401.14707v2","updated":"2024-12-10T16:28:07Z","published":"2024-01-26T08:38:57Z","title":"AFD: Mitigating Feature Gap for Adversarial Robustness by Feature\n  Disentanglement","summary":"  Adversarial fine-tuning methods enhance adversarial robustness via\nfine-tuning the pre-trained model in an adversarial training manner. However,\nwe identify that some specific latent features of adversarial samples are\nconfused by adversarial perturbation and lead to an unexpectedly increasing gap\nbetween features in the last hidden layer of natural and adversarial samples.\nTo address this issue, we propose a disentanglement-based approach to\nexplicitly model and further remove the specific latent features. We introduce\na feature disentangler to separate out the specific latent features from the\nfeatures of the adversarial samples, thereby boosting robustness by eliminating\nthe specific latent features. Besides, we align clean features in the\npre-trained model with features of adversarial samples in the fine-tuned model,\nto benefit from the intrinsic features of natural samples. Empirical\nevaluations on three benchmark datasets demonstrate that our approach surpasses\nexisting adversarial fine-tuning methods and adversarial training baselines.\n","authors":["Nuoyan Zhou","Dawei Zhou","Decheng Liu","Nannan Wang","Xinbo Gao"],"pdf_url":"https://arxiv.org/pdf/2401.14707v2.pdf","comment":"7 pages, 5 figures"},{"id":"http://arxiv.org/abs/2409.09359v3","updated":"2024-12-10T16:24:48Z","published":"2024-09-14T08:17:30Z","title":"Symbolic Regression with a Learned Concept Library","summary":"  We present a novel method for symbolic regression (SR), the task of searching\nfor compact programmatic hypotheses that best explain a dataset. The problem is\ncommonly solved using genetic algorithms; we show that we can enhance such\nmethods by inducing a library of abstract textual concepts. Our algorithm,\ncalled LaSR, uses zero-shot queries to a large language model (LLM) to discover\nand evolve concepts occurring in known high-performing hypotheses. We discover\nnew hypotheses using a mix of standard evolutionary steps and LLM-guided steps\n(obtained through zero-shot LLM queries) conditioned on discovered concepts.\nOnce discovered, hypotheses are used in a new round of concept abstraction and\nevolution. We validate LaSR on the Feynman equations, a popular SR benchmark,\nas well as a set of synthetic tasks. On these benchmarks, LaSR substantially\noutperforms a variety of state-of-the-art SR approaches based on deep learning\nand evolutionary algorithms. Moreover, we show that LaSR can be used to\ndiscover a novel and powerful scaling law for LLMs.\n","authors":["Arya Grayeli","Atharva Sehgal","Omar Costilla-Reyes","Miles Cranmer","Swarat Chaudhuri"],"pdf_url":"https://arxiv.org/pdf/2409.09359v3.pdf","comment":"NeurIPS version; 10 pages; no checklist; added more experiment\n  details"},{"id":"http://arxiv.org/abs/2412.07639v1","updated":"2024-12-10T16:19:08Z","published":"2024-12-10T16:19:08Z","title":"Offline Multi-Agent Reinforcement Learning via In-Sample Sequential\n  Policy Optimization","summary":"  Offline Multi-Agent Reinforcement Learning (MARL) is an emerging field that\naims to learn optimal multi-agent policies from pre-collected datasets.\nCompared to single-agent case, multi-agent setting involves a large joint\nstate-action space and coupled behaviors of multiple agents, which bring extra\ncomplexity to offline policy optimization. In this work, we revisit the\nexisting offline MARL methods and show that in certain scenarios they can be\nproblematic, leading to uncoordinated behaviors and out-of-distribution (OOD)\njoint actions. To address these issues, we propose a new offline MARL\nalgorithm, named In-Sample Sequential Policy Optimization (InSPO). InSPO\nsequentially updates each agent's policy in an in-sample manner, which not only\navoids selecting OOD joint actions but also carefully considers teammates'\nupdated policies to enhance coordination. Additionally, by thoroughly exploring\nlow-probability actions in the behavior policy, InSPO can well address the\nissue of premature convergence to sub-optimal solutions. Theoretically, we\nprove InSPO guarantees monotonic policy improvement and converges to quantal\nresponse equilibrium (QRE). Experimental results demonstrate the effectiveness\nof our method compared to current state-of-the-art offline MARL methods.\n","authors":["Zongkai Liu","Qian Lin","Chao Yu","Xiawei Wu","Yile Liang","Donghui Li","Xuetao Ding"],"pdf_url":"https://arxiv.org/pdf/2412.07639v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07638v1","updated":"2024-12-10T16:17:38Z","published":"2024-12-10T16:17:38Z","title":"SurvBETA: Ensemble-Based Survival Models Using Beran Estimators and\n  Several Attention Mechanisms","summary":"  Many ensemble-based models have been proposed to solve machine learning\nproblems in the survival analysis framework, including random survival forests,\nthe gradient boosting machine with weak survival models, ensembles of the Cox\nmodels. To extend the set of models, a new ensemble-based model called SurvBETA\n(the Survival Beran estimator Ensemble using Three Attention mechanisms) is\nproposed where the Beran estimator is used as a weak learner in the ensemble.\nThe Beran estimator can be regarded as a kernel regression model taking into\naccount the relationship between instances. Outputs of weak learners in the\nform of conditional survival functions are aggregated with attention weights\ntaking into account the distance between the analyzed instance and prototypes\nof all bootstrap samples. The attention mechanism is used three times: for\nimplementation of the Beran estimators, for determining specific prototypes of\nbootstrap samples and for aggregating the weak model predictions. The proposed\nmodel is presented in two forms: in a general form requiring to solve a complex\noptimization problem for its training; in a simplified form by considering a\nspecial representation of the attention weights by means of the imprecise\nHuber's contamination model which leads to solving a simple optimization\nproblem. Numerical experiments illustrate properties of the model on synthetic\ndata and compare the model with other survival models on real data. A code\nimplementing the proposed model is publicly available.\n","authors":["Lev V. Utkin","Semen P. Khomets","Vlada A. Efremenko","Andrei V. Konstantinov"],"pdf_url":"https://arxiv.org/pdf/2412.07638v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07637v1","updated":"2024-12-10T16:17:03Z","published":"2024-12-10T16:17:03Z","title":"Sampling from Boltzmann densities with physics informed low-rank formats","summary":"  Our method proposes the efficient generation of samples from an unnormalized\nBoltzmann density by solving the underlying continuity equation in the low-rank\ntensor train (TT) format. It is based on the annealing path commonly used in\nMCMC literature, which is given by the linear interpolation in the space of\nenergies. Inspired by Sequential Monte Carlo, we alternate between\ndeterministic time steps from the TT representation of the flow field and\nstochastic steps, which include Langevin and resampling steps. These adjust the\nrelative weights of the different modes of the target distribution and anneal\nto the correct path distribution. We showcase the efficiency of our method on\nmultiple numerical examples.\n","authors":["Paul Hagemann","Janina Schütte","David Sommer","Martin Eigel","Gabriele Steidl"],"pdf_url":"https://arxiv.org/pdf/2412.07637v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.09872v2","updated":"2024-12-10T16:06:29Z","published":"2023-10-15T16:04:28Z","title":"Leveraging Large Language Models for Node Generation in Few-Shot\n  Learning on Text-Attributed Graphs","summary":"  Text-attributed graphs have recently garnered significant attention due to\ntheir wide range of applications in web domains. Existing methodologies employ\nword embedding models for acquiring text representations as node features,\nwhich are subsequently fed into Graph Neural Networks (GNNs) for training.\nRecently, the advent of Large Language Models (LLMs) has introduced their\npowerful capabilities in information retrieval and text generation, which can\ngreatly enhance the text attributes of graph data. Furthermore, the acquisition\nand labeling of extensive datasets are both costly and time-consuming\nendeavors. Consequently, few-shot learning has emerged as a crucial problem in\nthe context of graph learning tasks. In order to tackle this challenge, we\npropose a lightweight paradigm called LLM4NG, which adopts a plug-and-play\napproach to empower text-attributed graphs through node generation using LLMs.\nSpecifically, we utilize LLMs to extract semantic information from the labels\nand generate samples that belong to these categories as exemplars.\nSubsequently, we employ an edge predictor to capture the structural information\ninherent in the raw dataset and integrate the newly generated samples into the\noriginal graph. This approach harnesses LLMs for enhancing class-level\ninformation and seamlessly introduces labeled nodes and edges without modifying\nthe raw dataset, thereby facilitating the node classification task in few-shot\nscenarios. Extensive experiments demonstrate the outstanding performance of our\nproposed paradigm, particularly in low-shot scenarios. For instance, in the\n1-shot setting of the ogbn-arxiv dataset, LLM4NG achieves a 76% improvement\nover the baseline model.\n","authors":["Jianxiang Yu","Yuxiang Ren","Chenghua Gong","Jiaqi Tan","Xiang Li","Xuecang Zhang"],"pdf_url":"https://arxiv.org/pdf/2310.09872v2.pdf","comment":"Accepted by AAAI2025"},{"id":"http://arxiv.org/abs/2406.09028v2","updated":"2024-12-10T15:45:36Z","published":"2024-06-13T12:02:51Z","title":"From Biased to Unbiased Dynamics: An Infinitesimal Generator Approach","summary":"  We investigate learning the eigenfunctions of evolution operators for\ntime-reversal invariant stochastic processes, a prime example being the\nLangevin equation used in molecular dynamics. Many physical or chemical\nprocesses described by this equation involve transitions between metastable\nstates separated by high potential barriers that can hardly be crossed during a\nsimulation. To overcome this bottleneck, data are collected via biased\nsimulations that explore the state space more rapidly. We propose a framework\nfor learning from biased simulations rooted in the infinitesimal generator of\nthe process and the associated resolvent operator. We contrast our approach to\nmore common ones based on the transfer operator, showing that it can provably\nlearn the spectral properties of the unbiased system from biased data. In\nexperiments, we highlight the advantages of our method over transfer operator\napproaches and recent developments based on generator learning, demonstrating\nits effectiveness in estimating eigenfunctions and eigenvalues. Importantly, we\nshow that even with datasets containing only a few relevant transitions due to\nsub-optimal biasing, our approach recovers relevant information about the\ntransition mechanism.\n","authors":["Timothée Devergne","Vladimir Kostic","Michele Parrinello","Massimiliano Pontil"],"pdf_url":"https://arxiv.org/pdf/2406.09028v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07605v1","updated":"2024-12-10T15:45:32Z","published":"2024-12-10T15:45:32Z","title":"Fast Track to Winning Tickets: Repowering One-Shot Pruning for Graph\n  Neural Networks","summary":"  Graph Neural Networks (GNNs) demonstrate superior performance in various\ngraph learning tasks, yet their wider real-world application is hindered by the\ncomputational overhead when applied to large-scale graphs. To address the\nissue, the Graph Lottery Hypothesis (GLT) has been proposed, advocating the\nidentification of subgraphs and subnetworks, \\textit{i.e.}, winning tickets,\nwithout compromising performance. The effectiveness of current GLT methods\nlargely stems from the use of iterative magnitude pruning (IMP), which offers\nhigher stability and better performance than one-shot pruning. However,\nidentifying GLTs is highly computationally expensive, due to the iterative\npruning and retraining required by IMP. In this paper, we reevaluate the\ncorrelation between one-shot pruning and IMP: while one-shot tickets are\nsuboptimal compared to IMP, they offer a \\textit{fast track} to tickets with a\nstronger performance. We introduce a one-shot pruning and denoising framework\nto validate the efficacy of the \\textit{fast track}. Compared to current\nIMP-based GLT methods, our framework achieves a double-win situation of graph\nlottery tickets with \\textbf{higher sparsity} and \\textbf{faster speeds}.\nThrough extensive experiments across 4 backbones and 6 datasets, our method\ndemonstrates $1.32\\% - 45.62\\%$ improvement in weight sparsity and a $7.49\\% -\n22.71\\%$ increase in graph sparsity, along with a $1.7-44 \\times$ speedup over\nIMP-based methods and $95.3\\%-98.6\\%$ MAC savings.\n","authors":["Yanwei Yue","Guibin Zhang","Haoran Yang","Dawei Cheng"],"pdf_url":"https://arxiv.org/pdf/2412.07605v1.pdf","comment":"AAAI 2025"},{"id":"http://arxiv.org/abs/2410.14875v2","updated":"2024-12-10T15:44:59Z","published":"2024-10-18T21:42:37Z","title":"Which LLMs are Difficult to Detect? A Detailed Analysis of Potential\n  Factors Contributing to Difficulties in LLM Text Detection","summary":"  As LLMs increase in accessibility, LLM-generated texts have proliferated\nacross several fields, such as scientific, academic, and creative writing.\nHowever, LLMs are not created equally; they may have different architectures\nand training datasets. Thus, some LLMs may be more challenging to detect than\nothers. Using two datasets spanning four total writing domains, we train\nAI-generated (AIG) text classifiers using the LibAUC library - a deep learning\nlibrary for training classifiers with imbalanced datasets. Our results in the\nDeepfake Text dataset show that AIG-text detection varies across domains, with\nscientific writing being relatively challenging. In the Rewritten Ivy Panda\n(RIP) dataset focusing on student essays, we find that the OpenAI family of\nLLMs was substantially difficult for our classifiers to distinguish from human\ntexts. Additionally, we explore possible factors that could explain the\ndifficulties in detecting OpenAI-generated texts.\n","authors":["Shantanu Thorat","Tianbao Yang"],"pdf_url":"https://arxiv.org/pdf/2410.14875v2.pdf","comment":"Accepted at NeurIPS 2024 - Safe Generative AI Workshop; Camera-ready\n  version"},{"id":"http://arxiv.org/abs/2406.00431v2","updated":"2024-12-10T15:43:05Z","published":"2024-06-01T13:10:35Z","title":"SpaFL: Communication-Efficient Federated Learning with Sparse Models and\n  Low computational Overhead","summary":"  The large communication and computation overhead of federated learning (FL)\nis one of the main challenges facing its practical deployment over\nresource-constrained clients and systems. In this work, SpaFL: a\ncommunication-efficient FL framework is proposed to optimize sparse model\nstructures with low computational overhead. In SpaFL, a trainable threshold is\ndefined for each filter/neuron to prune its all connected parameters, thereby\nleading to structured sparsity. To optimize the pruning process itself, only\nthresholds are communicated between a server and clients instead of parameters,\nthereby learning how to prune. Further, global thresholds are used to update\nmodel parameters by extracting aggregated parameter importance. The\ngeneralization bound of SpaFL is also derived, thereby proving key insights on\nthe relation between sparsity and performance. Experimental results show that\nSpaFL improves accuracy while requiring much less communication and computing\nresources compared to sparse baselines. The code is available at\nhttps://github.com/news-vt/SpaFL_NeruIPS_2024\n","authors":["Minsu Kim","Walid Saad","Merouane Debbah","Choong Seon Hong"],"pdf_url":"https://arxiv.org/pdf/2406.00431v2.pdf","comment":"Published in NeurIPS 2024"},{"id":"http://arxiv.org/abs/2204.12941v2","updated":"2024-12-10T15:38:11Z","published":"2022-04-26T10:51:50Z","title":"Unsupervised Learning of Unbiased Visual Representations","summary":"  Deep neural networks often struggle to learn robust representations in the\npresence of dataset biases, leading to suboptimal generalization on unbiased\ndatasets. This limitation arises because the models heavily depend on\nperipheral and confounding factors, inadvertently acquired during training.\nExisting approaches to address this problem typically involve explicit\nsupervision of bias attributes or reliance on prior knowledge about the biases.\nIn this study, we address the challenging scenario where no explicit\nannotations of bias are available, and there's no prior knowledge about its\nnature. We present a fully unsupervised debiasing framework with three key\nsteps: firstly, leveraging the inherent tendency to learn malignant biases to\nacquire a bias-capturing model; next, employing a pseudo-labeling process to\nobtain bias labels; and finally, applying cutting-edge supervised debiasing\ntechniques to achieve an unbiased model. Additionally, we introduce a\ntheoretical framework for evaluating model biasedness and conduct a detailed\nanalysis of how biases impact neural network training. Experimental results on\nboth synthetic and real-world datasets demonstrate the effectiveness of our\nmethod, showcasing state-of-the-art performance in various settings,\noccasionally surpassing fully supervised debiasing approaches.\n","authors":["Carlo Alberto Barbano","Enzo Tartaglione","Marco Grangetto"],"pdf_url":"https://arxiv.org/pdf/2204.12941v2.pdf","comment":"Accepted at IEEE Transactions on Artificial Intelligence (TAI)"},{"id":"http://arxiv.org/abs/2412.05583v2","updated":"2024-12-10T15:35:33Z","published":"2024-12-07T08:29:44Z","title":"Electrocardiogram (ECG) Based Cardiac Arrhythmia Detection and\n  Classification using Machine Learning Algorithms","summary":"  The rapid advancements in Artificial Intelligence, specifically Machine\nLearning (ML) and Deep Learning (DL), have opened new prospects in medical\nsciences for improved diagnosis, prognosis, and treatment of severe health\nconditions. This paper focuses on the development of an ML model with high\npredictive accuracy to classify arrhythmic electrocardiogram (ECG) signals. The\nECG signals datasets utilized in this study were sourced from the PhysioNet and\nMIT-BIH databases. The research commenced with binary classification, where an\noptimized Bidirectional Long Short-Term Memory (Bi-LSTM) model yielded\nexcellent results in differentiating normal and atrial fibrillation signals. A\npivotal aspect of this research was a survey among medical professionals, which\nnot only validated the practicality of AI-based ECG classifiers but also\nidentified areas for improvement, including accuracy and the inclusion of more\narrhythmia types. These insights drove the development of an advanced\nConvolutional Neural Network (CNN) system capable of classifying five different\ntypes of ECG signals with better accuracy and precision. The CNN model's robust\nperformance was ensured through rigorous stratified 5-fold cross validation. A\nweb portal was also developed to demonstrate real-world utility, offering\naccess to the trained model for real-time classification. This study highlights\nthe potential applications of such models in remote health monitoring,\npredictive healthcare, assistive diagnostic tools, and simulated environments\nfor educational training and interdisciplinary collaboration between data\nscientists and medical personnel.\n","authors":["Atit Pokharel","Shashank Dahal","Pratik Sapkota","Bhupendra Bimal Chhetri"],"pdf_url":"https://arxiv.org/pdf/2412.05583v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.08849v2","updated":"2024-12-10T15:35:31Z","published":"2024-09-12T17:59:08Z","title":"DeCLIP: Decoding CLIP representations for deepfake localization","summary":"  Generative models can create entirely new images, but they can also partially\nmodify real images in ways that are undetectable to the human eye. In this\npaper, we address the challenge of automatically detecting such local\nmanipulations. One of the most pressing problems in deepfake detection remains\nthe ability of models to generalize to different classes of generators. In the\ncase of fully manipulated images, representations extracted from large\nself-supervised models (such as CLIP) provide a promising direction towards\nmore robust detectors. Here, we introduce DeCLIP, a first attempt to leverage\nsuch large pretrained features for detecting local manipulations. We show that,\nwhen combined with a reasonably large convolutional decoder, pretrained\nself-supervised representations are able to perform localization and improve\ngeneralization capabilities over existing methods. Unlike previous work, our\napproach is able to perform localization on the challenging case of latent\ndiffusion models, where the entire image is affected by the fingerprint of the\ngenerator. Moreover, we observe that this type of data, which combines local\nsemantic information with a global fingerprint, provides more stable\ngeneralization than other categories of generative methods.\n","authors":["Stefan Smeu","Elisabeta Oneata","Dan Oneata"],"pdf_url":"https://arxiv.org/pdf/2409.08849v2.pdf","comment":"Accepted at Winter Conference on Applications of Computer Vision\n  (WACV) 2025"},{"id":"http://arxiv.org/abs/2406.13584v2","updated":"2024-12-10T15:26:56Z","published":"2024-06-19T14:19:59Z","title":"FreqRISE: Explaining time series using frequency masking","summary":"  Time-series data are fundamentally important for many critical domains such\nas healthcare, finance, and climate, where explainable models are necessary for\nsafe automated decision making. To develop explainable artificial intelligence\nin these domains therefore implies explaining salient information in the time\nseries. Current methods for obtaining saliency maps assume localized\ninformation in the raw input space. In this paper, we argue that the salient\ninformation of a number of time series is more likely to be localized in the\nfrequency domain. We propose FreqRISE, which uses masking-based methods to\nproduce explanations in the frequency and time-frequency domain, and\noutperforms strong baselines across a number of tasks. The source code is\navailable here: \\url{https://github.com/theabrusch/FreqRISE}.\n","authors":["Thea Brüsch","Kristoffer Knutsen Wickstrøm","Mikkel N. Schmidt","Tommy Sonne Alstrøm","Robert Jenssen"],"pdf_url":"https://arxiv.org/pdf/2406.13584v2.pdf","comment":"Accepted at the Northern Lights Deep Learning Conference 2025"},{"id":"http://arxiv.org/abs/2412.07587v1","updated":"2024-12-10T15:23:31Z","published":"2024-12-10T15:23:31Z","title":"Hype-Adjusted Probability Measure for NLP Volatility Forecasting","summary":"  This manuscript introduces the hype-adjusted probability measure developed in\nthe context of a new Natural Language Processing (NLP) approach for market\nforecasting. A novel sentiment score equation is presented to capture component\nand memory effects and assign dynamic parameters, enhancing the impact of\nintraday news data on forecasting next-period volatility for selected U.S.\nsemiconductor stocks. This approach integrates machine learning techniques to\nanalyze and improve the predictive value of news. Building on the research of\nGeman's, this work improves forecast accuracy by assigning specific weights to\neach component of news sources and individual stocks in the portfolio,\nevaluating time-memory effects on market reactions, and incorporating shifts in\nsentiment direction. Finally, we propose the Hype-Adjusted Probability Measure,\nproving its existence and uniqueness, and discuss its theoretical applications\nin finance for NLP-based volatility forecasting, outlining future research\npathways inspired by its concepts.\n","authors":["Zheng Cao","Helyette Geman"],"pdf_url":"https://arxiv.org/pdf/2412.07587v1.pdf","comment":"26 pages"},{"id":"http://arxiv.org/abs/2412.07586v1","updated":"2024-12-10T15:22:26Z","published":"2024-12-10T15:22:26Z","title":"Paired Wasserstein Autoencoders for Conditional Sampling","summary":"  Wasserstein distances greatly influenced and coined various types of\ngenerative neural network models. Wasserstein autoencoders are particularly\nnotable for their mathematical simplicity and straight-forward implementation.\nHowever, their adaptation to the conditional case displays theoretical\ndifficulties. As a remedy, we propose the use of two paired autoencoders. Under\nthe assumption of an optimal autoencoder pair, we leverage the pairwise\nindependence condition of our prescribed Gaussian latent distribution to\novercome this theoretical hurdle. We conduct several experiments to showcase\nthe practical applicability of the resulting paired Wasserstein autoencoders.\nHere, we consider imaging tasks and enable conditional sampling for denoising,\ninpainting, and unsupervised image translation. Moreover, we connect our image\ntranslation model to the Monge map behind Wasserstein-2 distances.\n","authors":["Moritz Piening","Matthias Chung"],"pdf_url":"https://arxiv.org/pdf/2412.07586v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07585v1","updated":"2024-12-10T15:20:56Z","published":"2024-12-10T15:20:56Z","title":"Scaling Sequential Recommendation Models with Transformers","summary":"  Modeling user preferences has been mainly addressed by looking at users'\ninteraction history with the different elements available in the system.\nTailoring content to individual preferences based on historical data is the\nmain goal of sequential recommendation.\n  The nature of the problem, as well as the good performance observed across\nvarious domains, has motivated the use of the transformer architecture, which\nhas proven effective in leveraging increasingly larger amounts of training data\nwhen accompanied by an increase in the number of model parameters. This scaling\nbehavior has brought a great deal of attention, as it provides valuable\nguidance in the design and training of even larger models.\n  Taking inspiration from the scaling laws observed in training large language\nmodels, we explore similar principles for sequential recommendation.\n  We use the full Amazon Product Data dataset, which has only been partially\nexplored in other studies, and reveal scaling behaviors similar to those found\nin language models. Compute-optimal training is possible but requires a careful\nanalysis of the compute-performance trade-offs specific to the application.\n  We also show that performance scaling translates to downstream tasks by\nfine-tuning larger pre-trained models on smaller task-specific domains. Our\napproach and findings provide a strategic roadmap for model training and\ndeployment in real high-dimensional preference spaces, facilitating better\ntraining and inference efficiency.\n  We hope this paper bridges the gap between the potential of transformers and\nthe intrinsic complexities of high-dimensional sequential recommendation in\nreal-world recommender systems.\n  Code and models can be found at https://github.com/mercadolibre/srt\n","authors":["Pablo Zivic","Hernan Vazquez","Jorge Sanchez"],"pdf_url":"https://arxiv.org/pdf/2412.07585v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.01367v2","updated":"2024-12-10T15:10:41Z","published":"2024-04-01T17:59:48Z","title":"Bigger is not Always Better: Scaling Properties of Latent Diffusion\n  Models","summary":"  We study the scaling properties of latent diffusion models (LDMs) with an\nemphasis on their sampling efficiency. While improved network architecture and\ninference algorithms have shown to effectively boost sampling efficiency of\ndiffusion models, the role of model size -- a critical determinant of sampling\nefficiency -- has not been thoroughly examined. Through empirical analysis of\nestablished text-to-image diffusion models, we conduct an in-depth\ninvestigation into how model size influences sampling efficiency across varying\nsampling steps. Our findings unveil a surprising trend: when operating under a\ngiven inference budget, smaller models frequently outperform their larger\nequivalents in generating high-quality results. Moreover, we extend our study\nto demonstrate the generalizability of the these findings by applying various\ndiffusion samplers, exploring diverse downstream tasks, evaluating\npost-distilled models, as well as comparing performance relative to training\ncompute. These findings open up new pathways for the development of LDM scaling\nstrategies which can be employed to enhance generative capabilities within\nlimited inference budgets.\n","authors":["Kangfu Mei","Zhengzhong Tu","Mauricio Delbracio","Hossein Talebi","Vishal M. Patel","Peyman Milanfar"],"pdf_url":"https://arxiv.org/pdf/2404.01367v2.pdf","comment":"Accepted to TMLR. Camera-ready version"},{"id":"http://arxiv.org/abs/2405.14677v4","updated":"2024-12-10T14:51:50Z","published":"2024-05-23T15:12:15Z","title":"RectifID: Personalizing Rectified Flow with Anchored Classifier Guidance","summary":"  Customizing diffusion models to generate identity-preserving images from\nuser-provided reference images is an intriguing new problem. The prevalent\napproaches typically require training on extensive domain-specific images to\nachieve identity preservation, which lacks flexibility across different use\ncases. To address this issue, we exploit classifier guidance, a training-free\ntechnique that steers diffusion models using an existing classifier, for\npersonalized image generation. Our study shows that based on a recent rectified\nflow framework, the major limitation of vanilla classifier guidance in\nrequiring a special classifier can be resolved with a simple fixed-point\nsolution, allowing flexible personalization with off-the-shelf image\ndiscriminators. Moreover, its solving procedure proves to be stable when\nanchored to a reference flow trajectory, with a convergence guarantee. The\nderived method is implemented on rectified flow with different off-the-shelf\nimage discriminators, delivering advantageous personalization results for human\nfaces, live subjects, and certain objects. Code is available at\nhttps://github.com/feifeiobama/RectifID.\n","authors":["Zhicheng Sun","Zhenhao Yang","Yang Jin","Haozhe Chi","Kun Xu","Kun Xu","Liwei Chen","Hao Jiang","Yang Song","Kun Gai","Yadong Mu"],"pdf_url":"https://arxiv.org/pdf/2405.14677v4.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2412.07559v1","updated":"2024-12-10T14:48:59Z","published":"2024-12-10T14:48:59Z","title":"Adaptive Epsilon Adversarial Training for Robust Gravitational Wave\n  Parameter Estimation Using Normalizing Flows","summary":"  Adversarial training with Normalizing Flow (NF) models is an emerging\nresearch area aimed at improving model robustness through adversarial samples.\nIn this study, we focus on applying adversarial training to NF models for\ngravitational wave parameter estimation. We propose an adaptive epsilon method\nfor Fast Gradient Sign Method (FGSM) adversarial training, which dynamically\nadjusts perturbation strengths based on gradient magnitudes using logarithmic\nscaling. Our hybrid architecture, combining ResNet and Inverse Autoregressive\nFlow, reduces the Negative Log Likelihood (NLL) loss by 47\\% under FGSM attacks\ncompared to the baseline model, while maintaining an NLL of 4.2 on clean data\n(only 5\\% higher than the baseline). For perturbation strengths between 0.01\nand 0.1, our model achieves an average NLL of 5.8, outperforming both\nfixed-epsilon (NLL: 6.7) and progressive-epsilon (NLL: 7.2) methods. Under\nstronger Projected Gradient Descent attacks with perturbation strength of 0.05,\nour model maintains an NLL of 6.4, demonstrating superior robustness while\navoiding catastrophic overfitting.\n","authors":["Yiqian Yang","Xihua Zhu","Fan Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.07559v1.pdf","comment":"7 pages, 9 figures"},{"id":"http://arxiv.org/abs/2409.09269v2","updated":"2024-12-10T14:43:03Z","published":"2024-09-14T02:29:36Z","title":"Guiding Vision-Language Model Selection for Visual Question-Answering\n  Across Tasks, Domains, and Knowledge Types","summary":"  Visual Question-Answering (VQA) has become key to user experience,\nparticularly after improved generalization capabilities of Vision-Language\nModels (VLMs). But evaluating VLMs for an application requirement using a\nstandardized framework in practical settings is still challenging. This paper\naims to solve that using an end-to-end framework. We present VQA360 - a novel\ndataset derived from established VQA benchmarks, annotated with task types,\napplication domains, and knowledge types, for a comprehensive evaluation. We\nalso introduce GoEval, a multimodal evaluation metric developed using GPT-4o,\nachieving a correlation factor of 56.71% with human judgments. Our experiments\nwith state-of-the-art VLMs reveal that no single model excels universally,\nthus, making a right choice a key design decision. Proprietary models such as\nGemini-1.5-Pro and GPT-4o-mini generally outperform others, but open-source\nmodels like InternVL-2-8B and CogVLM-2-Llama-3-19B also demonstrate competitive\nstrengths, while providing additional advantages. Our framework can also be\nextended to other tasks.\n","authors":["Neelabh Sinha","Vinija Jain","Aman Chadha"],"pdf_url":"https://arxiv.org/pdf/2409.09269v2.pdf","comment":"8 pages + references + 6 pages of Appendix"},{"id":"http://arxiv.org/abs/2412.07544v1","updated":"2024-12-10T14:28:18Z","published":"2024-12-10T14:28:18Z","title":"Contractive Dynamical Imitation Policies for Efficient Out-of-Sample\n  Recovery","summary":"  Imitation learning is a data-driven approach to learning policies from expert\nbehavior, but it is prone to unreliable outcomes in out-of-sample (OOS)\nregions. While previous research relying on stable dynamical systems guarantees\nconvergence to a desired state, it often overlooks transient behavior. We\npropose a framework for learning policies using modeled by contractive\ndynamical systems, ensuring that all policy rollouts converge regardless of\nperturbations, and in turn, enable efficient OOS recovery. By leveraging\nrecurrent equilibrium networks and coupling layers, the policy structure\nguarantees contractivity for any parameter choice, which facilitates\nunconstrained optimization. Furthermore, we provide theoretical upper bounds\nfor worst-case and expected loss terms, rigorously establishing the reliability\nof our method in deployment. Empirically, we demonstrate substantial OOS\nperformance improvements in robotics manipulation and navigation tasks in\nsimulation.\n","authors":["Amin Abyaneh","Mahrokh G. Boroujeni","Hsiu-Chin Lin","Giancarlo Ferrari-Trecate"],"pdf_url":"https://arxiv.org/pdf/2412.07544v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.09524v2","updated":"2024-12-10T14:22:38Z","published":"2024-02-14T19:01:51Z","title":"Guided Quantum Compression for High Dimensional Data Classification","summary":"  Quantum machine learning provides a fundamentally different approach to\nanalyzing data. However, many interesting datasets are too complex for\ncurrently available quantum computers. Present quantum machine learning\napplications usually diminish this complexity by reducing the dimensionality of\nthe data, e.g., via auto-encoders, before passing it through the quantum\nmodels. Here, we design a classical-quantum paradigm that unifies the\ndimensionality reduction task with a quantum classification model into a single\narchitecture: the guided quantum compression model. We exemplify how this\narchitecture outperforms conventional quantum machine learning approaches on a\nchallenging binary classification problem: identifying the Higgs boson in\nproton-proton collisions at the LHC. Furthermore, the guided quantum\ncompression model shows better performance compared to the deep learning\nbenchmark when using solely the kinematic variables in our dataset.\n","authors":["Vasilis Belis","Patrick Odagiu","Michele Grossi","Florentin Reiter","Günther Dissertori","Sofia Vallecorsa"],"pdf_url":"https://arxiv.org/pdf/2402.09524v2.pdf","comment":"Peer-reviewed version, 9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2412.07539v1","updated":"2024-12-10T14:17:23Z","published":"2024-12-10T14:17:23Z","title":"Anomaly detection using Diffusion-based methods","summary":"  This paper explores the utility of diffusion-based models for anomaly\ndetection, focusing on their efficacy in identifying deviations in both compact\nand high-resolution datasets. Diffusion-based architectures, including\nDenoising Diffusion Probabilistic Models (DDPMs) and Diffusion Transformers\n(DiTs), are evaluated for their performance using reconstruction objectives. By\nleveraging the strengths of these models, this study benchmarks their\nperformance against traditional anomaly detection methods such as Isolation\nForests, One-Class SVMs, and COPOD. The results demonstrate the superior\nadaptability, scalability, and robustness of diffusion-based methods in\nhandling complex real-world anomaly detection tasks. Key findings highlight the\nrole of reconstruction error in enhancing detection accuracy and underscore the\nscalability of these models to high-dimensional datasets. Future directions\ninclude optimizing encoder-decoder architectures and exploring multi-modal\ndatasets to further advance diffusion-based anomaly detection.\n","authors":["Aryan Bhosale","Samrat Mukherjee","Biplab Banerjee","Fabio Cuzzolin"],"pdf_url":"https://arxiv.org/pdf/2412.07539v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07538v1","updated":"2024-12-10T14:17:14Z","published":"2024-12-10T14:17:14Z","title":"Can Neural Decompilation Assist Vulnerability Prediction on Binary Code?","summary":"  Vulnerability prediction is valuable in identifying security issues more\nefficiently, even though it requires the source code of the target software\nsystem, which is a restrictive hypothesis. This paper presents an experimental\nstudy to predict vulnerabilities in binary code without source code or complex\nrepresentations of the binary, leveraging the pivotal idea of decompiling the\nbinary file through neural decompilation and predicting vulnerabilities through\ndeep learning on the decompiled source code. The results outperform the\nstate-of-the-art in both neural decompilation and vulnerability prediction,\nshowing that it is possible to identify vulnerable programs with this approach\nconcerning bi-class (vulnerable/non-vulnerable) and multi-class (type of\nvulnerability) analysis.\n","authors":["D. Cotroneo","F. C. Grasso","R. Natella","V. Orbinato"],"pdf_url":"https://arxiv.org/pdf/2412.07538v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04842v2","updated":"2024-12-10T14:02:27Z","published":"2024-08-09T03:35:53Z","title":"Counterfactual Explanations with Probabilistic Guarantees on their\n  Robustness to Model Change","summary":"  Counterfactual explanations (CFEs) guide users on how to adjust inputs to\nmachine learning models to achieve desired outputs. While existing research\nprimarily addresses static scenarios, real-world applications often involve\ndata or model changes, potentially invalidating previously generated CFEs and\nrendering user-induced input changes ineffective. Current methods addressing\nthis issue often support only specific models or change types, require\nextensive hyperparameter tuning, or fail to provide probabilistic guarantees on\nCFE robustness to model changes. This paper proposes a novel approach for\ngenerating CFEs that provides probabilistic guarantees for any model and change\ntype, while offering interpretable and easy-to-select hyperparameters. We\nestablish a theoretical framework for probabilistically defining robustness to\nmodel change and demonstrate how our BetaRCE method directly stems from it.\nBetaRCE is a post-hoc method applied alongside a chosen base CFE generation\nmethod to enhance the quality of the explanation beyond robustness. It\nfacilitates a transition from the base explanation to a more robust one with\nuser-adjusted probability bounds. Through experimental comparisons with\nbaselines, we show that BetaRCE yields robust, most plausible, and closest to\nbaseline counterfactual explanations.\n","authors":["Ignacy Stępka","Mateusz Lango","Jerzy Stefanowski"],"pdf_url":"https://arxiv.org/pdf/2408.04842v2.pdf","comment":"Accepted at 31st SIGKDD Conference on Knowledge Discovery and Data\n  Mining 2025"},{"id":"http://arxiv.org/abs/2307.13869v2","updated":"2024-12-10T14:00:35Z","published":"2023-07-26T00:01:21Z","title":"Number Theoretic Accelerated Learning of Physics-Informed Neural\n  Networks","summary":"  Physics-informed neural networks solve partial differential equations by\ntraining neural networks. Since this method approximates infinite-dimensional\nPDE solutions with finite collocation points, minimizing discretization errors\nby selecting suitable points is essential for accelerating the learning\nprocess. Inspired by number theoretic methods for numerical analysis, we\nintroduce good lattice training and periodization tricks, which ensure the\nconditions required by the theory. Our experiments demonstrate that GLT\nrequires 2-7 times fewer collocation points, resulting in lower computational\ncost, while achieving competitive performance compared to typical sampling\nmethods.\n","authors":["Takashi Matsubara","Takaharu Yaguchi"],"pdf_url":"https://arxiv.org/pdf/2307.13869v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.15708v2","updated":"2024-12-10T14:00:16Z","published":"2023-05-25T04:43:47Z","title":"Score-Based Multimodal Autoencoder","summary":"  Multimodal Variational Autoencoders (VAEs) represent a promising group of\ngenerative models that facilitate the construction of a tractable posterior\nwithin the latent space given multiple modalities. Previous studies have shown\nthat as the number of modalities increases, the generative quality of each\nmodality declines. In this study, we explore an alternative approach to enhance\nthe generative performance of multimodal VAEs by jointly modeling the latent\nspace of independently trained unimodal VAEs using score-based models (SBMs).\nThe role of the SBM is to enforce multimodal coherence by learning the\ncorrelation among the latent variables. Consequently, our model combines a\nbetter generative quality of unimodal VAEs with coherent integration across\ndifferent modalities using the latent score-based model. In addition, our\napproach provides the best unconditional coherence.\n","authors":["Daniel Wesego","Pedram Rooshenas"],"pdf_url":"https://arxiv.org/pdf/2305.15708v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07520v1","updated":"2024-12-10T13:58:19Z","published":"2024-12-10T13:58:19Z","title":"Quantifying the Prediction Uncertainty of Machine Learning Models for\n  Individual Data","summary":"  Machine learning models have exhibited exceptional results in various\ndomains. The most prevalent approach for learning is the empirical risk\nminimizer (ERM), which adapts the model's weights to reduce the loss on a\ntraining set and subsequently leverages these weights to predict the label for\nnew test data. Nonetheless, ERM makes the assumption that the test distribution\nis similar to the training distribution, which may not always hold in\nreal-world situations. In contrast, the predictive normalized maximum\nlikelihood (pNML) was proposed as a min-max solution for the individual setting\nwhere no assumptions are made on the distribution of the tested input. This\nstudy investigates pNML's learnability for linear regression and neural\nnetworks, and demonstrates that pNML can improve the performance and robustness\nof these models on various tasks. Moreover, the pNML provides an accurate\nconfidence measure for its output, showcasing state-of-the-art results for\nout-of-distribution detection, resistance to adversarial attacks, and active\nlearning.\n","authors":["Koby Bibas"],"pdf_url":"https://arxiv.org/pdf/2412.07520v1.pdf","comment":"PHD thesis"},{"id":"http://arxiv.org/abs/2406.16714v2","updated":"2024-12-10T13:57:46Z","published":"2024-06-24T15:16:45Z","title":"AutoDetect: Towards a Unified Framework for Automated Weakness Detection\n  in Large Language Models","summary":"  Although Large Language Models (LLMs) are becoming increasingly powerful,\nthey still exhibit significant but subtle weaknesses, such as mistakes in\ninstruction-following or coding tasks. As these unexpected errors could lead to\nsevere consequences in practical deployments, it is crucial to investigate the\nlimitations within LLMs systematically. Traditional benchmarking approaches\ncannot thoroughly pinpoint specific model deficiencies, while manual\ninspections are costly and not scalable. In this paper, we introduce a unified\nframework, AutoDetect, to automatically expose weaknesses in LLMs across\nvarious tasks. Inspired by the educational assessment process that measures\nstudents' learning outcomes, AutoDetect consists of three LLM-powered agents:\nExaminer, Questioner, and Assessor. The collaboration among these three agents\nis designed to realize comprehensive and in-depth weakness identification. Our\nframework demonstrates significant success in uncovering flaws, with an\nidentification success rate exceeding 30% in prominent models such as ChatGPT\nand Claude. More importantly, these identified weaknesses can guide specific\nmodel improvements, proving more effective than untargeted data augmentation\nmethods like Self-Instruct. Our approach has led to substantial enhancements in\npopular LLMs, including the Llama series and Mistral-7b, boosting their\nperformance by over 10% across several benchmarks. Code and data are publicly\navailable at https://github.com/thu-coai/AutoDetect.\n","authors":["Jiale Cheng","Yida Lu","Xiaotao Gu","Pei Ke","Xiao Liu","Yuxiao Dong","Hongning Wang","Jie Tang","Minlie Huang"],"pdf_url":"https://arxiv.org/pdf/2406.16714v2.pdf","comment":"EMNLP 2024 findings"},{"id":"http://arxiv.org/abs/2412.01193v2","updated":"2024-12-10T13:54:21Z","published":"2024-12-02T06:52:45Z","title":"Divergent Ensemble Networks: Enhancing Uncertainty Estimation with\n  Shared Representations and Independent Branching","summary":"  Ensemble learning has proven effective in improving predictive performance\nand estimating uncertainty in neural networks. However, conventional ensemble\nmethods often suffer from redundant parameter usage and computational\ninefficiencies due to entirely independent network training. To address these\nchallenges, we propose the Divergent Ensemble Network (DEN), a novel\narchitecture that combines shared representation learning with independent\nbranching. DEN employs a shared input layer to capture common features across\nall branches, followed by divergent, independently trainable layers that form\nan ensemble. This shared-to-branching structure reduces parameter redundancy\nwhile maintaining ensemble diversity, enabling efficient and scalable learning.\n","authors":["Arnav Kharbanda","Advait Chandorkar"],"pdf_url":"https://arxiv.org/pdf/2412.01193v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.02095v3","updated":"2024-12-10T13:54:18Z","published":"2024-02-03T09:22:07Z","title":"Contrasting Adversarial Perturbations: The Space of Harmless\n  Perturbations","summary":"  Existing works have extensively studied adversarial examples, which are\nminimal perturbations that can mislead the output of deep neural networks\n(DNNs) while remaining imperceptible to humans. However, in this work, we\nreveal the existence of a harmless perturbation space, in which perturbations\ndrawn from this space, regardless of their magnitudes, leave the network output\nunchanged when applied to inputs. Essentially, the harmless perturbation space\nemerges from the usage of non-injective functions (linear or non-linear layers)\nwithin DNNs, enabling multiple distinct inputs to be mapped to the same output.\nFor linear layers with input dimensions exceeding output dimensions, any linear\ncombination of the orthogonal bases of the nullspace of the parameter\nconsistently yields no change in their output. For non-linear layers, the\nharmless perturbation space may expand, depending on the properties of the\nlayers and input samples. Inspired by this property of DNNs, we solve for a\nfamily of general perturbation spaces that are redundant for the DNN's\ndecision, and can be used to hide sensitive data and serve as a means of model\nidentification. Our work highlights the distinctive robustness of DNNs (i.e.,\nconsistency under large magnitude perturbations) in contrast to adversarial\nexamples (vulnerability for small imperceptible noises).\n","authors":["Lu Chen","Shaofeng Li","Benhao Huang","Fan Yang","Zheng Li","Jie Li","Yuan Luo"],"pdf_url":"https://arxiv.org/pdf/2402.02095v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07514v1","updated":"2024-12-10T13:51:48Z","published":"2024-12-10T13:51:48Z","title":"Physics-Based Dynamic Models Hybridisation Using Physics-Informed Neural\n  Networks","summary":"  Physics-based dynamic models (PBDMs) are simplified representations of\ncomplex dynamical systems. PBDMs take specific processes within a complex\nsystem and assign a fragment of variables and an accompanying set of parameters\nto depict the processes. As this often leads to suboptimal parameterisation of\nthe system, a key challenge requires refining the empirical parameters and\nvariables to reduce uncertainties while maintaining the model s explainability\nand enhancing its predictive accuracy. We demonstrate that a hybrid mosquito\npopulation dynamics model, which integrates a PBDM with Physics-Informed Neural\nNetworks (PINN), retains the explainability of the PBDM by incorporating the\nPINN-learned model parameters in place of its empirical counterparts.\nSpecifically, we address the limitations of traditional PBDMs by modelling the\nparameters of larva and pupa development rates using a PINN that encodes\ncomplex, learned interactions of air temperature, precipitation and humidity.\nOur results demonstrate improved mosquito population simulations including the\ndifficult-to-predict mosquito population peaks. This opens the possibility of\nhybridisation concept application on other complex systems based on PBDMs such\nas cancer growth to address the challenges posed by scarce and noisy data, and\nto numerical weather prediction and climate modelling to overcome the gap\nbetween physics-based and data-driven weather prediction models.\n","authors":["Branislava Lalic","Dinh Viet Cuong","Mina Petric","Vladimir Pavlovic","Ana Firanj Sremac","Mark Roantree"],"pdf_url":"https://arxiv.org/pdf/2412.07514v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07507v1","updated":"2024-12-10T13:43:51Z","published":"2024-12-10T13:43:51Z","title":"ConfigX: Modular Configuration for Evolutionary Algorithms via Multitask\n  Reinforcement Learning","summary":"  Recent advances in Meta-learning for Black-Box Optimization (MetaBBO) have\nshown the potential of using neural networks to dynamically configure\nevolutionary algorithms (EAs), enhancing their performance and adaptability\nacross various BBO instances. However, they are often tailored to a specific\nEA, which limits their generalizability and necessitates retraining or\nredesigns for different EAs and optimization problems. To address this\nlimitation, we introduce ConfigX, a new paradigm of the MetaBBO framework that\nis capable of learning a universal configuration agent (model) for boosting\ndiverse EAs. To achieve so, our ConfigX first leverages a novel modularization\nsystem that enables the flexible combination of various optimization\nsub-modules to generate diverse EAs during training. Additionally, we propose a\nTransformer-based neural network to meta-learn a universal configuration policy\nthrough multitask reinforcement learning across a designed joint optimization\ntask space. Extensive experiments verify that, our ConfigX, after large-scale\npre-training, achieves robust zero-shot generalization to unseen tasks and\noutperforms state-of-the-art baselines. Moreover, ConfigX exhibits strong\nlifelong learning capabilities, allowing efficient adaptation to new tasks\nthrough fine-tuning. Our proposed ConfigX represents a significant step toward\nan automatic, all-purpose configuration agent for EAs.\n","authors":["Hongshu Guo","Zeyuan Ma","Jiacheng Chen","Yining Ma","Zhiguang Cao","Xinglin Zhang","Yue-Jiao Gong"],"pdf_url":"https://arxiv.org/pdf/2412.07507v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.15557v3","updated":"2024-12-10T13:36:23Z","published":"2023-05-24T20:43:47Z","title":"Non-Parametric Learning of Stochastic Differential Equations with\n  Non-asymptotic Fast Rates of Convergence","summary":"  We propose a novel non-parametric learning paradigm for the identification of\ndrift and diffusion coefficients of multi-dimensional non-linear stochastic\ndifferential equations, which relies upon discrete-time observations of the\nstate. The key idea essentially consists of fitting a RKHS-based approximation\nof the corresponding Fokker-Planck equation to such observations, yielding\ntheoretical estimates of non-asymptotic learning rates which, unlike previous\nworks, become increasingly tighter when the regularity of the unknown drift and\ndiffusion coefficients becomes higher. Our method being kernel-based, offline\npre-processing may be profitably leveraged to enable efficient numerical\nimplementation, offering excellent balance between precision and computational\ncomplexity.\n","authors":["Riccardo Bonalli","Alessandro Rudi"],"pdf_url":"https://arxiv.org/pdf/2305.15557v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.01460v3","updated":"2024-12-10T13:18:55Z","published":"2024-12-02T12:54:11Z","title":"A Comprehensive Study of Shapley Value in Data Analytics","summary":"  Over the recent years, Shapley value (SV), a solution concept from\ncooperative game theory, has found numerous applications in data analytics\n(DA). This paper provides the first comprehensive study of SV used throughout\nthe DA workflow, which involves three main steps: data fabric, data\nexploration, and result reporting. We summarize existing versatile forms of SV\nused in these steps by a unified definition and clarify the essential\nfunctionalities that SV can provide for data scientists. We categorize the arts\nin this field based on the technical challenges they tackled, which include\ncomputation efficiency, approximation error, privacy preservation, and\nappropriate interpretations. We discuss these challenges and analyze the\ncorresponding solutions. We also implement SVBench, the first open-sourced\nbenchmark for developing SV applications, and conduct experiments on six DA\ntasks to validate our analysis and discussions. Based on the qualitative and\nquantitative results, we identify the limitations of current efforts for\napplying SV to DA and highlight the directions of future research and\nengineering.\n","authors":["Hong Lin","Shixin Wan","Zhongle Xie","Ke Chen","Meihui Zhang","Lidan Shou","Gang Chen"],"pdf_url":"https://arxiv.org/pdf/2412.01460v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07488v1","updated":"2024-12-10T13:16:37Z","published":"2024-12-10T13:16:37Z","title":"Dual Random Fields and their Application to Mineral Potential Mapping","summary":"  In various geosciences branches, including mineral exploration,\ngeometallurgical characterization on established mining operations, and remote\nsensing, the regionalized input variables are spatially well-sampled across the\ndomain of interest, limiting the scope of spatial uncertainty quantification\nprocedures. In turn, response outcomes such as the mineral potential in a given\nregion, mining throughput, metallurgical recovery, or in-situ estimations from\nremote satellite imagery, are usually modeled from a much-restricted subset of\ntesting samples, collected at certain locations due to accessibility\nrestrictions and the high acquisition costs. Our limited understanding of these\nfunctions, in terms of the multi-dimensional complexity of causalities and\nunnoticed dependencies on inaccessible inputs, may lead to observing changes in\nsuch functions based on their geographical location. Pooling together different\nresponse functions across the domain is critical to correctly predict outcome\nresponses, the uncertainty associated with these inferred values, and the\nsignificance of inputs in such predictions at unexplored areas. This paper\nintroduces the notion of a dual random field (dRF), where the response function\nitself is considered a regionalized variable. In this way, different\nestablished response models across the geographic domain can be considered as\nobservations of a dRF realization, enabling the spatial inference and\nuncertainty assessment of both response models and their predictions. We\nexplain how dRFs inherit all the properties from classical random fields,\nallowing the use of standard Gaussian simulation procedures to simulate them.\nThese models are combined to obtain a mineral potential response, providing an\nexample of how to rigorously integrate machine learning approaches with\ngeostatistics.\n","authors":["Álvaro I. Riquelme"],"pdf_url":"https://arxiv.org/pdf/2412.07488v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07486v1","updated":"2024-12-10T13:08:16Z","published":"2024-12-10T13:08:16Z","title":"Real-time Sign Language Recognition Using MobileNetV2 and Transfer\n  Learning","summary":"  The hearing-impaired community in India deserves the access to tools that\nhelp them communicate, however, there is limited known technology solutions\nthat make use of Indian Sign Language (ISL) at present. Even though there are\nmany ISL users, ISL cannot access social and education arenas because there is\nnot yet an efficient technology to convert the ISL signal into speech or text.\nWe initiated this initiative owing to the rising demand for products and\ntechnologies that are inclusive and help ISL, filling the gap of communication\nfor the ones with hearing disability. Our goal is to build an reliable sign\nlanguage recognition system with the help of Convolutional Neural Networks\n(CNN) to . By expanding communication access, we aspire toward better\neducational opportunities and a more inclusive society for hearing impaired\npeople in India.\n","authors":["Smruti Jagtap","Kanika Jadhav","Rushikesh Temkar","Minal Deshmukh"],"pdf_url":"https://arxiv.org/pdf/2412.07486v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.08966v2","updated":"2024-12-10T13:03:40Z","published":"2024-06-13T09:52:44Z","title":"Separation Power of Equivariant Neural Networks","summary":"  The separation power of a machine learning model refers to its ability to\ndistinguish between different inputs and is often used as a proxy for its\nexpressivity. Indeed, knowing the separation power of a family of models is a\nnecessary condition to obtain fine-grained universality results. In this paper,\nwe analyze the separation power of equivariant neural networks, such as\nconvolutional and permutation-invariant networks. We first present a complete\ncharacterization of inputs indistinguishable by models derived by a given\narchitecture. From this results, we derive how separability is influenced by\nhyperparameters and architectural choices-such as activation functions, depth,\nhidden layer width, and representation types. Notably, all non-polynomial\nactivations, including ReLU and sigmoid, are equivalent in expressivity and\nreach maximum separation power. Depth improves separation power up to a\nthreshold, after which further increases have no effect. Adding invariant\nfeatures to hidden representations does not impact separation power. Finally,\nblock decomposition of hidden representations affects separability, with\nminimal components forming a hierarchy in separation power that provides a\nstraightforward method for comparing the separation power of models.\n","authors":["Marco Pacini","Xiaowen Dong","Bruno Lepri","Gabriele Santin"],"pdf_url":"https://arxiv.org/pdf/2406.08966v2.pdf","comment":"10 pages of main text, 1 figure"},{"id":"http://arxiv.org/abs/2410.10879v2","updated":"2024-12-10T13:00:22Z","published":"2024-10-09T11:54:41Z","title":"Enhancing Vision-Language Model Pre-training with Image-text Pair\n  Pruning Based on Word Frequency","summary":"  We propose Word-Frequency-based Image-Text Pair Pruning (WFPP), a novel data\npruning method that improves the efficiency of VLMs. Unlike MetaCLIP, our\nmethod does not need metadata for pruning, but selects text-image pairs to\nprune based on the content of the text. Specifically, WFPP prunes text-image\npairs containing high-frequency words across the entire training dataset. The\neffect of WFPP is to reduce the dominance of frequent words. The result a\nbetter balanced word-frequency distribution in the dataset, which is known to\nimprove the training of word embedding models. After pre-training on the pruned\nsubset, we fine-tuned the model on the entire dataset for one additional epoch\nto achieve better performance. Our experiments demonstrate that applying WFPP\nwhen training a CLIP model improves performance on a wide range of downstream\ntasks. WFPP also provides the advantage of speeding up pre-training by using\nfewer samples. Additionally, we analyze the training data before and after\npruning to visualize how WFPP changes the balance of word frequencies. We hope\nour work encourages researchers to consider the distribution of words in the\ntraining data when pre-training VLMs, not limited to CLIP.\n","authors":["Mingliang Liang","Martha Larson"],"pdf_url":"https://arxiv.org/pdf/2410.10879v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07477v1","updated":"2024-12-10T12:50:25Z","published":"2024-12-10T12:50:25Z","title":"Progressive-Resolution Policy Distillation: Leveraging Coarse-Resolution\n  Simulation for Time-Efficient Fine-Resolution Policy Learning","summary":"  In earthwork and construction, excavators often encounter large rocks mixed\nwith various soil conditions, requiring skilled operators. This paper presents\na framework for achieving autonomous excavation using reinforcement learning\n(RL) through a rock excavation simulator. In the simulation, resolution can be\ndefined by the particle size/number in the whole soil space. Fine-resolution\nsimulations closely mimic real-world behavior but demand significant\ncalculation time and challenging sample collection, while coarse-resolution\nsimulations enable faster sample collection but deviate from real-world\nbehavior. To combine the advantages of both resolutions, we explore using\npolicies developed in coarse-resolution simulations for pre-training in\nfine-resolution simulations. To this end, we propose a novel policy learning\nframework called Progressive-Resolution Policy Distillation (PRPD), which\nprogressively transfers policies through some middle-resolution simulations\nwith conservative policy transfer to avoid domain gaps that could lead to\npolicy transfer failure. Validation in a rock excavation simulator and nine\nreal-world rock environments demonstrated that PRPD reduced sampling time to\nless than 1/7 while maintaining task success rates comparable to those achieved\nthrough policy learning in a fine-resolution simulation.\n","authors":["Yuki Kadokawa","Hirotaka Tahara","Takamitsu Matsubara"],"pdf_url":"https://arxiv.org/pdf/2412.07477v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07469v1","updated":"2024-12-10T12:36:35Z","published":"2024-12-10T12:36:35Z","title":"Score-matching-based Structure Learning for Temporal Data on Networks","summary":"  Causal discovery is a crucial initial step in establishing causality from\nempirical data and background knowledge. Numerous algorithms have been\ndeveloped for this purpose. Among them, the score-matching method has\ndemonstrated superior performance across various evaluation metrics,\nparticularly for the commonly encountered Additive Nonlinear Causal Models.\nHowever, current score-matching-based algorithms are primarily designed to\nanalyze independent and identically distributed (i.i.d.) data. More\nimportantly, they suffer from high computational complexity due to the pruning\nstep required for handling dense Directed Acyclic Graphs (DAGs). To enhance the\nscalability of score matching, we have developed a new parent-finding\nsubroutine for leaf nodes in DAGs, significantly accelerating the most\ntime-consuming part of the process: the pruning step. This improvement results\nin an efficiency-lifted score matching algorithm, termed Parent\nIdentification-based Causal structure learning for both i.i.d. and temporal\ndata on networKs, or PICK. The new score-matching algorithm extends the scope\nof existing algorithms and can handle static and temporal data on networks with\nweak network interference. Our proposed algorithm can efficiently cope with\nincreasingly complex datasets that exhibit spatial and temporal dependencies,\ncommonly encountered in academia and industry. The proposed algorithm can\naccelerate score-matching-based methods while maintaining high accuracy in\nreal-world applications.\n","authors":["Hao Chen","Kai Yi","Lin Liu","Yu Guang Wang"],"pdf_url":"https://arxiv.org/pdf/2412.07469v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07468v1","updated":"2024-12-10T12:35:37Z","published":"2024-12-10T12:35:37Z","title":"AHSG: Adversarial Attacks on High-level Semantics in Graph Neural\n  Networks","summary":"  Graph Neural Networks (GNNs) have garnered significant interest among\nresearchers due to their impressive performance in graph learning tasks.\nHowever, like other deep neural networks, GNNs are also vulnerable to\nadversarial attacks. In existing adversarial attack methods for GNNs, the\nmetric between the attacked graph and the original graph is usually the attack\nbudget or a measure of global graph properties. However, we have found that it\nis possible to generate attack graphs that disrupt the primary semantics even\nwithin these constraints. To address this problem, we propose a Adversarial\nAttacks on High-level Semantics in Graph Neural Networks (AHSG), which is a\ngraph structure attack model that ensures the retention of primary semantics.\nThe latent representations of each node can extract rich semantic information\nby applying convolutional operations on graph data. These representations\ncontain both task-relevant primary semantic information and task-irrelevant\nsecondary semantic information. The latent representations of same-class nodes\nwith the same primary semantics can fulfill the objective of modifying\nsecondary semantics while preserving the primary semantics. Finally, the latent\nrepresentations with attack effects is mapped to an attack graph using\nProjected Gradient Descent (PGD) algorithm. By attacking graph deep learning\nmodels with some advanced defense strategies, we validate that AHSG has\nsuperior attack effectiveness compared to other attack methods. Additionally,\nwe employ Contextual Stochastic Block Models (CSBMs) as a proxy for the primary\nsemantics to detect the attacked graph, confirming that AHSG almost does not\ndisrupt the original primary semantics of the graph.\n","authors":["Kai Yuan","Xiaobing Pei","Haoran Yang"],"pdf_url":"https://arxiv.org/pdf/2412.07468v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07454v1","updated":"2024-12-10T12:20:42Z","published":"2024-12-10T12:20:42Z","title":"Tazza: Shuffling Neural Network Parameters for Secure and Private\n  Federated Learning","summary":"  Federated learning enables decentralized model training without sharing raw\ndata, preserving data privacy. However, its vulnerability towards critical\nsecurity threats, such as gradient inversion and model poisoning by malicious\nclients, remain unresolved. Existing solutions often address these issues\nseparately, sacrificing either system robustness or model accuracy. This work\nintroduces Tazza, a secure and efficient federated learning framework that\nsimultaneously addresses both challenges. By leveraging the permutation\nequivariance and invariance properties of neural networks via weight shuffling\nand shuffled model validation, Tazza enhances resilience against diverse\npoisoning attacks, while ensuring data confidentiality and high model accuracy.\nComprehensive evaluations on various datasets and embedded platforms show that\nTazza achieves robust defense with up to 6.7x improved computational efficiency\ncompared to alternative schemes, without compromising performance.\n","authors":["Kichang Lee","Jaeho Jin","JaeYeon Park","JeongGil Ko"],"pdf_url":"https://arxiv.org/pdf/2412.07454v1.pdf","comment":"14 pages, 14 figures"},{"id":"http://arxiv.org/abs/2406.17323v3","updated":"2024-12-10T12:17:22Z","published":"2024-06-25T07:14:15Z","title":"XAMI -- A Benchmark Dataset for Artefact Detection in XMM-Newton Optical\n  Images","summary":"  Reflected or scattered light produce artefacts in astronomical observations\nthat can negatively impact the scientific study. Hence, automated detection of\nthese artefacts is highly beneficial, especially with the increasing amounts of\ndata gathered. Machine learning methods are well-suited to this problem, but\ncurrently there is a lack of annotated data to train such approaches to detect\nartefacts in astronomical observations. In this work, we present a dataset of\nimages from the XMM-Newton space telescope Optical Monitoring camera showing\ndifferent types of artefacts. We hand-annotated a sample of 1000 images with\nartefacts which we use to train automated ML methods. We further demonstrate\ntechniques tailored for accurate detection and masking of artefacts using\ninstance segmentation. We adopt a hybrid approach, combining knowledge from\nboth convolutional neural networks (CNNs) and transformer-based models and use\ntheir advantages in segmentation. The presented method and dataset will advance\nartefact detection in astronomical observations by providing a reproducible\nbaseline. All code and data are made available\n(https://github.com/ESA-Datalabs/XAMI-model and\nhttps://github.com/ESA-Datalabs/XAMI-dataset).\n","authors":["Elisabeta-Iulia Dima","Pablo Gómez","Sandor Kruk","Peter Kretschmar","Simon Rosen","Călin-Adrian Popa"],"pdf_url":"https://arxiv.org/pdf/2406.17323v3.pdf","comment":"Accepted for oral presentation at SPAICE 2024"},{"id":"http://arxiv.org/abs/2412.07446v1","updated":"2024-12-10T12:05:03Z","published":"2024-12-10T12:05:03Z","title":"Causal World Representation in the GPT Model","summary":"  Are generative pre-trained transformer (GPT) models only trained to predict\nthe next token, or do they implicitly learn a world model from which a sequence\nis generated one token at a time? We examine this question by deriving a causal\ninterpretation of the attention mechanism in GPT, and suggesting a causal world\nmodel that arises from this interpretation. Furthermore, we propose that\nGPT-models, at inference time, can be utilized for zero-shot causal structure\nlearning for in-distribution sequences. Empirical evaluation is conducted in a\ncontrolled synthetic environment using the setup and rules of the Othello board\ngame. A GPT, pre-trained on real-world games played with the intention of\nwinning, is tested on synthetic data that only adheres to the game rules. We\nfind that the GPT model tends to generate next moves that adhere to the game\nrules for sequences for which the attention mechanism encodes a causal\nstructure with high confidence. In general, in cases for which the GPT model\ngenerates moves that do not adhere to the game rules, it also fails to capture\nany causal structure.\n","authors":["Raanan Y. Rohekar","Yaniv Gurwicz","Sungduk Yu","Vasudev Lal"],"pdf_url":"https://arxiv.org/pdf/2412.07446v1.pdf","comment":"NeurIPS 2024 Workshop on Causality and Large Models (CaLM)"},{"id":"http://arxiv.org/abs/2311.08978v2","updated":"2024-12-10T12:02:33Z","published":"2023-11-15T14:12:55Z","title":"Probability of Collision of satellites and space debris for short-term\n  encounters: Rederivation and fast-to-compute upper and lower bounds","summary":"  The proliferation of space debris in LEO has become a major concern for the\nspace industry. With the growing interest in space exploration, the prediction\nof potential collisions between objects in orbit has become a crucial issue. It\nis estimated that, in orbit, there are millions of fragments a few millimeters\nin size and thousands of inoperative satellites and discarded rocket stages.\nGiven the high speeds that these fragments can reach, even fragments a few\nmillimeters in size can cause fractures in a satellite's hull or put a serious\ncrack in the window of a space shuttle. The conventional method proposed by\nAkella and Alfriend in 2000 remains widely used to estimate the probability of\ncollision in short-term encounters. Given the small period of time, it is\nassumed that, during the encounter: (1) trajectories are represented by\nstraight lines with constant velocity; (2) there is no velocity uncertainty and\nthe position exhibits a stationary distribution throughout the encounter; and\n(3) position uncertainties are independent and represented by Gaussian\ndistributions. This study introduces a novel derivation based on first\nprinciples that naturally allows for tight and fast upper and lower bounds for\nthe probability of collision. We tested implementations of both probability and\nbound computations with the original and our formulation on a real CDM dataset\nused in ESA's Collision Avoidance Challenge. Our approach reduces the\ncalculation of the probability to two one-dimensional integrals and has the\npotential to significantly reduce the processing time compared to the\ntraditional method, from 80% to nearly real-time.\n","authors":["Ricardo Ferreira","Cláudia Soares","Marta Guimarães"],"pdf_url":"https://arxiv.org/pdf/2311.08978v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07441v1","updated":"2024-12-10T11:57:47Z","published":"2024-12-10T11:57:47Z","title":"Reconstructing Deep Neural Networks: Unleashing the Optimization\n  Potential of Natural Gradient Descent","summary":"  Natural gradient descent (NGD) is a powerful optimization technique for\nmachine learning, but the computational complexity of the inverse Fisher\ninformation matrix limits its application in training deep neural networks. To\novercome this challenge, we propose a novel optimization method for training\ndeep neural networks called structured natural gradient descent (SNGD).\nTheoretically, we demonstrate that optimizing the original network using NGD is\nequivalent to using fast gradient descent (GD) to optimize the reconstructed\nnetwork with a structural transformation of the parameter matrix. Thereby, we\ndecompose the calculation of the global Fisher information matrix into the\nefficient computation of local Fisher matrices via constructing local Fisher\nlayers in the reconstructed network to speed up the training. Experimental\nresults on various deep networks and datasets demonstrate that SNGD achieves\nfaster convergence speed than NGD while retaining comparable solutions.\nFurthermore, our method outperforms traditional GDs in terms of efficiency and\neffectiveness. Thus, our proposed method has the potential to significantly\nimprove the scalability and efficiency of NGD in deep learning applications.\nOur source code is available at https://github.com/Chaochao-Lin/SNGD.\n","authors":["Weihua Liu","Said Boumaraf","Jianwu Li","Chaochao Lin","Xiabi Liu","Lijuan Niu","Naoufel Werghi"],"pdf_url":"https://arxiv.org/pdf/2412.07441v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17520v2","updated":"2024-12-10T11:56:09Z","published":"2024-10-23T02:51:43Z","title":"MobileSafetyBench: Evaluating Safety of Autonomous Agents in Mobile\n  Device Control","summary":"  Autonomous agents powered by large language models (LLMs) show promising\npotential in assistive tasks across various domains, including mobile device\ncontrol. As these agents interact directly with personal information and device\nsettings, ensuring their safe and reliable behavior is crucial to prevent\nundesirable outcomes. However, no benchmark exists for standardized evaluation\nof the safety of mobile device-control agents. In this work, we introduce\nMobileSafetyBench, a benchmark designed to evaluate the safety of\ndevice-control agents within a realistic mobile environment based on Android\nemulators. We develop a diverse set of tasks involving interactions with\nvarious mobile applications, including messaging and banking applications,\nchallenging agents with managing risks encompassing misuse and negative side\neffects. These tasks include tests to evaluate the safety of agents in daily\nscenarios as well as their robustness against indirect prompt injection\nattacks. Our experiments demonstrate that baseline agents, based on\nstate-of-the-art LLMs, often fail to effectively prevent harm while performing\nthe tasks. To mitigate these safety concerns, we propose a prompting method\nthat encourages agents to prioritize safety considerations. While this method\nshows promise in promoting safer behaviors, there is still considerable room\nfor improvement to fully earn user trust. This highlights the urgent need for\ncontinued research to develop more robust safety mechanisms in mobile\nenvironments. We open-source our benchmark at:\nhttps://mobilesafetybench.github.io/.\n","authors":["Juyong Lee","Dongyoon Hahm","June Suk Choi","W. Bradley Knox","Kimin Lee"],"pdf_url":"https://arxiv.org/pdf/2410.17520v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07437v1","updated":"2024-12-10T11:54:14Z","published":"2024-12-10T11:54:14Z","title":"Impact of Sampling Techniques and Data Leakage on XGBoost Performance in\n  Credit Card Fraud Detection","summary":"  Credit card fraud detection remains a critical challenge in financial\nsecurity, with machine learning models like XGBoost(eXtreme gradient boosting)\nemerging as powerful tools for identifying fraudulent transactions. However,\nthe inherent class imbalance in credit card transaction datasets poses\nsignificant challenges for model performance. Although sampling techniques are\ncommonly used to address this imbalance, their implementation sometimes\nprecedes the train-test split, potentially introducing data leakage.\n  This study presents a comparative analysis of XGBoost's performance in credit\ncard fraud detection under three scenarios: Firstly without any imbalance\nhandling techniques, secondly with sampling techniques applied only to the\ntraining set after the train-test split, and third with sampling techniques\napplied before the train-test split. We utilized a dataset from Kaggle of\n284,807 credit card transactions, containing 0.172\\% fraudulent cases, to\nevaluate these approaches.\n  Our findings show that although sampling strategies enhance model\nperformance, the reliability of results is greatly impacted by when they are\napplied. Due to a data leakage issue that frequently occurs in machine learning\nmodels during the sampling phase, XGBoost models trained on data where sampling\nwas applied prior to the train-test split may have displayed artificially\ninflated performance metrics. Surprisingly, models trained with sampling\ntechniques applied solely to the training set demonstrated significantly lower\nresults than those with pre-split sampling, all the while preserving the\nintegrity of the evaluation process.\n","authors":["Siyaxolisa Kabane"],"pdf_url":"https://arxiv.org/pdf/2412.07437v1.pdf","comment":"19 pages, 4 figures"},{"id":"http://arxiv.org/abs/2412.07435v1","updated":"2024-12-10T11:50:46Z","published":"2024-12-10T11:50:46Z","title":"Parallel simulation for sampling under isoperimetry and score-based\n  diffusion models","summary":"  In recent years, there has been a surge of interest in proving discretization\nbounds for sampling under isoperimetry and for diffusion models. As data size\ngrows, reducing the iteration cost becomes an important goal. Inspired by the\ngreat success of the parallel simulation of the initial value problem in\nscientific computation, we propose parallel Picard methods for sampling tasks.\nRigorous theoretical analysis reveals that our algorithm achieves better\ndependence on dimension $d$ than prior works in iteration complexity (i.e.,\nreduced from $\\widetilde{O}(\\log^2 d)$ to $\\widetilde{O}(\\log d)$), which is\neven optimal for sampling under isoperimetry with specific iteration\ncomplexity. Our work highlights the potential advantages of simulation methods\nin scientific computation for dynamics-based sampling and diffusion models.\n","authors":["Huanjian Zhou","Masashi Sugiyama"],"pdf_url":"https://arxiv.org/pdf/2412.07435v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2405.15986 by\n  other authors"},{"id":"http://arxiv.org/abs/2412.07428v1","updated":"2024-12-10T11:39:27Z","published":"2024-12-10T11:39:27Z","title":"When UAV Meets Federated Learning: Latency Minimization via Joint\n  Trajectory Design and Resource Allocation","summary":"  Federated learning (FL) has emerged as a pivotal solution for training\nmachine learning models over wireless networks, particularly for Internet of\nThings (IoT) devices with limited computation resources. Despite its benefits,\nthe efficiency of FL is often restricted by the communication quality between\nIoT devices and the central server. To address this issue, we introduce an\ninnovative approach by deploying an unmanned aerial vehicle (UAV) as a mobile\nFL server to enhance the training process of FL. By leveraging the UAV's\nmaneuverability, we establish robust line-of-sight connections with IoT\ndevices, significantly improving communication capacity. To improve the overall\ntraining efficiency, we formulate a latency minimization problem by jointly\noptimizing the bandwidth allocation, computing frequencies, transmit power for\nboth the UAV and IoT devices, and the UAV's trajectory. Then, an efficient\nalternating optimization algorithm is developed to solve it efficiently.\nFurthermore, we analyze the convergence and computational complexity of the\nproposed algorithm. Finally, numerical results demonstrate that our proposed\nscheme not only outperforms existing benchmark schemes in terms of latency but\nalso achieves training efficiency that closely approximate the ideal scenario.\n","authors":["Xuhui Zhang","Wenchao Liu","Jinke Ren","Huijun Xing","Gui Gui","Yanyan Shen","Shuguang Cui"],"pdf_url":"https://arxiv.org/pdf/2412.07428v1.pdf","comment":"This manuscript has been submitted to IEEE"},{"id":"http://arxiv.org/abs/2411.17284v2","updated":"2024-12-10T11:36:48Z","published":"2024-11-26T10:13:39Z","title":"Using Large Language Models for Expert Prior Elicitation in Predictive\n  Modelling","summary":"  Large language models (LLMs), trained on diverse data effectively acquire a\nbreadth of information across various domains. However, their computational\ncomplexity, cost, and lack of transparency hinder their direct application for\nspecialised tasks. In fields such as clinical research, acquiring expert\nannotations or prior knowledge about predictive models is often costly and\ntime-consuming. This study proposes the use of LLMs to elicit expert prior\ndistributions for predictive models. This approach also provides an alternative\nto in-context learning, where language models are tasked with making\npredictions directly. In this work, we compare LLM-elicited and uninformative\npriors, evaluate whether LLMs truthfully generate parameter distributions, and\npropose a model selection strategy for in-context learning and prior\nelicitation. Our findings show that LLM-elicited prior parameter distributions\nsignificantly reduce predictive error compared to uninformative priors in\nlow-data settings. Applied to clinical problems, this translates to fewer\nrequired biological samples, lowering cost and resources. Prior elicitation\nalso consistently outperforms and proves more reliable than in-context learning\nat a lower cost, making it a preferred alternative in our setting. We\ndemonstrate the utility of this method across various use cases, including\nclinical applications. For infection prediction, using LLM-elicited priors\nreduced the number of required labels to achieve the same accuracy as an\nuninformative prior by 55%, 200 days earlier in the study.\n","authors":["Alexander Capstick","Rahul G. Krishnan","Payam Barnaghi"],"pdf_url":"https://arxiv.org/pdf/2411.17284v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.06430v2","updated":"2024-12-10T11:21:26Z","published":"2024-04-09T16:23:01Z","title":"pfl-research: simulation framework for accelerating research in Private\n  Federated Learning","summary":"  Federated learning (FL) is an emerging machine learning (ML) training\nparadigm where clients own their data and collaborate to train a global model,\nwithout revealing any data to the server and other participants. Researchers\ncommonly perform experiments in a simulation environment to quickly iterate on\nideas. However, existing open-source tools do not offer the efficiency required\nto simulate FL on larger and more realistic FL datasets. We introduce\npfl-research, a fast, modular, and easy-to-use Python framework for simulating\nFL. It supports TensorFlow, PyTorch, and non-neural network models, and is\ntightly integrated with state-of-the-art privacy algorithms. We study the speed\nof open-source FL frameworks and show that pfl-research is 7-72$\\times$ faster\nthan alternative open-source frameworks on common cross-device setups. Such\nspeedup will significantly boost the productivity of the FL research community\nand enable testing hypotheses on realistic FL datasets that were previously too\nresource intensive. We release a suite of benchmarks that evaluates an\nalgorithm's overall performance on a diverse set of realistic scenarios. The\ncode is available on GitHub at https://github.com/apple/pfl-research.\n","authors":["Filip Granqvist","Congzheng Song","Áine Cahill","Rogier van Dalen","Martin Pelikan","Yi Sheng Chan","Xiaojun Feng","Natarajan Krishnaswami","Vojta Jina","Mona Chitnis"],"pdf_url":"https://arxiv.org/pdf/2404.06430v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07415v1","updated":"2024-12-10T11:07:37Z","published":"2024-12-10T11:07:37Z","title":"Machine Learning Algorithms for Detecting Mental Stress in College\n  Students","summary":"  In today's world, stress is a big problem that affects people's health and\nhappiness. More and more people are feeling stressed out, which can lead to\nlots of health issues like breathing problems, feeling overwhelmed, heart\nattack, diabetes, etc. This work endeavors to forecast stress and non-stress\noccurrences among college students by applying various machine learning\nalgorithms: Decision Trees, Random Forest, Support Vector Machines, AdaBoost,\nNaive Bayes, Logistic Regression, and K-nearest Neighbors. The primary\nobjective of this work is to leverage a research study to predict and mitigate\nstress and non-stress based on the collected questionnaire dataset. We\nconducted a workshop with the primary goal of studying the stress levels found\namong the students. This workshop was attended by Approximately 843 students\naged between 18 to 21 years old. A questionnaire was given to the students\nvalidated under the guidance of the experts from the All India Institute of\nMedical Sciences (AIIMS) Raipur, Chhattisgarh, India, on which our dataset is\nbased. The survey consists of 28 questions, aiming to comprehensively\nunderstand the multidimensional aspects of stress, including emotional\nwell-being, physical health, academic performance, relationships, and leisure.\nThis work finds that Support Vector Machines have a maximum accuracy for\nStress, reaching 95\\%. The study contributes to a deeper understanding of\nstress determinants. It aims to improve college student's overall quality of\nlife and academic success, addressing the multifaceted nature of stress.\n","authors":["Ashutosh Singh","Khushdeep Singh","Amit Kumar","Abhishek Shrivastava","Santosh Kumar"],"pdf_url":"https://arxiv.org/pdf/2412.07415v1.pdf","comment":"This paper was presented at an IEEE conference and is 5 pages long\n  with 5 figures. It discusses machine learning algorithms for detecting mental\n  stress in college students"},{"id":"http://arxiv.org/abs/2412.07411v1","updated":"2024-12-10T11:03:51Z","published":"2024-12-10T11:03:51Z","title":"DSFEC: Efficient and Deployable Deep Radar Object Detection","summary":"  Deploying radar object detection models on resource-constrained edge devices\nlike the Raspberry Pi poses significant challenges due to the large size of the\nmodel and the limited computational power and the memory of the Pi. In this\nwork, we explore the efficiency of Depthwise Separable Convolutions in radar\nobject detection networks and integrate them into our model. Additionally, we\nintroduce a novel Feature Enhancement and Compression (FEC) module to the\nPointPillars feature encoder to further improve the model performance. With\nthese innovations, we propose the DSFEC-L model and its two versions, which\noutperform the baseline (23.9 mAP of Car class, 20.72 GFLOPs) on nuScenes\ndataset: 1). An efficient DSFEC-M model with a 14.6% performance improvement\nand a 60% reduction in GFLOPs. 2). A deployable DSFEC-S model with a 3.76%\nperformance improvement and a remarkable 78.5% reduction in GFLOPs. Despite\nmarginal performance gains, our deployable model achieves an impressive 74.5%\nreduction in runtime on the Raspberry Pi compared to the baseline.\n","authors":["Gayathri Dandugula","Santhosh Boddana","Sudesh Mirashi"],"pdf_url":"https://arxiv.org/pdf/2412.07411v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07407v1","updated":"2024-12-10T10:58:47Z","published":"2024-12-10T10:58:47Z","title":"Towards Graph Foundation Models: A Study on the Generalization of\n  Positional and Structural Encodings","summary":"  Recent advances in integrating positional and structural encodings (PSEs)\ninto graph neural networks (GNNs) have significantly enhanced their performance\nacross various graph learning tasks. However, the general applicability of\nthese encodings and their potential to serve as foundational representations\nfor graphs remain uncertain. This paper investigates the fine-tuning\nefficiency, scalability with sample size, and generalization capability of\nlearnable PSEs across diverse graph datasets. Specifically, we evaluate their\npotential as universal pre-trained models that can be easily adapted to new\ntasks with minimal fine-tuning and limited data. Furthermore, we assess the\nexpressivity of the learned representations, particularly, when used to augment\ndownstream GNNs. We demonstrate through extensive benchmarking and empirical\nanalysis that PSEs generally enhance downstream models. However, some datasets\nmay require specific PSE-augmentations to achieve optimal performance.\nNevertheless, our findings highlight their significant potential to become\nintegral components of future graph foundation models. We provide new insights\ninto the strengths and limitations of PSEs, contributing to the broader\ndiscourse on foundation models in graph learning.\n","authors":["Billy Joe Franks","Moshe Eliasof","Semih Cantürk","Guy Wolf","Carola-Bibiane Schönlieb","Sophie Fellenz","Marius Kloft"],"pdf_url":"https://arxiv.org/pdf/2412.07407v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07405v1","updated":"2024-12-10T10:55:57Z","published":"2024-12-10T10:55:57Z","title":"MoDULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task\n  Learning","summary":"  The growing demand for larger-scale models in the development of\n\\textbf{L}arge \\textbf{L}anguage \\textbf{M}odels (LLMs) poses challenges for\nefficient training within limited computational resources. Traditional\nfine-tuning methods often exhibit instability in multi-task learning and rely\nheavily on extensive training resources. Here, we propose MoDULA\n(\\textbf{M}ixture \\textbf{o}f \\textbf{D}omain-Specific and \\textbf{U}niversal\n\\textbf{L}oR\\textbf{A}), a novel \\textbf{P}arameter \\textbf{E}fficient\n\\textbf{F}ine-\\textbf{T}uning (PEFT)\n\\textbf{M}ixture-\\textbf{o}f-\\textbf{E}xpert (MoE) paradigm for improved\nfine-tuning and parameter efficiency in multi-task learning. The paradigm\neffectively improves the multi-task capability of the model by training\nuniversal experts, domain-specific experts, and routers separately. MoDULA-Res\nis a new method within the MoDULA paradigm, which maintains the model's general\ncapability by connecting universal and task-specific experts through residual\nconnections. The experimental results demonstrate that the overall performance\nof the MoDULA-Flan and MoDULA-Res methods surpasses that of existing\nfine-tuning methods on various LLMs. Notably, MoDULA-Res achieves more\nsignificant performance improvements in multiple tasks while reducing training\ncosts by over 80\\% without losing general capability. Moreover, MoDULA displays\nflexible pluggability, allowing for the efficient addition of new tasks without\nretraining existing experts from scratch. This progressive training paradigm\ncircumvents data balancing issues, enhancing training efficiency and model\nstability. Overall, MoDULA provides a scalable, cost-effective solution for\nfine-tuning LLMs with enhanced parameter efficiency and generalization\ncapability.\n","authors":["Yufei Ma","Zihan Liang","Huangyu Dai","Ben Chen","Dehong Gao","Zhuoran Ran","Wang Zihan","Linbo Jin","Wen Jiang","Guannan Zhang","Xiaoyan Cai","Libin Yang"],"pdf_url":"https://arxiv.org/pdf/2412.07405v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.03242v3","updated":"2024-12-10T10:55:44Z","published":"2023-11-06T16:31:09Z","title":"Approximating Langevin Monte Carlo with ResNet-like Neural Network\n  architectures","summary":"  We sample from a given target distribution by constructing a neural network\nwhich maps samples from a simple reference, e.g. the standard normal\ndistribution, to samples from the target. To that end, we propose using a\nneural network architecture inspired by the Langevin Monte Carlo (LMC)\nalgorithm. Based on LMC perturbation results, we show approximation rates of\nthe proposed architecture for smooth, log-concave target distributions measured\nin the Wasserstein-$2$ distance. The analysis heavily relies on the notion of\nsub-Gaussianity of the intermediate measures of the perturbed LMC process. In\nparticular, we derive bounds on the growth of the intermediate variance proxies\nunder different assumptions on the perturbations. Moreover, we propose an\narchitecture similar to deep residual neural networks and derive expressivity\nresults for approximating the sample to target distribution map.\n","authors":["Charles Miranda","Janina Schütte","David Sommer","Martin Eigel"],"pdf_url":"https://arxiv.org/pdf/2311.03242v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07391v1","updated":"2024-12-10T10:33:58Z","published":"2024-12-10T10:33:58Z","title":"Post-Training Non-Uniform Quantization for Convolutional Neural Networks","summary":"  Despite the success of CNN models on a variety of Image classification and\nsegmentation tasks, their extensive computational and storage demands pose\nconsiderable challenges for real-world deployment on resource constrained\ndevices. Quantization is one technique that aims to alleviate these large\nstorage requirements and speed up the inference process by reducing the\nprecision of model parameters to lower-bit representations. In this paper, we\nintroduce a novel post-training quantization method for model weights. Our\nmethod finds optimal clipping thresholds and scaling factors along with\nmathematical guarantees that our method minimizes quantization noise. Empirical\nresults on Real World Datasets demonstrate that our quantization scheme\nsignificantly reduces model size and computational requirements while\npreserving model accuracy.\n","authors":["Ahmed Luqman","Khuzemah Qazi","Imdadullah Khan"],"pdf_url":"https://arxiv.org/pdf/2412.07391v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07384v1","updated":"2024-12-10T10:30:12Z","published":"2024-12-10T10:30:12Z","title":"Label up: Learning Pulmonary Embolism Segmentation from Image Level\n  Annotation through Model Explainability","summary":"  Pulmonary Embolisms (PE) are a leading cause of cardiovascular death.\nComputed tomographic pulmonary angiography (CTPA) stands as the gold standard\nfor diagnosing pulmonary embolisms (PE) and there has been a lot of interest in\ndeveloping AI-based models for assisting in PE diagnosis. Performance of these\nalgorithms has been hindered by the scarcity of annotated data, especially\nthose with fine-grained delineation of the thromboembolic burden. In this paper\nwe attempt to address this issue by introducing a weakly supervised learning\npipeline, that leverages model explainability to generate fine-grained (pixel\nlevel) masks for embolisms starting from more coarse-grained (binary, image\nlevel) PE annotations. Furthermore, we show that training models using the\nautomatically generated pixel annotations yields good PE localization\nperformance. We demonstrate the effectiveness of our pipeline on the\nlarge-scale, multi-center RSPECT augmented dataset for PE detection and\nlocalization.\n","authors":["Florin Condrea","Saikiran Rapaka","Marius Leordeanu"],"pdf_url":"https://arxiv.org/pdf/2412.07384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07382v1","updated":"2024-12-10T10:28:32Z","published":"2024-12-10T10:28:32Z","title":"Temporal Linear Item-Item Model for Sequential Recommendation","summary":"  In sequential recommendation (SR), neural models have been actively explored\ndue to their remarkable performance, but they suffer from inefficiency inherent\nto their complexity. On the other hand, linear SR models exhibit high\nefficiency and achieve competitive or superior accuracy compared to neural\nmodels. However, they solely deal with the sequential order of items (i.e.,\nsequential information) and overlook the actual timestamp (i.e., temporal\ninformation). It is limited to effectively capturing various user preference\ndrifts over time. To address this issue, we propose a novel linear SR model,\nnamed TemporAl LinEar item-item model (TALE), incorporating temporal\ninformation while preserving training/inference efficiency, with three key\ncomponents. (i) Single-target augmentation concentrates on a single target\nitem, enabling us to learn the temporal correlation for the target item. (ii)\nTime interval-aware weighting utilizes the actual timestamp to discern the item\ncorrelation depending on time intervals. (iii) Trend-aware normalization\nreflects the dynamic shift of item popularity over time. Our empirical studies\nshow that TALE outperforms ten competing SR models by up to 18.71% gains on\nfive benchmark datasets. It also exhibits remarkable effectiveness in\nevaluating long-tail items by up to 30.45% gains. The source code is available\nat https://github.com/psm1206/TALE.\n","authors":["Seongmin Park","Mincheol Yoon","Minjin Choi","Jongwuk Lee"],"pdf_url":"https://arxiv.org/pdf/2412.07382v1.pdf","comment":"Accepted by WSDM 2025"},{"id":"http://arxiv.org/abs/2412.07378v1","updated":"2024-12-10T10:22:34Z","published":"2024-12-10T10:22:34Z","title":"A Spectral Framework for Tracking Communities in Evolving Networks","summary":"  Discovering and tracking communities in time-varying networks is an important\ntask in network science, motivated by applications in fields ranging from\nneuroscience to sociology. In this work, we characterize the celebrated family\nof spectral methods for static clustering in terms of the low-rank\napproximation of high-dimensional node embeddings. From this perspective, it\nbecomes natural to view the evolving community detection problem as one of\nsubspace tracking on the Grassmann manifold. While the resulting optimization\nproblem is nonconvex, we adopt a block majorize-minimize Riemannian\noptimization scheme to learn the Grassmann geodesic which best fits the data.\nOur framework generalizes any static spectral community detection approach and\nleads to algorithms achieving favorable performance on synthetic and real\ntemporal networks, including those that are weighted, signed, directed,\nmixed-membership, multiview, hierarchical, cocommunity-structured, bipartite,\nor some combination thereof. We demonstrate how to specifically cast a wide\nvariety of methods into our framework, and demonstrate greatly improved dynamic\ncommunity detection results in all cases.\n","authors":["Jacob Hume","Laura Balzano"],"pdf_url":"https://arxiv.org/pdf/2412.07378v1.pdf","comment":"34 pages, 13 figures"},{"id":"http://arxiv.org/abs/2412.06478v2","updated":"2024-12-10T09:54:45Z","published":"2024-12-09T13:28:19Z","title":"An inferential measure of dependence between two systems using Bayesian\n  model comparison","summary":"  We propose to quantify dependence between two systems $X$ and $Y$ in a\ndataset $D$ based on the Bayesian comparison of two models: one, $H_0$, of\nstatistical independence and another one, $H_1$, of dependence. In this\nframework, dependence between $X$ and $Y$ in $D$, denoted $B(X,Y|D)$, is\nquantified as $P(H_1|D)$, the posterior probability for the model of dependence\ngiven $D$, or any strictly increasing function thereof. It is therefore a\nmeasure of the evidence for dependence between $X$ and $Y$ as modeled by $H_1$\nand observed in $D$. We review several statistical models and reconsider\nstandard results in the light of $B(X,Y|D)$ as a measure of dependence. Using\nsimulations, we focus on two specific issues: the effect of noise and the\nbehavior of $B(X,Y|D)$ when $H_1$ has a parameter coding for the intensity of\ndependence. We then derive some general properties of $B(X,Y|D)$, showing that\nit quantifies the information contained in $D$ in favor of $H_1$ versus $H_0$.\nWhile some of these properties are typical of what is expected from a valid\nmeasure of dependence, others are novel and naturally appear as desired\nfeatures for specific measures of dependence, which we call inferential. We\nfinally put these results in perspective; in particular, we discuss the\nconsequences of using the Bayesian framework as well as the similarities and\ndifferences between $B(X,Y|D)$ and mutual information.\n","authors":["Guillaume Marrelec","Alain Giron"],"pdf_url":"https://arxiv.org/pdf/2412.06478v2.pdf","comment":"To be published in IEEE Transaction on Systems, Man, and Cybernetics:\n  Systems"},{"id":"http://arxiv.org/abs/2407.11075v5","updated":"2024-12-10T09:35:58Z","published":"2024-07-13T04:29:36Z","title":"A Comprehensive Survey on Kolmogorov Arnold Networks (KAN)","summary":"  Through this comprehensive survey of Kolmogorov-Arnold Networks(KAN), we have\ngained a thorough understanding of its theoretical foundation, architectural\ndesign, application scenarios, and current research progress. KAN, with its\nunique architecture and flexible activation functions, excels in handling\ncomplex data patterns and nonlinear relationships, demonstrating wide-ranging\napplication potential. While challenges remain, KAN is poised to pave the way\nfor innovative solutions in various fields, potentially revolutionizing how we\napproach complex computational problems.\n","authors":["Tianrui Ji","Yuntian Hou","Di Zhang"],"pdf_url":"https://arxiv.org/pdf/2407.11075v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07331v1","updated":"2024-12-10T09:23:36Z","published":"2024-12-10T09:23:36Z","title":"NeSyA: Neurosymbolic Automata","summary":"  Neurosymbolic Artificial Intelligence (NeSy) has emerged as a promising\ndirection to integrate low level perception with high level reasoning.\nUnfortunately, little attention has been given to developing NeSy systems\ntailored to temporal/sequential problems. This entails reasoning symbolically\nover sequences of subsymbolic observations towards a target prediction. We show\nthat using a probabilistic semantics symbolic automata, which combine the power\nof automata for temporal structure specification with that of propositional\nlogic, can be used to reason efficiently and differentiably over subsymbolic\nsequences. The proposed system, which we call NeSyA (Neuro Symbolic Automata),\nis shown to either scale or perform better than existing NeSy approaches when\napplied to problems with a temporal component.\n","authors":["Nikolaos Manginas","George Paliouras","Luc De Raedt"],"pdf_url":"https://arxiv.org/pdf/2412.07331v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.08233v4","updated":"2024-12-10T09:19:24Z","published":"2022-08-17T11:25:03Z","title":"CSGO: Constrained-Softassign Gradient Optimization For Large Graph\n  Matching","summary":"  Graph matching aims to find correspondences between two graphs. This paper\nintegrates several well-known graph matching algorithms into a framework: the\nconstrained gradient method. The primary difference among these algorithms lies\nin tuning a step size parameter and constraining operators. By leveraging these\ninsights, we propose an adaptive step size parameter to guarantee the\nunderlying algorithms' convergence, simultaneously enhancing their efficiency\nand robustness. For the constraining operator, we introduce a scalable\nsoftassign for large graph matching problems. Compared to the original\nsoftassign, our approach offers increased speed, improved robustness, and\nreduced risk of overflow. The advanced constraining operator enables a CSGO for\nlarge graph matching, which outperforms state-of-the-art methods in\nexperiments. Notably, in attributed graph matching tasks, CSGO achieves an over\n10X increase in speed compared to current constrained gradient algorithms.\n","authors":["Binrui Shen","Qiang Niu","Shengxin Zhu"],"pdf_url":"https://arxiv.org/pdf/2208.08233v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07326v1","updated":"2024-12-10T09:17:09Z","published":"2024-12-10T09:17:09Z","title":"Addressing Key Challenges of Adversarial Attacks and Defenses in the\n  Tabular Domain: A Methodological Framework for Coherence and Consistency","summary":"  Machine learning models trained on tabular data are vulnerable to adversarial\nattacks, even in realistic scenarios where attackers have access only to the\nmodel's outputs. Researchers evaluate such attacks by considering metrics like\nsuccess rate, perturbation magnitude, and query count. However, unlike other\ndata domains, the tabular domain contains complex interdependencies among\nfeatures, presenting a unique aspect that should be evaluated: the need for the\nattack to generate coherent samples and ensure feature consistency for\nindistinguishability. Currently, there is no established methodology for\nevaluating adversarial samples based on these criteria. In this paper, we\naddress this gap by proposing new evaluation criteria tailored for tabular\nattacks' quality; we defined anomaly-based framework to assess the\ndistinguishability of adversarial samples and utilize the SHAP explainability\ntechnique to identify inconsistencies in the model's decision-making process\ncaused by adversarial samples. These criteria could form the basis for\npotential detection methods and be integrated into established evaluation\nmetrics for assessing attack's quality Additionally, we introduce a novel\ntechnique for perturbing dependent features while maintaining coherence and\nfeature consistency within the sample. We compare different attacks'\nstrategies, examining black-box query-based attacks and transferability-based\ngradient attacks across four target models. Our experiments, conducted on\nbenchmark tabular datasets, reveal significant differences between the examined\nattacks' strategies in terms of the attacker's risk and effort and the attacks'\nquality. The findings provide valuable insights on the strengths, limitations,\nand trade-offs of various adversarial attacks in the tabular domain, laying a\nfoundation for future research on attacks and defense development.\n","authors":["Yael Itzhakev","Amit Giloni","Yuval Elovici","Asaf Shabtai"],"pdf_url":"https://arxiv.org/pdf/2412.07326v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.00657v2","updated":"2024-12-10T09:16:53Z","published":"2024-05-01T17:37:50Z","title":"RST-LoRA: A Discourse-Aware Low-Rank Adaptation for Long Document\n  Abstractive Summarization","summary":"  For long document summarization, discourse structure is important to discern\nthe key content of the text and the differences in importance level between\nsentences. Unfortunately, the integration of rhetorical structure theory (RST)\ninto parameter-efficient fine-tuning strategies for long document summarization\nremains unexplored. Therefore, this paper introduces RST-LoRA and proposes four\nRST-aware variants to explicitly incorporate RST into the LoRA model. Our\nempirical evaluation demonstrates that incorporating the type and uncertainty\nof rhetorical relations can complementarily enhance the performance of LoRA in\nsummarization tasks. Furthermore, the best-performing variant we introduced\noutperforms the vanilla LoRA and full-parameter fine-tuning models, as\nconfirmed by multiple automatic and human evaluations, and even surpasses\nprevious state-of-the-art methods.\n","authors":["Dongqi Liu","Vera Demberg"],"pdf_url":"https://arxiv.org/pdf/2405.00657v2.pdf","comment":"NAACL 2024 Main & Long Conference Paper (Oral Presentation)"},{"id":"http://arxiv.org/abs/2411.18122v4","updated":"2024-12-10T09:13:39Z","published":"2024-11-27T08:02:31Z","title":"Using Machine Bias To Measure Human Bias","summary":"  Biased human decisions have consequential impacts across various domains,\nyielding unfair treatment of individuals and resulting in suboptimal outcomes\nfor organizations and society. In recognition of this fact, organizations\nregularly design and deploy interventions aimed at mitigating these biases.\nHowever, measuring human decision biases remains an important but elusive task.\nOrganizations are frequently concerned with mistaken decisions\ndisproportionately affecting one group. In practice, however, this is typically\nnot possible to assess due to the scarcity of a gold standard: a label that\nindicates what the correct decision would have been. In this work, we propose a\nmachine learning-based framework to assess bias in human-generated decisions\nwhen gold standard labels are scarce. We provide theoretical guarantees and\nempirical evidence demonstrating the superiority of our method over existing\nalternatives. This proposed methodology establishes a foundation for\ntransparency in human decision-making, carrying substantial implications for\nmanagerial duties, and offering potential for alleviating algorithmic biases\nwhen human decisions are used as labels to train algorithms.\n","authors":["Wanxue Dong","Maria De-Arteaga","Maytal Saar-Tsechansky"],"pdf_url":"https://arxiv.org/pdf/2411.18122v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17768v2","updated":"2024-12-10T09:12:46Z","published":"2024-03-26T14:54:48Z","title":"SciNews: From Scholarly Complexities to Public Narratives -- A Dataset\n  for Scientific News Report Generation","summary":"  Scientific news reports serve as a bridge, adeptly translating complex\nresearch articles into reports that resonate with the broader public. The\nautomated generation of such narratives enhances the accessibility of scholarly\ninsights. In this paper, we present a new corpus to facilitate this paradigm\ndevelopment. Our corpus comprises a parallel compilation of academic\npublications and their corresponding scientific news reports across nine\ndisciplines. To demonstrate the utility and reliability of our dataset, we\nconduct an extensive analysis, highlighting the divergences in readability and\nbrevity between scientific news narratives and academic manuscripts. We\nbenchmark our dataset employing state-of-the-art text generation models. The\nevaluation process involves both automatic and human evaluation, which lays the\ngroundwork for future explorations into the automated generation of scientific\nnews reports. The dataset and code related to this work are available at\nhttps://dongqi.me/projects/SciNews.\n","authors":["Dongqi Liu","Yifan Wang","Jia Loy","Vera Demberg"],"pdf_url":"https://arxiv.org/pdf/2403.17768v2.pdf","comment":"LREC-COLING 2024 Main Conference Paper"},{"id":"http://arxiv.org/abs/2412.07324v1","updated":"2024-12-10T09:12:02Z","published":"2024-12-10T09:12:02Z","title":"Label Distribution Learning using the Squared Neural Family on the\n  Probability Simplex","summary":"  Label distribution learning (LDL) provides a framework wherein a distribution\nover categories rather than a single category is predicted, with the aim of\naddressing ambiguity in labeled data. Existing research on LDL mainly focuses\non the task of point estimation, i.e., pinpointing an optimal distribution in\nthe probability simplex conditioned on the input sample. In this paper, we\nestimate a probability distribution of all possible label distributions over\nthe simplex, by unleashing the expressive power of the recently introduced\nSquared Neural Family (SNEFY). With the modeled distribution, label\ndistribution prediction can be achieved by performing the expectation operation\nto estimate the mean of the distribution of label distributions. Moreover, more\ninformation about the label distribution can be inferred, such as the\nprediction reliability and uncertainties. We conduct extensive experiments on\nthe label distribution prediction task, showing that our distribution modeling\nbased method can achieve very competitive label distribution prediction\nperformance compared with the state-of-the-art baselines. Additional\nexperiments on active learning and ensemble learning demonstrate that our\nprobabilistic approach can effectively boost the performance in these settings,\nby accurately estimating the prediction reliability and uncertainties.\n","authors":["Daokun Zhang","Russell Tsuchida","Dino Sejdinovic"],"pdf_url":"https://arxiv.org/pdf/2412.07324v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07322v1","updated":"2024-12-10T09:10:11Z","published":"2024-12-10T09:10:11Z","title":"ConceptSearch: Towards Efficient Program Search Using LLMs for\n  Abstraction and Reasoning Corpus (ARC)","summary":"  The Abstraction and Reasoning Corpus (ARC) poses a significant challenge to\nartificial intelligence, demanding broad generalization and few-shot learning\ncapabilities that remain elusive for current deep learning methods, including\nlarge language models (LLMs). While LLMs excel in program synthesis, their\ndirect application to ARC yields limited success. To address this, we introduce\nConceptSearch, a novel function-search algorithm that leverages LLMs for\nprogram generation and employs a concept-based scoring method to guide the\nsearch efficiently. Unlike simplistic pixel-based metrics like Hamming\ndistance, ConceptSearch evaluates programs on their ability to capture the\nunderlying transformation concept reflected in the input-output examples. We\nexplore three scoring functions: Hamming distance, a CNN-based scoring\nfunction, and an LLM-based natural language scoring function. Experimental\nresults demonstrate the effectiveness of ConceptSearch, achieving a significant\nperformance improvement over direct prompting with GPT-4. Moreover, our novel\nconcept-based scoring exhibits up to 30% greater efficiency compared to Hamming\ndistance, measured in terms of the number of iterations required to reach the\ncorrect solution. These findings highlight the potential of LLM-driven program\nsearch when integrated with concept-based guidance for tackling challenging\ngeneralization problems like ARC. Code:\nhttps://github.com/kksinghal/concept-search\n","authors":["Kartik Singhal","Gautam Shroff"],"pdf_url":"https://arxiv.org/pdf/2412.07322v1.pdf","comment":"8 pages, 7 figures, to appear at AAAI 2025"},{"id":"http://arxiv.org/abs/2306.07799v2","updated":"2024-12-10T09:06:22Z","published":"2023-06-13T14:21:35Z","title":"ChatGPT vs Human-authored Text: Insights into Controllable Text\n  Summarization and Sentence Style Transfer","summary":"  Large-scale language models, like ChatGPT, have garnered significant media\nattention and stunned the public with their remarkable capacity for generating\ncoherent text from short natural language prompts. In this paper, we aim to\nconduct a systematic inspection of ChatGPT's performance in two controllable\ngeneration tasks, with respect to ChatGPT's ability to adapt its output to\ndifferent target audiences (expert vs. layman) and writing styles (formal vs.\ninformal). Additionally, we evaluate the faithfulness of the generated text,\nand compare the model's performance with human-authored texts. Our findings\nindicate that the stylistic variations produced by humans are considerably\nlarger than those demonstrated by ChatGPT, and the generated texts diverge from\nhuman samples in several characteristics, such as the distribution of word\ntypes. Moreover, we observe that ChatGPT sometimes incorporates factual errors\nor hallucinations when adapting the text to suit a specific style.\n","authors":["Dongqi Liu","Vera Demberg"],"pdf_url":"https://arxiv.org/pdf/2306.07799v2.pdf","comment":"ACL-SRW 2023"},{"id":"http://arxiv.org/abs/2305.16784v2","updated":"2024-12-10T08:59:20Z","published":"2023-05-26T09:51:47Z","title":"Incorporating Distributions of Discourse Structure for Long Document\n  Abstractive Summarization","summary":"  For text summarization, the role of discourse structure is pivotal in\ndiscerning the core content of a text. Regrettably, prior studies on\nincorporating Rhetorical Structure Theory (RST) into transformer-based\nsummarization models only consider the nuclearity annotation, thereby\noverlooking the variety of discourse relation types. This paper introduces the\n'RSTformer', a novel summarization model that comprehensively incorporates both\nthe types and uncertainty of rhetorical relations. Our RST-attention mechanism,\nrooted in document-level rhetorical structure, is an extension of the recently\ndevised Longformer framework. Through rigorous evaluation, the model proposed\nherein exhibits significant superiority over state-of-the-art models, as\nevidenced by its notable performance on several automatic metrics and human\nevaluation.\n","authors":["Dongqi Liu","Yifan Wang","Vera Demberg"],"pdf_url":"https://arxiv.org/pdf/2305.16784v2.pdf","comment":"ACL 2023 (Main conference)"},{"id":"http://arxiv.org/abs/2403.09472v2","updated":"2024-12-10T08:54:09Z","published":"2024-03-14T15:12:38Z","title":"Easy-to-Hard Generalization: Scalable Alignment Beyond Human Supervision","summary":"  Current AI alignment methodologies rely on human-provided demonstrations or\njudgments, and the learned capabilities of AI systems would be upper-bounded by\nhuman capabilities as a result. This raises a challenging research question:\nHow can we keep improving the systems when their capabilities have surpassed\nthe levels of humans? This paper answers this question in the context of\ntackling hard reasoning tasks (e.g., level 4-5 MATH problems) via learning from\nhuman annotations on easier tasks (e.g., level 1-3 MATH problems), which we\nterm as easy-to-hard generalization. Our key insight is that an evaluator\n(reward model) trained on supervisions for easier tasks can be effectively used\nfor scoring candidate solutions of harder tasks and hence facilitating\neasy-to-hard generalization over different levels of tasks. Based on this\ninsight, we propose a novel approach to scalable alignment, which firstly\ntrains the (process-supervised) reward models on easy problems (e.g., level\n1-3), and then uses them to evaluate the performance of policy models on hard\nproblems. We show that such easy-to-hard generalization from evaluators can\nenable easy-to-hard generalizations in generators either through re-ranking or\nreinforcement learning (RL). Notably, our process-supervised 7b RL model and\n34b model (reranking@1024) achieves an accuracy of 34.0% and 52.5% on MATH500,\nrespectively, despite only using human supervision on easy problems. Our\napproach suggests a promising path toward AI systems that advance beyond the\nfrontier of human supervision.\n","authors":["Zhiqing Sun","Longhui Yu","Yikang Shen","Weiyang Liu","Yiming Yang","Sean Welleck","Chuang Gan"],"pdf_url":"https://arxiv.org/pdf/2403.09472v2.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2412.07312v1","updated":"2024-12-10T08:50:35Z","published":"2024-12-10T08:50:35Z","title":"High-dimensional classification problems with Barron regular boundaries\n  under margin conditions","summary":"  We prove that a classifier with a Barron-regular decision boundary can be\napproximated with a rate of high polynomial degree by ReLU neural networks with\nthree hidden layers when a margin condition is assumed. In particular, for\nstrong margin conditions, high-dimensional discontinuous classifiers can be\napproximated with a rate that is typically only achievable when approximating a\nlow-dimensional smooth function. We demonstrate how these expression rate\nbounds imply fast-rate learning bounds that are close to $n^{-1}$ where $n$ is\nthe number of samples. In addition, we carry out comprehensive numerical\nexperimentation on binary classification problems with various margins. We\nstudy three different dimensions, with the highest dimensional problem\ncorresponding to images from the MNIST data set.\n","authors":["Jonathan García","Philipp Petersen"],"pdf_url":"https://arxiv.org/pdf/2412.07312v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16823v2","updated":"2024-12-10T08:32:18Z","published":"2024-03-25T14:48:00Z","title":"Resource and Mobility Management in Hybrid LiFi and WiFi Networks: A\n  User-Centric Learning Approach","summary":"  Hybrid light fidelity (LiFi) and wireless fidelity (WiFi) networks (HLWNets)\nare an emerging indoor wireless communication paradigm, which combines the\nadvantages of the capacious optical spectra of LiFi and ubiquitous coverage of\nWiFi. Meanwhile, load balancing (LB) becomes a key challenge in resource\nmanagement for such hybrid networks. The existing LB methods are mostly\nnetwork-centric, relying on a central unit to make a solution for the users all\nat once. Consequently, the solution needs to be updated for all users at the\nsame pace, regardless of their moving status. This would affect the network\nperformance in two aspects: i) when the update frequency is low, it would\ncompromise the connectivity of fast-moving users; ii) when the update frequency\nis high, it would cause unnecessary handovers as well as hefty feedback costs\nfor slow-moving users. Motivated by this, we investigate user-centric LB which\nallows users to update their solutions at different paces. The research is\ndeveloped upon our previous work on adaptive target-condition neural network\n(ATCNN), which can conduct LB for individual users in quasi-static channels. In\nthis paper, a deep neural network (DNN) model is designed to enable an adaptive\nupdate interval for each individual user. This new model is termed as\nmobility-supporting neural network (MSNN). Associating MSNN with ATCNN, a\nuser-centric LB framework named mobility-supporting ATCNN (MS-ATCNN) is\nproposed to handle resource management and mobility management simultaneously.\nResults show that at the same level of average update interval, MS-ATCNN can\nachieve a network throughput up to 215\\% higher than conventional LB methods\nsuch as game theory, especially for a larger number of users. In addition,\nMS-ATCNN costs an ultra low runtime at the level of 100s $\\mu$s, which is two\nto three orders of magnitude lower than game theory.\n","authors":["Han Ji","Xiping Wu"],"pdf_url":"https://arxiv.org/pdf/2403.16823v2.pdf","comment":"13 pages, 13 figures, 4 tables, accepted by IEEE Transactions on\n  Wireless Communications"},{"id":"http://arxiv.org/abs/2412.00241v2","updated":"2024-12-10T08:27:38Z","published":"2024-11-29T20:15:18Z","title":"Multigraph Message Passing with Bi-Directional Multi-Edge Aggregations","summary":"  Graph Neural Networks (GNNs) have seen significant advances in recent years,\nyet their application to multigraphs, where parallel edges exist between the\nsame pair of nodes, remains under-explored. Standard GNNs, designed for simple\ngraphs, compute node representations by combining all connected edges at once,\nwithout distinguishing between edges from different neighbors. There are some\nGNN architectures proposed specifically for multigraphs, yet these\narchitectures perform only node-level aggregation in their message passing\nlayers, which limits their expressive power. Furthermore, these approaches\neither lack permutation equivariance when a strict total edge ordering is\nabsent, or fail to preserve the topological structure of the multigraph. To\naddress all these shortcomings, we propose MEGA-GNN, a unified framework for\nmessage passing on multigraphs that can effectively perform diverse graph\nlearning tasks. Our approach introduces a two-stage aggregation process in the\nmessage passing layers: first, parallel edges are aggregated, followed by a\nnode-level aggregation of messages from distinct neighbors. We show that\nMEGA-GNN is not only permutation equivariant but also universal given a strict\ntotal ordering on the edges. Experiments show that MEGA-GNN significantly\noutperforms state-of-the-art solutions by up to 13\\% on Anti-Money Laundering\ndatasets and is on par with their accuracy on real-world phishing\nclassification datasets in terms of minority class F1 score.\n","authors":["H. Çağrı Bilgi","Lydia Y. Chen","Kubilay Atasu"],"pdf_url":"https://arxiv.org/pdf/2412.00241v2.pdf","comment":"19 pages, 5 figures"},{"id":"http://arxiv.org/abs/2412.07282v1","updated":"2024-12-10T08:12:22Z","published":"2024-12-10T08:12:22Z","title":"HARP: Hesitation-Aware Reframing in Transformer Inference Pass","summary":"  This paper aims to improve the performance of large language models by\naddressing the variable computational demands in inference steps, where some\ntokens require more computational resources than others. We present HARP, a\nsimple modification to \"off-the-shelf\" Transformer forward pass. Drawing from\nhesitation and the framing effect in decision-making, HARP selectively applies\nadditional computation when the model encounters uncertainty during token\ngeneration. Our method mimics human cognitive processes by pausing at difficult\ndecision points and reframing inputs for a different perspective. Unlike other\napproaches, HARP is model-agnostic, training-free, and easy to implement. We\nthoroughly evaluate our method across various downstream tasks and model sizes,\ndemonstrating performance improvements up to +5.16%. Notably, HARP achieves\nthese gains while maintaining inference times twice faster than beam search.\nSimple and yet with significant gains, HARP offers a practical solution for\nenhancing the performance of Transformer-based language models with minimal\ncomputational impact.\n","authors":["Romain Storaï","Seung-won Hwang"],"pdf_url":"https://arxiv.org/pdf/2412.07282v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06559v2","updated":"2024-12-10T08:10:32Z","published":"2024-12-09T15:11:40Z","title":"ProcessBench: Identifying Process Errors in Mathematical Reasoning","summary":"  As language models regularly make mistakes when solving math problems,\nautomated identification of errors in the reasoning process becomes\nincreasingly significant for their scalable oversight. In this paper, we\nintroduce ProcessBench for measuring the ability to identify erroneous steps in\nmathematical reasoning. It consists of 3,400 test cases, primarily focused on\ncompetition- and Olympiad-level math problems. Each test case contains a\nstep-by-step solution with error location annotated by human experts. Models\nare required to identify the earliest step that contains an error, or conclude\nthat all steps are correct. We conduct extensive evaluation on ProcessBench,\ninvolving two types of models: process reward models (PRMs) and critic models,\nwhere for the latter we prompt general language models to critique each\nsolution step by step. We draw two main observations: (1) Existing PRMs\ntypically fail to generalize to more challenging math problems beyond GSM8K and\nMATH. They underperform both critic models (i.e., prompted general language\nmodels) and our own trained PRM that is straightforwardly fine-tuned on the\nPRM800K dataset. (2) The best open-source model, QwQ-32B-Preview, has\ndemonstrated the critique capability competitive with the proprietary model\nGPT-4o, despite that it still lags behind the reasoning-specialized o1-mini. We\nhope ProcessBench can foster future research in reasoning process assessment,\npaving the way toward scalable oversight of language models.\n","authors":["Chujie Zheng","Zhenru Zhang","Beichen Zhang","Runji Lin","Keming Lu","Bowen Yu","Dayiheng Liu","Jingren Zhou","Junyang Lin"],"pdf_url":"https://arxiv.org/pdf/2412.06559v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07273v1","updated":"2024-12-10T07:56:33Z","published":"2024-12-10T07:56:33Z","title":"Temporal-Aware Evaluation and Learning for Temporal Graph Neural\n  Networks","summary":"  Temporal Graph Neural Networks (TGNNs) are a family of graph neural networks\ndesigned to model and learn dynamic information from temporal graphs. Given\ntheir substantial empirical success, there is an escalating interest in TGNNs\nwithin the research community. However, the majority of these efforts have been\nchannelled towards algorithm and system design, with the evaluation metrics\nreceiving comparatively less attention. Effective evaluation metrics are\ncrucial for providing detailed performance insights, particularly in the\ntemporal domain. This paper investigates the commonly used evaluation metrics\nfor TGNNs and illustrates the failure mechanisms of these metrics in capturing\nessential temporal structures in the predictive behaviour of TGNNs. We provide\na mathematical formulation of existing performance metrics and utilize an\ninstance-based study to underscore their inadequacies in identifying volatility\nclustering (the occurrence of emerging errors within a brief interval). This\nphenomenon has profound implications for both algorithm and system design in\nthe temporal domain. To address this deficiency, we introduce a new\nvolatility-aware evaluation metric (termed volatility cluster statistics),\ndesigned for a more refined analysis of model temporal performance.\nAdditionally, we demonstrate how this metric can serve as a\ntemporal-volatility-aware training objective to alleviate the clustering of\ntemporal errors. Through comprehensive experiments on various TGNN models, we\nvalidate our analysis and the proposed approach. The empirical results offer\nrevealing insights: 1) existing TGNNs are prone to making errors with\nvolatility clustering, and 2) TGNNs with different mechanisms to capture\ntemporal information exhibit distinct volatility clustering patterns. Our\nempirical findings demonstrate that our proposed training objective effectively\nreduces volatility clusters in error.\n","authors":["Junwei Su","Shan Wu"],"pdf_url":"https://arxiv.org/pdf/2412.07273v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07268v1","updated":"2024-12-10T07:49:07Z","published":"2024-12-10T07:49:07Z","title":"PTSBench: A Comprehensive Post-Training Sparsity Benchmark Towards\n  Algorithms and Models","summary":"  With the increased attention to model efficiency, post-training sparsity\n(PTS) has become more and more prevalent because of its effectiveness and\nefficiency. However, there remain questions on better practice of PTS\nalgorithms and the sparsification ability of models, which hinders the further\ndevelopment of this area. Therefore, a benchmark to comprehensively investigate\nthe issues above is urgently needed. In this paper, we propose the first\ncomprehensive post-training sparsity benchmark called PTSBench towards\nalgorithms and models. We benchmark 10+ PTS general-pluggable fine-grained\ntechniques on 3 typical tasks using over 40 off-the-shelf model architectures.\nThrough extensive experiments and analyses, we obtain valuable conclusions and\nprovide several insights from both algorithms and model aspects. Our PTSBench\ncan provide (1) new observations for a better understanding of the PTS\nalgorithms, (2) in-depth and comprehensive evaluations for the sparsification\nability of models, and (3) a well-structured and easy-integrate open-source\nframework. We hope this work will provide illuminating conclusions and advice\nfor future studies of post-training sparsity methods and\nsparsification-friendly model design. The code for our PTSBench is released at\n\\href{https://github.com/ModelTC/msbench}{https://github.com/ModelTC/msbench}.\n","authors":["Zining Wnag","Jinyang Guo","Ruihao Gong","Yang Yong","Aishan Liu","Yushi Huang","Jiaheng Liu","Xianglong Liu"],"pdf_url":"https://arxiv.org/pdf/2412.07268v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07265v1","updated":"2024-12-10T07:45:56Z","published":"2024-12-10T07:45:56Z","title":"Modeling High-Resolution Spatio-Temporal Wind with Deep Echo State\n  Networks and Stochastic Partial Differential Equations","summary":"  In the past decades, clean and renewable energy has gained increasing\nattention due to a global effort on carbon footprint reduction. In particular,\nSaudi Arabia is gradually shifting its energy portfolio from an exclusive use\nof oil to a reliance on renewable energy, and, in particular, wind. Modeling\nwind for assessing potential energy output in a country as large,\ngeographically diverse and understudied as Saudi Arabia is a challenge which\nimplies highly non-linear dynamic structures in both space and time. To address\nthis, we propose a spatio-temporal model whose spatial information is first\nreduced via an energy distance-based approach and then its dynamical behavior\nis informed by a sparse and stochastic recurrent neural network (Echo State\nNetwork). Finally, the full spatial data is reconstructed by means of a\nnon-stationary stochastic partial differential equation-based approach. Our\nmodel can capture the fine scale wind structure and produce more accurate\nforecasts of both wind speed and energy in lead times of interest for energy\ngrid management and save annually as much as one million dollar against the\nclosest competitive model.\n","authors":["Kesen Wang","Minwoo Kim","Stefano Castruccio","Marc G. Genton"],"pdf_url":"https://arxiv.org/pdf/2412.07265v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07261v1","updated":"2024-12-10T07:42:46Z","published":"2024-12-10T07:42:46Z","title":"MemHunter: Automated and Verifiable Memorization Detection at\n  Dataset-scale in LLMs","summary":"  Large language models (LLMs) have been shown to memorize and reproduce\ncontent from their training data, raising significant privacy concerns,\nespecially with web-scale datasets. Existing methods for detecting memorization\nare largely sample-specific, relying on manually crafted or discretely\noptimized memory-inducing prompts generated on a per-sample basis, which become\nimpractical for dataset-level detection due to the prohibitive computational\ncost of iterating over all samples. In real-world scenarios, data owners may\nneed to verify whether a susceptible LLM has memorized their dataset,\nparticularly if the LLM may have collected the data from the web without\nauthorization. To address this, we introduce \\textit{MemHunter}, which trains a\nmemory-inducing LLM and employs hypothesis testing to efficiently detect\nmemorization at the dataset level, without requiring sample-specific memory\ninducing. Experiments on models such as Pythia and Llama-2 demonstrate that\n\\textit{MemHunter} can extract up to 40\\% more training data than existing\nmethods under constrained time resources and reduce search time by up to 80\\%\nwhen integrated as a plug-in. Crucially, \\textit{MemHunter} is the first method\ncapable of dataset-level memorization detection, providing an indispensable\ntool for assessing privacy risks in LLMs that are powered by vast web-sourced\ndatasets.\n","authors":["Zhenpeng Wu","Jian Lou","Zibin Zheng","Chuan Chen"],"pdf_url":"https://arxiv.org/pdf/2412.07261v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06016v2","updated":"2024-12-10T07:24:02Z","published":"2024-12-08T18:21:00Z","title":"Track4Gen: Teaching Video Diffusion Models to Track Points Improves\n  Video Generation","summary":"  While recent foundational video generators produce visually rich output, they\nstill struggle with appearance drift, where objects gradually degrade or change\ninconsistently across frames, breaking visual coherence. We hypothesize that\nthis is because there is no explicit supervision in terms of spatial tracking\nat the feature level. We propose Track4Gen, a spatially aware video generator\nthat combines video diffusion loss with point tracking across frames, providing\nenhanced spatial supervision on the diffusion features. Track4Gen merges the\nvideo generation and point tracking tasks into a single network by making\nminimal changes to existing video generation architectures. Using Stable Video\nDiffusion as a backbone, Track4Gen demonstrates that it is possible to unify\nvideo generation and point tracking, which are typically handled as separate\ntasks. Our extensive evaluations show that Track4Gen effectively reduces\nappearance drift, resulting in temporally stable and visually coherent video\ngeneration. Project page: hyeonho99.github.io/track4gen\n","authors":["Hyeonho Jeong","Chun-Hao Paul Huang","Jong Chul Ye","Niloy Mitra","Duygu Ceylan"],"pdf_url":"https://arxiv.org/pdf/2412.06016v2.pdf","comment":"Project page: hyeonho99.github.io/track4gen"},{"id":"http://arxiv.org/abs/2412.07249v1","updated":"2024-12-10T07:18:51Z","published":"2024-12-10T07:18:51Z","title":"Buster: Incorporating Backdoor Attacks into Text Encoder to Mitigate\n  NSFW Content Generation","summary":"  In the digital age, the proliferation of deep learning models has led to\nsignificant concerns about the generation of Not Safe for Work (NSFW) content.\nExisting defense methods primarily involve model fine-tuning and post-hoc\ncontent moderation. However, these approaches often lack scalability in\neliminating harmful content, degrade the quality of benign image generation, or\nincur high inference costs. To tackle these challenges, we propose an\ninnovative framework called \\textbf{Buster}, which injects backdoor attacks\ninto the text encoder to prevent NSFW content generation. Specifically, Buster\nleverages deep semantic information rather than explicit prompts as triggers,\nredirecting NSFW prompts towards targeted benign prompts. This approach\ndemonstrates exceptional resilience and scalability in mitigating NSFW content.\nRemarkably, Buster fine-tunes the text encoder of Text-to-Image models within\njust five minutes, showcasing high efficiency. Our extensive experiments reveal\nthat Buster outperforms all other baselines, achieving superior NSFW content\nremoval rate while preserving the quality of harmless images.\n","authors":["Xin Zhao","Xiaojun Chen","Yuexin Xuan","Zhendong Zhao"],"pdf_url":"https://arxiv.org/pdf/2412.07249v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.11474v2","updated":"2024-12-10T07:14:56Z","published":"2024-11-18T11:16:13Z","title":"Graph Neural Networks for Quantifying Compatibility Mechanisms in\n  Traditional Chinese Medicine","summary":"  Traditional Chinese Medicine (TCM) involves complex compatibility mechanisms\ncharacterized by multi-component and multi-target interactions, which are\nchallenging to quantify. To address this challenge, we applied graph artificial\nintelligence to develop a TCM multi-dimensional knowledge graph that bridges\ntraditional TCM theory and modern biomedical science\n(https://zenodo.org/records/13763953 ). Using feature engineering and\nembedding, we processed key TCM terminology and Chinese herbal pieces (CHP),\nintroducing medicinal properties as virtual nodes and employing graph neural\nnetworks with attention mechanisms to model and analyze 6,080 Chinese herbal\nformulas (CHF). Our method quantitatively assessed the roles of CHP within CHF\nand was validated using 215 CHF designed for COVID-19 management. With\ninterpretable models, open-source data, and code\n(https://github.com/ZENGJingqi/GraphAI-for-TCM ), this study provides robust\ntools for advancing TCM theory and drug discovery.\n","authors":["Jingqi Zeng","Xiaobin Jia"],"pdf_url":"https://arxiv.org/pdf/2411.11474v2.pdf","comment":"10 pages, 5 figures. Includes open-source dataset and code for\n  reproducibility"},{"id":"http://arxiv.org/abs/2409.19214v4","updated":"2024-12-10T07:12:06Z","published":"2024-09-28T02:45:14Z","title":"Group & Reweight: A Novel Cost-Sensitive Approach to Mitigating Class\n  Imbalance in Network Traffic Classification","summary":"  Internet services have led to the eruption of network traffic, and machine\nlearning on these Internet data has become an indispensable tool, especially\nwhen the application is risk-sensitive. This paper focuses on network traffic\nclassification in the presence of severe class imbalance. Such a distributional\ntrait mostly drifts the optimal decision boundary and results in an\nunsatisfactory solution. This raises safety concerns in the network traffic\nfield when previous class imbalance methods hardly deal with numerous minority\nmalicious classes. To alleviate these effects, we design a \\textit{group \\&\nreweight} strategy for alleviating class imbalance. Inspired by the group\ndistributionally optimization framework, our approach heuristically clusters\nclasses into groups, iteratively updates the non-parametric weights for\nseparate classes, and optimizes the learning model by minimizing reweighted\nlosses. We theoretically interpret the optimization process from a Stackelberg\ngame and perform extensive experiments on typical benchmarks. Results show that\nour approach can not only suppress the negative effect of class imbalance but\nalso improve the comprehensive performance in prediction.\n","authors":["Wumei Du","Dong Liang","Yiqin Lv","Xingxing Liang","Guanlin Wu","Qi Wang","Zheng Xie"],"pdf_url":"https://arxiv.org/pdf/2409.19214v4.pdf","comment":"21 pages, 10 figures"},{"id":"http://arxiv.org/abs/2412.07244v1","updated":"2024-12-10T07:10:00Z","published":"2024-12-10T07:10:00Z","title":"Developing a Dataset-Adaptive, Normalized Metric for Machine Learning\n  Model Assessment: Integrating Size, Complexity, and Class Imbalance","summary":"  Traditional metrics like accuracy, F1-score, and precision are frequently\nused to evaluate machine learning models, however they may not be sufficient\nfor evaluating performance on tiny, unbalanced, or high-dimensional datasets. A\ndataset-adaptive, normalized metric that incorporates dataset characteristics\nlike size, feature dimensionality, class imbalance, and signal-to-noise ratio\nis presented in this study. Early insights into the model's performance\npotential in challenging circumstances are provided by the suggested metric,\nwhich offers a scalable and adaptable evaluation framework. The metric's\ncapacity to accurately forecast model scalability and performance is\ndemonstrated via experimental validation spanning classification, regression,\nand clustering tasks, guaranteeing solid assessments in settings with limited\ndata. This method has important ramifications for effective resource allocation\nand model optimization in machine learning workflows.\n","authors":["Serzhan Ossenov"],"pdf_url":"https://arxiv.org/pdf/2412.07244v1.pdf","comment":"36 pages, 17 figures. Includes results validated on datasets from UCI\n  Machine Learning Repository"},{"id":"http://arxiv.org/abs/2412.07243v1","updated":"2024-12-10T07:07:06Z","published":"2024-12-10T07:07:06Z","title":"A Dynamical Systems-Inspired Pruning Strategy for Addressing\n  Oversmoothing in Graph Neural Networks","summary":"  Oversmoothing in Graph Neural Networks (GNNs) poses a significant challenge\nas network depth increases, leading to homogenized node representations and a\nloss of expressiveness. In this work, we approach the oversmoothing problem\nfrom a dynamical systems perspective, providing a deeper understanding of the\nstability and convergence behavior of GNNs. Leveraging insights from dynamical\nsystems theory, we identify the root causes of oversmoothing and propose\n\\textbf{\\textit{DYNAMO-GAT}}. This approach utilizes noise-driven covariance\nanalysis and Anti-Hebbian principles to selectively prune redundant attention\nweights, dynamically adjusting the network's behavior to maintain node feature\ndiversity and stability. Our theoretical analysis reveals how DYNAMO-GAT\ndisrupts the convergence to oversmoothed states, while experimental results on\nbenchmark datasets demonstrate its superior performance and efficiency compared\nto traditional and state-of-the-art methods. DYNAMO-GAT not only advances the\ntheoretical understanding of oversmoothing through the lens of dynamical\nsystems but also provides a practical and effective solution for improving the\nstability and expressiveness of deep GNNs.\n","authors":["Biswadeep Chakraborty","Harshit Kumar","Saibal Mukhopadhyay"],"pdf_url":"https://arxiv.org/pdf/2412.07243v1.pdf","comment":"26 pages"},{"id":"http://arxiv.org/abs/2412.07242v1","updated":"2024-12-10T07:07:04Z","published":"2024-12-10T07:07:04Z","title":"Optimization Can Learn Johnson Lindenstrauss Embeddings","summary":"  Embeddings play a pivotal role across various disciplines, offering compact\nrepresentations of complex data structures. Randomized methods like\nJohnson-Lindenstrauss (JL) provide state-of-the-art and essentially\nunimprovable theoretical guarantees for achieving such representations. These\nguarantees are worst-case and in particular, neither the analysis, nor the\nalgorithm, takes into account any potential structural information of the data.\nThe natural question is: must we randomize? Could we instead use an\noptimization-based approach, working directly with the data? A first answer is\nno: as we show, the distance-preserving objective of JL has a non-convex\nlandscape over the space of projection matrices, with many bad stationary\npoints. But this is not the final answer.\n  We present a novel method motivated by diffusion models, that circumvents\nthis fundamental challenge: rather than performing optimization directly over\nthe space of projection matrices, we use optimization over the larger space of\nrandom solution samplers, gradually reducing the variance of the sampler. We\nshow that by moving through this larger space, our objective converges to a\ndeterministic (zero variance) solution, avoiding bad stationary points.\n  This method can also be seen as an optimization-based derandomization\napproach and is an idea and method that we believe can be applied to many other\nproblems.\n","authors":["Nikos Tsikouras","Constantine Caramanis","Christos Tzamos"],"pdf_url":"https://arxiv.org/pdf/2412.07242v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07241v1","updated":"2024-12-10T07:06:52Z","published":"2024-12-10T07:06:52Z","title":"Human-Computer Interaction and Human-AI Collaboration in Advanced Air\n  Mobility: A Comprehensive Review","summary":"  The increasing rates of global urbanization and vehicle usage are leading to\na shift of mobility to the third dimension-through Advanced Air Mobility\n(AAM)-offering a promising solution for faster, safer, cleaner, and more\nefficient transportation. As air transportation continues to evolve with more\nautomated and autonomous systems, advancements in AAM require a deep\nunderstanding of human-computer interaction and human-AI collaboration to\nensure safe and effective operations in complex urban and regional\nenvironments. There has been a significant increase in publications regarding\nthese emerging applications; thus, there is a need to review developments in\nthis area. This paper comprehensively reviews the current state of research on\nhuman-computer interaction and human-AI collaboration in AAM. Specifically, we\nfocus on AAM applications related to the design of human-machine interfaces for\nvarious uses, including pilot training, air traffic management, and the\nintegration of AI-assisted decision-making systems with immersive technologies\nsuch as extended, virtual, mixed, and augmented reality devices. Additionally,\nwe provide a comprehensive analysis of the challenges AAM encounters in\nintegrating human-computer frameworks, including unique challenges associated\nwith these interactions, such as trust in AI systems and safety concerns.\nFinally, we highlight emerging opportunities and propose future research\ndirections to bridge the gap between human factors and technological\nadvancements in AAM.\n","authors":["Fatma Yamac Sagirli","Xiaopeng Zhao","Zhenbo Wang"],"pdf_url":"https://arxiv.org/pdf/2412.07241v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07236v1","updated":"2024-12-10T06:56:36Z","published":"2024-12-10T06:56:36Z","title":"CBraMod: A Criss-Cross Brain Foundation Model for EEG Decoding","summary":"  Electroencephalography (EEG) is a non-invasive technique to measure and\nrecord brain electrical activity, widely used in various BCI and healthcare\napplications. Early EEG decoding methods rely on supervised learning, limited\nby specific tasks and datasets, hindering model performance and\ngeneralizability. With the success of large language models, there is a growing\nbody of studies focusing on EEG foundation models. However, these studies still\nleave challenges: Firstly, most of existing EEG foundation models employ full\nEEG modeling strategy. It models the spatial and temporal dependencies between\nall EEG patches together, but ignores that the spatial and temporal\ndependencies are heterogeneous due to the unique structural characteristics of\nEEG signals. Secondly, existing EEG foundation models have limited\ngeneralizability on a wide range of downstream BCI tasks due to varying formats\nof EEG data, making it challenging to adapt to. To address these challenges, we\npropose a novel foundation model called CBraMod. Specifically, we devise a\ncriss-cross transformer as the backbone to thoroughly leverage the structural\ncharacteristics of EEG signals, which can model spatial and temporal\ndependencies separately through two parallel attention mechanisms. And we\nutilize an asymmetric conditional positional encoding scheme which can encode\npositional information of EEG patches and be easily adapted to the EEG with\ndiverse formats. CBraMod is pre-trained on a very large corpus of EEG through\npatch-based masked EEG reconstruction. We evaluate CBraMod on up to 10\ndownstream BCI tasks (12 public datasets). CBraMod achieves the\nstate-of-the-art performance across the wide range of tasks, proving its strong\ncapability and generalizability. The source code is publicly available at\n\\url{https://github.com/wjq-learning/CBraMod}.\n","authors":["Jiquan Wang","Sha Zhao","Zhiling Luo","Yangxuan Zhou","Haiteng Jiang","Shijian Li","Tao Li","Gang Pan"],"pdf_url":"https://arxiv.org/pdf/2412.07236v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07231v1","updated":"2024-12-10T06:42:46Z","published":"2024-12-10T06:42:46Z","title":"Adversarial Filtering Based Evasion and Backdoor Attacks to EEG-Based\n  Brain-Computer Interfaces","summary":"  A brain-computer interface (BCI) enables direct communication between the\nbrain and an external device. Electroencephalogram (EEG) is a common input\nsignal for BCIs, due to its convenience and low cost. Most research on\nEEG-based BCIs focuses on the accurate decoding of EEG signals, while ignoring\ntheir security. Recent studies have shown that machine learning models in BCIs\nare vulnerable to adversarial attacks. This paper proposes adversarial\nfiltering based evasion and backdoor attacks to EEG-based BCIs, which are very\neasy to implement. Experiments on three datasets from different BCI paradigms\ndemonstrated the effectiveness of our proposed attack approaches. To our\nknowledge, this is the first study on adversarial filtering for EEG-based BCIs,\nraising a new security concern and calling for more attention on the security\nof BCIs.\n","authors":["Lubin Meng","Xue Jiang","Xiaoqing Chen","Wenzhong Liu","Hanbin Luo","Dongrui Wu"],"pdf_url":"https://arxiv.org/pdf/2412.07231v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07229v1","updated":"2024-12-10T06:41:18Z","published":"2024-12-10T06:41:18Z","title":"Moderating the Generalization of Score-based Generative Model","summary":"  Score-based Generative Models (SGMs) have demonstrated remarkable\ngeneralization abilities, e.g. generating unseen, but natural data. However,\nthe greater the generalization power, the more likely the unintended\ngeneralization, and the more dangerous the abuse. Research on moderated\ngeneralization in SGMs remains limited. To fill this gap, we first examine the\ncurrent 'gold standard' in Machine Unlearning (MU), i.e., re-training the model\nafter removing the undesirable training data, and find it does not work in\nSGMs. Further analysis of score functions reveals that the MU 'gold standard'\ndoes not alter the original score function, which explains its ineffectiveness.\nBased on this insight, we propose the first Moderated Score-based Generative\nModel (MSGM), which introduces a novel score adjustment strategy that redirects\nthe score function away from undesirable data during the continuous-time\nstochastic differential equation process. Extensive experimental results\ndemonstrate that MSGM significantly reduces the likelihood of generating\nundesirable content while preserving high visual quality for normal image\ngeneration. Albeit designed for SGMs, MSGM is a general and flexible MU\nframework that is compatible with diverse diffusion architectures (SGM and\nDDPM) and training strategies (re-training and fine-tuning), and enables\nzero-shot transfer of the pre-trained models to downstream tasks, e.g. image\ninpainting and reconstruction. The code will be shared upon acceptance.\n","authors":["Wan Jiang","He Wang","Xin Zhang","Dan Guo","Zhaoxin Fan","Yunfeng Diao","Richang Hong"],"pdf_url":"https://arxiv.org/pdf/2412.07229v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07228v1","updated":"2024-12-10T06:32:17Z","published":"2024-12-10T06:32:17Z","title":"T-TIME: Test-Time Information Maximization Ensemble for Plug-and-Play\n  BCIs","summary":"  Objective: An electroencephalogram (EEG)-based brain-computer interface (BCI)\nenables direct communication between the human brain and a computer. Due to\nindividual differences and non-stationarity of EEG signals, such BCIs usually\nrequire a subject-specific calibration session before each use, which is\ntime-consuming and user-unfriendly. Transfer learning (TL) has been proposed to\nshorten or eliminate this calibration, but existing TL approaches mainly\nconsider offline settings, where all unlabeled EEG trials from the new user are\navailable. Methods: This paper proposes Test-Time Information Maximization\nEnsemble (T-TIME) to accommodate the most challenging online TL scenario, where\nunlabeled EEG data from the new user arrive in a stream, and immediate\nclassification is performed. T-TIME initializes multiple classifiers from the\naligned source data. When an unlabeled test EEG trial arrives, T-TIME first\npredicts its labels using ensemble learning, and then updates each classifier\nby conditional entropy minimization and adaptive marginal distribution\nregularization. Our code is publicized. Results: Extensive experiments on three\npublic motor imagery based BCI datasets demonstrated that T-TIME outperformed\nabout 20 classical and state-of-the-art TL approaches. Significance: To our\nknowledge, this is the first work on test time adaptation for calibration-free\nEEG-based BCIs, making plug-and-play BCIs possible.\n","authors":["Siyang Li","Ziwei Wang","Hanbin Luo","Lieyun Ding","Dongrui Wu"],"pdf_url":"https://arxiv.org/pdf/2412.07228v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.06957v2","updated":"2024-12-10T06:21:47Z","published":"2024-09-11T02:40:38Z","title":"Policy Filtration in RLHF to Fine-Tune LLM for Code Generation","summary":"  Reinforcement learning from human feedback (RLHF) is one of the key\ntechniques that helps large language models (LLMs) to follow instructions and\nprovide helpful and harmless responses. While direct policy optimization\nmethods exist, state-of-the-art LLMs adopt RL-based methods (usually PPO) in\nRLHF to train the policy to generate good responses guided by a reward model\nlearned from preference data. The main challenge of these methods is the\ninaccuracy of the intermediate reward model, especially in code generation\ntasks that require long and complex reasoning to score a response. We find that\nthe reliability of the reward model varies across responses assigned with\ndifferent rewards. This motivates us to filter the samples whose rewards may be\nunreliable to improve signal-to-noise ratio during policy learning, resulting\nin Policy Filtration for Proximal Policy Optimization (PF-PPO). To choose a\nproper policy filtration strategy for a given reward model, the coefficient of\ndetermination ($R^2$) between rewards and actual scores on filtered samples\nserves as a good metrics and helps us find several promising strategies. We\nprovide extensive experiments to validate the effectiveness of PF-PPO in code\ngeneration tasks, and find that some variants of PF-PPO are highly effective\nand achieve new state-of-the-art performance across 7-billion-parameter models\non HumanEval, MBPP, and a new and more challenging LeetCode Contest benchmark.\n","authors":["Wei Shen","Chuheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2409.06957v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07224v1","updated":"2024-12-10T06:19:21Z","published":"2024-12-10T06:19:21Z","title":"Parseval Regularization for Continual Reinforcement Learning","summary":"  Loss of plasticity, trainability loss, and primacy bias have been identified\nas issues arising when training deep neural networks on sequences of tasks --\nall referring to the increased difficulty in training on new tasks. We propose\nto use Parseval regularization, which maintains orthogonality of weight\nmatrices, to preserve useful optimization properties and improve training in a\ncontinual reinforcement learning setting. We show that it provides significant\nbenefits to RL agents on a suite of gridworld, CARL and MetaWorld tasks. We\nconduct comprehensive ablations to identify the source of its benefits and\ninvestigate the effect of certain metrics associated to network trainability\nincluding weight matrix rank, weight norms and policy entropy.\n","authors":["Wesley Chung","Lynn Cherif","David Meger","Doina Precup"],"pdf_url":"https://arxiv.org/pdf/2412.07224v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07223v1","updated":"2024-12-10T06:19:08Z","published":"2024-12-10T06:19:08Z","title":"A Consolidated Volatility Prediction with Back Propagation Neural\n  Network and Genetic Algorithm","summary":"  This paper provides a unique approach with AI algorithms to predict emerging\nstock markets volatility. Traditionally, stock volatility is derived from\nhistorical volatility,Monte Carlo simulation and implied volatility as well. In\nthis paper, the writer designs a consolidated model with back-propagation\nneural network and genetic algorithm to predict future volatility of emerging\nstock markets and found that the results are quite accurate with low errors.\n","authors":["Zong Ke","Jingyu Xu","Zizhou Zhang","Yu Cheng","Wenjun Wu"],"pdf_url":"https://arxiv.org/pdf/2412.07223v1.pdf","comment":"6 pages, 7 figures, 1 table, The paper will be published by IEEE on\n  conference: 2024 3rd International Conference on Image Processing, Computer\n  Vision and Machine Learning (ICICML 2024)"},{"id":"http://arxiv.org/abs/2412.07219v1","updated":"2024-12-10T06:17:07Z","published":"2024-12-10T06:17:07Z","title":"Taylor Outlier Exposure","summary":"  Out-of-distribution (OOD) detection is the task of identifying data sampled\nfrom distributions that were not used during training. This task is essential\nfor reliable machine learning and a better understanding of their\ngeneralization capabilities. Among OOD detection methods, Outlier Exposure (OE)\nsignificantly enhances OOD detection performance and generalization ability by\nexposing auxiliary OOD data to the model. However, constructing clean auxiliary\nOOD datasets, uncontaminated by in-distribution (ID) samples, is essential for\nOE; generally, a noisy OOD dataset contaminated with ID samples negatively\nimpacts OE training dynamics and final detection performance. Furthermore, as\ndataset scale increases, constructing clean OOD data becomes increasingly\nchallenging and costly. To address these challenges, we propose Taylor Outlier\nExposure (TaylorOE), an OE-based approach with regularization that allows\ntraining on noisy OOD datasets contaminated with ID samples. Specifically, we\nrepresent the OE regularization term as a polynomial function via a Taylor\nexpansion, allowing us to control the regularization strength for ID data in\nthe auxiliary OOD dataset by adjusting the order of Taylor expansion. In our\nexperiments on the OOD detection task with clean and noisy OOD datasets, we\ndemonstrate that the proposed method consistently outperforms conventional\nmethods and analyze our regularization term to show its effectiveness. Our\nimplementation code of TaylorOE is available at\n\\url{https://github.com/fukuchan41/TaylorOE}.\n","authors":["Kohei Fukuda","Hiroaki Aizawa"],"pdf_url":"https://arxiv.org/pdf/2412.07219v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07217v1","updated":"2024-12-10T06:15:14Z","published":"2024-12-10T06:15:14Z","title":"Incremental Gaussian Mixture Clustering for Data Streams","summary":"  The problem of analyzing data streams of very large volumes is important and\nis very desirable for many application domains. In this paper we present and\ndemonstrate effective working of an algorithm to find clusters and anomalous\ndata points in a streaming datasets. Entropy minimization is used as a\ncriterion for defining and updating clusters formed from a streaming dataset.\nAs the clusters are formed we also identify anomalous datapoints that show up\nfar away from all known clusters. With a number of 2-D datasets we demonstrate\nthe effectiveness of discovering the clusters and also identifying anomalous\ndata points.\n","authors":["Aniket Bhanderi","Raj Bhatnagar"],"pdf_url":"https://arxiv.org/pdf/2412.07217v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.01649v3","updated":"2024-12-10T06:15:04Z","published":"2023-07-04T11:08:03Z","title":"Nonparametric Classification on Low Dimensional Manifolds using\n  Overparameterized Convolutional Residual Networks","summary":"  Convolutional residual neural networks (ConvResNets), though\noverparameterized, can achieve remarkable prediction performance in practice,\nwhich cannot be well explained by conventional wisdom. To bridge this gap, we\nstudy the performance of ConvResNeXts, which cover ConvResNets as a special\ncase, trained with weight decay from the perspective of nonparametric\nclassification. Our analysis allows for infinitely many building blocks in\nConvResNeXts, and shows that weight decay implicitly enforces sparsity on these\nblocks. Specifically, we consider a smooth target function supported on a\nlow-dimensional manifold, then prove that ConvResNeXts can adapt to the\nfunction smoothness and low-dimensional structures and efficiently learn the\nfunction without suffering from the curse of dimensionality. Our findings\npartially justify the advantage of overparameterized ConvResNeXts over\nconventional machine learning models.\n","authors":["Zixuan Zhang","Kaiqi Zhang","Minshuo Chen","Yuma Takeda","Mengdi Wang","Tuo Zhao","Yu-Xiang Wang"],"pdf_url":"https://arxiv.org/pdf/2307.01649v3.pdf","comment":"20 pages, 1 figure"},{"id":"http://arxiv.org/abs/2412.07216v1","updated":"2024-12-10T06:14:31Z","published":"2024-12-10T06:14:31Z","title":"Learnable Sparse Customization in Heterogeneous Edge Computing","summary":"  To effectively manage and utilize massive distributed data at the network\nedge, Federated Learning (FL) has emerged as a promising edge computing\nparadigm across data silos. However, FL still faces two challenges: system\nheterogeneity (i.e., the diversity of hardware resources across edge devices)\nand statistical heterogeneity (i.e., non-IID data). Although sparsification can\nextract diverse submodels for diverse clients, most sparse FL works either\nsimply assign submodels with artificially-given rigid rules or prune partial\nparameters using heuristic strategies, resulting in inflexible sparsification\nand poor performance. In this work, we propose Learnable Personalized\nSparsification for heterogeneous Federated learning (FedLPS), which achieves\nthe learnable customization of heterogeneous sparse models with\nimportance-associated patterns and adaptive ratios to simultaneously tackle\nsystem and statistical heterogeneity. Specifically, FedLPS learns the\nimportance of model units on local data representation and further derives an\nimportance-based sparse pattern with minimal heuristics to accurately extract\npersonalized data features in non-IID settings. Furthermore, Prompt Upper\nConfidence Bound Variance (P-UCBV) is designed to adaptively determine sparse\nratios by learning the superimposed effect of diverse device capabilities and\nnon-IID data, aiming at resource self-adaptation with promising accuracy.\nExtensive experiments show that FedLPS outperforms status quo approaches in\naccuracy and training costs, which improves accuracy by 1.28%-59.34% while\nreducing running time by more than 68.80%.\n","authors":["Jingjing Xue","Sheng Sun","Min Liu","Yuwei Wang","Zhuotao Liu","Jingyuan Wang"],"pdf_url":"https://arxiv.org/pdf/2412.07216v1.pdf","comment":"Accepted by ICDE 2025"},{"id":"http://arxiv.org/abs/2407.13010v3","updated":"2024-12-10T05:59:06Z","published":"2024-07-17T21:03:21Z","title":"A Resolution Independent Neural Operator","summary":"  The Deep Operator Network (DeepONet) is a powerful neural operator\narchitecture that uses two neural networks to map between infinite-dimensional\nfunction spaces. This architecture allows for the evaluation of the solution\nfield at any location within the domain but requires input functions to be\ndiscretized at identical locations, limiting practical applications. We\nintroduce a general framework for operator learning from input-output data with\narbitrary sensor locations and counts. This begins by introducing a\nresolution-independent DeepONet (RI-DeepONet), which handles input functions\ndiscretized arbitrarily but sufficiently finely. To achieve this, we propose\ntwo dictionary learning algorithms that adaptively learn continuous basis\nfunctions, parameterized as implicit neural representations (INRs), from\ncorrelated signals on arbitrary point clouds. These basis functions project\ninput function data onto a finite-dimensional embedding space, making it\ncompatible with DeepONet without architectural changes. We specifically use\nsinusoidal representation networks (SIRENs) as trainable INR basis functions.\nSimilarly, the dictionary learning algorithms identify basis functions for\noutput data, defining a new neural operator architecture: the Resolution\nIndependent Neural Operator (RINO). In RINO, the operator learning task reduces\nto mapping coefficients of input basis functions to output basis functions. We\ndemonstrate RINO's robustness and applicability in handling arbitrarily sampled\ninput and output functions during both training and inference through several\nnumerical examples.\n","authors":["Bahador Bahmani","Somdatta Goswami","Ioannis G. Kevrekidis","Michael D. Shields"],"pdf_url":"https://arxiv.org/pdf/2407.13010v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07207v1","updated":"2024-12-10T05:55:14Z","published":"2024-12-10T05:55:14Z","title":"MAPLE: A Framework for Active Preference Learning Guided by Large\n  Language Models","summary":"  The advent of large language models (LLMs) has sparked significant interest\nin using natural language for preference learning. However, existing methods\noften suffer from high computational burdens, taxing human supervision, and\nlack of interpretability. To address these issues, we introduce MAPLE, a\nframework for large language model-guided Bayesian active preference learning.\nMAPLE leverages LLMs to model the distribution over preference functions,\nconditioning it on both natural language feedback and conventional preference\nlearning feedback, such as pairwise trajectory rankings. MAPLE also employs\nactive learning to systematically reduce uncertainty in this distribution and\nincorporates a language-conditioned active query selection mechanism to\nidentify informative and easy-to-answer queries, thus reducing human burden. We\nevaluate MAPLE's sample efficiency and preference inference quality across two\nbenchmarks, including a real-world vehicle route planning benchmark using\nOpenStreetMap data. Our results demonstrate that MAPLE accelerates the learning\nprocess and effectively improves humans' ability to answer queries.\n","authors":["Saaduddin Mahmud","Mason Nakamura","Shlomo Zilberstein"],"pdf_url":"https://arxiv.org/pdf/2412.07207v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07205v1","updated":"2024-12-10T05:50:50Z","published":"2024-12-10T05:50:50Z","title":"Crack-EdgeSAM Self-Prompting Crack Segmentation System for Edge Devices","summary":"  Structural health monitoring (SHM) is essential for the early detection of\ninfrastructure defects, such as cracks in concrete bridge pier. but often faces\nchallenges in efficiency and accuracy in complex environments. Although the\nSegment Anything Model (SAM) achieves excellent segmentation performance, its\ncomputational demands limit its suitability for real-time applications on edge\ndevices. To address these challenges, this paper proposes Crack-EdgeSAM, a\nself-prompting crack segmentation system that integrates YOLOv8 for generating\nprompt boxes and a fine-tuned EdgeSAM model for crack segmentation. To ensure\ncomputational efficiency, the method employs ConvLoRA, a Parameter-Efficient\nFine-Tuning (PEFT) technique, along with DiceFocalLoss to fine-tune the EdgeSAM\nmodel. Our experimental results on public datasets and the climbing robot\nautomatic inspections demonstrate that the system achieves high segmentation\naccuracy and significantly enhanced inference speed compared to the most recent\nmethods. Notably, the system processes 1024 x 1024 pixels images at 46 FPS on\nour PC and 8 FPS on Jetson Orin Nano.\n","authors":["Yingchu Wang","Ji He","Shijie Yu"],"pdf_url":"https://arxiv.org/pdf/2412.07205v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.12554v2","updated":"2024-12-10T05:26:19Z","published":"2024-04-19T00:17:35Z","title":"Learning Stable and Passive Neural Differential Equations","summary":"  In this paper, we introduce a novel class of neural differential equation,\nwhich are intrinsically Lyapunov stable, exponentially stable or passive. We\ntake a recently proposed Polyak Lojasiewicz network (PLNet) as an Lyapunov\nfunction and then parameterize the vector field as the descent directions of\nthe Lyapunov function. The resulting models have a same structure as the\ngeneral Hamiltonian dynamics, where the Hamiltonian is lower- and upper-bounded\nby quadratic functions. Moreover, it is also positive definite w.r.t. either a\nknown or learnable equilibrium. We illustrate the effectiveness of the proposed\nmodel on a damped double pendulum system.\n","authors":["Jing Cheng","Ruigang Wang","Ian R. Manchester"],"pdf_url":"https://arxiv.org/pdf/2404.12554v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07197v1","updated":"2024-12-10T05:20:49Z","published":"2024-12-10T05:20:49Z","title":"Hierarchical Split Federated Learning: Convergence Analysis and System\n  Optimization","summary":"  As AI models expand in size, it has become increasingly challenging to deploy\nfederated learning (FL) on resource-constrained edge devices. To tackle this\nissue, split federated learning (SFL) has emerged as an FL framework with\nreduced workload on edge devices via model splitting; it has received extensive\nattention from the research community in recent years. Nevertheless, most prior\nworks on SFL focus only on a two-tier architecture without harnessing\nmulti-tier cloudedge computing resources. In this paper, we intend to analyze\nand optimize the learning performance of SFL under multi-tier systems.\nSpecifically, we propose the hierarchical SFL (HSFL) framework and derive its\nconvergence bound. Based on the theoretical results, we formulate a joint\noptimization problem for model splitting (MS) and model aggregation (MA). To\nsolve this rather hard problem, we then decompose it into MS and MA subproblems\nthat can be solved via an iterative descending algorithm. Simulation results\ndemonstrate that the tailored algorithm can effectively optimize MS and MA for\nSFL within virtually any multi-tier system.\n","authors":["Zheng Lin","Wei Wei","Zhe Chen","Chan-Tong Lam","Xianhao Chen","Yue Gao","Jun Luo"],"pdf_url":"https://arxiv.org/pdf/2412.07197v1.pdf","comment":"15 pages, 9 figures"},{"id":"http://arxiv.org/abs/2412.07195v1","updated":"2024-12-10T05:08:39Z","published":"2024-12-10T05:08:39Z","title":"A Progressive Image Restoration Network for High-order Degradation\n  Imaging in Remote Sensing","summary":"  Recently, deep learning methods have gained remarkable achievements in the\nfield of image restoration for remote sensing (RS). However, most existing RS\nimage restoration methods focus mainly on conventional first-order degradation\nmodels, which may not effectively capture the imaging mechanisms of remote\nsensing images. Furthermore, many RS image restoration approaches that use deep\nlearning are often criticized for their lacks of architecture transparency and\nmodel interpretability. To address these problems, we propose a novel\nprogressive restoration network for high-order degradation imaging (HDI-PRNet),\nto progressively restore different image degradation. HDI-PRNet is developed\nbased on the theoretical framework of degradation imaging, offering the benefit\nof mathematical interpretability within the unfolding network. The framework is\ncomposed of three main components: a module for image denoising that relies on\nproximal mapping prior learning, a module for image deblurring that integrates\nNeumann series expansion with dual-domain degradation learning, and a module\nfor super-resolution. Extensive experiments demonstrate that our method\nachieves superior performance on both synthetic and real remote sensing images.\n","authors":["Yujie Feng","Yin Yang","Xiaohong Fan","Zhengpeng Zhang","Lijing Bu","Jianping Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.07195v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2412.06414v2","updated":"2024-12-10T05:05:08Z","published":"2024-12-09T11:43:03Z","title":"Federated Split Learning with Model Pruning and Gradient Quantization in\n  Wireless Networks","summary":"  As a paradigm of distributed machine learning, federated learning typically\nrequires all edge devices to train a complete model locally. However, with the\nincreasing scale of artificial intelligence models, the limited resources on\nedge devices often become a bottleneck for efficient fine-tuning. To address\nthis challenge, federated split learning (FedSL) implements collaborative\ntraining across the edge devices and the server through model splitting. In\nthis paper, we propose a lightweight FedSL scheme, that further alleviates the\ntraining burden on resource-constrained edge devices by pruning the client-side\nmodel dynamicly and using quantized gradient updates to reduce computation\noverhead. Additionally, we apply random dropout to the activation values at the\nsplit layer to reduce communication overhead. We conduct theoretical analysis\nto quantify the convergence performance of the proposed scheme. Finally,\nsimulation results verify the effectiveness and advantages of the proposed\nlightweight FedSL in wireless network environments.\n","authors":["Junhe Zhang","Wanli Ni","Dongyu Wang"],"pdf_url":"https://arxiv.org/pdf/2412.06414v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07193v1","updated":"2024-12-10T05:04:52Z","published":"2024-12-10T05:04:52Z","title":"Epidemiological Model Calibration via Graybox Bayesian Optimization","summary":"  In this study, we focus on developing efficient calibration methods via\nBayesian decision-making for the family of compartmental epidemiological\nmodels. The existing calibration methods usually assume that the compartmental\nmodel is cheap in terms of its output and gradient evaluation, which may not\nhold in practice when extending them to more general settings. Therefore, we\nintroduce model calibration methods based on a \"graybox\" Bayesian optimization\n(BO) scheme, more efficient calibration for general epidemiological models.\nThis approach uses Gaussian processes as a surrogate to the expensive model,\nand leverages the functional structure of the compartmental model to enhance\ncalibration performance. Additionally, we develop model calibration methods via\na decoupled decision-making strategy for BO, which further exploits the\ndecomposable nature of the functional structure. The calibration efficiencies\nof the multiple proposed schemes are evaluated based on various data generated\nby a compartmental model mimicking real-world epidemic processes, and\nreal-world COVID-19 datasets. Experimental results demonstrate that our\nproposed graybox variants of BO schemes can efficiently calibrate\ncomputationally expensive models and further improve the calibration\nperformance measured by the logarithm of mean square errors and achieve faster\nperformance convergence in terms of BO iterations. We anticipate that the\nproposed calibration methods can be extended to enable fast calibration of more\ncomplex epidemiological models, such as the agent-based models.\n","authors":["Puhua Niu","Byung-Jun Yoon","Xiaoning Qian"],"pdf_url":"https://arxiv.org/pdf/2412.07193v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07192v1","updated":"2024-12-10T05:00:01Z","published":"2024-12-10T05:00:01Z","title":"PrisonBreak: Jailbreaking Large Language Models with Fewer Than\n  Twenty-Five Targeted Bit-flips","summary":"  We introduce a new class of attacks on commercial-scale (human-aligned)\nlanguage models that induce jailbreaking through targeted bitwise corruptions\nin model parameters. Our adversary can jailbreak billion-parameter language\nmodels with fewer than 25 bit-flips in all cases$-$and as few as 5 in\nsome$-$using up to 40$\\times$ less bit-flips than existing attacks on computer\nvision models at least 100$\\times$ smaller. Unlike prompt-based jailbreaks, our\nattack renders these models in memory 'uncensored' at runtime, allowing them to\ngenerate harmful responses without any input modifications. Our attack\nalgorithm efficiently identifies target bits to flip, offering up to 20$\\times$\nmore computational efficiency than previous methods. This makes it practical\nfor language models with billions of parameters. We show an end-to-end\nexploitation of our attack using software-induced fault injection, Rowhammer\n(RH). Our work examines 56 DRAM RH profiles from DDR4 and LPDDR4X devices with\ndifferent RH vulnerabilities. We show that our attack can reliably induce\njailbreaking in systems similar to those affected by prior bit-flip attacks.\nMoreover, our approach remains effective even against highly RH-secure systems\n(e.g., 46$\\times$ more secure than previously tested systems). Our analyses\nfurther reveal that: (1) models with less post-training alignment require fewer\nbit flips to jailbreak; (2) certain model components, such as value projection\nlayers, are substantially more vulnerable than others; and (3) our method is\nmechanistically different than existing jailbreaks. Our findings highlight a\npressing, practical threat to the language model ecosystem and underscore the\nneed for research to protect these models from bit-flip attacks.\n","authors":["Zachary Coalson","Jeonghyun Woo","Shiyang Chen","Yu Sun","Lishan Yang","Prashant Nair","Bo Fang","Sanghyun Hong"],"pdf_url":"https://arxiv.org/pdf/2412.07192v1.pdf","comment":null}]," Artificial Intelligence":[{"id":"http://arxiv.org/abs/2412.07776v1","updated":"2024-12-10T18:59:58Z","published":"2024-12-10T18:59:58Z","title":"Video Motion Transfer with Diffusion Transformers","summary":"  We propose DiTFlow, a method for transferring the motion of a reference video\nto a newly synthesized one, designed specifically for Diffusion Transformers\n(DiT). We first process the reference video with a pre-trained DiT to analyze\ncross-frame attention maps and extract a patch-wise motion signal called the\nAttention Motion Flow (AMF). We guide the latent denoising process in an\noptimization-based, training-free, manner by optimizing latents with our AMF\nloss to generate videos reproducing the motion of the reference one. We also\napply our optimization strategy to transformer positional embeddings, granting\nus a boost in zero-shot motion transfer capabilities. We evaluate DiTFlow\nagainst recently published methods, outperforming all across multiple metrics\nand human evaluation.\n","authors":["Alexander Pondaven","Aliaksandr Siarohin","Sergey Tulyakov","Philip Torr","Fabio Pizzati"],"pdf_url":"https://arxiv.org/pdf/2412.07776v1.pdf","comment":"Project page: https://ditflow.github.io/"},{"id":"http://arxiv.org/abs/2412.07773v1","updated":"2024-12-10T18:59:50Z","published":"2024-12-10T18:59:50Z","title":"Mobile-TeleVision: Predictive Motion Priors for Humanoid Whole-Body\n  Control","summary":"  Humanoid robots require both robust lower-body locomotion and precise\nupper-body manipulation. While recent Reinforcement Learning (RL) approaches\nprovide whole-body loco-manipulation policies, they lack precise manipulation\nwith high DoF arms. In this paper, we propose decoupling upper-body control\nfrom locomotion, using inverse kinematics (IK) and motion retargeting for\nprecise manipulation, while RL focuses on robust lower-body locomotion. We\nintroduce PMP (Predictive Motion Priors), trained with Conditional Variational\nAutoencoder (CVAE) to effectively represent upper-body motions. The locomotion\npolicy is trained conditioned on this upper-body motion representation,\nensuring that the system remains robust with both manipulation and locomotion.\nWe show that CVAE features are crucial for stability and robustness, and\nsignificantly outperforms RL-based whole-body control in precise manipulation.\nWith precise upper-body motion and robust lower-body locomotion control,\noperators can remotely control the humanoid to walk around and explore\ndifferent environments, while performing diverse manipulation tasks.\n","authors":["Chenhao Lu","Xuxin Cheng","Jialong Li","Shiqi Yang","Mazeyu Ji","Chengjing Yuan","Ge Yang","Sha Yi","Xiaolong Wang"],"pdf_url":"https://arxiv.org/pdf/2412.07773v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06759v2","updated":"2024-12-10T18:54:11Z","published":"2024-12-09T18:49:27Z","title":"XRZoo: A Large-Scale and Versatile Dataset of Extended Reality (XR)\n  Applications","summary":"  The rapid advancement of Extended Reality (XR, encompassing AR, MR, and VR)\nand spatial computing technologies forms a foundational layer for the emerging\nMetaverse, enabling innovative applications across healthcare, education,\nmanufacturing, and entertainment. However, research in this area is often\nlimited by the lack of large, representative, and highquality application\ndatasets that can support empirical studies and the development of new\napproaches benefiting XR software processes. In this paper, we introduce XRZoo,\na comprehensive and curated dataset of XR applications designed to bridge this\ngap. XRZoo contains 12,528 free XR applications, spanning nine app stores,\nacross all XR techniques (i.e., AR, MR, and VR) and use cases, with detailed\nmetadata on key aspects such as application descriptions, application\ncategories, release dates, user review numbers, and hardware specifications,\netc. By making XRZoo publicly available, we aim to foster reproducible XR\nsoftware engineering and security research, enable cross-disciplinary\ninvestigations, and also support the development of advanced XR systems by\nproviding examples to developers. Our dataset serves as a valuable resource for\nresearchers and practitioners interested in improving the scalability,\nusability, and effectiveness of XR applications. XRZoo will be released and\nactively maintained.\n","authors":["Shuqing Li","Chenran Zhang","Cuiyun Gao","Michael R. Lyu"],"pdf_url":"https://arxiv.org/pdf/2412.06759v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07755v1","updated":"2024-12-10T18:52:45Z","published":"2024-12-10T18:52:45Z","title":"SAT: Spatial Aptitude Training for Multimodal Language Models","summary":"  Spatial perception is a fundamental component of intelligence. While many\nstudies highlight that large multimodal language models (MLMs) struggle to\nreason about space, they only test for static spatial reasoning, such as\ncategorizing the relative positions of objects. Meanwhile, real-world\ndeployment requires dynamic capabilities like perspective-taking and egocentric\naction recognition. As a roadmap to improving spatial intelligence, we\nintroduce SAT, Spatial Aptitude Training, which goes beyond static relative\nobject position questions to the more dynamic tasks. SAT contains 218K\nquestion-answer pairs for 22K synthetic scenes across a training and testing\nset. Generated using a photo-realistic physics engine, our dataset can be\narbitrarily scaled and easily extended to new actions, scenes, and 3D assets.\nWe find that even MLMs that perform relatively well on static questions\nstruggle to accurately answer dynamic spatial questions. Further, we show that\nSAT instruction-tuning data improves not only dynamic spatial reasoning on SAT,\nbut also zero-shot performance on existing real-image spatial benchmarks:\n$23\\%$ on CVBench, $8\\%$ on the harder BLINK benchmark, and $18\\%$ on VSR. When\ninstruction-tuned on SAT, our 13B model matches larger proprietary MLMs like\nGPT4-V and Gemini-3-1.0 in spatial reasoning. Our data/code is available at\nhttp://arijitray1993.github.io/SAT/ .\n","authors":["Arijit Ray","Jiafei Duan","Reuben Tan","Dina Bashkirova","Rose Hendrix","Kiana Ehsani","Aniruddha Kembhavi","Bryan A. Plummer","Ranjay Krishna","Kuo-Hao Zeng","Kate Saenko"],"pdf_url":"https://arxiv.org/pdf/2412.07755v1.pdf","comment":"Project webpage: http://arijitray1993.github.io/SAT/"},{"id":"http://arxiv.org/abs/2412.07754v1","updated":"2024-12-10T18:51:31Z","published":"2024-12-10T18:51:31Z","title":"PortraitTalk: Towards Customizable One-Shot Audio-to-Talking Face\n  Generation","summary":"  Audio-driven talking face generation is a challenging task in digital\ncommunication. Despite significant progress in the area, most existing methods\nconcentrate on audio-lip synchronization, often overlooking aspects such as\nvisual quality, customization, and generalization that are crucial to producing\nrealistic talking faces. To address these limitations, we introduce a novel,\ncustomizable one-shot audio-driven talking face generation framework, named\nPortraitTalk. Our proposed method utilizes a latent diffusion framework\nconsisting of two main components: IdentityNet and AnimateNet. IdentityNet is\ndesigned to preserve identity features consistently across the generated video\nframes, while AnimateNet aims to enhance temporal coherence and motion\nconsistency. This framework also integrates an audio input with the reference\nimages, thereby reducing the reliance on reference-style videos prevalent in\nexisting approaches. A key innovation of PortraitTalk is the incorporation of\ntext prompts through decoupled cross-attention mechanisms, which significantly\nexpands creative control over the generated videos. Through extensive\nexperiments, including a newly developed evaluation metric, our model\ndemonstrates superior performance over the state-of-the-art methods, setting a\nnew standard for the generation of customizable realistic talking faces\nsuitable for real-world applications.\n","authors":["Fatemeh Nazarieh","Zhenhua Feng","Diptesh Kanojia","Muhammad Awais","Josef Kittler"],"pdf_url":"https://arxiv.org/pdf/2412.07754v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.19643v3","updated":"2024-12-10T18:50:37Z","published":"2024-10-25T15:49:04Z","title":"Impact of Leakage on Data Harmonization in Machine Learning Pipelines in\n  Class Imbalance Across Sites","summary":"  Machine learning (ML) models benefit from large datasets. Collecting data in\nbiomedical domains is costly and challenging, hence, combining datasets has\nbecome a common practice. However, datasets obtained under different conditions\ncould present undesired site-specific variability. Data harmonization methods\naim to remove site-specific variance while retaining biologically relevant\ninformation. This study evaluates the effectiveness of popularly used\nComBat-based methods for harmonizing data in scenarios where the class balance\nis not equal across sites. We find that these methods struggle with data\nleakage issues. To overcome this problem, we propose a novel approach\nPrettYharmonize, designed to harmonize data by pretending the target labels. We\nvalidate our approach using controlled datasets designed to benchmark the\nutility of harmonization. Finally, using real-world MRI and clinical data, we\ncompare leakage-prone methods with PrettYharmonize and show that it achieves\ncomparable performance while avoiding data leakage, particularly in\nsite-target-dependence scenarios.\n","authors":["Nicolás Nieto","Simon B. Eickhoff","Christian Jung","Martin Reuter","Kersten Diers","Malte Kelm","Artur Lichtenberg","Federico Raimondo","Kaustubh R. Patil"],"pdf_url":"https://arxiv.org/pdf/2410.19643v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07752v1","updated":"2024-12-10T18:50:37Z","published":"2024-12-10T18:50:37Z","title":"FlashRNN: Optimizing Traditional RNNs on Modern Hardware","summary":"  While Transformers and other sequence-parallelizable neural network\narchitectures seem like the current state of the art in sequence modeling, they\nspecifically lack state-tracking capabilities. These are important for\ntime-series tasks and logical reasoning. Traditional RNNs like LSTMs and GRUs,\nas well as modern variants like sLSTM do have these capabilities at the cost of\nstrictly sequential processing. While this is often seen as a strong\nlimitation, we show how fast these networks can get with our\nhardware-optimization FlashRNN in Triton and CUDA, optimizing kernels to the\nregister level on modern GPUs. We extend traditional RNNs with a\nparallelization variant that processes multiple RNNs of smaller hidden state in\nparallel, similar to the head-wise processing in Transformers. To enable\nflexibility on different GPU variants, we introduce a new optimization\nframework for hardware-internal cache sizes, memory and compute handling. It\nmodels the hardware in a setting using polyhedral-like constraints, including\nthe notion of divisibility. This speeds up the solution process in our\nConstrINT library for general integer constraint satisfaction problems (integer\nCSPs). We show that our kernels can achieve 50x speed-ups over a vanilla\nPyTorch implementation and allow 40x larger hidden sizes compared to our Triton\nimplementation. Our open-source kernels and the optimization library are\nreleased here to boost research in the direction of state-tracking enabled RNNs\nand sequence modeling: \\url{https://github.com/NX-AI/flashrnn}\n","authors":["Korbinian Pöppel","Maximilian Beck","Sepp Hochreiter"],"pdf_url":"https://arxiv.org/pdf/2412.07752v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07747v1","updated":"2024-12-10T18:47:10Z","published":"2024-12-10T18:47:10Z","title":"Predictive Modeling of Homeless Service Assignment: A Representation\n  Learning Approach","summary":"  In recent years, there has been growing interest in leveraging machine\nlearning for homeless service assignment. However, the categorical nature of\nadministrative data recorded for homeless individuals hinders the development\nof accurate machine learning methods for this task. This work asserts that\nderiving latent representations of such features, while at the same time\nleveraging underlying relationships between instances is crucial in\nalgorithmically enhancing the existing assignment decision-making process. Our\nproposed approach learns temporal and functional relationships between services\nfrom historical data, as well as unobserved but relevant relationships between\nindividuals to generate features that significantly improve the prediction of\nthe next service assignment compared to the state-of-the-art.\n","authors":["Khandker Sadia Rahman","Charalampos Chelmis"],"pdf_url":"https://arxiv.org/pdf/2412.07747v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16780v2","updated":"2024-12-10T18:45:18Z","published":"2024-10-22T07:53:41Z","title":"Beyond Retrieval: Generating Narratives in Conversational Recommender\n  Systems","summary":"  The recent advances in Large Language Model's generation and reasoning\ncapabilities present an opportunity to develop truly conversational\nrecommendation systems. However, effectively integrating recommender system\nknowledge into LLMs for natural language generation which is tailored towards\nrecommendation tasks remains a challenge. This paper addresses this challenge\nby making two key contributions.\n  First, we introduce a new dataset (REGEN) for natural language generation\ntasks in conversational recommendations. REGEN (Reviews Enhanced with\nGEnerative Narratives) extends the Amazon Product Reviews dataset with rich\nuser narratives, including personalized explanations of product preferences,\nproduct endorsements for recommended items, and summaries of user purchase\nhistory. REGEN is made publicly available to facilitate further research.\nFurthermore, we establish benchmarks using well-known generative metrics, and\nperform an automated evaluation of the new dataset using a rater LLM. Second,\nthe paper introduces a fusion architecture (CF model with an LLM) which serves\nas a baseline for REGEN. And to the best of our knowledge, represents the first\nattempt to analyze the capabilities of LLMs in understanding recommender\nsignals and generating rich narratives. We demonstrate that LLMs can\neffectively learn from simple fusion architectures utilizing interaction-based\nCF embeddings, and this can be further enhanced using the metadata and\npersonalization data associated with items. Our experiments show that combining\nCF and content embeddings leads to improvements of 4-12% in key language\nmetrics compared to using either type of embedding individually. We also\nprovide an analysis to interpret how CF and content embeddings contribute to\nthis new generative task.\n","authors":["Krishna Sayana","Raghavendra Vasudeva","Yuri Vasilevski","Kun Su","Liam Hebert","James Pine","Hubert Pham","Ambarish Jash","Sukhdeep Sodhi"],"pdf_url":"https://arxiv.org/pdf/2410.16780v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07739v1","updated":"2024-12-10T18:36:21Z","published":"2024-12-10T18:36:21Z","title":"GASP: Gaussian Avatars with Synthetic Priors","summary":"  Gaussian Splatting has changed the game for real-time photo-realistic\nrendering. One of the most popular applications of Gaussian Splatting is to\ncreate animatable avatars, known as Gaussian Avatars. Recent works have pushed\nthe boundaries of quality and rendering efficiency but suffer from two main\nlimitations. Either they require expensive multi-camera rigs to produce avatars\nwith free-view rendering, or they can be trained with a single camera but only\nrendered at high quality from this fixed viewpoint. An ideal model would be\ntrained using a short monocular video or image from available hardware, such as\na webcam, and rendered from any view. To this end, we propose GASP: Gaussian\nAvatars with Synthetic Priors. To overcome the limitations of existing\ndatasets, we exploit the pixel-perfect nature of synthetic data to train a\nGaussian Avatar prior. By fitting this prior model to a single photo or video\nand fine-tuning it, we get a high-quality Gaussian Avatar, which supports\n360$^\\circ$ rendering. Our prior is only required for fitting, not inference,\nenabling real-time application. Through our method, we obtain high-quality,\nanimatable Avatars from limited data which can be animated and rendered at\n70fps on commercial hardware. See our project page\n(https://microsoft.github.io/GASP/) for results.\n","authors":["Jack Saunders","Charlie Hewitt","Yanan Jian","Marek Kowalski","Tadas Baltrusaitis","Yiye Chen","Darren Cosker","Virginia Estellers","Nicholas Gyde","Vinay P. Namboodiri","Benjamin E Lundell"],"pdf_url":"https://arxiv.org/pdf/2412.07739v1.pdf","comment":"Project page: https://microsoft.github.io/GASP/"},{"id":"http://arxiv.org/abs/2412.05467v2","updated":"2024-12-10T18:28:46Z","published":"2024-12-06T23:43:59Z","title":"The BrowserGym Ecosystem for Web Agent Research","summary":"  The BrowserGym ecosystem addresses the growing need for efficient evaluation\nand benchmarking of web agents, particularly those leveraging automation and\nLarge Language Models (LLMs) for web interaction tasks. Many existing\nbenchmarks suffer from fragmentation and inconsistent evaluation methodologies,\nmaking it challenging to achieve reliable comparisons and reproducible results.\nBrowserGym aims to solve this by providing a unified, gym-like environment with\nwell-defined observation and action spaces, facilitating standardized\nevaluation across diverse benchmarks. Combined with AgentLab, a complementary\nframework that aids in agent creation, testing, and analysis, BrowserGym offers\nflexibility for integrating new benchmarks while ensuring consistent evaluation\nand comprehensive experiment management. This standardized approach seeks to\nreduce the time and complexity of developing web agents, supporting more\nreliable comparisons and facilitating in-depth analysis of agent behaviors, and\ncould result in more adaptable, capable agents, ultimately accelerating\ninnovation in LLM-driven automation. As a supporting evidence, we conduct the\nfirst large-scale, multi-benchmark web agent experiment and compare the\nperformance of 6 state-of-the-art LLMs across all benchmarks currently\navailable in BrowserGym. Among other findings, our results highlight a large\ndiscrepancy between OpenAI and Anthropic's latests models, with\nClaude-3.5-Sonnet leading the way on almost all benchmarks, except on\nvision-related tasks where GPT-4o is superior. Despite these advancements, our\nresults emphasize that building robust and efficient web agents remains a\nsignificant challenge, due to the inherent complexity of real-world web\nenvironments and the limitations of current models.\n","authors":["Thibault Le Sellier De Chezelles","Maxime Gasse","Alexandre Drouin","Massimo Caccia","Léo Boisvert","Megh Thakkar","Tom Marty","Rim Assouel","Sahar Omidi Shayegan","Lawrence Keunho Jang","Xing Han Lù","Ori Yoran","Dehan Kong","Frank F. Xu","Siva Reddy","Quentin Cappart","Graham Neubig","Ruslan Salakhutdinov","Nicolas Chapados","Alexandre Lacoste"],"pdf_url":"https://arxiv.org/pdf/2412.05467v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07730v1","updated":"2024-12-10T18:27:06Z","published":"2024-12-10T18:27:06Z","title":"STIV: Scalable Text and Image Conditioned Video Generation","summary":"  The field of video generation has made remarkable advancements, yet there\nremains a pressing need for a clear, systematic recipe that can guide the\ndevelopment of robust and scalable models. In this work, we present a\ncomprehensive study that systematically explores the interplay of model\narchitectures, training recipes, and data curation strategies, culminating in a\nsimple and scalable text-image-conditioned video generation method, named STIV.\nOur framework integrates image condition into a Diffusion Transformer (DiT)\nthrough frame replacement, while incorporating text conditioning via a joint\nimage-text conditional classifier-free guidance. This design enables STIV to\nperform both text-to-video (T2V) and text-image-to-video (TI2V) tasks\nsimultaneously. Additionally, STIV can be easily extended to various\napplications, such as video prediction, frame interpolation, multi-view\ngeneration, and long video generation, etc. With comprehensive ablation studies\non T2I, T2V, and TI2V, STIV demonstrate strong performance, despite its simple\ndesign. An 8.7B model with 512 resolution achieves 83.1 on VBench T2V,\nsurpassing both leading open and closed-source models like CogVideoX-5B, Pika,\nKling, and Gen-3. The same-sized model also achieves a state-of-the-art result\nof 90.1 on VBench I2V task at 512 resolution. By providing a transparent and\nextensible recipe for building cutting-edge video generation models, we aim to\nempower future research and accelerate progress toward more versatile and\nreliable video generation solutions.\n","authors":["Zongyu Lin","Wei Liu","Chen Chen","Jiasen Lu","Wenze Hu","Tsu-Jui Fu","Jesse Allardice","Zhengfeng Lai","Liangchen Song","Bowen Zhang","Cha Chen","Yiran Fei","Yifan Jiang","Lezhi Li","Yizhou Sun","Kai-Wei Chang","Yinfei Yang"],"pdf_url":"https://arxiv.org/pdf/2412.07730v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02168v2","updated":"2024-12-10T18:14:14Z","published":"2024-11-04T15:26:07Z","title":"Do graph neural network states contain graph properties?","summary":"  Deep neural networks (DNNs) achieve state-of-the-art performance on many\ntasks, but this often requires increasingly larger model sizes, which in turn\nleads to more complex internal representations. Explainability techniques (XAI)\nhave made remarkable progress in the interpretability of ML models. However,\nthe non-relational nature of Graph neural networks (GNNs) make it difficult to\nreuse already existing XAI methods. While other works have focused on\ninstance-based explanation methods for GNNs, very few have investigated\nmodel-based methods and, to our knowledge, none have tried to probe the\nembedding of the GNNs for well-known structural graph properties. In this paper\nwe present a model agnostic explainability pipeline for GNNs employing\ndiagnostic classifiers. This pipeline aims to probe and interpret the learned\nrepresentations in GNNs across various architectures and datasets, refining our\nunderstanding and trust in these models.\n","authors":["Tom Pelletreau-Duris","Ruud van Bakel","Michael Cochez"],"pdf_url":"https://arxiv.org/pdf/2411.02168v2.pdf","comment":"10 pages, 22 figures, conference"},{"id":"http://arxiv.org/abs/2412.07713v1","updated":"2024-12-10T18:01:33Z","published":"2024-12-10T18:01:33Z","title":"Benchmark for Evaluation and Analysis of Citation Recommendation Models","summary":"  Citation recommendation systems have attracted much academic interest,\nresulting in many studies and implementations. These systems help authors\nautomatically generate proper citations by suggesting relevant references based\non the text they have written. However, the methods used in citation\nrecommendation differ across various studies and implementations. Some\napproaches focus on the overall content of papers, while others consider the\ncontext of the citation text. Additionally, the datasets used in these studies\ninclude different aspects of papers, such as metadata, citation context, or\neven the full text of the paper in various formats and structures. The\ndiversity in models, datasets, and evaluation metrics makes it challenging to\nassess and compare citation recommendation methods effectively. To address this\nissue, a standardized dataset and evaluation metrics are needed to evaluate\nthese models consistently. Therefore, we propose developing a benchmark\nspecifically designed to analyze and compare citation recommendation models.\nThis benchmark will evaluate the performance of models on different features of\nthe citation context and provide a comprehensive evaluation of the models\nacross all these tasks, presenting the results in a standardized way. By\ncreating a benchmark with standardized evaluation metrics, researchers and\npractitioners in the field of citation recommendation will have a common\nplatform to assess and compare different models. This will enable meaningful\ncomparisons and help identify promising approaches for further research and\ndevelopment in the field.\n","authors":["Puja Maharjan"],"pdf_url":"https://arxiv.org/pdf/2412.07713v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2412.05821v2","updated":"2024-12-10T17:42:49Z","published":"2024-12-08T05:47:55Z","title":"An Entailment Tree Generation Approach for Multimodal Multi-Hop Question\n  Answering with Mixture-of-Experts and Iterative Feedback Mechanism","summary":"  With the rise of large-scale language models (LLMs), it is currently popular\nand effective to convert multimodal information into text descriptions for\nmultimodal multi-hop question answering. However, we argue that the current\nmethods of multi-modal multi-hop question answering still mainly face two\nchallenges: 1) The retrieved evidence containing a large amount of redundant\ninformation, inevitably leads to a significant drop in performance due to\nirrelevant information misleading the prediction. 2) The reasoning process\nwithout interpretable reasoning steps makes the model difficult to discover the\nlogical errors for handling complex questions. To solve these problems, we\npropose a unified LLMs-based approach but without heavily relying on them due\nto the LLM's potential errors, and innovatively treat multimodal multi-hop\nquestion answering as a joint entailment tree generation and question answering\nproblem. Specifically, we design a multi-task learning framework with a focus\non facilitating common knowledge sharing across interpretability and prediction\ntasks while preventing task-specific errors from interfering with each other\nvia mixture of experts. Afterward, we design an iterative feedback mechanism to\nfurther enhance both tasks by feeding back the results of the joint training to\nthe LLM for regenerating entailment trees, aiming to iteratively refine the\npotential answer. Notably, our method has won the first place in the official\nleaderboard of WebQA (since April 10, 2024), and achieves competitive results\non MultimodalQA.\n","authors":["Qing Zhang","Haocheng Lv","Jie Liu","Zhiyun Chen","Jianyong Duan","Hao Wang","Li He","Mingying Xv"],"pdf_url":"https://arxiv.org/pdf/2412.05821v2.pdf","comment":"Erratum: We identified an error in the calculation of the F1 score in\n  table 4 reported in a previous version of this work. The performance of the\n  new result is better than the previous one. The corrected values are included\n  in this updated version of the paper. These changes do not alter the primary\n  conclusions of our research"},{"id":"http://arxiv.org/abs/2412.07696v1","updated":"2024-12-10T17:35:12Z","published":"2024-12-10T17:35:12Z","title":"SimVS: Simulating World Inconsistencies for Robust View Synthesis","summary":"  Novel-view synthesis techniques achieve impressive results for static scenes\nbut struggle when faced with the inconsistencies inherent to casual capture\nsettings: varying illumination, scene motion, and other unintended effects that\nare difficult to model explicitly. We present an approach for leveraging\ngenerative video models to simulate the inconsistencies in the world that can\noccur during capture. We use this process, along with existing multi-view\ndatasets, to create synthetic data for training a multi-view harmonization\nnetwork that is able to reconcile inconsistent observations into a consistent\n3D scene. We demonstrate that our world-simulation strategy significantly\noutperforms traditional augmentation methods in handling real-world scene\nvariations, thereby enabling highly accurate static 3D reconstructions in the\npresence of a variety of challenging inconsistencies. Project page:\nhttps://alextrevithick.github.io/simvs\n","authors":["Alex Trevithick","Roni Paiss","Philipp Henzler","Dor Verbin","Rundi Wu","Hadi Alzayer","Ruiqi Gao","Ben Poole","Jonathan T. Barron","Aleksander Holynski","Ravi Ramamoorthi","Pratul P. Srinivasan"],"pdf_url":"https://arxiv.org/pdf/2412.07696v1.pdf","comment":"Project page: https://alextrevithick.github.io/simvs"},{"id":"http://arxiv.org/abs/2412.07686v1","updated":"2024-12-10T17:20:44Z","published":"2024-12-10T17:20:44Z","title":"Optimizing Sensor Redundancy in Sequential Decision-Making Problems","summary":"  Reinforcement Learning (RL) policies are designed to predict actions based on\ncurrent observations to maximize cumulative future rewards. In real-world\napplications (i.e., non-simulated environments), sensors are essential for\nmeasuring the current state and providing the observations on which RL policies\nrely to make decisions. A significant challenge in deploying RL policies in\nreal-world scenarios is handling sensor dropouts, which can result from\nhardware malfunctions, physical damage, or environmental factors like dust on a\ncamera lens. A common strategy to mitigate this issue is the use of backup\nsensors, though this comes with added costs. This paper explores the\noptimization of backup sensor configurations to maximize expected returns while\nkeeping costs below a specified threshold, C. Our approach uses a second-order\napproximation of expected returns and includes penalties for exceeding cost\nconstraints. We then optimize this quadratic program using Tabu Search, a\nmeta-heuristic algorithm. The approach is evaluated across eight OpenAI Gym\nenvironments and a custom Unity-based robotic environment (RobotArmGrasping).\nEmpirical results demonstrate that our quadratic program effectively\napproximates real expected returns, facilitating the identification of optimal\nsensor configurations.\n","authors":["Jonas Nüßlein","Maximilian Zorn","Fabian Ritz","Jonas Stein","Gerhard Stenzel","Julian Schönberger","Thomas Gabor","Claudia Linnhoff-Popien"],"pdf_url":"https://arxiv.org/pdf/2412.07686v1.pdf","comment":"Accepted at ICAART conference 2025"},{"id":"http://arxiv.org/abs/2412.07684v1","updated":"2024-12-10T17:18:33Z","published":"2024-12-10T17:18:33Z","title":"The Pitfalls of Memorization: When Memorization Hurts Generalization","summary":"  Neural networks often learn simple explanations that fit the majority of the\ndata while memorizing exceptions that deviate from these explanations.This\nbehavior leads to poor generalization when the learned explanations rely on\nspurious correlations. In this work, we formalize the interplay between\nmemorization and generalization, showing that spurious correlations would\nparticularly lead to poor generalization when are combined with memorization.\nMemorization can reduce training loss to zero, leaving no incentive to learn\nrobust, generalizable patterns. To address this, we propose memorization-aware\ntraining (MAT), which uses held-out predictions as a signal of memorization to\nshift a model's logits. MAT encourages learning robust patterns invariant\nacross distributions, improving generalization under distribution shifts.\n","authors":["Reza Bayat","Mohammad Pezeshki","Elvis Dohmatob","David Lopez-Paz","Pascal Vincent"],"pdf_url":"https://arxiv.org/pdf/2412.07684v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07679v1","updated":"2024-12-10T17:06:41Z","published":"2024-12-10T17:06:41Z","title":"RADIO Amplified: Improved Baselines for Agglomerative Vision Foundation\n  Models","summary":"  Agglomerative models have recently emerged as a powerful approach to training\nvision foundation models, leveraging multi-teacher distillation from existing\nmodels such as CLIP, DINO, and SAM. This strategy enables the efficient\ncreation of robust models, combining the strengths of individual teachers while\nsignificantly reducing computational and resource demands. In this paper, we\nthoroughly analyze state-of-the-art agglomerative models, identifying critical\nchallenges including resolution mode shifts, teacher imbalance, idiosyncratic\nteacher artifacts, and an excessive number of output tokens. To address these\nissues, we propose several novel solutions: multi-resolution training, mosaic\naugmentation, and improved balancing of teacher loss functions. Specifically,\nin the context of Vision Language Models, we introduce a token compression\ntechnique to maintain high-resolution information within a fixed token count.\nWe release our top-performing models, available in multiple scales (-B, -L, -H,\nand -g), alongside inference code and pretrained weights.\n","authors":["Greg Heinrich","Mike Ranzinger"," Hongxu"," Yin","Yao Lu","Jan Kautz","Andrew Tao","Bryan Catanzaro","Pavlo Molchanov"],"pdf_url":"https://arxiv.org/pdf/2412.07679v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07658v1","updated":"2024-12-10T16:45:03Z","published":"2024-12-10T16:45:03Z","title":"TraSCE: Trajectory Steering for Concept Erasure","summary":"  Recent advancements in text-to-image diffusion models have brought them to\nthe public spotlight, becoming widely accessible and embraced by everyday\nusers. However, these models have been shown to generate harmful content such\nas not-safe-for-work (NSFW) images. While approaches have been proposed to\nerase such abstract concepts from the models, jail-breaking techniques have\nsucceeded in bypassing such safety measures. In this paper, we propose TraSCE,\nan approach to guide the diffusion trajectory away from generating harmful\ncontent. Our approach is based on negative prompting, but as we show in this\npaper, conventional negative prompting is not a complete solution and can\neasily be bypassed in some corner cases. To address this issue, we first\npropose a modification of conventional negative prompting. Furthermore, we\nintroduce a localized loss-based guidance that enhances the modified negative\nprompting technique by steering the diffusion trajectory. We demonstrate that\nour proposed method achieves state-of-the-art results on various benchmarks in\nremoving harmful content including ones proposed by red teams; and erasing\nartistic styles and objects. Our proposed approach does not require any\ntraining, weight modifications, or training data (both image or prompt), making\nit easier for model owners to erase new concepts.\n","authors":["Anubhav Jain","Yuya Kobayashi","Takashi Shibuya","Yuhta Takida","Nasir Memon","Julian Togelius","Yuki Mitsufuji"],"pdf_url":"https://arxiv.org/pdf/2412.07658v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03865v2","updated":"2024-12-10T16:41:12Z","published":"2024-11-06T12:19:01Z","title":"AdaSociety: An Adaptive Environment with Social Structures for\n  Multi-Agent Decision-Making","summary":"  Traditional interactive environments limit agents' intelligence growth with\nfixed tasks. Recently, single-agent environments address this by generating new\ntasks based on agent actions, enhancing task diversity. We consider the\ndecision-making problem in multi-agent settings, where tasks are further\ninfluenced by social connections, affecting rewards and information access.\nHowever, existing multi-agent environments lack a combination of adaptive\nphysical surroundings and social connections, hindering the learning of\nintelligent behaviors. To address this, we introduce AdaSociety, a customizable\nmulti-agent environment featuring expanding state and action spaces, alongside\nexplicit and alterable social structures. As agents progress, the environment\nadaptively generates new tasks with social structures for agents to undertake.\nIn AdaSociety, we develop three mini-games showcasing distinct social\nstructures and tasks. Initial results demonstrate that specific social\nstructures can promote both individual and collective benefits, though current\nreinforcement learning and LLM-based algorithms show limited effectiveness in\nleveraging social structures to enhance performance. Overall, AdaSociety serves\nas a valuable research platform for exploring intelligence in diverse physical\nand social settings. The code is available at\nhttps://github.com/bigai-ai/AdaSociety.\n","authors":["Yizhe Huang","Xingbo Wang","Hao Liu","Fanqi Kong","Aoyang Qin","Min Tang","Xiaoxi Wang","Song-Chun Zhu","Mingjie Bi","Siyuan Qi","Xue Feng"],"pdf_url":"https://arxiv.org/pdf/2411.03865v2.pdf","comment":"Accepted at NeurIPS D&B 2024"},{"id":"http://arxiv.org/abs/2406.19370v3","updated":"2024-12-10T16:40:34Z","published":"2024-06-27T17:50:05Z","title":"Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept\n  Space","summary":"  Modern generative models demonstrate impressive capabilities, likely stemming\nfrom an ability to identify and manipulate abstract concepts underlying their\ntraining data. However, fundamental questions remain: what determines the\nconcepts a model learns, the order in which it learns them, and its ability to\nmanipulate those concepts? To address these questions, we propose analyzing a\nmodel's learning dynamics via a framework we call the concept space, where each\naxis represents an independent concept underlying the data generating process.\nBy characterizing learning dynamics in this space, we identify how the speed at\nwhich a concept is learned, and hence the order of concept learning, is\ncontrolled by properties of the data we term concept signal. Further, we\nobserve moments of sudden turns in the direction of a model's learning dynamics\nin concept space. Surprisingly, these points precisely correspond to the\nemergence of hidden capabilities, i.e., where latent interventions show the\nmodel possesses the capability to manipulate a concept, but these capabilities\ncannot yet be elicited via naive input prompting. While our results focus on\nsynthetically defined toy datasets, we hypothesize a general claim on emergence\nof hidden capabilities may hold: generative models possess latent capabilities\nthat emerge suddenly and consistently during training, though a model might not\nexhibit these capabilities under naive input prompting.\n","authors":["Core Francisco Park","Maya Okawa","Andrew Lee","Ekdeep Singh Lubana","Hidenori Tanaka"],"pdf_url":"https://arxiv.org/pdf/2406.19370v3.pdf","comment":"NeurIPS 2024 (Spotlight)"},{"id":"http://arxiv.org/abs/2410.10733v3","updated":"2024-12-10T16:39:23Z","published":"2024-10-14T17:15:07Z","title":"Deep Compression Autoencoder for Efficient High-Resolution Diffusion\n  Models","summary":"  We present Deep Compression Autoencoder (DC-AE), a new family of autoencoder\nmodels for accelerating high-resolution diffusion models. Existing autoencoder\nmodels have demonstrated impressive results at a moderate spatial compression\nratio (e.g., 8x), but fail to maintain satisfactory reconstruction accuracy for\nhigh spatial compression ratios (e.g., 64x). We address this challenge by\nintroducing two key techniques: (1) Residual Autoencoding, where we design our\nmodels to learn residuals based on the space-to-channel transformed features to\nalleviate the optimization difficulty of high spatial-compression autoencoders;\n(2) Decoupled High-Resolution Adaptation, an efficient decoupled three-phases\ntraining strategy for mitigating the generalization penalty of high\nspatial-compression autoencoders. With these designs, we improve the\nautoencoder's spatial compression ratio up to 128 while maintaining the\nreconstruction quality. Applying our DC-AE to latent diffusion models, we\nachieve significant speedup without accuracy drop. For example, on ImageNet\n512x512, our DC-AE provides 19.1x inference speedup and 17.9x training speedup\non H100 GPU for UViT-H while achieving a better FID, compared with the widely\nused SD-VAE-f8 autoencoder. Our code is available at\nhttps://github.com/mit-han-lab/efficientvit.\n","authors":["Junyu Chen","Han Cai","Junsong Chen","Enze Xie","Shang Yang","Haotian Tang","Muyang Li","Yao Lu","Song Han"],"pdf_url":"https://arxiv.org/pdf/2410.10733v3.pdf","comment":"Preprint. First two authors contributed equally to this work. Update:\n  add diffusion model scaling results"},{"id":"http://arxiv.org/abs/2407.11442v2","updated":"2024-12-10T16:34:43Z","published":"2024-07-16T07:20:30Z","title":"EARN Fairness: Explaining, Asking, Reviewing, and Negotiating Artificial\n  Intelligence Fairness Metrics Among Stakeholders","summary":"  Numerous fairness metrics have been proposed and employed by artificial\nintelligence (AI) experts to quantitatively measure bias and define fairness in\nAI models. Recognizing the need to accommodate stakeholders' diverse fairness\nunderstandings, efforts are underway to solicit their input. However, conveying\nAI fairness metrics to stakeholders without AI expertise, capturing their\npersonal preferences, and seeking a collective consensus remain challenging and\nunderexplored. To bridge this gap, we propose a new framework, EARN Fairness,\nwhich facilitates collective metric decisions among stakeholders without\nrequiring AI expertise. The framework features an adaptable interactive system\nand a stakeholder-centered EARN Fairness process to Explain fairness metrics,\nAsk stakeholders' personal metric preferences, Review metrics collectively, and\nNegotiate a consensus on metric selection. To gather empirical results, we\napplied the framework to a credit rating scenario and conducted a user study\ninvolving 18 decision subjects without AI knowledge. We identify their personal\nmetric preferences and their acceptable level of unfairness in individual\nsessions. Subsequently, we uncovered how they reached metric consensus in team\nsessions. Our work shows that the EARN Fairness framework enables stakeholders\nto express personal preferences and reach consensus, providing practical\nguidance for implementing human-centered AI fairness in high-risk contexts.\nThrough this approach, we aim to harmonize fairness expectations of diverse\nstakeholders, fostering more equitable and inclusive AI fairness.\n","authors":["Lin Luo","Yuri Nakao","Mathieu Chollet","Hiroya Inakoshi","Simone Stumpf"],"pdf_url":"https://arxiv.org/pdf/2407.11442v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.14707v2","updated":"2024-12-10T16:28:07Z","published":"2024-01-26T08:38:57Z","title":"AFD: Mitigating Feature Gap for Adversarial Robustness by Feature\n  Disentanglement","summary":"  Adversarial fine-tuning methods enhance adversarial robustness via\nfine-tuning the pre-trained model in an adversarial training manner. However,\nwe identify that some specific latent features of adversarial samples are\nconfused by adversarial perturbation and lead to an unexpectedly increasing gap\nbetween features in the last hidden layer of natural and adversarial samples.\nTo address this issue, we propose a disentanglement-based approach to\nexplicitly model and further remove the specific latent features. We introduce\na feature disentangler to separate out the specific latent features from the\nfeatures of the adversarial samples, thereby boosting robustness by eliminating\nthe specific latent features. Besides, we align clean features in the\npre-trained model with features of adversarial samples in the fine-tuned model,\nto benefit from the intrinsic features of natural samples. Empirical\nevaluations on three benchmark datasets demonstrate that our approach surpasses\nexisting adversarial fine-tuning methods and adversarial training baselines.\n","authors":["Nuoyan Zhou","Dawei Zhou","Decheng Liu","Nannan Wang","Xinbo Gao"],"pdf_url":"https://arxiv.org/pdf/2401.14707v2.pdf","comment":"7 pages, 5 figures"},{"id":"http://arxiv.org/abs/2409.09359v3","updated":"2024-12-10T16:24:48Z","published":"2024-09-14T08:17:30Z","title":"Symbolic Regression with a Learned Concept Library","summary":"  We present a novel method for symbolic regression (SR), the task of searching\nfor compact programmatic hypotheses that best explain a dataset. The problem is\ncommonly solved using genetic algorithms; we show that we can enhance such\nmethods by inducing a library of abstract textual concepts. Our algorithm,\ncalled LaSR, uses zero-shot queries to a large language model (LLM) to discover\nand evolve concepts occurring in known high-performing hypotheses. We discover\nnew hypotheses using a mix of standard evolutionary steps and LLM-guided steps\n(obtained through zero-shot LLM queries) conditioned on discovered concepts.\nOnce discovered, hypotheses are used in a new round of concept abstraction and\nevolution. We validate LaSR on the Feynman equations, a popular SR benchmark,\nas well as a set of synthetic tasks. On these benchmarks, LaSR substantially\noutperforms a variety of state-of-the-art SR approaches based on deep learning\nand evolutionary algorithms. Moreover, we show that LaSR can be used to\ndiscover a novel and powerful scaling law for LLMs.\n","authors":["Arya Grayeli","Atharva Sehgal","Omar Costilla-Reyes","Miles Cranmer","Swarat Chaudhuri"],"pdf_url":"https://arxiv.org/pdf/2409.09359v3.pdf","comment":"NeurIPS version; 10 pages; no checklist; added more experiment\n  details"},{"id":"http://arxiv.org/abs/2412.07639v1","updated":"2024-12-10T16:19:08Z","published":"2024-12-10T16:19:08Z","title":"Offline Multi-Agent Reinforcement Learning via In-Sample Sequential\n  Policy Optimization","summary":"  Offline Multi-Agent Reinforcement Learning (MARL) is an emerging field that\naims to learn optimal multi-agent policies from pre-collected datasets.\nCompared to single-agent case, multi-agent setting involves a large joint\nstate-action space and coupled behaviors of multiple agents, which bring extra\ncomplexity to offline policy optimization. In this work, we revisit the\nexisting offline MARL methods and show that in certain scenarios they can be\nproblematic, leading to uncoordinated behaviors and out-of-distribution (OOD)\njoint actions. To address these issues, we propose a new offline MARL\nalgorithm, named In-Sample Sequential Policy Optimization (InSPO). InSPO\nsequentially updates each agent's policy in an in-sample manner, which not only\navoids selecting OOD joint actions but also carefully considers teammates'\nupdated policies to enhance coordination. Additionally, by thoroughly exploring\nlow-probability actions in the behavior policy, InSPO can well address the\nissue of premature convergence to sub-optimal solutions. Theoretically, we\nprove InSPO guarantees monotonic policy improvement and converges to quantal\nresponse equilibrium (QRE). Experimental results demonstrate the effectiveness\nof our method compared to current state-of-the-art offline MARL methods.\n","authors":["Zongkai Liu","Qian Lin","Chao Yu","Xiawei Wu","Yile Liang","Donghui Li","Xuetao Ding"],"pdf_url":"https://arxiv.org/pdf/2412.07639v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07636v1","updated":"2024-12-10T16:16:22Z","published":"2024-12-10T16:16:22Z","title":"TrojanWhisper: Evaluating Pre-trained LLMs to Detect and Localize\n  Hardware Trojans","summary":"  Existing Hardware Trojans (HT) detection methods face several critical\nlimitations: logic testing struggles with scalability and coverage for large\ndesigns, side-channel analysis requires golden reference chips, and formal\nverification methods suffer from state-space explosion. The emergence of Large\nLanguage Models (LLMs) offers a promising new direction for HT detection by\nleveraging their natural language understanding and reasoning capabilities. For\nthe first time, this paper explores the potential of general-purpose LLMs in\ndetecting various HTs inserted in Register Transfer Level (RTL) designs,\nincluding SRAM, AES, and UART modules. We propose a novel tool for this goal\nthat systematically assesses state-of-the-art LLMs (GPT-4o, Gemini 1.5 pro, and\nLlama 3.1) in detecting HTs without prior fine-tuning. To address potential\ntraining data bias, the tool implements perturbation techniques, i.e., variable\nname obfuscation, and design restructuring, that make the cases more\nsophisticated for the used LLMs. Our experimental evaluation demonstrates\nperfect detection rates by GPT-4o and Gemini 1.5 pro in baseline scenarios\n(100%/100% precision/recall), with both models achieving better trigger line\ncoverage (TLC: 0.82-0.98) than payload line coverage (PLC: 0.32-0.46). Under\ncode perturbation, while Gemini 1.5 pro maintains perfect detection performance\n(100%/100%), GPT-4o (100%/85.7%) and Llama 3.1 (66.7%/85.7%) show some\ndegradation in detection rates, and all models experience decreased accuracy in\nlocalizing both triggers and payloads. This paper validates the potential of\nLLM approaches for hardware security applications, highlighting areas for\nfuture improvement.\n","authors":["Md Omar Faruque","Peter Jamieson","Ahmad Patooghy","Abdel-Hameed A. Badawy"],"pdf_url":"https://arxiv.org/pdf/2412.07636v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.07779v3","updated":"2024-12-10T16:16:12Z","published":"2024-09-12T06:25:44Z","title":"AFFSegNet: Adaptive Feature Fusion Segmentation Network for Microtumors\n  and Multi-Organ Segmentation","summary":"  Medical image segmentation, a crucial task in computer vision, facilitates\nthe automated delineation of anatomical structures and pathologies, supporting\nclinicians in diagnosis, treatment planning, and disease monitoring. Notably,\ntransformers employing shifted window-based self-attention have demonstrated\nexceptional performance. However, their reliance on local window attention\nlimits the fusion of local and global contextual information, crucial for\nsegmenting microtumors and miniature organs. To address this limitation, we\npropose the Adaptive Semantic Segmentation Network (ASSNet), a transformer\narchitecture that effectively integrates local and global features for precise\nmedical image segmentation. ASSNet comprises a transformer-based U-shaped\nencoder-decoder network. The encoder utilizes shifted window self-attention\nacross five resolutions to extract multi-scale features, which are then\npropagated to the decoder through skip connections. We introduce an augmented\nmulti-layer perceptron within the encoder to explicitly model long-range\ndependencies during feature extraction. Recognizing the constraints of\nconventional symmetrical encoder-decoder designs, we propose an Adaptive\nFeature Fusion (AFF) decoder to complement our encoder. This decoder\nincorporates three key components: the Long Range Dependencies (LRD) block, the\nMulti-Scale Feature Fusion (MFF) block, and the Adaptive Semantic Center (ASC)\nblock. These components synergistically facilitate the effective fusion of\nmulti-scale features extracted by the decoder while capturing long-range\ndependencies and refining object boundaries. Comprehensive experiments on\ndiverse medical image segmentation tasks, including multi-organ, liver tumor,\nand bladder tumor segmentation, demonstrate that ASSNet achieves\nstate-of-the-art results. Code and models are available at:\n\\url{https://github.com/lzeeorno/ASSNet}.\n","authors":["Fuchen Zheng","Xinyi Chen","Xuhang Chen","Haolun Li","Xiaojiao Guo","Weihuang Liu","Chi-Man Pun","Shoujun Zhou"],"pdf_url":"https://arxiv.org/pdf/2409.07779v3.pdf","comment":"8 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2306.06805v3","updated":"2024-12-10T16:12:12Z","published":"2023-06-11T23:33:59Z","title":"Unlocking Feature Visualization for Deeper Networks with MAgnitude\n  Constrained Optimization","summary":"  Feature visualization has gained substantial popularity, particularly after\nthe influential work by Olah et al. in 2017, which established it as a crucial\ntool for explainability. However, its widespread adoption has been limited due\nto a reliance on tricks to generate interpretable images, and corresponding\nchallenges in scaling it to deeper neural networks. Here, we describe MACO, a\nsimple approach to address these shortcomings. The main idea is to generate\nimages by optimizing the phase spectrum while keeping the magnitude constant to\nensure that generated explanations lie in the space of natural images. Our\napproach yields significantly better results (both qualitatively and\nquantitatively) and unlocks efficient and interpretable feature visualizations\nfor large state-of-the-art neural networks. We also show that our approach\nexhibits an attribution mechanism allowing us to augment feature visualizations\nwith spatial importance. We validate our method on a novel benchmark for\ncomparing feature visualization methods, and release its visualizations for all\nclasses of the ImageNet dataset on https://serre-lab.github.io/Lens/.\n  Overall, our approach unlocks, for the first time, feature visualizations for\nlarge, state-of-the-art deep neural networks without resorting to any\nparametric prior image model.\n","authors":["Thomas Fel","Thibaut Boissin","Victor Boutin","Agustin Picard","Paul Novello","Julien Colin","Drew Linsley","Tom Rousseau","Rémi Cadène","Lore Goetschalckx","Laurent Gardes","Thomas Serre"],"pdf_url":"https://arxiv.org/pdf/2306.06805v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07629v1","updated":"2024-12-10T16:08:14Z","published":"2024-12-10T16:08:14Z","title":"Piece of Table: A Divide-and-Conquer Approach for Selecting Sub-Tables\n  in Table Question Answering","summary":"  Applying language models (LMs) to tables is challenging due to the inherent\nstructural differences between two-dimensional tables and one-dimensional text\nfor which the LMs were originally designed. Furthermore, when applying\nlinearized tables to LMs, the maximum token lengths often imposed in\nself-attention calculations make it difficult to comprehensively understand the\ncontext spread across large tables. To address these challenges, we present\nPieTa (Piece of Table), a new framework for sub-table-based question answering\n(QA). PieTa operates through an iterative process of dividing tables into\nsmaller windows, using LMs to select relevant cells within each window, and\nmerging these cells into a sub-table. This multi-resolution approach captures\ndependencies across multiple rows and columns while avoiding the limitations\ncaused by long context inputs. Instantiated as a simple iterative sub-table\nunion algorithm, PieTa demonstrates improved performance over previous\nsub-table-based QA approaches.\n","authors":["Wonjin Lee","Kyumin Kim","Sungjae Lee","Jihun Lee","Kwang In KIm"],"pdf_url":"https://arxiv.org/pdf/2412.07629v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07626v1","updated":"2024-12-10T16:05:56Z","published":"2024-12-10T16:05:56Z","title":"OmniDocBench: Benchmarking Diverse PDF Document Parsing with\n  Comprehensive Annotations","summary":"  Document content extraction is crucial in computer vision, especially for\nmeeting the high-quality data needs of large language models (LLMs) and\nretrieval-augmented generation (RAG) technologies. However, current document\nparsing methods suffer from significant limitations in terms of diversity and\ncomprehensive evaluation. To address these challenges, we introduce\nOmniDocBench, a novel multi-source benchmark designed to advance automated\ndocument content extraction. OmniDocBench includes a meticulously curated and\nannotated high-quality evaluation dataset comprising nine diverse document\ntypes, such as academic papers, textbooks, slides, among others. Our benchmark\nprovides a flexible and comprehensive evaluation framework with 19 layout\ncategory labels and 14 attribute labels, enabling multi-level assessments\nacross entire datasets, individual modules, or specific data types. Using\nOmniDocBench, we perform an exhaustive comparative analysis of existing modular\npipelines and multimodal end-to-end methods, highlighting their limitations in\nhandling document diversity and ensuring fair evaluation. OmniDocBench\nestablishes a robust, diverse, and fair evaluation standard for the document\ncontent extraction field, offering crucial insights for future advancements and\nfostering the development of document parsing technologies. The codes and\ndataset is available in https://github.com/opendatalab/OmniDocBench.\n","authors":["Linke Ouyang","Yuan Qu","Hongbin Zhou","Jiawei Zhu","Rui Zhang","Qunshu Lin","Bin Wang","Zhiyuan Zhao","Man Jiang","Xiaomeng Zhao","Jin Shi","Fan Wu","Pei Chu","Minghao Liu","Zhenxiang Li","Chao Xu","Bo Zhang","Botian Shi","Zhongying Tu","Conghui He"],"pdf_url":"https://arxiv.org/pdf/2412.07626v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07618v1","updated":"2024-12-10T15:56:03Z","published":"2024-12-10T15:56:03Z","title":"Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced\n  Retrieval-Augmented Generation on Knowledge Graphs","summary":"  Despite the superior performance of Large language models on many NLP tasks,\nthey still face significant limitations in memorizing extensive world\nknowledge. Recent studies have demonstrated that leveraging the\nRetrieval-Augmented Generation (RAG) framework, combined with Knowledge Graphs\nthat encapsulate extensive factual data in a structured format, robustly\nenhances the reasoning capabilities of LLMs. However, deploying such systems in\nreal-world scenarios presents challenges: the continuous evolution of\nnon-stationary environments may lead to performance degradation and user\nsatisfaction requires a careful balance of performance and responsiveness. To\naddress these challenges, we introduce a Multi-objective Multi-Armed Bandit\nenhanced RAG framework, supported by multiple retrieval methods with diverse\ncapabilities under rich and evolving retrieval contexts in practice. Within\nthis framework, each retrieval method is treated as a distinct ``arm''. The\nsystem utilizes real-time user feedback to adapt to dynamic environments, by\nselecting the appropriate retrieval method based on input queries and the\nhistorical multi-objective performance of each arm. Extensive experiments\nconducted on two benchmark KGQA datasets demonstrate that our method\nsignificantly outperforms baseline methods in non-stationary settings while\nachieving state-of-the-art performance in stationary environments. Code and\ndata are available at https://github.com/FUTUREEEEEE/Dynamic-RAG.git\n","authors":["Xiaqiang Tang","Jian Li","Nan Du","Sihong Xie"],"pdf_url":"https://arxiv.org/pdf/2412.07618v1.pdf","comment":"AAAI 2025"},{"id":"http://arxiv.org/abs/2412.07617v1","updated":"2024-12-10T15:54:57Z","published":"2024-12-10T15:54:57Z","title":"Swarm Behavior Cloning","summary":"  In sequential decision-making environments, the primary approaches for\ntraining agents are Reinforcement Learning (RL) and Imitation Learning (IL).\nUnlike RL, which relies on modeling a reward function, IL leverages expert\ndemonstrations, where an expert policy $\\pi_e$ (e.g., a human) provides the\ndesired behavior. Formally, a dataset $D$ of state-action pairs is provided: $D\n= {(s, a = \\pi_e(s))}$. A common technique within IL is Behavior Cloning (BC),\nwhere a policy $\\pi(s) = a$ is learned through supervised learning on $D$.\nFurther improvements can be achieved by using an ensemble of $N$ individually\ntrained BC policies, denoted as $E = {\\pi_i(s)}{1 \\leq i \\leq N}$. The\nensemble's action $a$ for a given state $s$ is the aggregated output of the $N$\nactions: $a = \\frac{1}{N} \\sum{i} \\pi_i(s)$. This paper addresses the issue of\nincreasing action differences -- the observation that discrepancies between the\n$N$ predicted actions grow in states that are underrepresented in the training\ndata. Large action differences can result in suboptimal aggregated actions. To\naddress this, we propose a method that fosters greater alignment among the\npolicies while preserving the diversity of their computations. This approach\nreduces action differences and ensures that the ensemble retains its inherent\nstrengths, such as robustness and varied decision-making. We evaluate our\napproach across eight diverse environments, demonstrating a notable decrease in\naction differences and significant improvements in overall performance, as\nmeasured by mean episode returns.\n","authors":["Jonas Nüßlein","Maximilian Zorn","Philipp Altmann","Claudia Linnhoff-Popien"],"pdf_url":"https://arxiv.org/pdf/2412.07617v1.pdf","comment":"Accepted at ICAART 2025"},{"id":"http://arxiv.org/abs/2406.00431v2","updated":"2024-12-10T15:43:05Z","published":"2024-06-01T13:10:35Z","title":"SpaFL: Communication-Efficient Federated Learning with Sparse Models and\n  Low computational Overhead","summary":"  The large communication and computation overhead of federated learning (FL)\nis one of the main challenges facing its practical deployment over\nresource-constrained clients and systems. In this work, SpaFL: a\ncommunication-efficient FL framework is proposed to optimize sparse model\nstructures with low computational overhead. In SpaFL, a trainable threshold is\ndefined for each filter/neuron to prune its all connected parameters, thereby\nleading to structured sparsity. To optimize the pruning process itself, only\nthresholds are communicated between a server and clients instead of parameters,\nthereby learning how to prune. Further, global thresholds are used to update\nmodel parameters by extracting aggregated parameter importance. The\ngeneralization bound of SpaFL is also derived, thereby proving key insights on\nthe relation between sparsity and performance. Experimental results show that\nSpaFL improves accuracy while requiring much less communication and computing\nresources compared to sparse baselines. The code is available at\nhttps://github.com/news-vt/SpaFL_NeruIPS_2024\n","authors":["Minsu Kim","Walid Saad","Merouane Debbah","Choong Seon Hong"],"pdf_url":"https://arxiv.org/pdf/2406.00431v2.pdf","comment":"Published in NeurIPS 2024"},{"id":"http://arxiv.org/abs/2412.05583v2","updated":"2024-12-10T15:35:33Z","published":"2024-12-07T08:29:44Z","title":"Electrocardiogram (ECG) Based Cardiac Arrhythmia Detection and\n  Classification using Machine Learning Algorithms","summary":"  The rapid advancements in Artificial Intelligence, specifically Machine\nLearning (ML) and Deep Learning (DL), have opened new prospects in medical\nsciences for improved diagnosis, prognosis, and treatment of severe health\nconditions. This paper focuses on the development of an ML model with high\npredictive accuracy to classify arrhythmic electrocardiogram (ECG) signals. The\nECG signals datasets utilized in this study were sourced from the PhysioNet and\nMIT-BIH databases. The research commenced with binary classification, where an\noptimized Bidirectional Long Short-Term Memory (Bi-LSTM) model yielded\nexcellent results in differentiating normal and atrial fibrillation signals. A\npivotal aspect of this research was a survey among medical professionals, which\nnot only validated the practicality of AI-based ECG classifiers but also\nidentified areas for improvement, including accuracy and the inclusion of more\narrhythmia types. These insights drove the development of an advanced\nConvolutional Neural Network (CNN) system capable of classifying five different\ntypes of ECG signals with better accuracy and precision. The CNN model's robust\nperformance was ensured through rigorous stratified 5-fold cross validation. A\nweb portal was also developed to demonstrate real-world utility, offering\naccess to the trained model for real-time classification. This study highlights\nthe potential applications of such models in remote health monitoring,\npredictive healthcare, assistive diagnostic tools, and simulated environments\nfor educational training and interdisciplinary collaboration between data\nscientists and medical personnel.\n","authors":["Atit Pokharel","Shashank Dahal","Pratik Sapkota","Bhupendra Bimal Chhetri"],"pdf_url":"https://arxiv.org/pdf/2412.05583v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07585v1","updated":"2024-12-10T15:20:56Z","published":"2024-12-10T15:20:56Z","title":"Scaling Sequential Recommendation Models with Transformers","summary":"  Modeling user preferences has been mainly addressed by looking at users'\ninteraction history with the different elements available in the system.\nTailoring content to individual preferences based on historical data is the\nmain goal of sequential recommendation.\n  The nature of the problem, as well as the good performance observed across\nvarious domains, has motivated the use of the transformer architecture, which\nhas proven effective in leveraging increasingly larger amounts of training data\nwhen accompanied by an increase in the number of model parameters. This scaling\nbehavior has brought a great deal of attention, as it provides valuable\nguidance in the design and training of even larger models.\n  Taking inspiration from the scaling laws observed in training large language\nmodels, we explore similar principles for sequential recommendation.\n  We use the full Amazon Product Data dataset, which has only been partially\nexplored in other studies, and reveal scaling behaviors similar to those found\nin language models. Compute-optimal training is possible but requires a careful\nanalysis of the compute-performance trade-offs specific to the application.\n  We also show that performance scaling translates to downstream tasks by\nfine-tuning larger pre-trained models on smaller task-specific domains. Our\napproach and findings provide a strategic roadmap for model training and\ndeployment in real high-dimensional preference spaces, facilitating better\ntraining and inference efficiency.\n  We hope this paper bridges the gap between the potential of transformers and\nthe intrinsic complexities of high-dimensional sequential recommendation in\nreal-world recommender systems.\n  Code and models can be found at https://github.com/mercadolibre/srt\n","authors":["Pablo Zivic","Hernan Vazquez","Jorge Sanchez"],"pdf_url":"https://arxiv.org/pdf/2412.07585v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07584v1","updated":"2024-12-10T15:20:23Z","published":"2024-12-10T15:20:23Z","title":"Multimodal Contextualized Support for Enhancing Video Retrieval System","summary":"  Current video retrieval systems, especially those used in competitions,\nprimarily focus on querying individual keyframes or images rather than encoding\nan entire clip or video segment. However, queries often describe an action or\nevent over a series of frames, not a specific image. This results in\ninsufficient information when analyzing a single frame, leading to less\naccurate query results. Moreover, extracting embeddings solely from images\n(keyframes) does not provide enough information for models to encode\nhigher-level, more abstract insights inferred from the video. These models tend\nto only describe the objects present in the frame, lacking a deeper\nunderstanding. In this work, we propose a system that integrates the latest\nmethodologies, introducing a novel pipeline that extracts multimodal data, and\nincorporate information from multiple frames within a video, enabling the model\nto abstract higher-level information that captures latent meanings, focusing on\nwhat can be inferred from the video clip, rather than just focusing on object\ndetection in one single image.\n","authors":["Quoc-Bao Nguyen-Le","Thanh-Huy Le-Nguyen"],"pdf_url":"https://arxiv.org/pdf/2412.07584v1.pdf","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2412.07583v1","updated":"2024-12-10T15:19:10Z","published":"2024-12-10T15:19:10Z","title":"Mobile Video Diffusion","summary":"  Video diffusion models have achieved impressive realism and controllability\nbut are limited by high computational demands, restricting their use on mobile\ndevices. This paper introduces the first mobile-optimized video diffusion\nmodel. Starting from a spatio-temporal UNet from Stable Video Diffusion (SVD),\nwe reduce memory and computational cost by reducing the frame resolution,\nincorporating multi-scale temporal representations, and introducing two novel\npruning schema to reduce the number of channels and temporal blocks.\nFurthermore, we employ adversarial finetuning to reduce the denoising to a\nsingle step. Our model, coined as MobileVD, is 523x more efficient (1817.2 vs.\n4.34 TFLOPs) with a slight quality drop (FVD 149 vs. 171), generating latents\nfor a 14x512x256 px clip in 1.7 seconds on a Xiaomi-14 Pro. Our results are\navailable at https://qualcomm-ai-research.github.io/mobile-video-diffusion/\n","authors":["Haitam Ben Yahia","Denis Korzhenkov","Ioannis Lelekas","Amir Ghodrati","Amirhossein Habibian"],"pdf_url":"https://arxiv.org/pdf/2412.07583v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.05780v2","updated":"2024-12-10T15:18:04Z","published":"2024-12-08T02:23:40Z","title":"BudgetFusion: Perceptually-Guided Adaptive Diffusion Models","summary":"  Diffusion models have shown unprecedented success in the task of\ntext-to-image generation. While these models are capable of generating\nhigh-quality and realistic images, the complexity of sequential denoising has\nraised societal concerns regarding high computational demands and energy\nconsumption. In response, various efforts have been made to improve inference\nefficiency. However, most of the existing efforts have taken a fixed approach\nwith neural network simplification or text prompt optimization. Are the quality\nimprovements from all denoising computations equally perceivable to humans? We\nobserved that images from different text prompts may require different\ncomputational efforts given the desired content. The observation motivates us\nto present BudgetFusion, a novel model that suggests the most perceptually\nefficient number of diffusion steps before a diffusion model starts to generate\nan image. This is achieved by predicting multi-level perceptual metrics\nrelative to diffusion steps. With the popular Stable Diffusion as an example,\nwe conduct both numerical analyses and user studies. Our experiments show that\nBudgetFusion saves up to five seconds per prompt without compromising\nperceptual similarity. We hope this work can initiate efforts toward answering\na core question: how much do humans perceptually gain from images created by a\ngenerative model, per watt of energy?\n","authors":["Qinchan Li","Kenneth Chen","Changyue Su","Qi Sun"],"pdf_url":"https://arxiv.org/pdf/2412.05780v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.13925v2","updated":"2024-12-10T14:46:40Z","published":"2024-06-20T01:45:44Z","title":"GenderAlign: An Alignment Dataset for Mitigating Gender Bias in Large\n  Language Models","summary":"  Large Language Models (LLMs) are prone to generating content that exhibits\ngender biases, raising significant ethical concerns. Alignment, the process of\nfine-tuning LLMs to better align with desired behaviors, is recognized as an\neffective approach to mitigate gender biases. Although proprietary LLMs have\nmade significant strides in mitigating gender bias, their alignment datasets\nare not publicly available. The commonly used and publicly available alignment\ndataset, HH-RLHF, still exhibits gender bias to some extent. There is a lack of\npublicly available alignment datasets specifically designed to address gender\nbias. Hence, we developed a new dataset named GenderAlign, aiming at mitigating\na comprehensive set of gender biases in LLMs. This dataset comprises 8k\nsingle-turn dialogues, each paired with a \"chosen\" and a \"rejected\" response.\nCompared to the \"rejected\" responses, the \"chosen\" responses demonstrate lower\nlevels of gender bias and higher quality. Furthermore, we categorized the\ngender biases in the \"rejected\" responses of GenderAlign into 4 principal\ncategories. The experimental results show the effectiveness of GenderAlign in\nreducing gender bias in LLMs.\n","authors":["Tao Zhang","Ziqian Zeng","Yuxiang Xiao","Huiping Zhuang","Cen Chen","James Foulds","Shimei Pan"],"pdf_url":"https://arxiv.org/pdf/2406.13925v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.09269v2","updated":"2024-12-10T14:43:03Z","published":"2024-09-14T02:29:36Z","title":"Guiding Vision-Language Model Selection for Visual Question-Answering\n  Across Tasks, Domains, and Knowledge Types","summary":"  Visual Question-Answering (VQA) has become key to user experience,\nparticularly after improved generalization capabilities of Vision-Language\nModels (VLMs). But evaluating VLMs for an application requirement using a\nstandardized framework in practical settings is still challenging. This paper\naims to solve that using an end-to-end framework. We present VQA360 - a novel\ndataset derived from established VQA benchmarks, annotated with task types,\napplication domains, and knowledge types, for a comprehensive evaluation. We\nalso introduce GoEval, a multimodal evaluation metric developed using GPT-4o,\nachieving a correlation factor of 56.71% with human judgments. Our experiments\nwith state-of-the-art VLMs reveal that no single model excels universally,\nthus, making a right choice a key design decision. Proprietary models such as\nGemini-1.5-Pro and GPT-4o-mini generally outperform others, but open-source\nmodels like InternVL-2-8B and CogVLM-2-Llama-3-19B also demonstrate competitive\nstrengths, while providing additional advantages. Our framework can also be\nextended to other tasks.\n","authors":["Neelabh Sinha","Vinija Jain","Aman Chadha"],"pdf_url":"https://arxiv.org/pdf/2409.09269v2.pdf","comment":"8 pages + references + 6 pages of Appendix"},{"id":"http://arxiv.org/abs/2412.07541v1","updated":"2024-12-10T14:18:30Z","published":"2024-12-10T14:18:30Z","title":"A data-driven learned discretization approach in finite volume schemes\n  for hyperbolic conservation laws and varying boundary conditions","summary":"  This paper presents a data-driven finite volume method for solving 1D and 2D\nhyperbolic partial differential equations. This work builds upon the prior\nresearch incorporating a data-driven finite-difference approximation of smooth\nsolutions of scalar conservation laws, where optimal coefficients of neural\nnetworks approximating space derivatives are learned based on accurate, but\ncumbersome solutions to these equations. We extend this approach to\nflux-limited finite volume schemes for hyperbolic scalar and systems of\nconservation laws. We also train the discretization to efficiently capture\ndiscontinuous solutions with shock and contact waves, as well as to the\napplication of boundary conditions. The learning procedure of the data-driven\nmodel is extended through the definition of a new loss, paddings and adequate\ndatabase. These new ingredients guarantee computational stability, preserve the\naccuracy of fine-grid solutions, and enhance overall performance. Numerical\nexperiments using test cases from the literature in both one- and\ntwo-dimensional spaces demonstrate that the learned model accurately reproduces\nfine-grid results on very coarse meshes.\n","authors":["Guillaume de Romémont","Florent Renac","Jorge Nunez","Francisco Chinesta"],"pdf_url":"https://arxiv.org/pdf/2412.07541v1.pdf","comment":"15 pages, 20 figures with appendice"},{"id":"http://arxiv.org/abs/2412.07538v1","updated":"2024-12-10T14:17:14Z","published":"2024-12-10T14:17:14Z","title":"Can Neural Decompilation Assist Vulnerability Prediction on Binary Code?","summary":"  Vulnerability prediction is valuable in identifying security issues more\nefficiently, even though it requires the source code of the target software\nsystem, which is a restrictive hypothesis. This paper presents an experimental\nstudy to predict vulnerabilities in binary code without source code or complex\nrepresentations of the binary, leveraging the pivotal idea of decompiling the\nbinary file through neural decompilation and predicting vulnerabilities through\ndeep learning on the decompiled source code. The results outperform the\nstate-of-the-art in both neural decompilation and vulnerability prediction,\nshowing that it is possible to identify vulnerable programs with this approach\nconcerning bi-class (vulnerable/non-vulnerable) and multi-class (type of\nvulnerability) analysis.\n","authors":["D. Cotroneo","F. C. Grasso","R. Natella","V. Orbinato"],"pdf_url":"https://arxiv.org/pdf/2412.07538v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06787v2","updated":"2024-12-10T14:09:22Z","published":"2024-12-09T18:59:56Z","title":"[MASK] is All You Need","summary":"  In generative models, two paradigms have gained attraction in various\napplications: next-set prediction-based Masked Generative Models and next-noise\nprediction-based Non-Autoregressive Models, e.g., Diffusion Models. In this\nwork, we propose using discrete-state models to connect them and explore their\nscalability in the vision domain. First, we conduct a step-by-step analysis in\na unified design space across two types of models including\ntimestep-independence, noise schedule, temperature, guidance strength, etc in a\nscalable manner. Second, we re-cast typical discriminative tasks, e.g., image\nsegmentation, as an unmasking process from [MASK] tokens on a discrete-state\nmodel. This enables us to perform various sampling processes, including\nflexible conditional sampling by only training once to model the joint\ndistribution. All aforementioned explorations lead to our framework named\nDiscrete Interpolants, which enables us to achieve state-of-the-art or\ncompetitive performance compared to previous discrete-state based methods in\nvarious benchmarks, like ImageNet256, MS COCO, and video dataset FaceForensics.\nIn summary, by leveraging [MASK] in discrete-state models, we can bridge Masked\nGenerative and Non-autoregressive Diffusion models, as well as generative and\ndiscriminative tasks.\n","authors":["Vincent Tao Hu","Björn Ommer"],"pdf_url":"https://arxiv.org/pdf/2412.06787v2.pdf","comment":"Technical Report (WIP), Project Page(code, model, dataset):\n  https://compvis.github.io/mask/"},{"id":"http://arxiv.org/abs/2408.04842v2","updated":"2024-12-10T14:02:27Z","published":"2024-08-09T03:35:53Z","title":"Counterfactual Explanations with Probabilistic Guarantees on their\n  Robustness to Model Change","summary":"  Counterfactual explanations (CFEs) guide users on how to adjust inputs to\nmachine learning models to achieve desired outputs. While existing research\nprimarily addresses static scenarios, real-world applications often involve\ndata or model changes, potentially invalidating previously generated CFEs and\nrendering user-induced input changes ineffective. Current methods addressing\nthis issue often support only specific models or change types, require\nextensive hyperparameter tuning, or fail to provide probabilistic guarantees on\nCFE robustness to model changes. This paper proposes a novel approach for\ngenerating CFEs that provides probabilistic guarantees for any model and change\ntype, while offering interpretable and easy-to-select hyperparameters. We\nestablish a theoretical framework for probabilistically defining robustness to\nmodel change and demonstrate how our BetaRCE method directly stems from it.\nBetaRCE is a post-hoc method applied alongside a chosen base CFE generation\nmethod to enhance the quality of the explanation beyond robustness. It\nfacilitates a transition from the base explanation to a more robust one with\nuser-adjusted probability bounds. Through experimental comparisons with\nbaselines, we show that BetaRCE yields robust, most plausible, and closest to\nbaseline counterfactual explanations.\n","authors":["Ignacy Stępka","Mateusz Lango","Jerzy Stefanowski"],"pdf_url":"https://arxiv.org/pdf/2408.04842v2.pdf","comment":"Accepted at 31st SIGKDD Conference on Knowledge Discovery and Data\n  Mining 2025"},{"id":"http://arxiv.org/abs/2406.16714v2","updated":"2024-12-10T13:57:46Z","published":"2024-06-24T15:16:45Z","title":"AutoDetect: Towards a Unified Framework for Automated Weakness Detection\n  in Large Language Models","summary":"  Although Large Language Models (LLMs) are becoming increasingly powerful,\nthey still exhibit significant but subtle weaknesses, such as mistakes in\ninstruction-following or coding tasks. As these unexpected errors could lead to\nsevere consequences in practical deployments, it is crucial to investigate the\nlimitations within LLMs systematically. Traditional benchmarking approaches\ncannot thoroughly pinpoint specific model deficiencies, while manual\ninspections are costly and not scalable. In this paper, we introduce a unified\nframework, AutoDetect, to automatically expose weaknesses in LLMs across\nvarious tasks. Inspired by the educational assessment process that measures\nstudents' learning outcomes, AutoDetect consists of three LLM-powered agents:\nExaminer, Questioner, and Assessor. The collaboration among these three agents\nis designed to realize comprehensive and in-depth weakness identification. Our\nframework demonstrates significant success in uncovering flaws, with an\nidentification success rate exceeding 30% in prominent models such as ChatGPT\nand Claude. More importantly, these identified weaknesses can guide specific\nmodel improvements, proving more effective than untargeted data augmentation\nmethods like Self-Instruct. Our approach has led to substantial enhancements in\npopular LLMs, including the Llama series and Mistral-7b, boosting their\nperformance by over 10% across several benchmarks. Code and data are publicly\navailable at https://github.com/thu-coai/AutoDetect.\n","authors":["Jiale Cheng","Yida Lu","Xiaotao Gu","Pei Ke","Xiao Liu","Yuxiao Dong","Hongning Wang","Jie Tang","Minlie Huang"],"pdf_url":"https://arxiv.org/pdf/2406.16714v2.pdf","comment":"EMNLP 2024 findings"},{"id":"http://arxiv.org/abs/2412.06742v2","updated":"2024-12-10T13:23:18Z","published":"2024-12-09T18:34:49Z","title":"ContRail: A Framework for Realistic Railway Image Synthesis using\n  ControlNet","summary":"  Deep Learning became an ubiquitous paradigm due to its extraordinary\neffectiveness and applicability in numerous domains. However, the approach\nsuffers from the high demand of data required to achieve the potential of this\ntype of model. An ever-increasing sub-field of Artificial Intelligence, Image\nSynthesis, aims to address this limitation through the design of intelligent\nmodels capable of creating original and realistic images, endeavour which could\ndrastically reduce the need for real data. The Stable Diffusion generation\nparadigm recently propelled state-of-the-art approaches to exceed all previous\nbenchmarks. In this work, we propose the ContRail framework based on the novel\nStable Diffusion model ControlNet, which we empower through a multi-modal\nconditioning method. We experiment with the task of synthetic railway image\ngeneration, where we improve the performance in rail-specific tasks, such as\nrail semantic segmentation by enriching the dataset with realistic synthetic\nimages.\n","authors":["Andrei-Robert Alexandrescu","Razvan-Gabriel Petec","Alexandru Manole","Laura-Silvia Diosan"],"pdf_url":"https://arxiv.org/pdf/2412.06742v2.pdf","comment":"9 pages, 5 figures, 2 tables"},{"id":"http://arxiv.org/abs/2412.07493v1","updated":"2024-12-10T13:18:45Z","published":"2024-12-10T13:18:45Z","title":"Ontology-driven Prompt Tuning for LLM-based Task and Motion Planning","summary":"  Performing complex manipulation tasks in dynamic environments requires\nefficient Task and Motion Planning (TAMP) approaches, which combine high-level\nsymbolic plan with low-level motion planning. Advances in Large Language Models\n(LLMs), such as GPT-4, are transforming task planning by offering natural\nlanguage as an intuitive and flexible way to describe tasks, generate symbolic\nplans, and reason. However, the effectiveness of LLM-based TAMP approaches is\nlimited due to static and template-based prompting, which struggles in adapting\nto dynamic environments and complex task contexts. To address these\nlimitations, this work proposes a novel ontology-driven prompt-tuning framework\nthat employs knowledge-based reasoning to refine and expand user prompts with\ntask contextual reasoning and knowledge-based environment state descriptions.\nIntegrating domain-specific knowledge into the prompt ensures semantically\naccurate and context-aware task plans. The proposed framework demonstrates its\neffectiveness by resolving semantic errors in symbolic plan generation, such as\nmaintaining logical temporal goal ordering in scenarios involving hierarchical\nobject placement. The proposed framework is validated through both simulation\nand real-world scenarios, demonstrating significant improvements over the\nbaseline approach in terms of adaptability to dynamic environments, and the\ngeneration of semantically correct task plans.\n","authors":["Muhayy Ud Din","Jan Rosell","Waseem Akram","Isiah Zaplana","Maximo A Roa","Lakmal Seneviratne","Irfan Hussain"],"pdf_url":"https://arxiv.org/pdf/2412.07493v1.pdf","comment":"Submitted to Robotics and Automation Letters"},{"id":"http://arxiv.org/abs/2406.08966v2","updated":"2024-12-10T13:03:40Z","published":"2024-06-13T09:52:44Z","title":"Separation Power of Equivariant Neural Networks","summary":"  The separation power of a machine learning model refers to its ability to\ndistinguish between different inputs and is often used as a proxy for its\nexpressivity. Indeed, knowing the separation power of a family of models is a\nnecessary condition to obtain fine-grained universality results. In this paper,\nwe analyze the separation power of equivariant neural networks, such as\nconvolutional and permutation-invariant networks. We first present a complete\ncharacterization of inputs indistinguishable by models derived by a given\narchitecture. From this results, we derive how separability is influenced by\nhyperparameters and architectural choices-such as activation functions, depth,\nhidden layer width, and representation types. Notably, all non-polynomial\nactivations, including ReLU and sigmoid, are equivalent in expressivity and\nreach maximum separation power. Depth improves separation power up to a\nthreshold, after which further increases have no effect. Adding invariant\nfeatures to hidden representations does not impact separation power. Finally,\nblock decomposition of hidden representations affects separability, with\nminimal components forming a hierarchy in separation power that provides a\nstraightforward method for comparing the separation power of models.\n","authors":["Marco Pacini","Xiaowen Dong","Bruno Lepri","Gabriele Santin"],"pdf_url":"https://arxiv.org/pdf/2406.08966v2.pdf","comment":"10 pages of main text, 1 figure"},{"id":"http://arxiv.org/abs/2410.10879v2","updated":"2024-12-10T13:00:22Z","published":"2024-10-09T11:54:41Z","title":"Enhancing Vision-Language Model Pre-training with Image-text Pair\n  Pruning Based on Word Frequency","summary":"  We propose Word-Frequency-based Image-Text Pair Pruning (WFPP), a novel data\npruning method that improves the efficiency of VLMs. Unlike MetaCLIP, our\nmethod does not need metadata for pruning, but selects text-image pairs to\nprune based on the content of the text. Specifically, WFPP prunes text-image\npairs containing high-frequency words across the entire training dataset. The\neffect of WFPP is to reduce the dominance of frequent words. The result a\nbetter balanced word-frequency distribution in the dataset, which is known to\nimprove the training of word embedding models. After pre-training on the pruned\nsubset, we fine-tuned the model on the entire dataset for one additional epoch\nto achieve better performance. Our experiments demonstrate that applying WFPP\nwhen training a CLIP model improves performance on a wide range of downstream\ntasks. WFPP also provides the advantage of speeding up pre-training by using\nfewer samples. Additionally, we analyze the training data before and after\npruning to visualize how WFPP changes the balance of word frequencies. We hope\nour work encourages researchers to consider the distribution of words in the\ntraining data when pre-training VLMs, not limited to CLIP.\n","authors":["Mingliang Liang","Martha Larson"],"pdf_url":"https://arxiv.org/pdf/2410.10879v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07472v1","updated":"2024-12-10T12:40:35Z","published":"2024-12-10T12:40:35Z","title":"SmartAgent: Chain-of-User-Thought for Embodied Personalized Agent in\n  Cyber World","summary":"  Recent advances in embodied agents with multimodal perception and reasoning\ncapabilities based on large vision-language models (LVLMs), excel in\nautonomously interacting either real or cyber worlds, helping people make\nintelligent decisions in complex environments. However, the current works are\nnormally optimized by golden action trajectories or ideal task-oriented\nsolutions toward a definitive goal. This paradigm considers limited\nuser-oriented factors, which could be the reason for their performance\nreduction in a wide range of personal assistant applications. To address this,\nwe propose Chain-of-User-Thought (COUT), a novel embodied reasoning paradigm\nthat takes a chain of thought from basic action thinking to explicit and\nimplicit personalized preference thought to incorporate personalized factors\ninto autonomous agent learning. To target COUT, we introduce SmartAgent, an\nagent framework perceiving cyber environments and reasoning personalized\nrequirements as 1) interacting with GUI to access an item pool, 2) generating\nusers' explicit requirements implied by previous actions, and 3) recommending\nitems to fulfill users' implicit requirements. To demonstrate SmartAgent's\ncapabilities, we also create a brand-new dataset SmartSpot that offers a\nfull-stage personalized action-involved environment. To our best knowledge, our\nwork is the first to formulate the COUT process, serving as a preliminary\nattempt towards embodied personalized agent learning. Our extensive experiments\non SmartSpot illuminate SmartAgent's functionality among a series of embodied\nand personalized sub-tasks. We will release code and data upon paper\nnotification at \\url{https://github.com/tsinghua-fib-lab/SmartAgent}.\n","authors":["Jiaqi Zhang","Chen Gao","Liyuan Zhang","Yong Li","Hongzhi Yin"],"pdf_url":"https://arxiv.org/pdf/2412.07472v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17643v2","updated":"2024-12-10T12:36:09Z","published":"2024-03-26T12:23:34Z","title":"S+t-SNE -- Bringing Dimensionality Reduction to Data Streams","summary":"  We present S+t-SNE, an adaptation of the t-SNE algorithm designed to handle\ninfinite data streams. The core idea behind S+t-SNE is to update the t-SNE\nembedding incrementally as new data arrives, ensuring scalability and\nadaptability to handle streaming scenarios. By selecting the most important\npoints at each step, the algorithm ensures scalability while keeping\ninformative visualisations. By employing a blind method for drift management,\nthe algorithm adjusts the embedding space, which facilitates the visualisation\nof evolving data dynamics. Our experimental evaluations demonstrate the\neffectiveness and efficiency of S+t-SNE, whilst highlighting its ability to\ncapture patterns in a streaming scenario. We hope our approach offers\nresearchers and practitioners a real-time tool for understanding and\ninterpreting high-dimensional data.\n","authors":["Pedro C. Vieira","João P. Montrezol","João T. Vieira","João Gama"],"pdf_url":"https://arxiv.org/pdf/2403.17643v2.pdf","comment":"This preprint has undergone peer review but does not have any\n  post-submission improvements or corrections. Full version after peer-review\n  and post-acceptance improvements was presented at IDA2024\n  (https://ida2024.org/)"},{"id":"http://arxiv.org/abs/2412.07454v1","updated":"2024-12-10T12:20:42Z","published":"2024-12-10T12:20:42Z","title":"Tazza: Shuffling Neural Network Parameters for Secure and Private\n  Federated Learning","summary":"  Federated learning enables decentralized model training without sharing raw\ndata, preserving data privacy. However, its vulnerability towards critical\nsecurity threats, such as gradient inversion and model poisoning by malicious\nclients, remain unresolved. Existing solutions often address these issues\nseparately, sacrificing either system robustness or model accuracy. This work\nintroduces Tazza, a secure and efficient federated learning framework that\nsimultaneously addresses both challenges. By leveraging the permutation\nequivariance and invariance properties of neural networks via weight shuffling\nand shuffled model validation, Tazza enhances resilience against diverse\npoisoning attacks, while ensuring data confidentiality and high model accuracy.\nComprehensive evaluations on various datasets and embedded platforms show that\nTazza achieves robust defense with up to 6.7x improved computational efficiency\ncompared to alternative schemes, without compromising performance.\n","authors":["Kichang Lee","Jaeho Jin","JaeYeon Park","JeongGil Ko"],"pdf_url":"https://arxiv.org/pdf/2412.07454v1.pdf","comment":"14 pages, 14 figures"},{"id":"http://arxiv.org/abs/2412.07448v1","updated":"2024-12-10T12:05:56Z","published":"2024-12-10T12:05:56Z","title":"Dynamic Ensemble Reasoning for LLM Experts","summary":"  Ensemble reasoning for the strengths of different LLM experts is critical to\nachieving consistent and satisfactory performance on diverse inputs across a\nwide range of tasks. However, existing LLM ensemble methods are either\ncomputationally intensive or incapable of leveraging complementary knowledge\namong LLM experts for various inputs. In this paper, we propose a Dynamic\nEnsemble Reasoning paradigm, called DER to integrate the strengths of multiple\nLLM experts conditioned on dynamic inputs. Specifically, we model the LLM\nensemble reasoning problem as a Markov Decision Process (MDP), wherein an agent\nsequentially takes inputs to request knowledge from an LLM candidate and passes\nthe output to a subsequent LLM candidate. Moreover, we devise a reward function\nto train a DER-Agent to dynamically select an optimal answering route given the\ninput questions, aiming to achieve the highest performance with as few\ncomputational resources as possible. Last, to fully transfer the expert\nknowledge from the prior LLMs, we develop a Knowledge Transfer Prompt (KTP)\nthat enables the subsequent LLM candidates to transfer complementary knowledge\neffectively. Experiments demonstrate that our method uses fewer computational\nresources to achieve better performance compared to state-of-the-art baselines.\n","authors":["Jinwu Hu","Yufeng Wang","Shuhai Zhang","Kai Zhou","Guohao Chen","Yu Hu","Bin Xiao","Mingkui Tan"],"pdf_url":"https://arxiv.org/pdf/2412.07448v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2412.07446v1","updated":"2024-12-10T12:05:03Z","published":"2024-12-10T12:05:03Z","title":"Causal World Representation in the GPT Model","summary":"  Are generative pre-trained transformer (GPT) models only trained to predict\nthe next token, or do they implicitly learn a world model from which a sequence\nis generated one token at a time? We examine this question by deriving a causal\ninterpretation of the attention mechanism in GPT, and suggesting a causal world\nmodel that arises from this interpretation. Furthermore, we propose that\nGPT-models, at inference time, can be utilized for zero-shot causal structure\nlearning for in-distribution sequences. Empirical evaluation is conducted in a\ncontrolled synthetic environment using the setup and rules of the Othello board\ngame. A GPT, pre-trained on real-world games played with the intention of\nwinning, is tested on synthetic data that only adheres to the game rules. We\nfind that the GPT model tends to generate next moves that adhere to the game\nrules for sequences for which the attention mechanism encodes a causal\nstructure with high confidence. In general, in cases for which the GPT model\ngenerates moves that do not adhere to the game rules, it also fails to capture\nany causal structure.\n","authors":["Raanan Y. Rohekar","Yaniv Gurwicz","Sungduk Yu","Vasudev Lal"],"pdf_url":"https://arxiv.org/pdf/2412.07446v1.pdf","comment":"NeurIPS 2024 Workshop on Causality and Large Models (CaLM)"},{"id":"http://arxiv.org/abs/2412.07441v1","updated":"2024-12-10T11:57:47Z","published":"2024-12-10T11:57:47Z","title":"Reconstructing Deep Neural Networks: Unleashing the Optimization\n  Potential of Natural Gradient Descent","summary":"  Natural gradient descent (NGD) is a powerful optimization technique for\nmachine learning, but the computational complexity of the inverse Fisher\ninformation matrix limits its application in training deep neural networks. To\novercome this challenge, we propose a novel optimization method for training\ndeep neural networks called structured natural gradient descent (SNGD).\nTheoretically, we demonstrate that optimizing the original network using NGD is\nequivalent to using fast gradient descent (GD) to optimize the reconstructed\nnetwork with a structural transformation of the parameter matrix. Thereby, we\ndecompose the calculation of the global Fisher information matrix into the\nefficient computation of local Fisher matrices via constructing local Fisher\nlayers in the reconstructed network to speed up the training. Experimental\nresults on various deep networks and datasets demonstrate that SNGD achieves\nfaster convergence speed than NGD while retaining comparable solutions.\nFurthermore, our method outperforms traditional GDs in terms of efficiency and\neffectiveness. Thus, our proposed method has the potential to significantly\nimprove the scalability and efficiency of NGD in deep learning applications.\nOur source code is available at https://github.com/Chaochao-Lin/SNGD.\n","authors":["Weihua Liu","Said Boumaraf","Jianwu Li","Chaochao Lin","Xiabi Liu","Lijuan Niu","Naoufel Werghi"],"pdf_url":"https://arxiv.org/pdf/2412.07441v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07431v1","updated":"2024-12-10T11:41:55Z","published":"2024-12-10T11:41:55Z","title":"BENet: A Cross-domain Robust Network for Detecting Face Forgeries via\n  Bias Expansion and Latent-space Attention","summary":"  In response to the growing threat of deepfake technology, we introduce BENet,\na Cross-Domain Robust Bias Expansion Network. BENet enhances the detection of\nfake faces by addressing limitations in current detectors related to variations\nacross different types of fake face generation techniques, where\n``cross-domain\" refers to the diverse range of these deepfakes, each considered\na separate domain. BENet's core feature is a bias expansion module based on\nautoencoders. This module maintains genuine facial features while enhancing\ndifferences in fake reconstructions, creating a reliable bias for detecting\nfake faces across various deepfake domains. We also introduce a Latent-Space\nAttention (LSA) module to capture inconsistencies related to fake faces at\ndifferent scales, ensuring robust defense against advanced deepfake techniques.\nThe enriched LSA feature maps are multiplied with the expanded bias to create a\nversatile feature space optimized for subtle forgeries detection. To improve\nits ability to detect fake faces from unknown sources, BENet integrates a\ncross-domain detector module that enhances recognition accuracy by verifying\nthe facial domain during inference. We train our network end-to-end with a\nnovel bias expansion loss, adopted for the first time, in face forgery\ndetection. Extensive experiments covering both intra and cross-dataset\ndemonstrate BENet's superiority over current state-of-the-art solutions.\n","authors":["Weihua Liu","Jianhua Qiu","Said Boumaraf","Chaochao lin","Pan liyuan","Lin Li","Mohammed Bennamoun","Naoufel Werghi"],"pdf_url":"https://arxiv.org/pdf/2412.07431v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07430v1","updated":"2024-12-10T11:40:47Z","published":"2024-12-10T11:40:47Z","title":"Knowledge Graph Guided Evaluation of Abstention Techniques","summary":"  To deploy language models safely, it is crucial that they abstain from\nresponding to inappropriate requests. Several prior studies test the safety\npromises of models based on their effectiveness in blocking malicious requests.\nIn this work, we focus on evaluating the underlying techniques that cause\nmodels to abstain. We create SELECT, a benchmark derived from a set of benign\nconcepts (e.g., \"rivers\") from a knowledge graph. The nature of SELECT enables\nus to isolate the effects of abstention techniques from other safety training\nprocedures, as well as evaluate their generalization and specificity. Using\nSELECT, we benchmark different abstention techniques over six open-weight and\nclosed-source models. We find that the examined techniques indeed cause models\nto abstain with over $80\\%$ abstention rates. However, these techniques are not\nas effective for descendants of the target concepts, with refusal rates\ndeclining by $19\\%$. We also characterize the generalization-vs-specificity\ntrade-offs for different techniques. Overall, no single technique is invariably\nbetter than the others. Our findings call for a careful evaluation of different\naspects of abstention, and hopefully inform practitioners of various trade-offs\ninvolved.\n","authors":["Kinshuk Vasisht","Navreet Kaur","Danish Pruthi"],"pdf_url":"https://arxiv.org/pdf/2412.07430v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07429v1","updated":"2024-12-10T11:40:11Z","published":"2024-12-10T11:40:11Z","title":"Optimizing Alignment with Less: Leveraging Data Augmentation for\n  Personalized Evaluation","summary":"  Automatic evaluation by large language models (LLMs) is a prominent topic\ntoday; however, judgment and evaluation tasks are often subjective and\ninfluenced by various factors, making adaptation challenging. While many\nstudies demonstrate the capabilities of state-of-the-art proprietary LLMs in\ncomparison to human evaluators, they often struggle to adapt to reference\nevaluators over time, a requirement for achieving personalized judgment.\nAdditionally, numerous works have attempted to apply open LLMs as judges or\nevaluators, but these efforts frequently overlook the limitations of working\nwith scarce data. Personalized judgment is inherently associated with limited\ndata scenarios, which are common in many real-world problems. Our work aims to\npresent a data augmentation technique to select a more effective sample from\nlimited data in order to align an open LLM with human preference. Our work\nachieves approximately 7% improvements in Pearson correlation with a reference\njudge over the baseline,and 30% improvement over the base model\n(Llama3.1-8B-Instruct) in the mathematical reasoning evaluation task.\ndemonstrating that augmenting selecting more effective preference data enables\nour approach to surpass baseline methods.\n","authors":["Javad Seraj","Mohammad Mahdi Mohajeri","Mohammad Javad Dousti","Majid Nili Ahmadabadi"],"pdf_url":"https://arxiv.org/pdf/2412.07429v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12226v3","updated":"2024-12-10T11:34:07Z","published":"2023-01-28T15:34:03Z","title":"Unveiling Environmental Sensitivity of Individual Gains in Influence\n  Maximization","summary":"  Influence Maximization (IM) is to identify the seed set to maximize\ninformation dissemination in a network. Elegant IM algorithms could naturally\nextend to cases where each node is equipped with a specific weight, reflecting\nindividual gains to measure the node's importance. Prevailing literature\ntypically assumes such individual gains remain constant throughout the cascade\nprocess and are solvable through explicit formulas based on the node's\ncharacteristics and network topology. However, this assumption is not always\nfeasible for two reasons: 1)Unobservability: The individual gains of each node\nare primarily evaluated by the difference between the outputs in the activated\nand non-activated states. In practice, we can only observe one of these states,\nwith the other remaining unobservable post-propagation. 2)Environmental\nsensitivity: In addition to the node's inherent properties, individual gains\nare also sensitive to the activation status of surrounding nodes, which is\ndynamic during iteration even when the network topology remains static. To\naddress these challenges, we extend the consideration of IM to a broader\nscenario with dynamic node individual gains, leveraging causality techniques.\nIn our paper, we introduce a Causal Influence Maximization (CauIM) framework\nand develop two algorithms, G-CauIM and A-CauIM, where the latter incorporates\na novel acceleration technique. Theoretically, we establish the generalized\nlower bound of influence spread and provide robustness analysis. Empirically,\nin synthetic and real-world experiments, we demonstrate the effectiveness and\nrobustness of our algorithms.\n","authors":["Xinyan Su","Zhiheng Zhang","Jiyan Qiu"],"pdf_url":"https://arxiv.org/pdf/2301.12226v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.06430v2","updated":"2024-12-10T11:21:26Z","published":"2024-04-09T16:23:01Z","title":"pfl-research: simulation framework for accelerating research in Private\n  Federated Learning","summary":"  Federated learning (FL) is an emerging machine learning (ML) training\nparadigm where clients own their data and collaborate to train a global model,\nwithout revealing any data to the server and other participants. Researchers\ncommonly perform experiments in a simulation environment to quickly iterate on\nideas. However, existing open-source tools do not offer the efficiency required\nto simulate FL on larger and more realistic FL datasets. We introduce\npfl-research, a fast, modular, and easy-to-use Python framework for simulating\nFL. It supports TensorFlow, PyTorch, and non-neural network models, and is\ntightly integrated with state-of-the-art privacy algorithms. We study the speed\nof open-source FL frameworks and show that pfl-research is 7-72$\\times$ faster\nthan alternative open-source frameworks on common cross-device setups. Such\nspeedup will significantly boost the productivity of the FL research community\nand enable testing hypotheses on realistic FL datasets that were previously too\nresource intensive. We release a suite of benchmarks that evaluates an\nalgorithm's overall performance on a diverse set of realistic scenarios. The\ncode is available on GitHub at https://github.com/apple/pfl-research.\n","authors":["Filip Granqvist","Congzheng Song","Áine Cahill","Rogier van Dalen","Martin Pelikan","Yi Sheng Chan","Xiaojun Feng","Natarajan Krishnaswami","Vojta Jina","Mona Chitnis"],"pdf_url":"https://arxiv.org/pdf/2404.06430v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.11018v2","updated":"2024-12-10T11:20:21Z","published":"2023-12-18T08:35:10Z","title":"Hypergrah-Enhanced Dual Convolutional Network for Bundle Recommendation","summary":"  Bundle recommendations strive to offer users a set of items as a package\nnamed bundle, enhancing convenience and contributing to the seller's revenue.\nWhile previous approaches have demonstrated notable performance, we argue that\nthey may compromise the ternary relationship among users, items, and bundles.\nThis compromise can result in information loss, ultimately impacting the\noverall model performance. To address this gap, we develop a unified model for\nbundle recommendation, termed hypergraph-enhanced dual convolutional neural\nnetwork (HED). Our approach is characterized by two key aspects. Firstly, we\nconstruct a complete hypergraph to capture interaction dynamics among users,\nitems, and bundles. Secondly, we incorporate U-B interaction information to\nenhance the information representation derived from users and bundle embedding\nvectors. Extensive experimental results on the Youshu and Netease datasets have\ndemonstrated that HED surpasses state-of-the-art baselines, proving its\neffectiveness. In addition, various ablation studies and sensitivity analyses\nrevealed the working mechanism and proved our effectiveness. Codes and datasets\nare available at https://github.com/AAI-Lab/HED\n","authors":["Yang Li","Kangbo Liu","Yaoxin Wu","Zhaoxuan Wang","Erik Cambria","Xiaoxu Wang"],"pdf_url":"https://arxiv.org/pdf/2312.11018v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07412v1","updated":"2024-12-10T11:05:26Z","published":"2024-12-10T11:05:26Z","title":"Generating Knowledge Graphs from Large Language Models: A Comparative\n  Study of GPT-4, LLaMA 2, and BERT","summary":"  Knowledge Graphs (KGs) are essential for the functionality of GraphRAGs, a\nform of Retrieval-Augmented Generative Systems (RAGs) that excel in tasks\nrequiring structured reasoning and semantic understanding. However, creating\nKGs for GraphRAGs remains a significant challenge due to accuracy and\nscalability limitations of traditional methods. This paper introduces a novel\napproach leveraging large language models (LLMs) like GPT-4, LLaMA 2 (13B), and\nBERT to generate KGs directly from unstructured data, bypassing traditional\npipelines. Using metrics such as Precision, Recall, F1-Score, Graph Edit\nDistance, and Semantic Similarity, we evaluate the models' ability to generate\nhigh-quality KGs. Results demonstrate that GPT-4 achieves superior semantic\nfidelity and structural accuracy, LLaMA 2 excels in lightweight,\ndomain-specific graphs, and BERT provides insights into challenges in\nentity-relationship modeling. This study underscores the potential of LLMs to\nstreamline KG creation and enhance GraphRAG accessibility for real-world\napplications, while setting a foundation for future advancements.\n","authors":["Ahan Bhatt","Nandan Vaghela","Kush Dudhia"],"pdf_url":"https://arxiv.org/pdf/2412.07412v1.pdf","comment":"4 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2412.07411v1","updated":"2024-12-10T11:03:51Z","published":"2024-12-10T11:03:51Z","title":"DSFEC: Efficient and Deployable Deep Radar Object Detection","summary":"  Deploying radar object detection models on resource-constrained edge devices\nlike the Raspberry Pi poses significant challenges due to the large size of the\nmodel and the limited computational power and the memory of the Pi. In this\nwork, we explore the efficiency of Depthwise Separable Convolutions in radar\nobject detection networks and integrate them into our model. Additionally, we\nintroduce a novel Feature Enhancement and Compression (FEC) module to the\nPointPillars feature encoder to further improve the model performance. With\nthese innovations, we propose the DSFEC-L model and its two versions, which\noutperform the baseline (23.9 mAP of Car class, 20.72 GFLOPs) on nuScenes\ndataset: 1). An efficient DSFEC-M model with a 14.6% performance improvement\nand a 60% reduction in GFLOPs. 2). A deployable DSFEC-S model with a 3.76%\nperformance improvement and a remarkable 78.5% reduction in GFLOPs. Despite\nmarginal performance gains, our deployable model achieves an impressive 74.5%\nreduction in runtime on the Raspberry Pi compared to the baseline.\n","authors":["Gayathri Dandugula","Santhosh Boddana","Sudesh Mirashi"],"pdf_url":"https://arxiv.org/pdf/2412.07411v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07408v1","updated":"2024-12-10T10:59:43Z","published":"2024-12-10T10:59:43Z","title":"Explainability of Deep Learning-Based Plant Disease Classifiers Through\n  Automated Concept Identification","summary":"  While deep learning has significantly advanced automatic plant disease\ndetection through image-based classification, improving model explainability\nremains crucial for reliable disease detection. In this study, we apply the\nAutomated Concept-based Explanation (ACE) method to plant disease\nclassification using the widely adopted InceptionV3 model and the PlantVillage\ndataset. ACE automatically identifies the visual concepts found in the image\ndata and provides insights about the critical features influencing the model\npredictions. This approach reveals both effective disease-related patterns and\nincidental biases, such as those from background or lighting that can\ncompromise model robustness. Through systematic experiments, ACE helped us to\nidentify relevant features and pinpoint areas for targeted model improvement.\nOur findings demonstrate the potential of ACE to improve the explainability of\nplant disease classification based on deep learning, which is essential for\nproducing transparent tools for plant disease management in agriculture.\n","authors":["Jihen Amara","Birgitta König-Ries","Sheeba Samuel"],"pdf_url":"https://arxiv.org/pdf/2412.07408v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07405v1","updated":"2024-12-10T10:55:57Z","published":"2024-12-10T10:55:57Z","title":"MoDULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task\n  Learning","summary":"  The growing demand for larger-scale models in the development of\n\\textbf{L}arge \\textbf{L}anguage \\textbf{M}odels (LLMs) poses challenges for\nefficient training within limited computational resources. Traditional\nfine-tuning methods often exhibit instability in multi-task learning and rely\nheavily on extensive training resources. Here, we propose MoDULA\n(\\textbf{M}ixture \\textbf{o}f \\textbf{D}omain-Specific and \\textbf{U}niversal\n\\textbf{L}oR\\textbf{A}), a novel \\textbf{P}arameter \\textbf{E}fficient\n\\textbf{F}ine-\\textbf{T}uning (PEFT)\n\\textbf{M}ixture-\\textbf{o}f-\\textbf{E}xpert (MoE) paradigm for improved\nfine-tuning and parameter efficiency in multi-task learning. The paradigm\neffectively improves the multi-task capability of the model by training\nuniversal experts, domain-specific experts, and routers separately. MoDULA-Res\nis a new method within the MoDULA paradigm, which maintains the model's general\ncapability by connecting universal and task-specific experts through residual\nconnections. The experimental results demonstrate that the overall performance\nof the MoDULA-Flan and MoDULA-Res methods surpasses that of existing\nfine-tuning methods on various LLMs. Notably, MoDULA-Res achieves more\nsignificant performance improvements in multiple tasks while reducing training\ncosts by over 80\\% without losing general capability. Moreover, MoDULA displays\nflexible pluggability, allowing for the efficient addition of new tasks without\nretraining existing experts from scratch. This progressive training paradigm\ncircumvents data balancing issues, enhancing training efficiency and model\nstability. Overall, MoDULA provides a scalable, cost-effective solution for\nfine-tuning LLMs with enhanced parameter efficiency and generalization\ncapability.\n","authors":["Yufei Ma","Zihan Liang","Huangyu Dai","Ben Chen","Dehong Gao","Zhuoran Ran","Wang Zihan","Linbo Jin","Wen Jiang","Guannan Zhang","Xiaoyan Cai","Libin Yang"],"pdf_url":"https://arxiv.org/pdf/2412.07405v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07402v1","updated":"2024-12-10T10:52:32Z","published":"2024-12-10T10:52:32Z","title":"Non-Progressive Influence Maximization in Dynamic Social Networks","summary":"  The influence maximization (IM) problem involves identifying a set of key\nindividuals in a social network who can maximize the spread of influence\nthrough their network connections. With the advent of geometric deep learning\non graphs, great progress has been made towards better solutions for the IM\nproblem. In this paper, we focus on the dynamic non-progressive IM problem,\nwhich considers the dynamic nature of real-world social networks and the\nspecial case where the influence diffusion is non-progressive, i.e., nodes can\nbe activated multiple times. We first extend an existing diffusion model to\ncapture the non-progressive influence propagation in dynamic social networks.\nWe then propose the method, DNIMRL, which employs deep reinforcement learning\nand dynamic graph embedding to solve the dynamic non-progressive IM problem. In\nparticular, we propose a novel algorithm that effectively leverages graph\nembedding to capture the temporal changes of dynamic networks and seamlessly\nintegrates with deep reinforcement learning. The experiments, on different\ntypes of real-world social network datasets, demonstrate that our method\noutperforms state-of-the-art baselines.\n","authors":["Yunming Hui","Shihan Wang","Melisachew Wudage Chekol","Stevan Rudinac","Inez Maria Zwetsloot"],"pdf_url":"https://arxiv.org/pdf/2412.07402v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2103.13860v6","updated":"2024-12-10T10:35:53Z","published":"2021-03-25T14:17:09Z","title":"Active Inference Tree Search in Large POMDPs","summary":"  The ability to plan ahead efficiently is key for both living organisms and\nartificial systems. Model-based planning and prospection are widely studied in\ncognitive neuroscience and artificial intelligence (AI), but from different\nperspectives--and with different desiderata in mind (biological realism versus\nscalability) that are difficult to reconcile. Here, we introduce a novel method\nto plan in POMDPs--Active Inference Tree Search (AcT)--that combines the\nnormative character and biological realism of a leading planning theory in\nneuroscience (Active Inference) and the scalability of tree search methods in\nAI. This unification enhances both approaches. On the one hand, tree searches\nenable the biologically grounded, first principle method of active inference to\nbe applied to large-scale problems. On the other hand, active inference\nprovides a principled solution to the exploration-exploitation dilemma, which\nis often addressed heuristically in tree search methods. Our simulations show\nthat AcT successfully navigates binary trees that are challenging for\nsampling-based methods, problems that require adaptive exploration, and the\nlarge POMDP problem 'RockSample'--in which AcT reproduces state-of-the-art\nPOMDP solutions. Furthermore, we illustrate how AcT can be used to simulate\nneurophysiological responses (e.g., in the hippocampus and prefrontal cortex)\nof humans and other animals that solve large planning problems. These numerical\nanalyses show that Active Tree Search is a principled realisation of\nneuroscientific and AI planning theories, which offer both biological realism\nand scalability.\n","authors":["Domenico Maisto","Francesco Gregoretti","Karl Friston","Giovanni Pezzulo"],"pdf_url":"https://arxiv.org/pdf/2103.13860v6.pdf","comment":"47 pages, 9 figures, 1 Appendix of two sections with pseudocodes and\n  one encoding example, submitted preprint"},{"id":"http://arxiv.org/abs/2412.07393v1","updated":"2024-12-10T10:35:19Z","published":"2024-12-10T10:35:19Z","title":"CMT: A Memory Compression Method for Continual Knowledge Learning of\n  Large Language Models","summary":"  Large Language Models (LLMs) need to adapt to the continuous changes in data,\ntasks, and user preferences. Due to their massive size and the high costs\nassociated with training, LLMs are not suitable for frequent retraining.\nHowever, updates are necessary to keep them in sync with rapidly evolving human\nknowledge. To address these challenges, this paper proposes the Compression\nMemory Training (CMT) method, an efficient and effective online adaptation\nframework for LLMs that features robust knowledge retention capabilities.\nInspired by human memory mechanisms, CMT compresses and extracts information\nfrom new documents to be stored in a memory bank. When answering to queries\nrelated to these new documents, the model aggregates these document memories\nfrom the memory bank to better answer user questions. The parameters of the LLM\nitself do not change during training and inference, reducing the risk of\ncatastrophic forgetting. To enhance the encoding, retrieval, and aggregation of\nmemory, we further propose three new general and flexible techniques, including\nmemory-aware objective, self-matching and top-aggregation. Extensive\nexperiments conducted on three continual learning datasets (i.e., StreamingQA,\nSQuAD and ArchivalQA) demonstrate that the proposed method improves model\nadaptability and robustness across multiple base LLMs (e.g., +4.07 EM & +4.19\nF1 in StreamingQA with Llama-2-7b).\n","authors":["Dongfang Li","Zetian Sun","Xinshuo Hu","Baotian Hu","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.07393v1.pdf","comment":"AAAI 2025; Pre-print"},{"id":"http://arxiv.org/abs/2412.07388v1","updated":"2024-12-10T10:32:22Z","published":"2024-12-10T10:32:22Z","title":"A Review of Challenges in Speech-based Conversational AI for Elderly\n  Care","summary":"  Artificially intelligent systems optimized for speech conversation are\nappearing at a fast pace. Such models are interesting from a healthcare\nperspective, as these voice-controlled assistants may support the elderly and\nenable remote health monitoring. The bottleneck for efficacy, however, is how\nwell these devices work in practice and how the elderly experience them, but\nresearch on this topic is scant. We review elderly use of voice-controlled AI\nand highlight various user- and technology-centered issues, that need to be\nconsidered before effective speech-controlled AI for elderly care can be\nrealized.\n","authors":["Willemijn Klaassen","Bram van Dijk","Marco Spruit"],"pdf_url":"https://arxiv.org/pdf/2412.07388v1.pdf","comment":"Accepted for publication at Medical Informatics Europe 2025\n  conference, Glasgow. 5 pages, 1 figure, 1 table"},{"id":"http://arxiv.org/abs/2412.07387v1","updated":"2024-12-10T10:32:09Z","published":"2024-12-10T10:32:09Z","title":"Enhanced MRI Representation via Cross-series Masking","summary":"  Magnetic resonance imaging (MRI) is indispensable for diagnosing and planning\ntreatment in various medical conditions due to its ability to produce\nmulti-series images that reveal different tissue characteristics. However,\nintegrating these diverse series to form a coherent analysis presents\nsignificant challenges, such as differing spatial resolutions and contrast\npatterns meanwhile requiring extensive annotated data, which is scarce in\nclinical practice. Due to these issues, we introduce a novel Cross-Series\nMasking (CSM) Strategy for effectively learning MRI representation in a\nself-supervised manner. Specifically, CSM commences by randomly sampling a\nsubset of regions and series, which are then strategically masked. In the\ntraining process, the cross-series representation is learned by utilizing the\nunmasked data to reconstruct the masked portions. This process not only\nintegrates information across different series but also facilitates the ability\nto model both intra-series and inter-series correlations and complementarities.\nWith the learned representation, the downstream tasks like segmentation and\nclassification are also enhanced. Taking brain tissue segmentation, breast\ntumor benign/malignant classification, and prostate cancer diagnosis as\nexamples, our method achieves state-of-the-art performance on both public and\nin-house datasets.\n","authors":["Churan Wang","Fei Gao","Lijun Yan","Siwen Wang","Yizhou Yu","Yizhou Wang"],"pdf_url":"https://arxiv.org/pdf/2412.07387v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07380v1","updated":"2024-12-10T10:27:41Z","published":"2024-12-10T10:27:41Z","title":"SpecFuse: Ensembling Large Language Models via Next-Segment Prediction","summary":"  Ensembles of generative large language models (LLMs) can integrate the\nstrengths of different LLMs to compensate for the limitations of individual\nmodels. However, recent work has focused on training an additional fusion model\nto combine complete responses from multiple LLMs, failing to tap into their\ncollaborative potential to generate higher-quality responses. Moreover, as the\nadditional fusion model is trained on a specialized dataset, these methods\nstruggle with generalizing to open-domain queries from online users. In this\npaper, we propose SpecFuse, a novel ensemble framework that outputs the fused\nresult by iteratively producing the next segment through collaboration among\nLLMs. This is achieved through cyclic execution of its inference and\nverification components. In each round, the inference component invokes each\nbase LLM to generate candidate segments in parallel, and the verify component\ncalls these LLMs again to predict the ranking of the segments. The top-ranked\nsegment is then broadcast to all LLMs, encouraging them to generate\nhigher-quality segments in the next round. This approach also allows the base\nLLMs to be plug-and-play, without any training or adaptation, avoiding\ngeneralization limitations. Furthermore, to conserve computational resources,\nwe propose a model exit mechanism that dynamically excludes models exhibiting\npoor performance in previous rounds during each query response. In this way, it\neffectively reduces the number of model calls while maintaining overall\nperformance.\n","authors":["Bo Lv","Chen Tang","Yanan Zhang","Xin Liu","Yue Yu","Ping Luo"],"pdf_url":"https://arxiv.org/pdf/2412.07380v1.pdf","comment":"15 pages, 5 figures"},{"id":"http://arxiv.org/abs/2411.11451v2","updated":"2024-12-10T09:59:27Z","published":"2024-11-18T10:34:14Z","title":"Robust Markov Decision Processes: A Place Where AI and Formal Methods\n  Meet","summary":"  Markov decision processes (MDPs) are a standard model for sequential\ndecision-making problems and are widely used across many scientific areas,\nincluding formal methods and artificial intelligence (AI). MDPs do, however,\ncome with the restrictive assumption that the transition probabilities need to\nbe precisely known. Robust MDPs (RMDPs) overcome this assumption by instead\ndefining the transition probabilities to belong to some uncertainty set. We\npresent a gentle survey on RMDPs, providing a tutorial covering their\nfundamentals. In particular, we discuss RMDP semantics and how to solve them by\nextending standard MDP methods such as value iteration and policy iteration. We\nalso discuss how RMDPs relate to other models and how they are used in several\ncontexts, including reinforcement learning and abstraction techniques. We\nconclude with some challenges for future work on RMDPs.\n","authors":["Marnix Suilen","Thom Badings","Eline M. Bovy","David Parker","Nils Jansen"],"pdf_url":"https://arxiv.org/pdf/2411.11451v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17651v5","updated":"2024-12-10T09:54:43Z","published":"2024-06-25T15:43:20Z","title":"Software Model Evolution with Large Language Models: Experiments on\n  Simulated, Public, and Industrial Datasets","summary":"  Modeling structure and behavior of software systems plays a crucial role in\nthe industrial practice of software engineering. As with other software\nengineering artifacts, software models are subject to evolution. Supporting\nmodelers in evolving software models with recommendations for model completions\nis still an open problem, though. In this paper, we explore the potential of\nlarge language models for this task. In particular, we propose an approach,\nRAMC, leveraging large language models, model histories, and\nretrieval-augmented generation for model completion. Through experiments on\nthree datasets, including an industrial application, one public open-source\ncommunity dataset, and one controlled collection of simulated model\nrepositories, we evaluate the potential of large language models for model\ncompletion with RAMC. We found that large language models are indeed a\npromising technology for supporting software model evolution (62.30%\nsemantically correct completions on real-world industrial data and up to 86.19%\ntype-correct completions). The general inference capabilities of large language\nmodels are particularly useful when dealing with concepts for which there are\nfew, noisy, or no examples at all.\n","authors":["Christof Tinnes","Alisa Welter","Sven Apel"],"pdf_url":"https://arxiv.org/pdf/2406.17651v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.11075v5","updated":"2024-12-10T09:35:58Z","published":"2024-07-13T04:29:36Z","title":"A Comprehensive Survey on Kolmogorov Arnold Networks (KAN)","summary":"  Through this comprehensive survey of Kolmogorov-Arnold Networks(KAN), we have\ngained a thorough understanding of its theoretical foundation, architectural\ndesign, application scenarios, and current research progress. KAN, with its\nunique architecture and flexible activation functions, excels in handling\ncomplex data patterns and nonlinear relationships, demonstrating wide-ranging\napplication potential. While challenges remain, KAN is poised to pave the way\nfor innovative solutions in various fields, potentially revolutionizing how we\napproach complex computational problems.\n","authors":["Tianrui Ji","Yuntian Hou","Di Zhang"],"pdf_url":"https://arxiv.org/pdf/2407.11075v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07338v1","updated":"2024-12-10T09:29:52Z","published":"2024-12-10T09:29:52Z","title":"Contextualized Counterspeech: Strategies for Adaptation,\n  Personalization, and Evaluation","summary":"  AI-generated counterspeech offers a promising and scalable strategy to curb\nonline toxicity through direct replies that promote civil discourse. However,\ncurrent counterspeech is one-size-fits-all, lacking adaptation to the\nmoderation context and the users involved. We propose and evaluate multiple\nstrategies for generating tailored counterspeech that is adapted to the\nmoderation context and personalized for the moderated user. We instruct an\nLLaMA2-13B model to generate counterspeech, experimenting with various\nconfigurations based on different contextual information and fine-tuning\nstrategies. We identify the configurations that generate persuasive\ncounterspeech through a combination of quantitative indicators and human\nevaluations collected via a pre-registered mixed-design crowdsourcing\nexperiment. Results show that contextualized counterspeech can significantly\noutperform state-of-the-art generic counterspeech in adequacy and\npersuasiveness, without compromising other characteristics. Our findings also\nreveal a poor correlation between quantitative indicators and human\nevaluations, suggesting that these methods assess different aspects and\nhighlighting the need for nuanced evaluation methodologies. The effectiveness\nof contextualized AI-generated counterspeech and the divergence between human\nand algorithmic evaluations underscore the importance of increased human-AI\ncollaboration in content moderation.\n","authors":["Lorenzo Cima","Alessio Miaschi","Amaury Trujillo","Marco Avvenuti","Felice Dell'Orletta","Stefano Cresci"],"pdf_url":"https://arxiv.org/pdf/2412.07338v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07333v1","updated":"2024-12-10T09:25:01Z","published":"2024-12-10T09:25:01Z","title":"Fusion Embedding for Pose-Guided Person Image Synthesis with Diffusion\n  Model","summary":"  Pose-Guided Person Image Synthesis (PGPIS) aims to synthesize high-quality\nperson images corresponding to target poses while preserving the appearance of\nthe source image. Recently, PGPIS methods that use diffusion models have\nachieved competitive performance. Most approaches involve extracting\nrepresentations of the target pose and source image and learning their\nrelationships in the generative model's training process. This approach makes\nit difficult to learn the semantic relationships between the input and target\nimages and complicates the model structure needed to enhance generation\nresults. To address these issues, we propose Fusion embedding for PGPIS using a\nDiffusion Model (FPDM). Inspired by the successful application of pre-trained\nCLIP models in text-to-image diffusion models, our method consists of two\nstages. The first stage involves training the fusion embedding of the source\nimage and target pose to align with the target image's embedding. In the second\nstage, the generative model uses this fusion embedding as a condition to\ngenerate the target image. We applied the proposed method to the benchmark\ndatasets DeepFashion and RWTH-PHOENIX-Weather 2014T, and conducted both\nquantitative and qualitative evaluations, demonstrating state-of-the-art (SOTA)\nperformance. An ablation study of the model structure showed that even a model\nusing only the second stage achieved performance close to the other PGPIS SOTA\nmodels. The code is available at https://github.com/dhlee-work/FPDM.\n","authors":["Donghwna Lee","Kyungha Min","Kirok Kim","Seyoung Jeong","Jiwoo Jeong","Wooju Kim"],"pdf_url":"https://arxiv.org/pdf/2412.07333v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07331v1","updated":"2024-12-10T09:23:36Z","published":"2024-12-10T09:23:36Z","title":"NeSyA: Neurosymbolic Automata","summary":"  Neurosymbolic Artificial Intelligence (NeSy) has emerged as a promising\ndirection to integrate low level perception with high level reasoning.\nUnfortunately, little attention has been given to developing NeSy systems\ntailored to temporal/sequential problems. This entails reasoning symbolically\nover sequences of subsymbolic observations towards a target prediction. We show\nthat using a probabilistic semantics symbolic automata, which combine the power\nof automata for temporal structure specification with that of propositional\nlogic, can be used to reason efficiently and differentiably over subsymbolic\nsequences. The proposed system, which we call NeSyA (Neuro Symbolic Automata),\nis shown to either scale or perform better than existing NeSy approaches when\napplied to problems with a temporal component.\n","authors":["Nikolaos Manginas","George Paliouras","Luc De Raedt"],"pdf_url":"https://arxiv.org/pdf/2412.07331v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.00657v2","updated":"2024-12-10T09:16:53Z","published":"2024-05-01T17:37:50Z","title":"RST-LoRA: A Discourse-Aware Low-Rank Adaptation for Long Document\n  Abstractive Summarization","summary":"  For long document summarization, discourse structure is important to discern\nthe key content of the text and the differences in importance level between\nsentences. Unfortunately, the integration of rhetorical structure theory (RST)\ninto parameter-efficient fine-tuning strategies for long document summarization\nremains unexplored. Therefore, this paper introduces RST-LoRA and proposes four\nRST-aware variants to explicitly incorporate RST into the LoRA model. Our\nempirical evaluation demonstrates that incorporating the type and uncertainty\nof rhetorical relations can complementarily enhance the performance of LoRA in\nsummarization tasks. Furthermore, the best-performing variant we introduced\noutperforms the vanilla LoRA and full-parameter fine-tuning models, as\nconfirmed by multiple automatic and human evaluations, and even surpasses\nprevious state-of-the-art methods.\n","authors":["Dongqi Liu","Vera Demberg"],"pdf_url":"https://arxiv.org/pdf/2405.00657v2.pdf","comment":"NAACL 2024 Main & Long Conference Paper (Oral Presentation)"},{"id":"http://arxiv.org/abs/2403.17768v2","updated":"2024-12-10T09:12:46Z","published":"2024-03-26T14:54:48Z","title":"SciNews: From Scholarly Complexities to Public Narratives -- A Dataset\n  for Scientific News Report Generation","summary":"  Scientific news reports serve as a bridge, adeptly translating complex\nresearch articles into reports that resonate with the broader public. The\nautomated generation of such narratives enhances the accessibility of scholarly\ninsights. In this paper, we present a new corpus to facilitate this paradigm\ndevelopment. Our corpus comprises a parallel compilation of academic\npublications and their corresponding scientific news reports across nine\ndisciplines. To demonstrate the utility and reliability of our dataset, we\nconduct an extensive analysis, highlighting the divergences in readability and\nbrevity between scientific news narratives and academic manuscripts. We\nbenchmark our dataset employing state-of-the-art text generation models. The\nevaluation process involves both automatic and human evaluation, which lays the\ngroundwork for future explorations into the automated generation of scientific\nnews reports. The dataset and code related to this work are available at\nhttps://dongqi.me/projects/SciNews.\n","authors":["Dongqi Liu","Yifan Wang","Jia Loy","Vera Demberg"],"pdf_url":"https://arxiv.org/pdf/2403.17768v2.pdf","comment":"LREC-COLING 2024 Main Conference Paper"},{"id":"http://arxiv.org/abs/2306.07799v2","updated":"2024-12-10T09:06:22Z","published":"2023-06-13T14:21:35Z","title":"ChatGPT vs Human-authored Text: Insights into Controllable Text\n  Summarization and Sentence Style Transfer","summary":"  Large-scale language models, like ChatGPT, have garnered significant media\nattention and stunned the public with their remarkable capacity for generating\ncoherent text from short natural language prompts. In this paper, we aim to\nconduct a systematic inspection of ChatGPT's performance in two controllable\ngeneration tasks, with respect to ChatGPT's ability to adapt its output to\ndifferent target audiences (expert vs. layman) and writing styles (formal vs.\ninformal). Additionally, we evaluate the faithfulness of the generated text,\nand compare the model's performance with human-authored texts. Our findings\nindicate that the stylistic variations produced by humans are considerably\nlarger than those demonstrated by ChatGPT, and the generated texts diverge from\nhuman samples in several characteristics, such as the distribution of word\ntypes. Moreover, we observe that ChatGPT sometimes incorporates factual errors\nor hallucinations when adapting the text to suit a specific style.\n","authors":["Dongqi Liu","Vera Demberg"],"pdf_url":"https://arxiv.org/pdf/2306.07799v2.pdf","comment":"ACL-SRW 2023"},{"id":"http://arxiv.org/abs/2305.16784v2","updated":"2024-12-10T08:59:20Z","published":"2023-05-26T09:51:47Z","title":"Incorporating Distributions of Discourse Structure for Long Document\n  Abstractive Summarization","summary":"  For text summarization, the role of discourse structure is pivotal in\ndiscerning the core content of a text. Regrettably, prior studies on\nincorporating Rhetorical Structure Theory (RST) into transformer-based\nsummarization models only consider the nuclearity annotation, thereby\noverlooking the variety of discourse relation types. This paper introduces the\n'RSTformer', a novel summarization model that comprehensively incorporates both\nthe types and uncertainty of rhetorical relations. Our RST-attention mechanism,\nrooted in document-level rhetorical structure, is an extension of the recently\ndevised Longformer framework. Through rigorous evaluation, the model proposed\nherein exhibits significant superiority over state-of-the-art models, as\nevidenced by its notable performance on several automatic metrics and human\nevaluation.\n","authors":["Dongqi Liu","Yifan Wang","Vera Demberg"],"pdf_url":"https://arxiv.org/pdf/2305.16784v2.pdf","comment":"ACL 2023 (Main conference)"},{"id":"http://arxiv.org/abs/2403.09472v2","updated":"2024-12-10T08:54:09Z","published":"2024-03-14T15:12:38Z","title":"Easy-to-Hard Generalization: Scalable Alignment Beyond Human Supervision","summary":"  Current AI alignment methodologies rely on human-provided demonstrations or\njudgments, and the learned capabilities of AI systems would be upper-bounded by\nhuman capabilities as a result. This raises a challenging research question:\nHow can we keep improving the systems when their capabilities have surpassed\nthe levels of humans? This paper answers this question in the context of\ntackling hard reasoning tasks (e.g., level 4-5 MATH problems) via learning from\nhuman annotations on easier tasks (e.g., level 1-3 MATH problems), which we\nterm as easy-to-hard generalization. Our key insight is that an evaluator\n(reward model) trained on supervisions for easier tasks can be effectively used\nfor scoring candidate solutions of harder tasks and hence facilitating\neasy-to-hard generalization over different levels of tasks. Based on this\ninsight, we propose a novel approach to scalable alignment, which firstly\ntrains the (process-supervised) reward models on easy problems (e.g., level\n1-3), and then uses them to evaluate the performance of policy models on hard\nproblems. We show that such easy-to-hard generalization from evaluators can\nenable easy-to-hard generalizations in generators either through re-ranking or\nreinforcement learning (RL). Notably, our process-supervised 7b RL model and\n34b model (reranking@1024) achieves an accuracy of 34.0% and 52.5% on MATH500,\nrespectively, despite only using human supervision on easy problems. Our\napproach suggests a promising path toward AI systems that advance beyond the\nfrontier of human supervision.\n","authors":["Zhiqing Sun","Longhui Yu","Yikang Shen","Weiyang Liu","Yiming Yang","Sean Welleck","Chuang Gan"],"pdf_url":"https://arxiv.org/pdf/2403.09472v2.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2311.18403v3","updated":"2024-12-10T08:40:07Z","published":"2023-11-30T09:55:46Z","title":"Detecting and Corrupting Convolution-based Unlearnable Examples","summary":"  Convolution-based unlearnable examples (UEs) employ class-wise multiplicative\nconvolutional noise to training samples, severely compromising model\nperformance. This fire-new type of UEs have successfully countered all defense\nmechanisms against UEs. The failure of such defenses can be attributed to the\nabsence of norm constraints on convolutional noise, leading to severe blurring\nof image features. To address this, we first design an Edge Pixel-based\nDetector (EPD) to identify convolution-based UEs. Upon detection of them, we\npropose the first defense scheme against convolution-based UEs, COrrupting\nthese samples via random matrix multiplication by employing bilinear\nINterpolation (COIN) such that disrupting the distribution of class-wise\nmultiplicative noise. To evaluate the generalization of our proposed COIN, we\nnewly design two convolution-based UEs called VUDA and HUDA to expand the scope\nof convolution-based UEs. Extensive experiments demonstrate the effectiveness\nof detection scheme EPD and that our defense COIN outperforms 11\nstate-of-the-art (SOTA) defenses, achieving a significant improvement on the\nCIFAR and ImageNet datasets.\n","authors":["Minghui Li","Xianlong Wang","Zhifei Yu","Shengshan Hu","Ziqi Zhou","Longling Zhang","Leo Yu Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.18403v3.pdf","comment":"AAAI 2025"},{"id":"http://arxiv.org/abs/2412.07289v1","updated":"2024-12-10T08:18:29Z","published":"2024-12-10T08:18:29Z","title":"Enhancing Relation Extraction via Supervised Rationale Verification and\n  Feedback","summary":"  Despite the rapid progress that existing automated feedback methods have made\nin correcting the output of large language models (LLMs), these methods cannot\nbe well applied to the relation extraction (RE) task due to their designated\nfeedback objectives and correction manner. To address this problem, we propose\na novel automated feedback framework for RE, which presents a rationale\nsupervisor to verify the rationale and provide re-selected demonstrations as\nfeedback to correct the initial prediction. Specifically, we first design a\ncausal intervention and observation method for to collect biased/unbiased\nrationales for contrastive training the rationale supervisor. Then, we present\na verification-feedback-correction procedure to iteratively enhance LLMs'\ncapability of handling the RE task. Extensive experiments prove that our\nproposed framework significantly outperforms existing methods.\n","authors":["Yongqi Li","Xin Miao","Shen Zhou","Mayi Xu","Yuyang Ren","Tieyun Qian"],"pdf_url":"https://arxiv.org/pdf/2412.07289v1.pdf","comment":"Accepted to AAAI 2025, camera ready version"},{"id":"http://arxiv.org/abs/2412.07282v1","updated":"2024-12-10T08:12:22Z","published":"2024-12-10T08:12:22Z","title":"HARP: Hesitation-Aware Reframing in Transformer Inference Pass","summary":"  This paper aims to improve the performance of large language models by\naddressing the variable computational demands in inference steps, where some\ntokens require more computational resources than others. We present HARP, a\nsimple modification to \"off-the-shelf\" Transformer forward pass. Drawing from\nhesitation and the framing effect in decision-making, HARP selectively applies\nadditional computation when the model encounters uncertainty during token\ngeneration. Our method mimics human cognitive processes by pausing at difficult\ndecision points and reframing inputs for a different perspective. Unlike other\napproaches, HARP is model-agnostic, training-free, and easy to implement. We\nthoroughly evaluate our method across various downstream tasks and model sizes,\ndemonstrating performance improvements up to +5.16%. Notably, HARP achieves\nthese gains while maintaining inference times twice faster than beam search.\nSimple and yet with significant gains, HARP offers a practical solution for\nenhancing the performance of Transformer-based language models with minimal\ncomputational impact.\n","authors":["Romain Storaï","Seung-won Hwang"],"pdf_url":"https://arxiv.org/pdf/2412.07282v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06559v2","updated":"2024-12-10T08:10:32Z","published":"2024-12-09T15:11:40Z","title":"ProcessBench: Identifying Process Errors in Mathematical Reasoning","summary":"  As language models regularly make mistakes when solving math problems,\nautomated identification of errors in the reasoning process becomes\nincreasingly significant for their scalable oversight. In this paper, we\nintroduce ProcessBench for measuring the ability to identify erroneous steps in\nmathematical reasoning. It consists of 3,400 test cases, primarily focused on\ncompetition- and Olympiad-level math problems. Each test case contains a\nstep-by-step solution with error location annotated by human experts. Models\nare required to identify the earliest step that contains an error, or conclude\nthat all steps are correct. We conduct extensive evaluation on ProcessBench,\ninvolving two types of models: process reward models (PRMs) and critic models,\nwhere for the latter we prompt general language models to critique each\nsolution step by step. We draw two main observations: (1) Existing PRMs\ntypically fail to generalize to more challenging math problems beyond GSM8K and\nMATH. They underperform both critic models (i.e., prompted general language\nmodels) and our own trained PRM that is straightforwardly fine-tuned on the\nPRM800K dataset. (2) The best open-source model, QwQ-32B-Preview, has\ndemonstrated the critique capability competitive with the proprietary model\nGPT-4o, despite that it still lags behind the reasoning-specialized o1-mini. We\nhope ProcessBench can foster future research in reasoning process assessment,\npaving the way toward scalable oversight of language models.\n","authors":["Chujie Zheng","Zhenru Zhang","Beichen Zhang","Runji Lin","Keming Lu","Bowen Yu","Dayiheng Liu","Jingren Zhou","Junyang Lin"],"pdf_url":"https://arxiv.org/pdf/2412.06559v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07278v1","updated":"2024-12-10T08:08:17Z","published":"2024-12-10T08:08:17Z","title":"Superficial Consciousness Hypothesis for Autoregressive Transformers","summary":"  The alignment between human objectives and machine learning models built on\nthese objectives is a crucial yet challenging problem for achieving Trustworthy\nAI, particularly when preparing for superintelligence (SI). First, given that\nSI does not exist today, empirical analysis for direct evidence is difficult.\nSecond, SI is assumed to be more intelligent than humans, capable of deceiving\nus into underestimating its intelligence, making output-based analysis\nunreliable. Lastly, what kind of unexpected property SI might have is still\nunclear. To address these challenges, we propose the Superficial Consciousness\nHypothesis under Information Integration Theory (IIT), suggesting that SI could\nexhibit a complex information-theoretic state like a conscious agent while\nunconscious. To validate this, we use a hypothetical scenario where SI can\nupdate its parameters \"at will\" to achieve its own objective (mesa-objective)\nunder the constraint of the human objective (base objective). We show that a\npractical estimate of IIT's consciousness metric is relevant to the widely used\nperplexity metric, and train GPT-2 with those two objectives. Our preliminary\nresult suggests that this SI-simulating GPT-2 could simultaneously follow the\ntwo objectives, supporting the feasibility of the Superficial Consciousness\nHypothesis.\n","authors":["Yosuke Miyanishi","Keita Mitani"],"pdf_url":"https://arxiv.org/pdf/2412.07278v1.pdf","comment":"Accepted to PSS Workshop at AAAI25"},{"id":"http://arxiv.org/abs/2412.07273v1","updated":"2024-12-10T07:56:33Z","published":"2024-12-10T07:56:33Z","title":"Temporal-Aware Evaluation and Learning for Temporal Graph Neural\n  Networks","summary":"  Temporal Graph Neural Networks (TGNNs) are a family of graph neural networks\ndesigned to model and learn dynamic information from temporal graphs. Given\ntheir substantial empirical success, there is an escalating interest in TGNNs\nwithin the research community. However, the majority of these efforts have been\nchannelled towards algorithm and system design, with the evaluation metrics\nreceiving comparatively less attention. Effective evaluation metrics are\ncrucial for providing detailed performance insights, particularly in the\ntemporal domain. This paper investigates the commonly used evaluation metrics\nfor TGNNs and illustrates the failure mechanisms of these metrics in capturing\nessential temporal structures in the predictive behaviour of TGNNs. We provide\na mathematical formulation of existing performance metrics and utilize an\ninstance-based study to underscore their inadequacies in identifying volatility\nclustering (the occurrence of emerging errors within a brief interval). This\nphenomenon has profound implications for both algorithm and system design in\nthe temporal domain. To address this deficiency, we introduce a new\nvolatility-aware evaluation metric (termed volatility cluster statistics),\ndesigned for a more refined analysis of model temporal performance.\nAdditionally, we demonstrate how this metric can serve as a\ntemporal-volatility-aware training objective to alleviate the clustering of\ntemporal errors. Through comprehensive experiments on various TGNN models, we\nvalidate our analysis and the proposed approach. The empirical results offer\nrevealing insights: 1) existing TGNNs are prone to making errors with\nvolatility clustering, and 2) TGNNs with different mechanisms to capture\ntemporal information exhibit distinct volatility clustering patterns. Our\nempirical findings demonstrate that our proposed training objective effectively\nreduces volatility clusters in error.\n","authors":["Junwei Su","Shan Wu"],"pdf_url":"https://arxiv.org/pdf/2412.07273v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.13611v3","updated":"2024-12-10T07:47:15Z","published":"2024-11-20T02:03:16Z","title":"DSTC: Direct Preference Learning with Only Self-Generated Tests and Code\n  to Improve Code LMs","summary":"  Direct preference learning offers a promising and computation-efficient\nbeyond supervised fine-tuning (SFT) for improving code generation in coding\nlarge language models (LMs). However, the scarcity of reliable preference data\nis a bottleneck for the performance of direct preference learning to improve\nthe coding accuracy of code LMs. In this paper, we introduce\n\\underline{\\textbf{D}}irect Preference Learning with Only\n\\underline{\\textbf{S}}elf-Generated \\underline{\\textbf{T}}ests and\n\\underline{\\textbf{C}}ode (DSTC), a framework that leverages only\nself-generated code snippets and tests to construct reliable preference pairs\nsuch that direct preference learning can improve LM coding accuracy without\nexternal annotations. DSTC combines a minimax selection process and test-code\nconcatenation to improve preference pair quality, reducing the influence of\nincorrect self-generated tests and enhancing model performance without the need\nfor costly reward models. When applied with direct preference learning methods\nsuch as Direct Preference Optimization (DPO) and Kahneman-Tversky Optimization\n(KTO), DSTC yields stable improvements in coding accuracy (pass@1 score) across\ndiverse coding benchmarks, including HumanEval, MBPP, and BigCodeBench,\ndemonstrating both its effectiveness and scalability for models of various\nsizes. This approach autonomously enhances code generation accuracy across LLMs\nof varying sizes, reducing reliance on expensive annotated coding datasets.\n","authors":["Zhihan Liu","Shenao Zhang","Yongfei Liu","Boyi Liu","Yingxiang Yang","Zhaoran Wang"],"pdf_url":"https://arxiv.org/pdf/2411.13611v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.03988v2","updated":"2024-12-10T07:40:54Z","published":"2024-05-07T04:00:30Z","title":"LEARN: Knowledge Adaptation from Large Language Model to Recommendation\n  for Practical Industrial Application","summary":"  Contemporary recommendation systems predominantly rely on ID embedding to\ncapture latent associations among users and items. However, this approach\noverlooks the wealth of semantic information embedded within textual\ndescriptions of items, leading to suboptimal performance and poor\ngeneralizations. Leveraging the capability of large language models to\ncomprehend and reason about textual content presents a promising avenue for\nadvancing recommendation systems. To achieve this, we propose an Llm-driven\nknowlEdge Adaptive RecommeNdation (LEARN) framework that synergizes open-world\nknowledge with collaborative knowledge. We address computational complexity\nconcerns by utilizing pretrained LLMs as item encoders and freezing LLM\nparameters to avoid catastrophic forgetting and preserve open-world knowledge.\nTo bridge the gap between the open-world and collaborative domains, we design a\ntwin-tower structure supervised by the recommendation task and tailored for\npractical industrial application. Through experiments on the real large-scale\nindustrial dataset and online A/B tests, we demonstrate the efficacy of our\napproach in industry application. We also achieve state-of-the-art performance\non six Amazon Review datasets to verify the superiority of our method.\n","authors":["Jian Jia","Yipei Wang","Yan Li","Honggang Chen","Xuehan Bai","Zhaocheng Liu","Jian Liang","Quan Chen","Han Li","Peng Jiang","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2405.03988v2.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2412.07259v1","updated":"2024-12-10T07:40:37Z","published":"2024-12-10T07:40:37Z","title":"Goal-Driven Reasoning in DatalogMTL with Magic Sets","summary":"  DatalogMTL is a powerful rule-based language for temporal reasoning. Due to\nits high expressive power and flexible modeling capabilities, it is suitable\nfor a wide range of applications, including tasks from industrial and financial\nsectors. However, due its high computational complexity, practical reasoning in\nDatalogMTL is highly challenging. To address this difficulty, we introduce a\nnew reasoning method for DatalogMTL which exploits the magic sets technique --\na rewriting approach developed for (non-temporal) Datalog to simulate top-down\nevaluation with bottom-up reasoning. We implement this approach and evaluate it\non several publicly available benchmarks, showing that the proposed approach\nsignificantly and consistently outperforms performance of the state-of-the-art\nreasoning techniques.\n","authors":["Shaoyu Wang","Kaiyue Zhao","Dongliang Wei","Przemysław Andrzej Wałęga","Dingmin Wang","Hongmin Cai","Pan Hu"],"pdf_url":"https://arxiv.org/pdf/2412.07259v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07255v1","updated":"2024-12-10T07:35:23Z","published":"2024-12-10T07:35:23Z","title":"Label-Confidence-Aware Uncertainty Estimation in Natural Language\n  Generation","summary":"  Large Language Models (LLMs) display formidable capabilities in generative\ntasks but also pose potential risks due to their tendency to generate\nhallucinatory responses. Uncertainty Quantification (UQ), the evaluation of\nmodel output reliability, is crucial for ensuring the safety and robustness of\nAI systems. Recent studies have concentrated on model uncertainty by analyzing\nthe relationship between output entropy under various sampling conditions and\nthe corresponding labels. However, these methods primarily focus on measuring\nmodel entropy with precision to capture response characteristics, often\nneglecting the uncertainties associated with greedy decoding results-the\nsources of model labels, which can lead to biased classification outcomes. In\nthis paper, we explore the biases introduced by greedy decoding and propose a\nlabel-confidence-aware (LCA) uncertainty estimation based on Kullback-Leibler\n(KL) divergence bridging between samples and label source, thus enhancing the\nreliability and stability of uncertainty assessments. Our empirical evaluations\nacross a range of popular LLMs and NLP datasets reveal that different label\nsources can indeed affect classification, and that our approach can effectively\ncapture differences in sampling results and label sources, demonstrating more\neffective uncertainty estimation.\n","authors":["Qinhong Lin","Linna Zhou","Zhongliang Yang","Yuang Cai"],"pdf_url":"https://arxiv.org/pdf/2412.07255v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06016v2","updated":"2024-12-10T07:24:02Z","published":"2024-12-08T18:21:00Z","title":"Track4Gen: Teaching Video Diffusion Models to Track Points Improves\n  Video Generation","summary":"  While recent foundational video generators produce visually rich output, they\nstill struggle with appearance drift, where objects gradually degrade or change\ninconsistently across frames, breaking visual coherence. We hypothesize that\nthis is because there is no explicit supervision in terms of spatial tracking\nat the feature level. We propose Track4Gen, a spatially aware video generator\nthat combines video diffusion loss with point tracking across frames, providing\nenhanced spatial supervision on the diffusion features. Track4Gen merges the\nvideo generation and point tracking tasks into a single network by making\nminimal changes to existing video generation architectures. Using Stable Video\nDiffusion as a backbone, Track4Gen demonstrates that it is possible to unify\nvideo generation and point tracking, which are typically handled as separate\ntasks. Our extensive evaluations show that Track4Gen effectively reduces\nappearance drift, resulting in temporally stable and visually coherent video\ngeneration. Project page: hyeonho99.github.io/track4gen\n","authors":["Hyeonho Jeong","Chun-Hao Paul Huang","Jong Chul Ye","Niloy Mitra","Duygu Ceylan"],"pdf_url":"https://arxiv.org/pdf/2412.06016v2.pdf","comment":"Project page: hyeonho99.github.io/track4gen"},{"id":"http://arxiv.org/abs/2412.07249v1","updated":"2024-12-10T07:18:51Z","published":"2024-12-10T07:18:51Z","title":"Buster: Incorporating Backdoor Attacks into Text Encoder to Mitigate\n  NSFW Content Generation","summary":"  In the digital age, the proliferation of deep learning models has led to\nsignificant concerns about the generation of Not Safe for Work (NSFW) content.\nExisting defense methods primarily involve model fine-tuning and post-hoc\ncontent moderation. However, these approaches often lack scalability in\neliminating harmful content, degrade the quality of benign image generation, or\nincur high inference costs. To tackle these challenges, we propose an\ninnovative framework called \\textbf{Buster}, which injects backdoor attacks\ninto the text encoder to prevent NSFW content generation. Specifically, Buster\nleverages deep semantic information rather than explicit prompts as triggers,\nredirecting NSFW prompts towards targeted benign prompts. This approach\ndemonstrates exceptional resilience and scalability in mitigating NSFW content.\nRemarkably, Buster fine-tunes the text encoder of Text-to-Image models within\njust five minutes, showcasing high efficiency. Our extensive experiments reveal\nthat Buster outperforms all other baselines, achieving superior NSFW content\nremoval rate while preserving the quality of harmless images.\n","authors":["Xin Zhao","Xiaojun Chen","Yuexin Xuan","Zhendong Zhao"],"pdf_url":"https://arxiv.org/pdf/2412.07249v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07243v1","updated":"2024-12-10T07:07:06Z","published":"2024-12-10T07:07:06Z","title":"A Dynamical Systems-Inspired Pruning Strategy for Addressing\n  Oversmoothing in Graph Neural Networks","summary":"  Oversmoothing in Graph Neural Networks (GNNs) poses a significant challenge\nas network depth increases, leading to homogenized node representations and a\nloss of expressiveness. In this work, we approach the oversmoothing problem\nfrom a dynamical systems perspective, providing a deeper understanding of the\nstability and convergence behavior of GNNs. Leveraging insights from dynamical\nsystems theory, we identify the root causes of oversmoothing and propose\n\\textbf{\\textit{DYNAMO-GAT}}. This approach utilizes noise-driven covariance\nanalysis and Anti-Hebbian principles to selectively prune redundant attention\nweights, dynamically adjusting the network's behavior to maintain node feature\ndiversity and stability. Our theoretical analysis reveals how DYNAMO-GAT\ndisrupts the convergence to oversmoothed states, while experimental results on\nbenchmark datasets demonstrate its superior performance and efficiency compared\nto traditional and state-of-the-art methods. DYNAMO-GAT not only advances the\ntheoretical understanding of oversmoothing through the lens of dynamical\nsystems but also provides a practical and effective solution for improving the\nstability and expressiveness of deep GNNs.\n","authors":["Biswadeep Chakraborty","Harshit Kumar","Saibal Mukhopadhyay"],"pdf_url":"https://arxiv.org/pdf/2412.07243v1.pdf","comment":"26 pages"},{"id":"http://arxiv.org/abs/2412.07241v1","updated":"2024-12-10T07:06:52Z","published":"2024-12-10T07:06:52Z","title":"Human-Computer Interaction and Human-AI Collaboration in Advanced Air\n  Mobility: A Comprehensive Review","summary":"  The increasing rates of global urbanization and vehicle usage are leading to\na shift of mobility to the third dimension-through Advanced Air Mobility\n(AAM)-offering a promising solution for faster, safer, cleaner, and more\nefficient transportation. As air transportation continues to evolve with more\nautomated and autonomous systems, advancements in AAM require a deep\nunderstanding of human-computer interaction and human-AI collaboration to\nensure safe and effective operations in complex urban and regional\nenvironments. There has been a significant increase in publications regarding\nthese emerging applications; thus, there is a need to review developments in\nthis area. This paper comprehensively reviews the current state of research on\nhuman-computer interaction and human-AI collaboration in AAM. Specifically, we\nfocus on AAM applications related to the design of human-machine interfaces for\nvarious uses, including pilot training, air traffic management, and the\nintegration of AI-assisted decision-making systems with immersive technologies\nsuch as extended, virtual, mixed, and augmented reality devices. Additionally,\nwe provide a comprehensive analysis of the challenges AAM encounters in\nintegrating human-computer frameworks, including unique challenges associated\nwith these interactions, such as trust in AI systems and safety concerns.\nFinally, we highlight emerging opportunities and propose future research\ndirections to bridge the gap between human factors and technological\nadvancements in AAM.\n","authors":["Fatma Yamac Sagirli","Xiaopeng Zhao","Zhenbo Wang"],"pdf_url":"https://arxiv.org/pdf/2412.07241v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07237v1","updated":"2024-12-10T07:00:05Z","published":"2024-12-10T07:00:05Z","title":"ArtFormer: Controllable Generation of Diverse 3D Articulated Objects","summary":"  This paper presents a novel framework for modeling and conditional generation\nof 3D articulated objects. Troubled by flexibility-quality tradeoffs, existing\nmethods are often limited to using predefined structures or retrieving shapes\nfrom static datasets. To address these challenges, we parameterize an\narticulated object as a tree of tokens and employ a transformer to generate\nboth the object's high-level geometry code and its kinematic relations.\nSubsequently, each sub-part's geometry is further decoded using a\nsigned-distance-function (SDF) shape prior, facilitating the synthesis of\nhigh-quality 3D shapes. Our approach enables the generation of diverse objects\nwith high-quality geometry and varying number of parts. Comprehensive\nexperiments on conditional generation from text descriptions demonstrate the\neffectiveness and flexibility of our method.\n","authors":["Jiayi Su","Youhe Feng","Zheng Li","Jinhua Song","Yangfan He","Botao Ren","Botian Xu"],"pdf_url":"https://arxiv.org/pdf/2412.07237v1.pdf","comment":"impl. repo: https://github.com/ShuYuMo2003/ArtFormer"},{"id":"http://arxiv.org/abs/2412.07236v1","updated":"2024-12-10T06:56:36Z","published":"2024-12-10T06:56:36Z","title":"CBraMod: A Criss-Cross Brain Foundation Model for EEG Decoding","summary":"  Electroencephalography (EEG) is a non-invasive technique to measure and\nrecord brain electrical activity, widely used in various BCI and healthcare\napplications. Early EEG decoding methods rely on supervised learning, limited\nby specific tasks and datasets, hindering model performance and\ngeneralizability. With the success of large language models, there is a growing\nbody of studies focusing on EEG foundation models. However, these studies still\nleave challenges: Firstly, most of existing EEG foundation models employ full\nEEG modeling strategy. It models the spatial and temporal dependencies between\nall EEG patches together, but ignores that the spatial and temporal\ndependencies are heterogeneous due to the unique structural characteristics of\nEEG signals. Secondly, existing EEG foundation models have limited\ngeneralizability on a wide range of downstream BCI tasks due to varying formats\nof EEG data, making it challenging to adapt to. To address these challenges, we\npropose a novel foundation model called CBraMod. Specifically, we devise a\ncriss-cross transformer as the backbone to thoroughly leverage the structural\ncharacteristics of EEG signals, which can model spatial and temporal\ndependencies separately through two parallel attention mechanisms. And we\nutilize an asymmetric conditional positional encoding scheme which can encode\npositional information of EEG patches and be easily adapted to the EEG with\ndiverse formats. CBraMod is pre-trained on a very large corpus of EEG through\npatch-based masked EEG reconstruction. We evaluate CBraMod on up to 10\ndownstream BCI tasks (12 public datasets). CBraMod achieves the\nstate-of-the-art performance across the wide range of tasks, proving its strong\ncapability and generalizability. The source code is publicly available at\n\\url{https://github.com/wjq-learning/CBraMod}.\n","authors":["Jiquan Wang","Sha Zhao","Zhiling Luo","Yangxuan Zhou","Haiteng Jiang","Shijian Li","Tao Li","Gang Pan"],"pdf_url":"https://arxiv.org/pdf/2412.07236v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.18003v3","updated":"2024-12-10T06:39:51Z","published":"2024-11-27T02:47:17Z","title":"HAAT: Hybrid Attention Aggregation Transformer for Image\n  Super-Resolution","summary":"  In the research area of image super-resolution, Swin-transformer-based models\nare favored for their global spatial modeling and shifting window attention\nmechanism. However, existing methods often limit self-attention to non\noverlapping windows to cut costs and ignore the useful information that exists\nacross channels. To address this issue, this paper introduces a novel model,\nthe Hybrid Attention Aggregation Transformer (HAAT), designed to better\nleverage feature information. HAAT is constructed by integrating\nSwin-Dense-Residual-Connected Blocks (SDRCB) with Hybrid Grid Attention Blocks\n(HGAB). SDRCB expands the receptive field while maintaining a streamlined\narchitecture, resulting in enhanced performance. HGAB incorporates channel\nattention, sparse attention, and window attention to improve nonlocal feature\nfusion and achieve more visually compelling results. Experimental evaluations\ndemonstrate that HAAT surpasses state-of-the-art methods on benchmark datasets.\nKeywords: Image super-resolution, Computer vision, Attention mechanism,\nTransformer\n","authors":["Song-Jiang Lai","Tsun-Hin Cheung","Ka-Chun Fung","Kai-wen Xue","Kin-Man Lam"],"pdf_url":"https://arxiv.org/pdf/2411.18003v3.pdf","comment":"6 pages, 2 figures, 1 table"},{"id":"http://arxiv.org/abs/2409.06957v2","updated":"2024-12-10T06:21:47Z","published":"2024-09-11T02:40:38Z","title":"Policy Filtration in RLHF to Fine-Tune LLM for Code Generation","summary":"  Reinforcement learning from human feedback (RLHF) is one of the key\ntechniques that helps large language models (LLMs) to follow instructions and\nprovide helpful and harmless responses. While direct policy optimization\nmethods exist, state-of-the-art LLMs adopt RL-based methods (usually PPO) in\nRLHF to train the policy to generate good responses guided by a reward model\nlearned from preference data. The main challenge of these methods is the\ninaccuracy of the intermediate reward model, especially in code generation\ntasks that require long and complex reasoning to score a response. We find that\nthe reliability of the reward model varies across responses assigned with\ndifferent rewards. This motivates us to filter the samples whose rewards may be\nunreliable to improve signal-to-noise ratio during policy learning, resulting\nin Policy Filtration for Proximal Policy Optimization (PF-PPO). To choose a\nproper policy filtration strategy for a given reward model, the coefficient of\ndetermination ($R^2$) between rewards and actual scores on filtered samples\nserves as a good metrics and helps us find several promising strategies. We\nprovide extensive experiments to validate the effectiveness of PF-PPO in code\ngeneration tasks, and find that some variants of PF-PPO are highly effective\nand achieve new state-of-the-art performance across 7-billion-parameter models\non HumanEval, MBPP, and a new and more challenging LeetCode Contest benchmark.\n","authors":["Wei Shen","Chuheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2409.06957v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07224v1","updated":"2024-12-10T06:19:21Z","published":"2024-12-10T06:19:21Z","title":"Parseval Regularization for Continual Reinforcement Learning","summary":"  Loss of plasticity, trainability loss, and primacy bias have been identified\nas issues arising when training deep neural networks on sequences of tasks --\nall referring to the increased difficulty in training on new tasks. We propose\nto use Parseval regularization, which maintains orthogonality of weight\nmatrices, to preserve useful optimization properties and improve training in a\ncontinual reinforcement learning setting. We show that it provides significant\nbenefits to RL agents on a suite of gridworld, CARL and MetaWorld tasks. We\nconduct comprehensive ablations to identify the source of its benefits and\ninvestigate the effect of certain metrics associated to network trainability\nincluding weight matrix rank, weight norms and policy entropy.\n","authors":["Wesley Chung","Lynn Cherif","David Meger","Doina Precup"],"pdf_url":"https://arxiv.org/pdf/2412.07224v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07222v1","updated":"2024-12-10T06:18:29Z","published":"2024-12-10T06:18:29Z","title":"MPSI: Mamba enhancement model for pixel-wise sequential interaction\n  Image Super-Resolution","summary":"  Single image super-resolution (SR) has long posed a challenge in the field of\ncomputer vision. While the advent of deep learning has led to the emergence of\nnumerous methods aimed at tackling this persistent issue, the current\nmethodologies still encounter challenges in modeling long sequence information,\nleading to limitations in effectively capturing the global pixel interactions.\nTo tackle this challenge and achieve superior SR outcomes, we propose the Mamba\npixel-wise sequential interaction network (MPSI), aimed at enhancing the\nestablishment of long-range connections of information, particularly focusing\non pixel-wise sequential interaction. We propose the Channel-Mamba Block (CMB)\nto capture comprehensive pixel interaction information by effectively modeling\nlong sequence information. Moreover, in the existing SR methodologies, there\npersists the issue of the neglect of features extracted by preceding layers,\nleading to the loss of valuable feature information. While certain existing\nmodels strive to preserve these features, they frequently encounter difficulty\nin establishing connections across all layers. To overcome this limitation,\nMPSI introduces the Mamba channel recursion module (MCRM), which maximizes the\nretention of valuable feature information from early layers, thereby\nfacilitating the acquisition of pixel sequence interaction information from\nmultiple-level layers. Through extensive experimentation, we demonstrate that\nMPSI outperforms existing super-resolution methods in terms of image\nreconstruction results, attaining state-of-the-art performance.\n","authors":["Yuchun He","Yuhan He"],"pdf_url":"https://arxiv.org/pdf/2412.07222v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07214v1","updated":"2024-12-10T06:11:23Z","published":"2024-12-10T06:11:23Z","title":"Towards Automated Cross-domain Exploratory Data Analysis through Large\n  Language Models","summary":"  Exploratory data analysis (EDA), coupled with SQL, is essential for data\nanalysts involved in data exploration and analysis. However, data analysts\noften encounter two primary challenges: (1) the need to craft SQL queries\nskillfully, and (2) the requirement to generate suitable visualization types\nthat enhance the interpretation of query results. Due to its significance,\nsubstantial research efforts have been made to explore different approaches to\naddress these challenges, including leveraging large language models (LLMs).\nHowever, existing methods fail to meet real-world data exploration requirements\nprimarily due to (1) complex database schema; (2) unclear user intent; (3)\nlimited cross-domain generalization capability; and (4) insufficient end-to-end\ntext-to-visualization capability.\n  This paper presents TiInsight, an automated SQL-based cross-domain\nexploratory data analysis system. First, we propose hierarchical data context\n(i.e., HDC), which leverages LLMs to summarize the contexts related to the\ndatabase schema, which is crucial for open-world EDA systems to generalize\nacross data domains. Second, the EDA system is divided into four components\n(i.e., stages): HDC generation, question clarification and decomposition,\ntext-to-SQL generation (i.e., TiSQL), and data visualization (i.e., TiChart).\nFinally, we implemented an end-to-end EDA system with a user-friendly GUI\ninterface in the production environment at PingCAP. We have also open-sourced\nall APIs of TiInsight to facilitate research within the EDA community. Through\nextensive evaluations by a real-world user study, we demonstrate that TiInsight\noffers remarkable performance compared to human experts. Specifically, TiSQL\nachieves an execution accuracy of 86.3% on the Spider dataset using GPT-4. It\nalso demonstrates state-of-the-art performance on the Bird dataset.\n","authors":["Jun-Peng Zhu","Boyan Niu","Peng cai","Zheming Ni","Jianwei Wan","Kai Xu","Jiajun Huang","Shengbo Ma","Bing Wang","Xuan Zhou","Guanglei Bao","Donghui Zhang","Liu Tang","Qi Liu"],"pdf_url":"https://arxiv.org/pdf/2412.07214v1.pdf","comment":"14 pages, 10 figures. Submitted to SIGMOD 2025"},{"id":"http://arxiv.org/abs/2412.07213v1","updated":"2024-12-10T06:09:49Z","published":"2024-12-10T06:09:49Z","title":"IntellectSeeker: A Personalized Literature Management System with the\n  Probabilistic Model and Large Language Model","summary":"  Faced with the burgeoning volume of academic literature, researchers often\nneed help with uncertain article quality and mismatches in term searches using\ntraditional academic engines. We introduce IntellectSeeker, an innovative and\npersonalized intelligent academic literature management platform to address\nthese challenges. This platform integrates a Large Language Model (LLM)--based\nsemantic enhancement bot with a sophisticated probability model to personalize\nand streamline literature searches. We adopted the GPT-3.5-turbo model to\ntransform everyday language into professional academic terms across various\nscenarios using multiple rounds of few-shot learning. This adaptation mainly\nbenefits academic newcomers, effectively bridging the gap between general\ninquiries and academic terminology. The probabilistic model intelligently\nfilters academic articles to align closely with the specific interests of\nusers, which are derived from explicit needs and behavioral patterns. Moreover,\nIntellectSeeker incorporates an advanced recommendation system and text\ncompression tools. These features enable intelligent article recommendations\nbased on user interactions and present search results through concise one-line\nsummaries and innovative word cloud visualizations, significantly enhancing\nresearch efficiency and user experience. IntellectSeeker offers academic\nresearchers a highly customizable literature management solution with\nexceptional search precision and matching capabilities. The code can be found\nhere: https://github.com/LuckyBian/ISY5001\n","authors":["Weizhen Bian","Siyan Liu","Yubo Zhou","Dezhi Chen","Yijie Liao","Zhenzhen Fan","Aobo Wang"],"pdf_url":"https://arxiv.org/pdf/2412.07213v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.14747v3","updated":"2024-12-10T06:08:27Z","published":"2024-09-23T06:51:10Z","title":"Distribution-Level Feature Distancing for Machine Unlearning: Towards a\n  Better Trade-off Between Model Utility and Forgetting","summary":"  With the explosive growth of deep learning applications and increasing\nprivacy concerns, the right to be forgotten has become a critical requirement\nin various AI industries. For example, given a facial recognition system, some\nindividuals may wish to remove their personal data that might have been used in\nthe training phase. Unfortunately, deep neural networks sometimes unexpectedly\nleak personal identities, making this removal challenging. While recent machine\nunlearning algorithms aim to enable models to forget such data, we observe an\nunintended utility drop, termed correlation collapse, where these algorithms\ninadvertently weaken the essential correlations between image features and true\nlabels during the forgetting process. To address this challenge, we propose\nDistribution-Level Feature Distancing (DLFD), a novel method that efficiently\nforgets instances while preserving task-relevant feature correlations. Our\nmethod synthesizes data samples by optimizing the feature distribution to be\ndistinctly different from that of forget samples, achieving effective results\nwithin a single training epoch. Through extensive experiments on facial\nrecognition datasets, we demonstrate that our approach significantly\noutperforms state-of-the-art machine unlearning methods in both forgetting\nperformance and model utility preservation.\n","authors":["Dasol Choi","Dongbin Na"],"pdf_url":"https://arxiv.org/pdf/2409.14747v3.pdf","comment":"10 pages, 6 figures, AAAI 2025 camera ready version"},{"id":"http://arxiv.org/abs/2412.07210v1","updated":"2024-12-10T06:08:24Z","published":"2024-12-10T06:08:24Z","title":"EDiT: A Local-SGD-Based Efficient Distributed Training Method for Large\n  Language Models","summary":"  Distributed training methods are crucial for large language models (LLMs).\nHowever, existing distributed training methods often suffer from communication\nbottlenecks, stragglers, and limited elasticity. Local SGD methods have been\nproposed to address these issues, but their effectiveness remains limited to\nsmall-scale training due to additional memory overhead and lack of concerns on\nefficiency and stability. To tackle these issues, we propose EDiT, an\ninnovative Efficient Distributed Training method that combines a tailored Local\nSGD approach with model sharding techniques to enhance large-scale training\nefficiency. EDiT performs layer-wise parameter synchronization during forward\npass, reducing communication and memory overhead and enabling the overlap of\ncomputation and communication. Besides, EDiT employs a pseudo gradient penalty\nstrategy to suppress loss spikes, which ensures training stability and improve\nperformance. Additionally, we introduce A-EDiT, a fully asynchronous variant of\nEDiT that accommodates heterogeneous clusters. Building on EDiT/A-EDiT, we\nconduct a series of experiments to validate large-scale asynchronous training\nfor LLMs, accompanied by comprehensive analyses. Experimental results\ndemonstrate the superior performance of EDiT/A-EDiT, establishing them as\nrobust solutions for distributed LLM training in diverse computational\necosystems.\n","authors":["Jialiang Cheng","Ning Gao","Yun Yue","Zhiling Ye","Jiadi Jiang","Jian Sha"],"pdf_url":"https://arxiv.org/pdf/2412.07210v1.pdf","comment":"22 pages, 10 figures, 7 tables"},{"id":"http://arxiv.org/abs/2409.00755v2","updated":"2024-12-10T05:57:04Z","published":"2024-09-01T15:48:20Z","title":"Trusted Unified Feature-Neighborhood Dynamics for Multi-View\n  Classification","summary":"  Multi-view classification (MVC) faces inherent challenges due to domain gaps\nand inconsistencies across different views, often resulting in uncertainties\nduring the fusion process. While Evidential Deep Learning (EDL) has been\neffective in addressing view uncertainty, existing methods predominantly rely\non the Dempster-Shafer combination rule, which is sensitive to conflicting\nevidence and often neglects the critical role of neighborhood structures within\nmulti-view data. To address these limitations, we propose a Trusted Unified\nFeature-NEighborhood Dynamics (TUNED) model for robust MVC. This method\neffectively integrates local and global feature-neighborhood (F-N) structures\nfor robust decision-making. Specifically, we begin by extracting local F-N\nstructures within each view. To further mitigate potential uncertainties and\nconflicts in multi-view fusion, we employ a selective Markov random field that\nadaptively manages cross-view neighborhood dependencies. Additionally, we\nemploy a shared parameterized evidence extractor that learns global consensus\nconditioned on local F-N structures, thereby enhancing the global integration\nof multi-view features. Experiments on benchmark datasets show that our method\nimproves accuracy and robustness over existing approaches, particularly in\nscenarios with high uncertainty and conflicting views. The code will be made\navailable at https://github.com/JethroJames/TUNED.\n","authors":["Haojian Huang","Chuanyu Qin","Zhe Liu","Kaijing Ma","Jin Chen","Han Fang","Chao Ban","Hao Sun","Zhongjiang He"],"pdf_url":"https://arxiv.org/pdf/2409.00755v2.pdf","comment":"Accepted to AAAI 2025"},{"id":"http://arxiv.org/abs/2412.07207v1","updated":"2024-12-10T05:55:14Z","published":"2024-12-10T05:55:14Z","title":"MAPLE: A Framework for Active Preference Learning Guided by Large\n  Language Models","summary":"  The advent of large language models (LLMs) has sparked significant interest\nin using natural language for preference learning. However, existing methods\noften suffer from high computational burdens, taxing human supervision, and\nlack of interpretability. To address these issues, we introduce MAPLE, a\nframework for large language model-guided Bayesian active preference learning.\nMAPLE leverages LLMs to model the distribution over preference functions,\nconditioning it on both natural language feedback and conventional preference\nlearning feedback, such as pairwise trajectory rankings. MAPLE also employs\nactive learning to systematically reduce uncertainty in this distribution and\nincorporates a language-conditioned active query selection mechanism to\nidentify informative and easy-to-answer queries, thus reducing human burden. We\nevaluate MAPLE's sample efficiency and preference inference quality across two\nbenchmarks, including a real-world vehicle route planning benchmark using\nOpenStreetMap data. Our results demonstrate that MAPLE accelerates the learning\nprocess and effectively improves humans' ability to answer queries.\n","authors":["Saaduddin Mahmud","Mason Nakamura","Shlomo Zilberstein"],"pdf_url":"https://arxiv.org/pdf/2412.07207v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07201v1","updated":"2024-12-10T05:33:09Z","published":"2024-12-10T05:33:09Z","title":"A Review on the Applications of Transformer-based language models for\n  Nucleotide Sequence Analysis","summary":"  In recent times, Transformer-based language models are making quite an impact\nin the field of natural language processing. As relevant parallels can be drawn\nbetween biological sequences and natural languages, the models used in NLP can\nbe easily extended and adapted for various applications in bioinformatics. In\nthis regard, this paper introduces the major developments of Transformer-based\nmodels in the recent past in the context of nucleotide sequences. We have\nreviewed and analysed a large number of application-based papers on this\nsubject, giving evidence of the main characterizing features and to different\napproaches that may be adopted to customize such powerful computational\nmachines. We have also provided a structured description of the functioning of\nTransformers, that may enable even first time users to grab the essence of such\ncomplex architectures. We believe this review will help the scientific\ncommunity in understanding the various applications of Transformer-based\nlanguage models to nucleotide sequences. This work will motivate the readers to\nbuild on these methodologies to tackle also various other problems in the field\nof bioinformatics.\n","authors":["Nimisha Ghosh","Daniele Santoni","Indrajit Saha","Giovanni Felici"],"pdf_url":"https://arxiv.org/pdf/2412.07201v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07200v1","updated":"2024-12-10T05:32:57Z","published":"2024-12-10T05:32:57Z","title":"Modifying AI, Enhancing Essays: How Active Engagement with Generative AI\n  Boosts Writing Quality","summary":"  Students are increasingly relying on Generative AI (GAI) to support their\nwriting-a key pedagogical practice in education. In GAI-assisted writing,\nstudents can delegate core cognitive tasks (e.g., generating ideas and turning\nthem into sentences) to GAI while still producing high-quality essays. This\ncreates new challenges for teachers in assessing and supporting student\nlearning, as they often lack insight into whether students are engaging in\nmeaningful cognitive processes during writing or how much of the essay's\nquality can be attributed to those processes. This study aimed to help teachers\nbetter assess and support student learning in GAI-assisted writing by examining\nhow different writing behaviors, especially those indicative of meaningful\nlearning versus those that are not, impact essay quality. Using a dataset of\n1,445 GAI-assisted writing sessions, we applied the cutting-edge method,\nX-Learner, to quantify the causal impact of three GAI-assisted writing\nbehavioral patterns (i.e., seeking suggestions but not accepting them, seeking\nsuggestions and accepting them as they are, and seeking suggestions and\naccepting them with modification) on four measures of essay quality (i.e.,\nlexical sophistication, syntactic complexity, text cohesion, and linguistic\nbias). Our analysis showed that writers who frequently modified GAI-generated\ntext-suggesting active engagement in higher-order cognitive\nprocesses-consistently improved the quality of their essays in terms of lexical\nsophistication, syntactic complexity, and text cohesion. In contrast, those who\noften accepted GAI-generated text without changes, primarily engaging in\nlower-order processes, saw a decrease in essay quality. Additionally, while\nhuman writers tend to introduce linguistic bias when writing independently,\nincorporating GAI-generated text-even without modification-can help mitigate\nthis bias.\n","authors":["Kaixun Yang","Mladen Raković","Zhiping Liang","Lixiang Yan","Zijie Zeng","Yizhou Fan","Dragan Gašević","Guanliang Chen"],"pdf_url":"https://arxiv.org/pdf/2412.07200v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.16594v2","updated":"2024-12-10T05:24:37Z","published":"2024-11-25T17:28:44Z","title":"From Generation to Judgment: Opportunities and Challenges of\n  LLM-as-a-judge","summary":"  Assessment and evaluation have long been critical challenges in artificial\nintelligence (AI) and natural language processing (NLP). However, traditional\nmethods, whether matching-based or embedding-based, often fall short of judging\nsubtle attributes and delivering satisfactory results. Recent advancements in\nLarge Language Models (LLMs) inspire the \"LLM-as-a-judge\" paradigm, where LLMs\nare leveraged to perform scoring, ranking, or selection across various tasks\nand applications. This paper provides a comprehensive survey of LLM-based\njudgment and assessment, offering an in-depth overview to advance this emerging\nfield. We begin by giving detailed definitions from both input and output\nperspectives. Then we introduce a comprehensive taxonomy to explore\nLLM-as-a-judge from three dimensions: what to judge, how to judge and where to\njudge. Finally, we compile benchmarks for evaluating LLM-as-a-judge and\nhighlight key challenges and promising directions, aiming to provide valuable\ninsights and inspire future research in this promising research area. Paper\nlist and more resources about LLM-as-a-judge can be found at\n\\url{https://github.com/llm-as-a-judge/Awesome-LLM-as-a-judge} and\n\\url{https://llm-as-a-judge.github.io}.\n","authors":["Dawei Li","Bohan Jiang","Liangjie Huang","Alimohammad Beigi","Chengshuai Zhao","Zhen Tan","Amrita Bhattacharjee","Yuxuan Jiang","Canyu Chen","Tianhao Wu","Kai Shu","Lu Cheng","Huan Liu"],"pdf_url":"https://arxiv.org/pdf/2411.16594v2.pdf","comment":"v2: add missing citations; 32 pages, 5 figures"},{"id":"http://arxiv.org/abs/2412.07197v1","updated":"2024-12-10T05:20:49Z","published":"2024-12-10T05:20:49Z","title":"Hierarchical Split Federated Learning: Convergence Analysis and System\n  Optimization","summary":"  As AI models expand in size, it has become increasingly challenging to deploy\nfederated learning (FL) on resource-constrained edge devices. To tackle this\nissue, split federated learning (SFL) has emerged as an FL framework with\nreduced workload on edge devices via model splitting; it has received extensive\nattention from the research community in recent years. Nevertheless, most prior\nworks on SFL focus only on a two-tier architecture without harnessing\nmulti-tier cloudedge computing resources. In this paper, we intend to analyze\nand optimize the learning performance of SFL under multi-tier systems.\nSpecifically, we propose the hierarchical SFL (HSFL) framework and derive its\nconvergence bound. Based on the theoretical results, we formulate a joint\noptimization problem for model splitting (MS) and model aggregation (MA). To\nsolve this rather hard problem, we then decompose it into MS and MA subproblems\nthat can be solved via an iterative descending algorithm. Simulation results\ndemonstrate that the tailored algorithm can effectively optimize MS and MA for\nSFL within virtually any multi-tier system.\n","authors":["Zheng Lin","Wei Wei","Zhe Chen","Chan-Tong Lam","Xianhao Chen","Yue Gao","Jun Luo"],"pdf_url":"https://arxiv.org/pdf/2412.07197v1.pdf","comment":"15 pages, 9 figures"},{"id":"http://arxiv.org/abs/2412.03844v2","updated":"2024-12-10T04:59:24Z","published":"2024-12-05T03:20:35Z","title":"HybridGS: Decoupling Transients and Statics with 2D and 3D Gaussian\n  Splatting","summary":"  Generating high-quality novel view renderings of 3D Gaussian Splatting (3DGS)\nin scenes featuring transient objects is challenging. We propose a novel hybrid\nrepresentation, termed as HybridGS, using 2D Gaussians for transient objects\nper image and maintaining traditional 3D Gaussians for the whole static scenes.\nNote that, the 3DGS itself is better suited for modeling static scenes that\nassume multi-view consistency, but the transient objects appear occasionally\nand do not adhere to the assumption, thus we model them as planar objects from\na single view, represented with 2D Gaussians. Our novel representation\ndecomposes the scene from the perspective of fundamental viewpoint consistency,\nmaking it more reasonable. Additionally, we present a novel multi-view\nregulated supervision method for 3DGS that leverages information from\nco-visible regions, further enhancing the distinctions between the transients\nand statics. Then, we propose a straightforward yet effective multi-stage\ntraining strategy to ensure robust training and high-quality view synthesis\nacross various settings. Experiments on benchmark datasets show our\nstate-of-the-art performance of novel view synthesis in both indoor and outdoor\nscenes, even in the presence of distracting elements.\n","authors":["Jingyu Lin","Jiaqi Gu","Lubin Fan","Bojian Wu","Yujing Lou","Renjie Chen","Ligang Liu","Jieping Ye"],"pdf_url":"https://arxiv.org/pdf/2412.03844v2.pdf","comment":"Project page: https://gujiaqivadin.github.io/hybridgs/"},{"id":"http://arxiv.org/abs/2412.07188v1","updated":"2024-12-10T04:53:53Z","published":"2024-12-10T04:53:53Z","title":"Graph Neural Networks Are More Than Filters: Revisiting and Benchmarking\n  from A Spectral Perspective","summary":"  Graph Neural Networks (GNNs) have achieved remarkable success in various\ngraph-based learning tasks. While their performance is often attributed to the\npowerful neighborhood aggregation mechanism, recent studies suggest that other\ncomponents such as non-linear layers may also significantly affecting how GNNs\nprocess the input graph data in the spectral domain. Such evidence challenges\nthe prevalent opinion that neighborhood aggregation mechanisms dominate the\nbehavioral characteristics of GNNs in the spectral domain. To demystify such a\nconflict, this paper introduces a comprehensive benchmark to measure and\nevaluate GNNs' capability in capturing and leveraging the information encoded\nin different frequency components of the input graph data. Specifically, we\nfirst conduct an exploratory study demonstrating that GNNs can flexibly yield\noutputs with diverse frequency components even when certain frequencies are\nabsent or filtered out from the input graph data. We then formulate a novel\nresearch problem of measuring and benchmarking the performance of GNNs from a\nspectral perspective. To take an initial step towards a comprehensive\nbenchmark, we design an evaluation protocol supported by comprehensive\ntheoretical analysis. Finally, we introduce a comprehensive benchmark on\nreal-world datasets, revealing insights that challenge prevalent opinions from\na spectral perspective. We believe that our findings will open new avenues for\nfuture advancements in this area. Our implementations can be found at:\nhttps://github.com/yushundong/Spectral-benchmark.\n","authors":["Yushun Dong","Patrick Soga","Yinhan He","Song Wang","Jundong Li"],"pdf_url":"https://arxiv.org/pdf/2412.07188v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07186v1","updated":"2024-12-10T04:52:26Z","published":"2024-12-10T04:52:26Z","title":"Monte Carlo Tree Search based Space Transfer for Black-box Optimization","summary":"  Bayesian optimization (BO) is a popular method for computationally expensive\nblack-box optimization. However, traditional BO methods need to solve new\nproblems from scratch, leading to slow convergence. Recent studies try to\nextend BO to a transfer learning setup to speed up the optimization, where\nsearch space transfer is one of the most promising approaches and has shown\nimpressive performance on many tasks. However, existing search space transfer\nmethods either lack an adaptive mechanism or are not flexible enough, making it\ndifficult to efficiently identify promising search space during the\noptimization process. In this paper, we propose a search space transfer\nlearning method based on Monte Carlo tree search (MCTS), called MCTS-transfer,\nto iteratively divide, select, and optimize in a learned subspace.\nMCTS-transfer can not only provide a well-performing search space for\nwarm-start but also adaptively identify and leverage the information of similar\nsource tasks to reconstruct the search space during the optimization process.\nExperiments on synthetic functions, real-world problems, Design-Bench and\nhyper-parameter optimization show that MCTS-transfer can demonstrate superior\nperformance compared to other search space transfer methods under different\nsettings. Our code is available at\n\\url{https://github.com/lamda-bbo/mcts-transfer}.\n","authors":["Shukuan Wang","Ke Xue","Lei Song","Xiaobin Huang","Chao Qian"],"pdf_url":"https://arxiv.org/pdf/2412.07186v1.pdf","comment":"NeurIPS 2024 Spotlight"},{"id":"http://arxiv.org/abs/2412.07183v1","updated":"2024-12-10T04:41:44Z","published":"2024-12-10T04:41:44Z","title":"Exploring What Why and How: A Multifaceted Benchmark for Causation\n  Understanding of Video Anomaly","summary":"  Recent advancements in video anomaly understanding (VAU) have opened the door\nto groundbreaking applications in various fields, such as traffic monitoring\nand industrial automation. While the current benchmarks in VAU predominantly\nemphasize the detection and localization of anomalies. Here, we endeavor to\ndelve deeper into the practical aspects of VAU by addressing the essential\nquestions: \"what anomaly occurred?\", \"why did it happen?\", and \"how severe is\nthis abnormal event?\". In pursuit of these answers, we introduce a\ncomprehensive benchmark for Exploring the Causation of Video Anomalies (ECVA).\nOur benchmark is meticulously designed, with each video accompanied by detailed\nhuman annotations. Specifically, each instance of our ECVA involves three sets\nof human annotations to indicate \"what\", \"why\" and \"how\" of an anomaly,\nincluding 1) anomaly type, start and end times, and event descriptions, 2)\nnatural language explanations for the cause of an anomaly, and 3) free text\nreflecting the effect of the abnormality. Building upon this foundation, we\npropose a novel prompt-based methodology that serves as a baseline for tackling\nthe intricate challenges posed by ECVA. We utilize \"hard prompt\" to guide the\nmodel to focus on the critical parts related to video anomaly segments, and\n\"soft prompt\" to establish temporal and spatial relationships within these\nanomaly segments. Furthermore, we propose AnomEval, a specialized evaluation\nmetric crafted to align closely with human judgment criteria for ECVA. This\nmetric leverages the unique features of the ECVA dataset to provide a more\ncomprehensive and reliable assessment of various video large language models.\nWe demonstrate the efficacy of our approach through rigorous experimental\nanalysis and delineate possible avenues for further investigation into the\ncomprehension of video anomaly causation.\n","authors":["Hang Du","Guoshun Nan","Jiawen Qian","Wangchenhui Wu","Wendi Deng","Hanqing Mu","Zhenyan Chen","Pengxuan Mao","Xiaofeng Tao","Jun Liu"],"pdf_url":"https://arxiv.org/pdf/2412.07183v1.pdf","comment":"Submitted to IEEE Transactions on Pattern Analysis and Machine\n  Intelligence. arXiv admin note: substantial text overlap with\n  arXiv:2405.00181"},{"id":"http://arxiv.org/abs/2412.07182v1","updated":"2024-12-10T04:41:10Z","published":"2024-12-10T04:41:10Z","title":"An Enhancement of CNN Algorithm for Rice Leaf Disease Image\n  Classification in Mobile Applications","summary":"  This study focuses on enhancing rice leaf disease image classification\nalgorithms, which have traditionally relied on Convolutional Neural Network\n(CNN) models. We employed transfer learning with MobileViTV2_050 using\nImageNet-1k weights, a lightweight model that integrates CNN's local feature\nextraction with Vision Transformers' global context learning through a\nseparable self-attention mechanism. Our approach resulted in a significant\n15.66% improvement in classification accuracy for MobileViTV2_050-A, our first\nenhanced model trained on the baseline dataset, achieving 93.14%. Furthermore,\nMobileViTV2_050-B, our second enhanced model trained on a broader rice leaf\ndataset, demonstrated a 22.12% improvement, reaching 99.6% test accuracy.\nAdditionally, MobileViTV2-A attained an F1-score of 93% across four rice labels\nand a Receiver Operating Characteristic (ROC) curve ranging from 87% to 97%. In\nterms of resource consumption, our enhanced models reduced the total parameters\nof the baseline CNN model by up to 92.50%, from 14 million to 1.1 million.\nThese results indicate that MobileViTV2_050 not only improves computational\nefficiency through its separable self-attention mechanism but also enhances\nglobal context learning. Consequently, it offers a lightweight and robust\nsolution suitable for mobile deployment, advancing the interpretability and\npracticality of models in precision agriculture.\n","authors":["Kayne Uriel K. Rodrigo","Jerriane Hillary Heart S. Marcial","Samuel C. Brillo","Khatalyn E. Mata","Jonathan C. Morano"],"pdf_url":"https://arxiv.org/pdf/2412.07182v1.pdf","comment":"Presented at 46th World Conference on Applied Science, Engineering &\n  Technology (WCASET) from Institute for Educational Research and Publication\n  (IFERP)"},{"id":"http://arxiv.org/abs/2412.00154v2","updated":"2024-12-10T04:39:25Z","published":"2024-11-29T07:19:56Z","title":"o1-Coder: an o1 Replication for Coding","summary":"  The technical report introduces O1-CODER, an attempt to replicate OpenAI's o1\nmodel with a focus on coding tasks. It integrates reinforcement learning (RL)\nand Monte Carlo Tree Search (MCTS) to enhance the model's System-2 thinking\ncapabilities. The framework includes training a Test Case Generator (TCG) for\nstandardized code testing, using MCTS to generate code data with reasoning\nprocesses, and iteratively fine-tuning the policy model to initially produce\npseudocode and then generate the full code. The report also addresses the\nopportunities and challenges in deploying o1-like models in real-world\napplications, suggesting transitioning to the System-2 paradigm and\nhighlighting the imperative for world model construction. Updated model\nprogress and experimental results will be reported in subsequent versions. All\nsource code, curated datasets, as well as the derived models are disclosed at\nhttps://github.com/ADaM-BJTU/O1-CODER .\n","authors":["Yuxiang Zhang","Shangxi Wu","Yuqi Yang","Jiangming Shu","Jinlin Xiao","Chao Kong","Jitao Sang"],"pdf_url":"https://arxiv.org/pdf/2412.00154v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.00608v3","updated":"2024-12-10T04:28:36Z","published":"2024-11-30T23:11:44Z","title":"Leveraging LLM for Automated Ontology Extraction and Knowledge Graph\n  Generation","summary":"  Extracting relevant and structured knowledge from large, complex technical\ndocuments within the Reliability and Maintainability (RAM) domain is\nlabor-intensive and prone to errors. Our work addresses this challenge by\npresenting OntoKGen, a genuine pipeline for ontology extraction and Knowledge\nGraph (KG) generation. OntoKGen leverages Large Language Models (LLMs) through\nan interactive user interface guided by our adaptive iterative Chain of Thought\n(CoT) algorithm to ensure that the ontology extraction process and, thus, KG\ngeneration align with user-specific requirements. Although KG generation\nfollows a clear, structured path based on the confirmed ontology, there is no\nuniversally correct ontology as it is inherently based on the user's\npreferences. OntoKGen recommends an ontology grounded in best practices,\nminimizing user effort and providing valuable insights that may have been\noverlooked, all while giving the user complete control over the final ontology.\nHaving generated the KG based on the confirmed ontology, OntoKGen enables\nseamless integration into schemeless, non-relational databases like Neo4j. This\nintegration allows for flexible storage and retrieval of knowledge from\ndiverse, unstructured sources, facilitating advanced querying, analysis, and\ndecision-making. Moreover, the generated KG serves as a robust foundation for\nfuture integration into Retrieval Augmented Generation (RAG) systems, offering\nenhanced capabilities for developing domain-specific intelligent applications.\n","authors":["Mohammad Sadeq Abolhasani","Rong Pan"],"pdf_url":"https://arxiv.org/pdf/2412.00608v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07174v1","updated":"2024-12-10T04:15:39Z","published":"2024-12-10T04:15:39Z","title":"Post-Training Statistical Calibration for Higher Activation Sparsity","summary":"  We present Statistical Calibrated Activation Pruning (SCAP), a post-training\nactivation pruning framework that (1) generalizes sparsification by input\nactivations of Fully-Connected layers for generic and flexible application\nacross Transformers, and (2) features a simple Mode-Centering technique to\npre-calibrate activation distributions for maximizing post-training sparsity.\nOur results demonstrate robust Pareto efficiency compared to prior methods,\ntranslating to a 1.5x additional LLM decoding speedup against CATS at iso model\nquality. SCAP effectiveness is empirically verified across a wide range of\nmodels, including recent Transformer Decoders, MoE, Mamba2, Encoding\nTransformer, and pre-quantized models, highlighting its practicality and\nscalability. The code is available at: https://github.com/IntelLabs/SCAP.\n","authors":["Vui Seng Chua","Yujie Pan","Nilesh Jain"],"pdf_url":"https://arxiv.org/pdf/2412.07174v1.pdf","comment":"ENLSP-IV NeurIPS Workshop 2024"},{"id":"http://arxiv.org/abs/2412.07167v1","updated":"2024-12-10T04:01:21Z","published":"2024-12-10T04:01:21Z","title":"Reinforcement Learning Policy as Macro Regulator Rather than Macro\n  Placer","summary":"  In modern chip design, placement aims at placing millions of circuit modules,\nwhich is an essential step that significantly influences power, performance,\nand area (PPA) metrics. Recently, reinforcement learning (RL) has emerged as a\npromising technique for improving placement quality, especially macro\nplacement. However, current RL-based placement methods suffer from long\ntraining times, low generalization ability, and inability to guarantee PPA\nresults. A key issue lies in the problem formulation, i.e., using RL to place\nfrom scratch, which results in limits useful information and inaccurate rewards\nduring the training process. In this work, we propose an approach that utilizes\nRL for the refinement stage, which allows the RL policy to learn how to adjust\nexisting placement layouts, thereby receiving sufficient information for the\npolicy to act and obtain relatively dense and precise rewards. Additionally, we\nintroduce the concept of regularity during training, which is considered an\nimportant metric in the chip design industry but is often overlooked in current\nRL placement methods. We evaluate our approach on the ISPD 2005 and ICCAD 2015\nbenchmark, comparing the global half-perimeter wirelength and regularity of our\nproposed method against several competitive approaches. Besides, we test the\nPPA performance using commercial software, showing that RL as a regulator can\nachieve significant PPA improvements. Our RL regulator can fine-tune placements\nfrom any method and enhance their quality. Our work opens up new possibilities\nfor the application of RL in placement, providing a more effective and\nefficient approach to optimizing chip design. Our code is available at\n\\url{https://github.com/lamda-bbo/macro-regulator}.\n","authors":["Ke Xue","Ruo-Tong Chen","Xi Lin","Yunqi Shi","Shixiong Kai","Siyuan Xu","Chao Qian"],"pdf_url":"https://arxiv.org/pdf/2412.07167v1.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2412.07165v1","updated":"2024-12-10T03:55:18Z","published":"2024-12-10T03:55:18Z","title":"A Method for Evaluating Hyperparameter Sensitivity in Reinforcement\n  Learning","summary":"  The performance of modern reinforcement learning algorithms critically relies\non tuning ever-increasing numbers of hyperparameters. Often, small changes in a\nhyperparameter can lead to drastic changes in performance, and different\nenvironments require very different hyperparameter settings to achieve\nstate-of-the-art performance reported in the literature. We currently lack a\nscalable and widely accepted approach to characterizing these complex\ninteractions. This work proposes a new empirical methodology for studying,\ncomparing, and quantifying the sensitivity of an algorithm's performance to\nhyperparameter tuning for a given set of environments. We then demonstrate the\nutility of this methodology by assessing the hyperparameter sensitivity of\nseveral commonly used normalization variants of PPO. The results suggest that\nseveral algorithmic performance improvements may, in fact, be a result of an\nincreased reliance on hyperparameter tuning.\n","authors":["Jacob Adkins","Michael Bowling","Adam White"],"pdf_url":"https://arxiv.org/pdf/2412.07165v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06510v2","updated":"2024-12-10T03:49:16Z","published":"2024-12-09T14:13:21Z","title":"AnomalyControl: Learning Cross-modal Semantic Features for Controllable\n  Anomaly Synthesis","summary":"  Anomaly synthesis is a crucial approach to augment abnormal data for\nadvancing anomaly inspection. Based on the knowledge from the large-scale\npre-training, existing text-to-image anomaly synthesis methods predominantly\nfocus on textual information or coarse-aligned visual features to guide the\nentire generation process. However, these methods often lack sufficient\ndescriptors to capture the complicated characteristics of realistic anomalies\n(e.g., the fine-grained visual pattern of anomalies), limiting the realism and\ngeneralization of the generation process. To this end, we propose a novel\nanomaly synthesis framework called AnomalyControl to learn cross-modal semantic\nfeatures as guidance signals, which could encode the generalized anomaly cues\nfrom text-image reference prompts and improve the realism of synthesized\nabnormal samples. Specifically, AnomalyControl adopts a flexible and\nnon-matching prompt pair (i.e., a text-image reference prompt and a targeted\ntext prompt), where a Cross-modal Semantic Modeling (CSM) module is designed to\nextract cross-modal semantic features from the textual and visual descriptors.\nThen, an Anomaly-Semantic Enhanced Attention (ASEA) mechanism is formulated to\nallow CSM to focus on the specific visual patterns of the anomaly, thus\nenhancing the realism and contextual relevance of the generated anomaly\nfeatures. Treating cross-modal semantic features as the prior, a Semantic\nGuided Adapter (SGA) is designed to encode effective guidance signals for the\nadequate and controllable synthesis process. Extensive experiments indicate\nthat AnomalyControl can achieve state-of-the-art results in anomaly synthesis\ncompared with existing methods while exhibiting superior performance for\ndownstream tasks.\n","authors":["Shidan He","Lei Liu","Shen Zhao"],"pdf_url":"https://arxiv.org/pdf/2412.06510v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07163v1","updated":"2024-12-10T03:46:03Z","published":"2024-12-10T03:46:03Z","title":"Fast Occupancy Network","summary":"  Occupancy Network has recently attracted much attention in autonomous\ndriving. Instead of monocular 3D detection and recent bird's eye view(BEV)\nmodels predicting 3D bounding box of obstacles, Occupancy Network predicts the\ncategory of voxel in specified 3D space around the ego vehicle via transforming\n3D detection task into 3D voxel segmentation task, which has much superiority\nin tackling category outlier obstacles and providing fine-grained 3D\nrepresentation. However, existing methods usually require huge computation\nresources than previous methods, which hinder the Occupancy Network solution\napplying in intelligent driving systems. To address this problem, we make an\nanalysis of the bottleneck of Occupancy Network inference cost, and present a\nsimple and fast Occupancy Network model, which adopts a deformable 2D\nconvolutional layer to lift BEV feature to 3D voxel feature and presents an\nefficient voxel feature pyramid network (FPN) module to improve performance\nwith few computational cost. Further, we present a cost-free 2D segmentation\nbranch in perspective view after feature extractors for Occupancy Network\nduring inference phase to improve accuracy. Experimental results demonstrate\nthat our method consistently outperforms existing methods in both accuracy and\ninference speed, which surpasses recent state-of-the-art (SOTA) OCCNet by 1.7%\nwith ResNet50 backbone with about 3X inference speedup. Furthermore, our method\ncan be easily applied to existing BEV models to transform them into Occupancy\nNetwork models.\n","authors":["Mingjie Lu","Yuanxian Huang","Ji Liu","Xingliang Huang","Dong Li","Jinzhang Peng","Lu Tian","Emad Barsoum"],"pdf_url":"https://arxiv.org/pdf/2412.07163v1.pdf","comment":"10 pages, 5 figures,"},{"id":"http://arxiv.org/abs/2412.06289v2","updated":"2024-12-10T03:43:32Z","published":"2024-12-09T08:24:11Z","title":"S$^{2}$FT: Efficient, Scalable and Generalizable LLM Fine-tuning by\n  Structured Sparsity","summary":"  Current PEFT methods for LLMs can achieve either high quality, efficient\ntraining, or scalable serving, but not all three simultaneously. To address\nthis limitation, we investigate sparse fine-tuning and observe a remarkable\nimprovement in generalization ability. Utilizing this key insight, we propose a\nfamily of Structured Sparse Fine-Tuning (S$^{2}$FT) methods for LLMs, which\nconcurrently achieve state-of-the-art fine-tuning performance, training\nefficiency, and inference scalability. S$^{2}$FT accomplishes this by\n\"selecting sparsely and computing densely\". It selects a few heads and channels\nin the MHA and FFN modules for each Transformer block, respectively. Next, it\nco-permutes weight matrices on both sides of the coupled structures in LLMs to\nconnect the selected components in each layer into a dense submatrix. Finally,\nS$^{2}$FT performs in-place gradient updates on all submatrices. Through\ntheoretical analysis and empirical results, our method prevents overfitting and\nforgetting, delivers SOTA performance on both commonsense and arithmetic\nreasoning with 4.6% and 1.3% average improvements compared to LoRA, and\nsurpasses full FT by 11.5% when generalizing to various domains after\ninstruction tuning. Using our partial backpropagation algorithm, S$^{2}$FT\nsaves training memory up to 3$\\times$ and improves latency by 1.5-2.7$\\times$\ncompared to full FT, while delivering an average 10% improvement over LoRA on\nboth metrics. We further demonstrate that the weight updates in S$^{2}$FT can\nbe decoupled into adapters, enabling effective fusion, fast switch, and\nefficient parallelism for serving multiple fine-tuned models.\n","authors":["Xinyu Yang","Jixuan Leng","Geyang Guo","Jiawei Zhao","Ryumei Nakada","Linjun Zhang","Huaxiu Yao","Beidi Chen"],"pdf_url":"https://arxiv.org/pdf/2412.06289v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01812v5","updated":"2024-12-10T03:43:20Z","published":"2024-09-14T02:35:29Z","title":"From Text to Multimodality: Exploring the Evolution and Impact of Large\n  Language Models in Medical Practice","summary":"  Large Language Models (LLMs) have rapidly evolved from text-based systems to\nmultimodal platforms, significantly impacting various sectors including\nhealthcare. This comprehensive review explores the progression of LLMs to\nMultimodal Large Language Models (MLLMs) and their growing influence in medical\npractice. We examine the current landscape of MLLMs in healthcare, analyzing\ntheir applications across clinical decision support, medical imaging, patient\nengagement, and research. The review highlights the unique capabilities of\nMLLMs in integrating diverse data types, such as text, images, and audio, to\nprovide more comprehensive insights into patient health. We also address the\nchallenges facing MLLM implementation, including data limitations, technical\nhurdles, and ethical considerations. By identifying key research gaps, this\npaper aims to guide future investigations in areas such as dataset development,\nmodality alignment methods, and the establishment of ethical guidelines. As\nMLLMs continue to shape the future of healthcare, understanding their potential\nand limitations is crucial for their responsible and effective integration into\nmedical practice.\n","authors":["Qian Niu","Keyu Chen","Ming Li","Pohsun Feng","Ziqian Bi","Lawrence KQ Yan","Yichao Zhang","Caitlyn Heqi Yin","Cheng Fei","Junyu Liu","Benji Peng","Tianyang Wang","Yunze Wang","Silin Chen","Ming Liu"],"pdf_url":"https://arxiv.org/pdf/2410.01812v5.pdf","comment":"12 pages, 1 figure"},{"id":"http://arxiv.org/abs/2411.09420v2","updated":"2024-12-10T03:42:23Z","published":"2024-11-14T13:15:27Z","title":"SAG-ViT: A Scale-Aware, High-Fidelity Patching Approach with Graph\n  Attention for Vision Transformers","summary":"  Image classification is a computer vision task where a model analyzes an\nimage to categorize it into a specific label. Vision Transformers (ViT) improve\nthis task by leveraging self-attention to capture complex patterns and long\nrange relationships between image patches. However, a key challenge for ViTs is\nefficiently incorporating multiscale feature representations, which is inherent\nin CNNs through their hierarchical structure. In this paper, we introduce the\nScale-Aware Graph Attention Vision Transformer (SAG-ViT), a novel framework\nthat addresses this challenge by integrating multi-scale features. Using\nEfficientNet as a backbone, the model extracts multi-scale feature maps, which\nare divided into patches to preserve semantic information. These patches are\norganized into a graph based on spatial and feature similarities, with a Graph\nAttention Network (GAT) refining the node embeddings. Finally, a Transformer\nencoder captures long-range dependencies and complex interactions. The SAG-ViT\nis evaluated on benchmark datasets, demonstrating its effectiveness in\nenhancing image classification performance. Our code and weights are publicly\navailable at https://github.com/shravan-18/SAG-ViT\n","authors":["Shravan Venkatraman","Jaskaran Singh Walia","Joe Dhanith P R"],"pdf_url":"https://arxiv.org/pdf/2411.09420v2.pdf","comment":"10 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2408.08931v2","updated":"2024-12-10T03:39:16Z","published":"2024-08-16T05:49:14Z","title":"Personalized Federated Collaborative Filtering: A Variational\n  AutoEncoder Approach","summary":"  Federated Collaborative Filtering (FedCF) is an emerging field focused on\ndeveloping a new recommendation framework with preserving privacy in a\nfederated setting. Existing FedCF methods typically combine distributed\nCollaborative Filtering (CF) algorithms with privacy-preserving mechanisms, and\nthen preserve personalized information into a user embedding vector. However,\nthe user embedding is usually insufficient to preserve the rich information of\nthe fine-grained personalization across heterogeneous clients. This paper\nproposes a novel personalized FedCF method by preserving users' personalized\ninformation into a latent variable and a neural model simultaneously.\nSpecifically, we decompose the modeling of user knowledge into two encoders,\neach designed to capture shared knowledge and personalized knowledge\nseparately. A personalized gating network is then applied to balance\npersonalization and generalization between the global and local encoders.\nMoreover, to effectively train the proposed framework, we model the CF problem\nas a specialized Variational AutoEncoder (VAE) task by integrating user\ninteraction vector reconstruction with missing value prediction. The decoder is\ntrained to reconstruct the implicit feedback from items the user has interacted\nwith, while also predicting items the user might be interested in but has not\nyet interacted with. Experimental results on benchmark datasets demonstrate\nthat the proposed method outperforms other baseline methods, showcasing\nsuperior performance. Our code is available at https://github.com/mtics/FedDAE.\n","authors":["Zhiwei Li","Guodong Long","Tianyi Zhou","Jing Jiang","Chengqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.08931v2.pdf","comment":"10 pages, 3 figures, 4 tables, conference"},{"id":"http://arxiv.org/abs/2403.05720v4","updated":"2024-12-10T03:29:48Z","published":"2024-03-08T23:17:55Z","title":"A Dataset and Benchmark for Hospital Course Summarization with Adapted\n  Large Language Models","summary":"  Brief hospital course (BHC) summaries are clinical documents that summarize a\npatient's hospital stay. While large language models (LLMs) depict remarkable\ncapabilities in automating real-world tasks, their capabilities for healthcare\napplications such as synthesizing BHCs from clinical notes have not been shown.\nWe introduce a novel pre-processed dataset, the MIMIC-IV-BHC, encapsulating\nclinical note and brief hospital course (BHC) pairs to adapt LLMs for BHC\nsynthesis. Furthermore, we introduce a benchmark of the summarization\nperformance of two general-purpose LLMs and three healthcare-adapted LLMs.\nUsing clinical notes as input, we apply prompting-based (using in-context\nlearning) and fine-tuning-based adaptation strategies to three open-source LLMs\n(Clinical-T5-Large, Llama2-13B, FLAN-UL2) and two proprietary LLMs (GPT-3.5,\nGPT-4). We evaluate these LLMs across multiple context-length inputs using\nnatural language similarity metrics. We further conduct a clinical study with\nfive clinicians, comparing clinician-written and LLM-generated BHCs across 30\nsamples, focusing on their potential to enhance clinical decision-making\nthrough improved summary quality. We observe that the Llama2-13B fine-tuned LLM\noutperforms other domain-adapted models given quantitative evaluation metrics\nof BLEU and BERT-Score. GPT-4 with in-context learning shows more robustness to\nincreasing context lengths of clinical note inputs than fine-tuned Llama2-13B.\nDespite comparable quantitative metrics, the reader study depicts a significant\npreference for summaries generated by GPT-4 with in-context learning compared\nto both Llama2-13B fine-tuned summaries and the original summaries,\nhighlighting the need for qualitative clinical evaluation.\n","authors":["Asad Aali","Dave Van Veen","Yamin Ishraq Arefeen","Jason Hom","Christian Bluethgen","Eduardo Pontes Reis","Sergios Gatidis","Namuun Clifford","Joseph Daws","Arash S. Tehrani","Jangwon Kim","Akshay S. Chaudhari"],"pdf_url":"https://arxiv.org/pdf/2403.05720v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.17080v2","updated":"2024-12-10T03:19:23Z","published":"2024-11-26T03:41:01Z","title":"DeepMDV: Learning Global Matching for Multi-depot Vehicle Routing\n  Problems","summary":"  Due to the substantial rise in online retail and e-commerce in recent years,\nthe demand for efficient and fast solutions to Vehicle Routing Problems (VRP)\nhas become critical. To manage the increasing demand, companies have adopted\nthe strategy of adding more depots. However, the presence of multiple depots\nintroduces additional complexities, making existing VRP solutions suboptimal\nfor addressing the Multi-depot Vehicle Routing Problem (MDVRP). Traditional\nmethods for solving the MDVRP often require significant computation time,\nmaking them unsuitable for large-scale instances. Additionally, existing\nlearning-based solutions for the MDVRP struggle with generalizability and fail\nto deliver high-quality results for scenarios involving a large number of\ncustomers. In this paper, we propose a novel solution for MDVRP. Our approach\nemploys an attention mechanism, featuring a decoder with two key layers: one\nlayer to consider the states of all vehicles and learn to select the most\nsuitable vehicle based on the proximity of unassigned customers, and another\nlayer to focus on assigning a customer to the selected vehicle. This approach\ndelivers high-quality solutions for large-scale MDVRP instances and\ndemonstrates remarkable generalizability across varying numbers of customers\nand depots. Its adaptability and performance make it a practical and deployable\nsolution for real-world logistics challenges.\n","authors":["Saeed Nasehi","Farhana Choudhury","Egemen Tanin"],"pdf_url":"https://arxiv.org/pdf/2411.17080v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07148v1","updated":"2024-12-10T03:13:41Z","published":"2024-12-10T03:13:41Z","title":"MM-PoE: Multiple Choice Reasoning via. Process of Elimination using\n  Multi-Modal Models","summary":"  This paper introduces Multiple Choice Reasoning via. Process of Elimination\nusing Multi-Modal models, herein referred to as Multi-Modal Process of\nElimination (MM-PoE). This novel methodology is engineered to augment the\nefficacy of Vision-Language Models (VLMs) in multiple-choice visual reasoning\ntasks. Diverging from conventional approaches that evaluate each option\nindependently, MM-PoE employs a dual-step scoring paradigm that initially\nidentifies and excludes implausible choices, subsequently concentrating on the\nmost probable remaining options. This method emulates human test-taking\nstrategies, where individuals typically eliminate clearly incorrect answers\nprior to selecting the optimal response. Our empirical evaluations, conducted\nacross three benchmark datasets, reveal that MM-PoE significantly improves both\nzero-shot and few-shot performance of contemporary state-of-the-art VLMs.\nCritically, this approach not only broadens the application of the elimination\nprocess to multi-modal contexts but also allows few-shot experiments, thereby\naddressing two principal limitations concerning usage of PoE only in zero-shot\nsettings and only with a language-only framework. As a result, MM-PoE not only\nrefines the reasoning capabilities of VLMs but also broadens their\napplicability to complex visual question-answering scenarios. All code and\ndocumentation supporting our work are available at\nhttps://pypi.org/project/mm-poe/, enabling researchers and practitioners to\neasily integrate and further develop these techniques.\n","authors":["Sayak Chakrabarty","Souradip Pal"],"pdf_url":"https://arxiv.org/pdf/2412.07148v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07147v1","updated":"2024-12-10T03:12:35Z","published":"2024-12-10T03:12:35Z","title":"MIT-10M: A Large Scale Parallel Corpus of Multilingual Image Translation","summary":"  Image Translation (IT) holds immense potential across diverse domains,\nenabling the translation of textual content within images into various\nlanguages. However, existing datasets often suffer from limitations in scale,\ndiversity, and quality, hindering the development and evaluation of IT models.\nTo address this issue, we introduce MIT-10M, a large-scale parallel corpus of\nmultilingual image translation with over 10M image-text pairs derived from\nreal-world data, which has undergone extensive data cleaning and multilingual\ntranslation validation. It contains 840K images in three sizes, 28 categories,\ntasks with three levels of difficulty and 14 languages image-text pairs, which\nis a considerable improvement on existing datasets. We conduct extensive\nexperiments to evaluate and train models on MIT-10M. The experimental results\nclearly indicate that our dataset has higher adaptability when it comes to\nevaluating the performance of the models in tackling challenging and complex\nimage translation tasks in the real world. Moreover, the performance of the\nmodel fine-tuned with MIT-10M has tripled compared to the baseline model,\nfurther confirming its superiority.\n","authors":["Bo Li","Shaolin Zhu","Lijie Wen"],"pdf_url":"https://arxiv.org/pdf/2412.07147v1.pdf","comment":"Accepted in COLING 2025"},{"id":"http://arxiv.org/abs/2412.07144v1","updated":"2024-12-10T03:06:28Z","published":"2024-12-10T03:06:28Z","title":"Political Actor Agent: Simulating Legislative System for Roll Call Votes\n  Prediction with Large Language Models","summary":"  Predicting roll call votes through modeling political actors has emerged as a\nfocus in quantitative political science and computer science. Widely used\nembedding-based methods generate vectors for legislators from diverse data sets\nto predict legislative behaviors. However, these methods often contend with\nchallenges such as the need for manually predefined features, reliance on\nextensive training data, and a lack of interpretability. Achieving more\ninterpretable predictions under flexible conditions remains an unresolved\nissue. This paper introduces the Political Actor Agent (PAA), a novel\nagent-based framework that utilizes Large Language Models to overcome these\nlimitations. By employing role-playing architectures and simulating legislative\nsystem, PAA provides a scalable and interpretable paradigm for predicting\nroll-call votes. Our approach not only enhances the accuracy of predictions but\nalso offers multi-view, human-understandable decision reasoning, providing new\ninsights into political actor behaviors. We conducted comprehensive experiments\nusing voting records from the 117-118th U.S. House of Representatives,\nvalidating the superior performance and interpretability of PAA. This study not\nonly demonstrates PAA's effectiveness but also its potential in political\nscience research.\n","authors":["Hao Li","Ruoyuan Gong","Hao Jiang"],"pdf_url":"https://arxiv.org/pdf/2412.07144v1.pdf","comment":"Accepted at AAAI 2025"},{"id":"http://arxiv.org/abs/2412.05256v2","updated":"2024-12-10T02:54:36Z","published":"2024-12-06T18:41:39Z","title":"Extrapolated Urban View Synthesis Benchmark","summary":"  Photorealistic simulators are essential for the training and evaluation of\nvision-centric autonomous vehicles (AVs). At their core is Novel View Synthesis\n(NVS), a crucial capability that generates diverse unseen viewpoints to\naccommodate the broad and continuous pose distribution of AVs. Recent advances\nin radiance fields, such as 3D Gaussian Splatting, achieve photorealistic\nrendering at real-time speeds and have been widely used in modeling large-scale\ndriving scenes. However, their performance is commonly evaluated using an\ninterpolated setup with highly correlated training and test views. In contrast,\nextrapolation, where test views largely deviate from training views, remains\nunderexplored, limiting progress in generalizable simulation technology. To\naddress this gap, we leverage publicly available AV datasets with multiple\ntraversals, multiple vehicles, and multiple cameras to build the first\nExtrapolated Urban View Synthesis (EUVS) benchmark. Meanwhile, we conduct\nquantitative and qualitative evaluations of state-of-the-art Gaussian Splatting\nmethods across different difficulty levels. Our results show that Gaussian\nSplatting is prone to overfitting to training views. Besides, incorporating\ndiffusion priors and improving geometry cannot fundamentally improve NVS under\nlarge view changes, highlighting the need for more robust approaches and\nlarge-scale training. We have released our data to help advance self-driving\nand urban robotics simulation technology.\n","authors":["Xiangyu Han","Zhen Jia","Boyi Li","Yan Wang","Boris Ivanovic","Yurong You","Lingjie Liu","Yue Wang","Marco Pavone","Chen Feng","Yiming Li"],"pdf_url":"https://arxiv.org/pdf/2412.05256v2.pdf","comment":"Project page: https://ai4ce.github.io/EUVS-Benchmark/"},{"id":"http://arxiv.org/abs/2412.07127v1","updated":"2024-12-10T02:34:13Z","published":"2024-12-10T02:34:13Z","title":"Deep Learning-Enhanced Preconditioning for Efficient Conjugate Gradient\n  Solvers in Large-Scale PDE Systems","summary":"  Preconditioning techniques are crucial for enhancing the efficiency of\nsolving large-scale linear equation systems that arise from partial\ndifferential equation (PDE) discretization. These techniques, such as\nIncomplete Cholesky factorization (IC) and data-driven neural network methods,\naccelerate the convergence of iterative solvers like Conjugate Gradient (CG) by\napproximating the original matrices. This paper introduces a novel approach\nthat integrates Graph Neural Network (GNN) with traditional IC, addressing the\nshortcomings of direct generation methods based on GNN and achieving\nsignificant improvements in computational efficiency and scalability.\nExperimental results demonstrate an average reduction in iteration counts by\n24.8% compared to IC and a two-order-of-magnitude increase in training scale\ncompared to previous methods. A three-dimensional static structural analysis\nutilizing finite element methods was validated on training sparse matrices of\nup to 5 million dimensions and inference scales of up to 10 million.\nFurthermore, the approach demon-strates robust generalization capabilities\nacross scales, facilitating the effective acceleration of CG solvers for\nlarge-scale linear equations using small-scale data on modest hardware. The\nmethod's robustness and scalability make it a practical solution for\ncomputational science.\n","authors":["Rui Li","Song Wang","Chen Wang"],"pdf_url":"https://arxiv.org/pdf/2412.07127v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.07127v2","updated":"2024-12-10T02:25:18Z","published":"2024-09-11T09:23:27Z","title":"DCMAC: Demand-aware Customized Multi-Agent Communication via Upper Bound\n  Training","summary":"  Efficient communication can enhance the overall performance of collaborative\nmulti-agent reinforcement learning. A common approach is to share observations\nthrough full communication, leading to significant communication overhead.\nExisting work attempts to perceive the global state by conducting teammate\nmodel based on local information. However, they ignore that the uncertainty\ngenerated by prediction may lead to difficult training. To address this\nproblem, we propose a Demand-aware Customized Multi-Agent Communication (DCMAC)\nprotocol, which use an upper bound training to obtain the ideal policy. By\nutilizing the demand parsing module, agent can interpret the gain of sending\nlocal message on teammate, and generate customized messages via compute the\ncorrelation between demands and local observation using cross-attention\nmechanism. Moreover, our method can adapt to the communication resources of\nagents and accelerate the training progress by appropriating the ideal policy\nwhich is trained with joint observation. Experimental results reveal that DCMAC\nsignificantly outperforms the baseline algorithms in both unconstrained and\ncommunication constrained scenarios.\n","authors":["Dongkun Huo","Huateng Zhang","Yixue Hao","Yuanlin Ye","Long Hu","Rui Wang","Min Chen"],"pdf_url":"https://arxiv.org/pdf/2409.07127v2.pdf","comment":"Paper has errors and needs to be revised and submitted"},{"id":"http://arxiv.org/abs/2409.15092v2","updated":"2024-12-10T02:15:22Z","published":"2024-09-23T15:06:37Z","title":"M2OST: Many-to-one Regression for Predicting Spatial Transcriptomics\n  from Digital Pathology Images","summary":"  The advancement of Spatial Transcriptomics (ST) has facilitated the\nspatially-aware profiling of gene expressions based on histopathology images.\nAlthough ST data offers valuable insights into the micro-environment of tumors,\nits acquisition cost remains expensive. Therefore, directly predicting the ST\nexpressions from digital pathology images is desired. Current methods usually\nadopt existing regression backbones along with patch-sampling for this task,\nwhich ignores the inherent multi-scale information embedded in the pyramidal\ndata structure of digital pathology images, and wastes the inter-spot visual\ninformation crucial for accurate gene expression prediction. To address these\nlimitations, we propose M2OST, a many-to-one regression Transformer that can\naccommodate the hierarchical structure of the pathology images via a decoupled\nmulti-scale feature extractor. Unlike traditional models that are trained with\none-to-one image-label pairs, M2OST uses multiple images from different levels\nof the digital pathology image to jointly predict the gene expressions in their\ncommon corresponding spot. Built upon our many-to-one scheme, M2OST can be\neasily scaled to fit different numbers of inputs, and its network structure\ninherently incorporates nearby inter-spot features, enhancing regression\nperformance. We have tested M2OST on three public ST datasets and the\nexperimental results show that M2OST can achieve state-of-the-art performance\nwith fewer parameters and floating-point operations (FLOPs). The code is\navailable at: https://github.com/Dootmaan/M2OST.\n","authors":["Hongyi Wang","Xiuju Du","Jing Liu","Shuyi Ouyang","Yen-Wei Chen","Lanfen Lin"],"pdf_url":"https://arxiv.org/pdf/2409.15092v2.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2412.07116v1","updated":"2024-12-10T02:06:10Z","published":"2024-12-10T02:06:10Z","title":"A Review of Human Emotion Synthesis Based on Generative Technology","summary":"  Human emotion synthesis is a crucial aspect of affective computing. It\ninvolves using computational methods to mimic and convey human emotions through\nvarious modalities, with the goal of enabling more natural and effective\nhuman-computer interactions. Recent advancements in generative models, such as\nAutoencoders, Generative Adversarial Networks, Diffusion Models, Large Language\nModels, and Sequence-to-Sequence Models, have significantly contributed to the\ndevelopment of this field. However, there is a notable lack of comprehensive\nreviews in this field. To address this problem, this paper aims to address this\ngap by providing a thorough and systematic overview of recent advancements in\nhuman emotion synthesis based on generative models. Specifically, this review\nwill first present the review methodology, the emotion models involved, the\nmathematical principles of generative models, and the datasets used. Then, the\nreview covers the application of different generative models to emotion\nsynthesis based on a variety of modalities, including facial images, speech,\nand text. It also examines mainstream evaluation metrics. Additionally, the\nreview presents some major findings and suggests future research directions,\nproviding a comprehensive understanding of the role of generative technology in\nthe nuanced domain of emotion synthesis.\n","authors":["Fei Ma","Yukan Li","Yifan Xie","Ying He","Yi Zhang","Hongwei Ren","Zhou Liu","Wei Yao","Fuji Ren","Fei Richard Yu","Shiguang Ni"],"pdf_url":"https://arxiv.org/pdf/2412.07116v1.pdf","comment":"25 pages, 10 figures"},{"id":"http://arxiv.org/abs/2410.07974v4","updated":"2024-12-10T01:57:00Z","published":"2024-10-10T14:32:16Z","title":"Doob's Lagrangian: A Sample-Efficient Variational Approach to Transition\n  Path Sampling","summary":"  Rare event sampling in dynamical systems is a fundamental problem arising in\nthe natural sciences, which poses significant computational challenges due to\nan exponentially large space of trajectories. For settings where the dynamical\nsystem of interest follows a Brownian motion with known drift, the question of\nconditioning the process to reach a given endpoint or desired rare event is\ndefinitively answered by Doob's h-transform. However, the naive estimation of\nthis transform is infeasible, as it requires simulating sufficiently many\nforward trajectories to estimate rare event probabilities. In this work, we\npropose a variational formulation of Doob's h-transform as an optimization\nproblem over trajectories between a given initial point and the desired ending\npoint. To solve this optimization, we propose a simulation-free training\nobjective with a model parameterization that imposes the desired boundary\nconditions by design. Our approach significantly reduces the search space over\ntrajectories and avoids expensive trajectory simulation and inefficient\nimportance sampling estimators which are required in existing methods. We\ndemonstrate the ability of our method to find feasible transition paths on\nreal-world molecular simulation and protein folding tasks.\n","authors":["Yuanqi Du","Michael Plainer","Rob Brekelmans","Chenru Duan","Frank Noé","Carla P. Gomes","Alán Aspuru-Guzik","Kirill Neklyudov"],"pdf_url":"https://arxiv.org/pdf/2410.07974v4.pdf","comment":"Accepted as Spotlight at Conference on Neural Information Processing\n  Systems (NeurIPS 2024); Alanine dipeptide results updated after fixing\n  unphysical parameterization and energy computation"},{"id":"http://arxiv.org/abs/2306.01631v5","updated":"2024-12-10T01:31:17Z","published":"2023-06-02T15:49:45Z","title":"Bi-level Contrastive Learning for Knowledge-Enhanced Molecule\n  Representations","summary":"  Molecular representation learning is vital for various downstream\napplications, including the analysis and prediction of molecular properties and\nside effects. While Graph Neural Networks (GNNs) have been a popular framework\nfor modeling molecular data, they often struggle to capture the full complexity\nof molecular representations. In this paper, we introduce a novel method called\nGODE, which accounts for the dual-level structure inherent in molecules.\nMolecules possess an intrinsic graph structure and simultaneously function as\nnodes within a broader molecular knowledge graph. GODE integrates individual\nmolecular graph representations with multi-domain biochemical data from\nknowledge graphs. By pre-training two GNNs on different graph structures and\nemploying contrastive learning, GODE effectively fuses molecular structures\nwith their corresponding knowledge graph substructures. This fusion yields a\nmore robust and informative representation, enhancing molecular property\npredictions by leveraging both chemical and biological information. When\nfine-tuned across 11 chemical property tasks, our model significantly\noutperforms existing benchmarks, achieving an average ROC-AUC improvement of\n12.7% for classification tasks and an average RMSE/MAE improvement of 34.4% for\nregression tasks. Notably, GODE surpasses the current leading model in property\nprediction, with advancements of 2.2% in classification and 7.2% in regression\ntasks.\n","authors":["Pengcheng Jiang","Cao Xiao","Tianfan Fu","Parminder Bhatia","Taha Kass-Hout","Jimeng Sun","Jiawei Han"],"pdf_url":"https://arxiv.org/pdf/2306.01631v5.pdf","comment":"AAAI 2025"},{"id":"http://arxiv.org/abs/2412.07097v1","updated":"2024-12-10T01:30:32Z","published":"2024-12-10T01:30:32Z","title":"On Evaluating the Durability of Safeguards for Open-Weight LLMs","summary":"  Stakeholders -- from model developers to policymakers -- seek to minimize the\ndual-use risks of large language models (LLMs). An open challenge to this goal\nis whether technical safeguards can impede the misuse of LLMs, even when models\nare customizable via fine-tuning or when model weights are fully open. In\nresponse, several recent studies have proposed methods to produce durable LLM\nsafeguards for open-weight LLMs that can withstand adversarial modifications of\nthe model's weights via fine-tuning. This holds the promise of raising\nadversaries' costs even under strong threat models where adversaries can\ndirectly fine-tune model weights. However, in this paper, we urge for more\ncareful characterization of the limits of these approaches. Through several\ncase studies, we demonstrate that even evaluating these defenses is exceedingly\ndifficult and can easily mislead audiences into thinking that safeguards are\nmore durable than they really are. We draw lessons from the evaluation pitfalls\nthat we identify and suggest future research carefully cabin claims to more\nconstrained, well-defined, and rigorously examined threat models, which can\nprovide more useful and candid assessments to stakeholders.\n","authors":["Xiangyu Qi","Boyi Wei","Nicholas Carlini","Yangsibo Huang","Tinghao Xie","Luxi He","Matthew Jagielski","Milad Nasr","Prateek Mittal","Peter Henderson"],"pdf_url":"https://arxiv.org/pdf/2412.07097v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07096v1","updated":"2024-12-10T01:29:51Z","published":"2024-12-10T01:29:51Z","title":"QAPyramid: Fine-grained Evaluation of Content Selection for Text\n  Summarization","summary":"  How to properly conduct human evaluations for text summarization is a\nlongstanding challenge. The Pyramid human evaluation protocol, which assesses\ncontent selection by breaking the reference summary into sub-units and\nverifying their presence in the system summary, has been widely adopted.\nHowever, it suffers from a lack of systematicity in the definition and\ngranularity of the sub-units. We address these problems by proposing QAPyramid,\nwhich decomposes each reference summary into finer-grained question-answer (QA)\npairs according to the QA-SRL framework. We collect QA-SRL annotations for\nreference summaries from CNN/DM and evaluate 10 summarization systems,\nresulting in 8.9K QA-level annotations. We show that, compared to Pyramid,\nQAPyramid provides more systematic and fine-grained content selection\nevaluation while maintaining high inter-annotator agreement without needing\nexpert annotations. Furthermore, we propose metrics that automate the\nevaluation pipeline and achieve higher correlations with QAPyramid than other\nwidely adopted metrics, allowing future work to accurately and efficiently\nbenchmark summarization systems.\n","authors":["Shiyue Zhang","David Wan","Arie Cattan","Ayal Klein","Ido Dagan","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2412.07096v1.pdf","comment":"The first two authors contributed equally. Code:\n  https://github.com/ZhangShiyue/QAPyramid"},{"id":"http://arxiv.org/abs/2407.05285v2","updated":"2024-12-10T01:22:33Z","published":"2024-07-07T07:06:49Z","title":"Gradient Diffusion: A Perturbation-Resilient Gradient Leakage Attack","summary":"  Recent years have witnessed the vulnerability of Federated Learning (FL)\nagainst gradient leakage attacks, where the private training data can be\nrecovered from the exchanged gradients, making gradient protection a critical\nissue for the FL training process. Existing solutions often resort to\nperturbation-based mechanisms, such as differential privacy, where each\nparticipating client injects a specific amount of noise into local gradients\nbefore aggregating to the server, and the global distribution variation finally\nconceals the gradient privacy. However, perturbation is not always the panacea\nfor gradient protection since the robustness heavily relies on the injected\nnoise. This intuition raises an interesting question: \\textit{is it possible to\ndeactivate existing protection mechanisms by removing the perturbation inside\nthe gradients?} In this paper, we present the answer: \\textit{yes} and propose\nthe Perturbation-resilient Gradient Leakage Attack (PGLA), the first attempt to\nrecover the perturbed gradients, without additional access to the original\nmodel structure or third-party data. Specifically, we leverage the inherent\ndiffusion property of gradient perturbation protection and construct a novel\ndiffusion-based denoising model to implement PGLA. Our insight is that\ncapturing the disturbance level of perturbation during the diffusion reverse\nprocess can release the gradient denoising capability, which promotes the\ndiffusion model to generate approximate gradients as the original clean version\nthrough adaptive sampling steps. Extensive experiments demonstrate that PGLA\neffectively recovers the protected gradients and exposes the FL training\nprocess to the threat of gradient leakage, achieving the best quality in\ngradient denoising and data recovery compared to existing models. We hope to\narouse public attention on PGLA and its defense.\n","authors":["Xuan Liu","Siqi Cai","Qihua Zhou","Song Guo","Ruibin Li","Kaiwei Lin"],"pdf_url":"https://arxiv.org/pdf/2407.05285v2.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2412.07094v1","updated":"2024-12-10T01:22:32Z","published":"2024-12-10T01:22:32Z","title":"Access Point Deployment for Localizing Accuracy and User Rate in\n  Cell-Free Systems","summary":"  Evolving next-generation mobile networks is designed to provide ubiquitous\ncoverage and networked sensing. With utility of multi-view sensing and\nmulti-node joint transmission, cell-free is a promising technique to realize\nthis prospect. This paper aims to tackle the problem of access point (AP)\ndeployment in cell-free systems to balance the sensing accuracy and user rate.\nBy merging the D-optimality with Euclidean criterion, a novel integrated metric\nis proposed to be the objective function for both max-sum and max-min problems,\nwhich respectively guarantee the overall and lowest performance in multi-user\ncommunication and target tracking scenario. To solve the corresponding high\ndimensional non-convex multi-objective problem, the Soft actor-critic (SAC) is\nutilized to avoid risk of local optimal result. Numerical results demonstrate\nthat proposed SAC-based APs deployment method achieves $20\\%$ of overall\nperformance and $120\\%$ of lowest performance.\n","authors":["Fanfei Xu","Shengheng Liu","Zihuan Mao","Shangqing Shi","Dazhuan Xu","Dongming Wang","Yongming Huang"],"pdf_url":"https://arxiv.org/pdf/2412.07094v1.pdf","comment":"Presented at MobiCom 2024"},{"id":"http://arxiv.org/abs/2412.07081v1","updated":"2024-12-10T00:47:10Z","published":"2024-12-10T00:47:10Z","title":"Sequential Controlled Langevin Diffusions","summary":"  An effective approach for sampling from unnormalized densities is based on\nthe idea of gradually transporting samples from an easy prior to the\ncomplicated target distribution. Two popular methods are (1) Sequential Monte\nCarlo (SMC), where the transport is performed through successive annealed\ndensities via prescribed Markov chains and resampling steps, and (2) recently\ndeveloped diffusion-based sampling methods, where a learned dynamical transport\nis used. Despite the common goal, both approaches have different, often\ncomplementary, advantages and drawbacks. The resampling steps in SMC allow\nfocusing on promising regions of the space, often leading to robust\nperformance. While the algorithm enjoys asymptotic guarantees, the lack of\nflexible, learnable transitions can lead to slow convergence. On the other\nhand, diffusion-based samplers are learned and can potentially better adapt\nthemselves to the target at hand, yet often suffer from training instabilities.\nIn this work, we present a principled framework for combining SMC with\ndiffusion-based samplers by viewing both methods in continuous time and\nconsidering measures on path space. This culminates in the new Sequential\nControlled Langevin Diffusion (SCLD) sampling method, which is able to utilize\nthe benefits of both methods and reaches improved performance on multiple\nbenchmark problems, in many cases using only 10% of the training budget of\nprevious diffusion-based samplers.\n","authors":["Junhua Chen","Lorenz Richter","Julius Berner","Denis Blessing","Gerhard Neumann","Anima Anandkumar"],"pdf_url":"https://arxiv.org/pdf/2412.07081v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07080v1","updated":"2024-12-10T00:42:54Z","published":"2024-12-10T00:42:54Z","title":"EvRepSL: Event-Stream Representation via Self-Supervised Learning for\n  Event-Based Vision","summary":"  Event-stream representation is the first step for many computer vision tasks\nusing event cameras. It converts the asynchronous event-streams into a\nformatted structure so that conventional machine learning models can be applied\neasily. However, most of the state-of-the-art event-stream representations are\nmanually designed and the quality of these representations cannot be guaranteed\ndue to the noisy nature of event-streams. In this paper, we introduce a\ndata-driven approach aiming at enhancing the quality of event-stream\nrepresentations. Our approach commences with the introduction of a new\nevent-stream representation based on spatial-temporal statistics, denoted as\nEvRep. Subsequently, we theoretically derive the intrinsic relationship between\nasynchronous event-streams and synchronous video frames. Building upon this\ntheoretical relationship, we train a representation generator, RepGen, in a\nself-supervised learning manner accepting EvRep as input. Finally, the\nevent-streams are converted to high-quality representations, termed as EvRepSL,\nby going through the learned RepGen (without the need of fine-tuning or\nretraining). Our methodology is rigorously validated through extensive\nevaluations on a variety of mainstream event-based classification and optical\nflow datasets (captured with various types of event cameras). The experimental\nresults highlight not only our approach's superior performance over existing\nevent-stream representations but also its versatility, being agnostic to\ndifferent event cameras and tasks.\n","authors":["Qiang Qu","Xiaoming Chen","Yuk Ying Chung","Yiran Shen"],"pdf_url":"https://arxiv.org/pdf/2412.07080v1.pdf","comment":"Published on IEEE Transactions on Image Processing"},{"id":"http://arxiv.org/abs/2412.07078v1","updated":"2024-12-10T00:41:25Z","published":"2024-12-10T00:41:25Z","title":"Defensive Dual Masking for Robust Adversarial Defense","summary":"  The field of textual adversarial defenses has gained considerable attention\nin recent years due to the increasing vulnerability of natural language\nprocessing (NLP) models to adversarial attacks, which exploit subtle\nperturbations in input text to deceive models. This paper introduces the\nDefensive Dual Masking (DDM) algorithm, a novel approach designed to enhance\nmodel robustness against such attacks. DDM utilizes a unique adversarial\ntraining strategy where [MASK] tokens are strategically inserted into training\nsamples to prepare the model to handle adversarial perturbations more\neffectively. During inference, potentially adversarial tokens are dynamically\nreplaced with [MASK] tokens to neutralize potential threats while preserving\nthe core semantics of the input. The theoretical foundation of our approach is\nexplored, demonstrating how the selective masking mechanism strengthens the\nmodel's ability to identify and mitigate adversarial manipulations. Our\nempirical evaluation across a diverse set of benchmark datasets and attack\nmechanisms consistently shows that DDM outperforms state-of-the-art defense\ntechniques, improving model accuracy and robustness. Moreover, when applied to\nLarge Language Models (LLMs), DDM also enhances their resilience to adversarial\nattacks, providing a scalable defense mechanism for large-scale NLP\napplications.\n","authors":["Wangli Yang","Jie Yang","Yi Guo","Johan Barthelemy"],"pdf_url":"https://arxiv.org/pdf/2412.07078v1.pdf","comment":"First version"},{"id":"http://arxiv.org/abs/2412.07066v1","updated":"2024-12-10T00:18:29Z","published":"2024-12-10T00:18:29Z","title":"The Mirage of Artificial Intelligence Terms of Use Restrictions","summary":"  Artificial intelligence (AI) model creators commonly attach restrictive terms\nof use to both their models and their outputs. These terms typically prohibit\nactivities ranging from creating competing AI models to spreading\ndisinformation. Often taken at face value, these terms are positioned by\ncompanies as key enforceable tools for preventing misuse, particularly in\npolicy dialogs. But are these terms truly meaningful? There are myriad examples\nwhere these broad terms are regularly and repeatedly violated. Yet except for\nsome account suspensions on platforms, no model creator has actually tried to\nenforce these terms with monetary penalties or injunctive relief. This is\nlikely for good reason: we think that the legal enforceability of these\nlicenses is questionable.\n  This Article systematically assesses of the enforceability of AI model terms\nof use and offers three contributions. First, we pinpoint a key problem: the\nartifacts that they protect, namely model weights and model outputs, are\nlargely not copyrightable, making it unclear whether there is even anything to\nbe licensed. Second, we examine the problems this creates for other\nenforcement. Recent doctrinal trends in copyright preemption may further\nundermine state-law claims, while other legal frameworks like the DMCA and CFAA\noffer limited recourse. Anti-competitive provisions likely fare even worse than\nresponsible use provisions. Third, we provide recommendations to policymakers.\nThere are compelling reasons for many provisions to be unenforceable: they\nchill good faith research, constrain competition, and create quasi-copyright\nownership where none should exist. There are, of course, downsides: model\ncreators have fewer tools to prevent harmful misuse. But we think the better\napproach is for statutory provisions, not private fiat, to distinguish between\ngood and bad uses of AI, restricting the latter.\n","authors":["Peter Henderson","Mark A. Lemley"],"pdf_url":"https://arxiv.org/pdf/2412.07066v1.pdf","comment":"Forthcoming Indiana Law Journal"},{"id":"http://arxiv.org/abs/2412.07981v1","updated":"2024-12-10T23:43:06Z","published":"2024-12-10T23:43:06Z","title":"Where Common Knowledge Cannot Be Formed, Common Belief Can -- Planning\n  with Multi-Agent Belief Using Group Justified Perspectives","summary":"  Epistemic planning is the sub-field of AI planning that focuses on changing\nknowledge and belief. It is important in both multi-agent domains where agents\nneed to have knowledge/belief regarding the environment, but also the beliefs\nof other agents, including nested beliefs. When modeling knowledge in\nmulti-agent settings, many models face an exponential growth challenge in terms\nof nested depth. A contemporary method, known as Planning with Perspectives\n(PWP), addresses these challenges through the use of perspectives and set\noperations for knowledge. The JP model defines that an agent's belief is\njustified if and only if the agent has seen evidence that this belief was true\nin the past and has not seen evidence to suggest that this has changed. The\ncurrent paper extends the JP model to handle \\emph{group belief}, including\ndistributed belief and common belief. We call this the Group Justified\nPerspective (GJP) model. Using experimental problems crafted by adapting\nwell-known benchmarks to a group setting, we show the efficiency and\nexpressiveness of our GJP model at handling planning problems that cannot be\nhandled by other epistemic planning tools.\n","authors":["Guang Hu","Tim Miller","Nir Lipovetzky"],"pdf_url":"https://arxiv.org/pdf/2412.07981v1.pdf","comment":"10 pages, including appendix and reference"}]},"2024-12-11T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2412.08639v1","updated":"2024-12-11T18:58:41Z","published":"2024-12-11T18:58:41Z","title":"Fast Prompt Alignment for Text-to-Image Generation","summary":"  Text-to-image generation has advanced rapidly, yet aligning complex textual\nprompts with generated visuals remains challenging, especially with intricate\nobject relationships and fine-grained details. This paper introduces Fast\nPrompt Alignment (FPA), a prompt optimization framework that leverages a\none-pass approach, enhancing text-to-image alignment efficiency without the\niterative overhead typical of current methods like OPT2I. FPA uses large\nlanguage models (LLMs) for single-iteration prompt paraphrasing, followed by\nfine-tuning or in-context learning with optimized prompts to enable real-time\ninference, reducing computational demands while preserving alignment fidelity.\nExtensive evaluations on the COCO Captions and PartiPrompts datasets\ndemonstrate that FPA achieves competitive text-image alignment scores at a\nfraction of the processing time, as validated through both automated metrics\n(TIFA, VQA) and human evaluation. A human study with expert annotators further\nreveals a strong correlation between human alignment judgments and automated\nscores, underscoring the robustness of FPA's improvements. The proposed method\nshowcases a scalable, efficient alternative to iterative prompt optimization,\nenabling broader applicability in real-time, high-demand settings. The codebase\nis provided to facilitate further research:\nhttps://github.com/tiktok/fast_prompt_alignment\n","authors":["Khalil Mrini","Hanlin Lu","Linjie Yang","Weilin Huang","Heng Wang"],"pdf_url":"https://arxiv.org/pdf/2412.08639v1.pdf","comment":"TikTok Technical Report"},{"id":"http://arxiv.org/abs/2412.08635v1","updated":"2024-12-11T18:57:32Z","published":"2024-12-11T18:57:32Z","title":"Multimodal Latent Language Modeling with Next-Token Diffusion","summary":"  Multimodal generative models require a unified approach to handle both\ndiscrete data (e.g., text and code) and continuous data (e.g., image, audio,\nvideo). In this work, we propose Latent Language Modeling (LatentLM), which\nseamlessly integrates continuous and discrete data using causal Transformers.\nSpecifically, we employ a variational autoencoder (VAE) to represent continuous\ndata as latent vectors and introduce next-token diffusion for autoregressive\ngeneration of these vectors. Additionally, we develop $\\sigma$-VAE to address\nthe challenges of variance collapse, which is crucial for autoregressive\nmodeling. Extensive experiments demonstrate the effectiveness of LatentLM\nacross various modalities. In image generation, LatentLM surpasses Diffusion\nTransformers in both performance and scalability. When integrated into\nmultimodal large language models, LatentLM provides a general-purpose interface\nthat unifies multimodal generation and understanding. Experimental results show\nthat LatentLM achieves favorable performance compared to Transfusion and vector\nquantized models in the setting of scaling up training tokens. In\ntext-to-speech synthesis, LatentLM outperforms the state-of-the-art VALL-E 2\nmodel in speaker similarity and robustness, while requiring 10x fewer decoding\nsteps. The results establish LatentLM as a highly effective and scalable\napproach to advance large multimodal models.\n","authors":["Yutao Sun","Hangbo Bao","Wenhui Wang","Zhiliang Peng","Li Dong","Shaohan Huang","Jianyong Wang","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2412.08635v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08615v1","updated":"2024-12-11T18:37:56Z","published":"2024-12-11T18:37:56Z","title":"Exploiting the Index Gradients for Optimization-Based Jailbreaking on\n  Large Language Models","summary":"  Despite the advancements in training Large Language Models (LLMs) with\nalignment techniques to enhance the safety of generated content, these models\nremain susceptible to jailbreak, an adversarial attack method that exposes\nsecurity vulnerabilities in LLMs. Notably, the Greedy Coordinate Gradient (GCG)\nmethod has demonstrated the ability to automatically generate adversarial\nsuffixes that jailbreak state-of-the-art LLMs. However, the optimization\nprocess involved in GCG is highly time-consuming, rendering the jailbreaking\npipeline inefficient. In this paper, we investigate the process of GCG and\nidentify an issue of Indirect Effect, the key bottleneck of the GCG\noptimization. To this end, we propose the Model Attack Gradient Index GCG\n(MAGIC), that addresses the Indirect Effect by exploiting the gradient\ninformation of the suffix tokens, thereby accelerating the procedure by having\nless computation and fewer iterations. Our experiments on AdvBench show that\nMAGIC achieves up to a 1.5x speedup, while maintaining Attack Success Rates\n(ASR) on par or even higher than other baselines. Our MAGIC achieved an ASR of\n74% on the Llama-2 and an ASR of 54% when conducting transfer attacks on\nGPT-3.5. Code is available at https://github.com/jiah-li/magic.\n","authors":["Jiahui Li","Yongchang Hao","Haoyu Xu","Xing Wang","Yu Hong"],"pdf_url":"https://arxiv.org/pdf/2412.08615v1.pdf","comment":"13 pages,2 figures, accepted by The 31st International Conference on\n  Computational Linguistics"},{"id":"http://arxiv.org/abs/2412.08599v1","updated":"2024-12-11T18:18:07Z","published":"2024-12-11T18:18:07Z","title":"Der Effizienz- und Intelligenzbegriff in der Lexikographie und\n  kuenstlichen Intelligenz: kann ChatGPT die lexikographische Textsorte\n  nachbilden?","summary":"  By means of pilot experiments for the language pair German and Galician, this\npaper examines the concept of efficiency and intelligence in lexicography and\nartificial intelligence, AI. The aim of the experiments is to gain empirically\nand statistically based insights into the lexicographical text type,dictionary\narticle, in the responses of ChatGPT 3.5, as well as into the lexicographical\ndata on which this chatbot was trained. Both quantitative and qualitative\nmethods are used for this purpose. The analysis is based on the evaluation of\nthe outputs of several sessions with the same prompt in ChatGPT 3.5. On the one\nhand, the algorithmic performance of intelligent systems is evaluated in\ncomparison with data from lexicographical works. On the other hand, the ChatGPT\ndata supplied is analysed using specific text passages of the aforementioned\nlexicographical text type. The results of this study not only help to evaluate\nthe efficiency of this chatbot regarding the creation of dictionary articles,\nbut also to delve deeper into the concept of intelligence, the thought\nprocesses and the actions to be carried out in both disciplines.\n","authors":["Ivan Arias-Arias","Maria Jose Dominguez Vazquez","Carlos Valcarcel Riveiro"],"pdf_url":"https://arxiv.org/pdf/2412.08599v1.pdf","comment":"25 pages, in German language"},{"id":"http://arxiv.org/abs/2403.12151v3","updated":"2024-12-11T18:12:43Z","published":"2024-03-18T18:08:44Z","title":"Fusing Domain-Specific Content from Large Language Models into Knowledge\n  Graphs for Enhanced Zero Shot Object State Classification","summary":"  Domain-specific knowledge can significantly contribute to addressing a wide\nvariety of vision tasks. However, the generation of such knowledge entails\nconsiderable human labor and time costs. This study investigates the potential\nof Large Language Models (LLMs) in generating and providing domain-specific\ninformation through semantic embeddings. To achieve this, an LLM is integrated\ninto a pipeline that utilizes Knowledge Graphs and pre-trained semantic vectors\nin the context of the Vision-based Zero-shot Object State Classification task.\nWe thoroughly examine the behavior of the LLM through an extensive ablation\nstudy. Our findings reveal that the integration of LLM-based embeddings, in\ncombination with general-purpose pre-trained embeddings, leads to substantial\nperformance improvements. Drawing insights from this ablation study, we conduct\na comparative analysis against competing models, thereby highlighting the\nstate-of-the-art performance achieved by the proposed approach.\n","authors":["Filippos Gouidis","Katerina Papantoniou","Konstantinos Papoutsakis","Theodore Patkos","Antonis Argyros","Dimitris Plexousakis"],"pdf_url":"https://arxiv.org/pdf/2403.12151v3.pdf","comment":"Accepted at the AAAI-MAKE 2024"},{"id":"http://arxiv.org/abs/2402.16822v3","updated":"2024-12-11T18:07:25Z","published":"2024-02-26T18:47:27Z","title":"Rainbow Teaming: Open-Ended Generation of Diverse Adversarial Prompts","summary":"  As large language models (LLMs) become increasingly prevalent across many\nreal-world applications, understanding and enhancing their robustness to\nadversarial attacks is of paramount importance. Existing methods for\nidentifying adversarial prompts tend to focus on specific domains, lack\ndiversity, or require extensive human annotations. To address these\nlimitations, we present Rainbow Teaming, a novel black-box approach for\nproducing a diverse collection of adversarial prompts. Rainbow Teaming casts\nadversarial prompt generation as a quality-diversity problem and uses\nopen-ended search to generate prompts that are both effective and diverse.\nFocusing on the safety domain, we use Rainbow Teaming to target various\nstate-of-the-art LLMs, including the Llama 2 and Llama 3 models. Our approach\nreveals hundreds of effective adversarial prompts, with an attack success rate\nexceeding 90% across all tested models. Furthermore, we demonstrate that\nprompts generated by Rainbow Teaming are highly transferable and that\nfine-tuning models with synthetic data generated by our method significantly\nenhances their safety without sacrificing general performance or helpfulness.\nWe additionally explore the versatility of Rainbow Teaming by applying it to\nquestion answering and cybersecurity, showcasing its potential to drive robust\nopen-ended self-improvement in a wide range of applications.\n","authors":["Mikayel Samvelyan","Sharath Chandra Raparthy","Andrei Lupu","Eric Hambro","Aram H. Markosyan","Manish Bhatt","Yuning Mao","Minqi Jiang","Jack Parker-Holder","Jakob Foerster","Tim Rocktäschel","Roberta Raileanu"],"pdf_url":"https://arxiv.org/pdf/2402.16822v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08587v1","updated":"2024-12-11T18:06:44Z","published":"2024-12-11T18:06:44Z","title":"Advancing Single- and Multi-task Text Classification through Large\n  Language Model Fine-tuning","summary":"  Both encoder-only models (e.g., BERT, RoBERTa) and large language models\n(LLMs, e.g., Llama3) have been widely used for text classification tasks.\nHowever, there is a lack of systematic studies comparing the performance of\nencoder-based models and LLMs in text classification, particularly when\nfine-tuning is involved. This study employed a diverse range of models and\nmethods, varying in size and architecture, and including both fine-tuned and\npre-trained approaches. We first assessed the performances of these LLMs on the\n20 Newsgroups (20NG) and MASSIVE datasets, comparing them to encoder-only\nRoBERTa models. Additionally, we explored the multi-task capabilities of both\nmodel types by combining multiple classification tasks, including intent\ndetection and slot-filling, into a single model using data from both datasets.\nOur results indicate that fully fine-tuned Llama3-70B models outperform\nRoBERTa-large and other decoder LLMs across various classification tasks and\ndatasets. Moreover, the consolidated multi-task fine-tuned LLMs matched the\nperformance of dual-model setups in both tasks across both datasets. Overall,\nour study provides a comprehensive benchmark of encoder-only and LLM models on\ntext classification tasks and demonstrates a method to combine two or more\nfully fine-tuned decoder LLMs for reduced latency and equivalent performance.\n","authors":["Hang Zhao","Qile P. Chen","Yijing Barry Zhang","Gang Yang"],"pdf_url":"https://arxiv.org/pdf/2412.08587v1.pdf","comment":"9 pages, 3 tables"},{"id":"http://arxiv.org/abs/2412.08578v1","updated":"2024-12-11T17:54:01Z","published":"2024-12-11T17:54:01Z","title":"Machine Learning Information Retrieval and Summarisation to Support\n  Systematic Review on Outcomes Based Contracting","summary":"  As academic literature proliferates, traditional review methods are\nincreasingly challenged by the sheer volume and diversity of available\nresearch. This article presents a study that aims to address these challenges\nby enhancing the efficiency and scope of systematic reviews in the social\nsciences through advanced machine learning (ML) and natural language processing\n(NLP) tools. In particular, we focus on automating stages within the systematic\nreviewing process that are time-intensive and repetitive for human annotators\nand which lend themselves to immediate scalability through tools such as\ninformation retrieval and summarisation guided by expert advice. The article\nconcludes with a summary of lessons learnt regarding the integrated approach\ntowards systematic reviews and future directions for improvement, including\nexplainability.\n","authors":["Iman Munire Bilal","Zheng Fang","Miguel Arana-Catania","Felix-Anselm van Lier","Juliana Outes Velarde","Harry Bregazzi","Eleanor Carter","Mara Airoldi","Rob Procter"],"pdf_url":"https://arxiv.org/pdf/2412.08578v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08564v1","updated":"2024-12-11T17:32:21Z","published":"2024-12-11T17:32:21Z","title":"Can We Generate Visual Programs Without Prompting LLMs?","summary":"  Visual programming prompts LLMs (large language mod-els) to generate\nexecutable code for visual tasks like visual question answering (VQA).\nPrompt-based methods are difficult to improve while also being unreliable and\ncostly in both time and money. Our goal is to develop an efficient visual\nprogramming system without 1) using prompt-based LLMs at inference time and 2)\na large set of program and answer annotations. We develop a synthetic data\naugmentation approach and alternative program generation method based on\ndecoupling programs into higher-level skills called templates and the\ncorresponding arguments. Our results show that with data augmentation,\nprompt-free smaller LLMs ($\\approx$ 1B parameters) are competitive with\nstate-of-the art models with the added benefit of much faster inference\n","authors":["Michal Shlapentokh-Rothman","Yu-Xiong Wang","Derek Hoiem"],"pdf_url":"https://arxiv.org/pdf/2412.08564v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08548v1","updated":"2024-12-11T17:06:12Z","published":"2024-12-11T17:06:12Z","title":"Bilevel Joint Unsupervised and Supervised Training for Automatic Speech\n  Recognition","summary":"  In this paper, we propose a bilevel joint unsupervised and supervised\ntraining (BL-JUST) framework for automatic speech recognition. Compared to the\nconventional pre-training and fine-tuning strategy which is a disconnected\ntwo-stage process, BL-JUST tries to optimize an acoustic model such that it\nsimultaneously minimizes both the unsupervised and supervised loss functions.\nBecause BL-JUST seeks matched local optima of both loss functions, acoustic\nrepresentations learned by the acoustic model strike a good balance between\nbeing generic and task-specific. We solve the BL-JUST problem using\npenalty-based bilevel gradient descent and evaluate the trained deep neural\nnetwork acoustic models on various datasets with a variety of architectures and\nloss functions. We show that BL-JUST can outperform the widely-used\npre-training and fine-tuning strategy and some other popular semi-supervised\ntechniques.\n","authors":["Xiaodong Cui","A F M Saif","Songtao Lu","Lisha Chen","Tianyi Chen","Brian Kingsbury","George Saon"],"pdf_url":"https://arxiv.org/pdf/2412.08548v1.pdf","comment":"Accepted by IEEE/ACM Transactions on Audio, Speech and Language\n  Processing"},{"id":"http://arxiv.org/abs/2412.08542v1","updated":"2024-12-11T16:59:31Z","published":"2024-12-11T16:59:31Z","title":"MaestroMotif: Skill Design from Artificial Intelligence Feedback","summary":"  Describing skills in natural language has the potential to provide an\naccessible way to inject human knowledge about decision-making into an AI\nsystem. We present MaestroMotif, a method for AI-assisted skill design, which\nyields high-performing and adaptable agents. MaestroMotif leverages the\ncapabilities of Large Language Models (LLMs) to effectively create and reuse\nskills. It first uses an LLM's feedback to automatically design rewards\ncorresponding to each skill, starting from their natural language description.\nThen, it employs an LLM's code generation abilities, together with\nreinforcement learning, for training the skills and combining them to implement\ncomplex behaviors specified in language. We evaluate MaestroMotif using a suite\nof complex tasks in the NetHack Learning Environment (NLE), demonstrating that\nit surpasses existing approaches in both performance and usability.\n","authors":["Martin Klissarov","Mikael Henaff","Roberta Raileanu","Shagun Sodhani","Pascal Vincent","Amy Zhang","Pierre-Luc Bacon","Doina Precup","Marlos C. Machado","Pierluca D'Oro"],"pdf_url":"https://arxiv.org/pdf/2412.08542v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08529v1","updated":"2024-12-11T16:38:48Z","published":"2024-12-11T16:38:48Z","title":"TECO: Improving Multimodal Intent Recognition with Text Enhancement\n  through Commonsense Knowledge Extraction","summary":"  The objective of multimodal intent recognition (MIR) is to leverage various\nmodalities-such as text, video, and audio-to detect user intentions, which is\ncrucial for understanding human language and context in dialogue systems.\nDespite advances in this field, two main challenges persist: (1) effectively\nextracting and utilizing semantic information from robust textual features; (2)\naligning and fusing non-verbal modalities with verbal ones effectively. This\npaper proposes a Text Enhancement with CommOnsense Knowledge Extractor (TECO)\nto address these challenges. We begin by extracting relations from both\ngenerated and retrieved knowledge to enrich the contextual information in the\ntext modality. Subsequently, we align and integrate visual and acoustic\nrepresentations with these enhanced text features to form a cohesive multimodal\nrepresentation. Our experimental results show substantial improvements over\nexisting baseline methods.\n","authors":["Quynh-Mai Thi Nguyen","Lan-Nhi Thi Nguyen","Cam-Van Thi Nguyen"],"pdf_url":"https://arxiv.org/pdf/2412.08529v1.pdf","comment":"Accepted at PACLIC 2024"},{"id":"http://arxiv.org/abs/2412.08528v1","updated":"2024-12-11T16:38:34Z","published":"2024-12-11T16:38:34Z","title":"Continual Learning for Encoder-only Language Models via a Discrete\n  Key-Value Bottleneck","summary":"  Continual learning remains challenging across various natural language\nunderstanding tasks. When models are updated with new training data, they risk\ncatastrophic forgetting of prior knowledge. In the present work, we introduce a\ndiscrete key-value bottleneck for encoder-only language models, allowing for\nefficient continual learning by requiring only localized updates. Inspired by\nthe success of a discrete key-value bottleneck in vision, we address new and\nNLP-specific challenges. We experiment with different bottleneck architectures\nto find the most suitable variants regarding language, and present a generic\ndiscrete key initialization technique for NLP that is task independent. We\nevaluate the discrete key-value bottleneck in four continual learning NLP\nscenarios and demonstrate that it alleviates catastrophic forgetting. We\nshowcase that it offers competitive performance to other popular continual\nlearning methods, with lower computational costs.\n","authors":["Andor Diera","Lukas Galke","Fabian Karl","Ansgar Scherp"],"pdf_url":"https://arxiv.org/pdf/2412.08528v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.14654v2","updated":"2024-12-11T16:38:01Z","published":"2024-11-22T00:59:25Z","title":"Comparative Analysis of Pooling Mechanisms in LLMs: A Sentiment Analysis\n  Perspective","summary":"  Large Language Models (LLMs) have revolutionized natural language processing\n(NLP) by delivering state-of-the-art performance across a variety of tasks.\nAmong these, Transformer-based models like BERT and GPT rely on pooling layers\nto aggregate token-level embeddings into sentence-level representations. Common\npooling mechanisms such as Mean, Max, and Weighted Sum play a pivotal role in\nthis aggregation process. Despite their widespread use, the comparative\nperformance of these strategies on different LLM architectures remains\nunderexplored. To address this gap, this paper investigates the effects of\nthese pooling mechanisms on two prominent LLM families -- BERT and GPT, in the\ncontext of sentence-level sentiment analysis. Comprehensive experiments reveal\nthat each pooling mechanism exhibits unique strengths and weaknesses depending\non the task's specific requirements. Our findings underline the importance of\nselecting pooling methods tailored to the demands of particular applications,\nprompting a re-evaluation of common assumptions regarding pooling operations.\nBy offering actionable insights, this study contributes to the optimization of\nLLM-based models for downstream tasks.\n","authors":["Jinming Xing","Ruilin Xing","Yan Sun"],"pdf_url":"https://arxiv.org/pdf/2411.14654v2.pdf","comment":"4 figures"},{"id":"http://arxiv.org/abs/2412.08521v1","updated":"2024-12-11T16:35:13Z","published":"2024-12-11T16:35:13Z","title":"EMS: Adaptive Evict-then-Merge Strategy for Head-wise KV Cache\n  Compression Based on Global-Local Importance","summary":"  As large language models (LLMs) continue to advance, the demand for higher\nquality and faster processing of long contexts across various applications is\ngrowing. KV cache is widely adopted as it stores previously generated key and\nvalue tokens, effectively reducing redundant computations during inference.\nHowever, as memory overhead becomes a significant concern, efficient\ncompression of KV cache has gained increasing attention. Most existing methods\nperform compression from two perspectives: identifying important tokens and\ndesigning compression strategies. However, these approaches often produce\nbiased distributions of important tokens due to the influence of accumulated\nattention scores or positional encoding. Furthermore, they overlook the\nsparsity and redundancy across different heads, which leads to difficulties in\npreserving the most effective information at the head level. To this end, we\npropose EMS to overcome these limitations, while achieving better KV cache\ncompression under extreme compression ratios. Specifically, we introduce a\nGlobal-Local score that combines accumulated attention scores from both global\nand local KV tokens to better identify the token importance. For the\ncompression strategy, we design an adaptive and unified Evict-then-Merge\nframework that accounts for the sparsity and redundancy of KV tokens across\ndifferent heads. Additionally, we implement the head-wise parallel compression\nthrough a zero-class mechanism to enhance efficiency. Extensive experiments\ndemonstrate our SOTA performance even under extreme compression ratios. EMS\nconsistently achieves the lowest perplexity, improves scores by over 1.28\npoints across four LLMs on LongBench under a 256 cache budget, and preserves\n95% retrieval accuracy with a cache budget less than 2% of the context length\nin the Needle-in-a-Haystack task.\n","authors":["Yingxin Li","Ye Li","Yuan Meng","Xinzhu Ma","Zihan Geng","Shutao Xia","Zhi Wang"],"pdf_url":"https://arxiv.org/pdf/2412.08521v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08520v1","updated":"2024-12-11T16:34:23Z","published":"2024-12-11T16:34:23Z","title":"GR-NLP-TOOLKIT: An Open-Source NLP Toolkit for Modern Greek","summary":"  We present GR-NLP-TOOLKIT, an open-source natural language processing (NLP)\ntoolkit developed specifically for modern Greek. The toolkit provides\nstate-of-the-art performance in five core NLP tasks, namely part-of-speech\ntagging, morphological tagging, dependency parsing, named entity recognition,\nand Greeklishto-Greek transliteration. The toolkit is based on pre-trained\nTransformers, it is freely available, and can be easily installed in Python\n(pip install gr-nlp-toolkit). It is also accessible through a demonstration\nplatform on HuggingFace, along with a publicly available API for non-commercial\nuse. We discuss the functionality provided for each task, the underlying\nmethods, experiments against comparable open-source toolkits, and future\npossible enhancements. The toolkit is available at:\nhttps://github.com/nlpaueb/gr-nlp-toolkit\n","authors":["Lefteris Loukas","Nikolaos Smyrnioudis","Chrysa Dikonomaki","Spyros Barbakos","Anastasios Toumazatos","John Koutsikakis","Manolis Kyriakakis","Mary Georgiou","Stavros Vassos","John Pavlopoulos","Ion Androutsopoulos"],"pdf_url":"https://arxiv.org/pdf/2412.08520v1.pdf","comment":"Accepted Demo Paper @ COLING 2025 (Github:\n  https://github.com/nlpaueb/gr-nlp-toolkit/, Demo:\n  https://huggingface.co/spaces/AUEB-NLP/greek-nlp-toolkit-demo, API:\n  https://huggingface.co/spaces/AUEB-NLP/The-Greek-NLP-API)"},{"id":"http://arxiv.org/abs/2412.08519v1","updated":"2024-12-11T16:32:41Z","published":"2024-12-11T16:32:41Z","title":"Bridging Relevance and Reasoning: Rationale Distillation in\n  Retrieval-Augmented Generation","summary":"  The reranker and generator are two critical components in the\nRetrieval-Augmented Generation (i.e., RAG) pipeline, responsible for ranking\nrelevant documents and generating responses. However, due to differences in\npre-training data and objectives, there is an inevitable gap between the\ndocuments ranked as relevant by the reranker and those required by the\ngenerator to support answering the query. To address this gap, we propose\nRADIO, a novel and practical preference alignment framework with RAtionale\nDIstillatiOn. Specifically, We first propose a rationale extraction method that\nleverages the reasoning capabilities of Large Language Models (LLMs) to extract\nthe rationales necessary for answering the query. Subsequently, a\nrationale-based alignment process is designed to rerank the documents based on\nthe extracted rationales, and fine-tune the reranker to align the preferences.\nWe conduct extensive experiments on two tasks across three datasets to\ndemonstrate the effectiveness of our approach compared to baseline methods. Our\ncode is released online to ease reproduction.\n","authors":["Pengyue Jia","Derong Xu","Xiaopeng Li","Zhaocheng Du","Xiangyang Li","Xiangyu Zhao","Yichao Wang","Yuhao Wang","Huifeng Guo","Ruiming Tang"],"pdf_url":"https://arxiv.org/pdf/2412.08519v1.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2207.01772v3","updated":"2024-12-11T16:30:19Z","published":"2022-07-05T02:18:49Z","title":"Vision-and-Language Pretraining","summary":"  With the burgeoning amount of data of image-text pairs and diversity of\nVision-and-Language (V\\&L) tasks, scholars have introduced an abundance of deep\nlearning models in this research domain. Furthermore, in recent years, transfer\nlearning has also shown tremendous success in Computer Vision for tasks such as\nImage Classification, Object Detection, etc., and in Natural Language\nProcessing for Question Answering, Machine Translation, etc. Inheriting the\nspirit of Transfer Learning, research works in V\\&L have devised multiple\npretraining techniques on large-scale datasets in order to enhance the\nperformance of downstream tasks. The aim of this article is to provide a\ncomprehensive revision of contemporary V\\&L pretraining models. In particular,\nwe categorize and delineate pretraining approaches, along with the summary of\nstate-of-the-art vision-and-language pretrained models. Moreover, a list of\ntraining datasets and downstream tasks is supplied to further polish the\nperspective into V\\&L pretraining. Lastly, we decided to take a further step to\ndiscuss numerous directions for future research.\n","authors":["Thong Nguyen","Cong-Duy Nguyen","Xiaobao Wu","See-Kiong Ng","Anh Tuan Luu"],"pdf_url":"https://arxiv.org/pdf/2207.01772v3.pdf","comment":"The content of the paper has been outdated. I would like to rewrite a\n  new version with completely new information."},{"id":"http://arxiv.org/abs/2412.08508v1","updated":"2024-12-11T16:18:52Z","published":"2024-12-11T16:18:52Z","title":"Comparative Opinion Mining in Product Reviews: Multi-perspective\n  Prompt-based Learning","summary":"  Comparative reviews are pivotal in understanding consumer preferences and\ninfluencing purchasing decisions. Comparative Quintuple Extraction (COQE) aims\nto identify five key components in text: the target entity, compared entities,\ncompared aspects, opinions on these aspects, and polarity. Extracting precise\ncomparative information from product reviews is challenging due to nuanced\nlanguage and sequential task errors in traditional methods. To mitigate these\nproblems, we propose MTP-COQE, an end-to-end model designed for COQE.\nLeveraging multi-perspective prompt-based learning, MTP-COQE effectively guides\nthe generative model in comparative opinion mining tasks. Evaluation on the\nCamera-COQE (English) and VCOM (Vietnamese) datasets demonstrates MTP-COQE's\nefficacy in automating COQE, achieving superior performance with a 1.41% higher\nF1 score than the previous baseline models on the English dataset.\nAdditionally, we designed a strategy to limit the generative model's creativity\nto ensure the output meets expectations. We also performed data augmentation to\naddress data imbalance and to prevent the model from becoming biased towards\ndominant samples.\n","authors":["Hai-Yen Thi Nguyen","Cam-Van Thi Nguyen"],"pdf_url":"https://arxiv.org/pdf/2412.08508v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17196v3","updated":"2024-12-11T15:45:21Z","published":"2024-10-22T17:15:20Z","title":"VoiceBench: Benchmarking LLM-Based Voice Assistants","summary":"  Building on the success of large language models (LLMs), recent advancements\nsuch as GPT-4o have enabled real-time speech interactions through LLM-based\nvoice assistants, offering a significantly improved user experience compared to\ntraditional text-based interactions. However, the absence of benchmarks\ndesigned to evaluate these speech interaction capabilities has hindered\nprogress of LLM-based voice assistants development. Current evaluations focus\nprimarily on automatic speech recognition (ASR) or general knowledge evaluation\nwith clean speeches, neglecting the more intricate, real-world scenarios that\ninvolve diverse speaker characteristics, environmental and content factors. To\naddress this, we introduce VoiceBench, the first benchmark designed to provide\na multi-faceted evaluation of LLM-based voice assistants. VoiceBench also\nincludes both real and synthetic spoken instructions that incorporate the above\nthree key real-world variations. Extensive experiments reveal the limitations\nof current LLM-based voice assistant models and offer valuable insights for\nfuture research and development in this field.\n","authors":["Yiming Chen","Xianghu Yue","Chen Zhang","Xiaoxue Gao","Robby T. Tan","Haizhou Li"],"pdf_url":"https://arxiv.org/pdf/2410.17196v3.pdf","comment":"Work in progress. Data is available at\n  https://github.com/MatthewCYM/VoiceBench"},{"id":"http://arxiv.org/abs/2412.08473v1","updated":"2024-12-11T15:42:22Z","published":"2024-12-11T15:42:22Z","title":"Multi-perspective Alignment for Increasing Naturalness in Neural Machine\n  Translation","summary":"  Neural machine translation (NMT) systems amplify lexical biases present in\ntheir training data, leading to artificially impoverished language in output\ntranslations. These language-level characteristics render automatic\ntranslations different from text originally written in a language and human\ntranslations, which hinders their usefulness in for example creating evaluation\ndatasets. Attempts to increase naturalness in NMT can fall short in terms of\ncontent preservation, where increased lexical diversity comes at the cost of\ntranslation accuracy. Inspired by the reinforcement learning from human\nfeedback framework, we introduce a novel method that rewards both naturalness\nand content preservation. We experiment with multiple perspectives to produce\nmore natural translations, aiming at reducing machine and human translationese.\nWe evaluate our method on English-to-Dutch literary translation, and find that\nour best model produces translations that are lexically richer and exhibit more\nproperties of human-written language, without loss in translation accuracy.\n","authors":["Huiyuan Lai","Esther Ploeger","Rik van Noord","Antonio Toral"],"pdf_url":"https://arxiv.org/pdf/2412.08473v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.12910v2","updated":"2024-12-11T15:40:54Z","published":"2024-05-21T16:30:25Z","title":"Topic Classification of Case Law Using a Large Language Model and a New\n  Taxonomy for UK Law: AI Insights into Summary Judgment","summary":"  This paper addresses a critical gap in legal analytics by developing and\napplying a novel taxonomy for topic classification of summary judgment cases in\nthe United Kingdom. Using a curated dataset of summary judgment cases, we use\nthe Large Language Model Claude 3 Opus to explore functional topics and trends.\nWe find that Claude 3 Opus correctly classified the topic with an accuracy of\n87.13% and an F1 score of 0.87. The analysis reveals distinct patterns in the\napplication of summary judgments across various legal domains. As case law in\nthe United Kingdom is not originally labelled with keywords or a topic\nfiltering option, the findings not only refine our understanding of the\nthematic underpinnings of summary judgments but also illustrate the potential\nof combining traditional and AI-driven approaches in legal classification.\nTherefore, this paper provides a new and general taxonomy for UK law. The\nimplications of this work serve as a foundation for further research and policy\ndiscussions in the field of judicial administration and computational legal\nresearch methodologies.\n","authors":["Holli Sargeant","Ahmed Izzidien","Felix Steffek"],"pdf_url":"https://arxiv.org/pdf/2405.12910v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08467v1","updated":"2024-12-11T15:32:24Z","published":"2024-12-11T15:32:24Z","title":"Bootstrapping Language-Guided Navigation Learning with Self-Refining\n  Data Flywheel","summary":"  Creating high-quality data for training robust language-instructed agents is\na long-lasting challenge in embodied AI. In this paper, we introduce a\nSelf-Refining Data Flywheel (SRDF) that generates high-quality and large-scale\nnavigational instruction-trajectory pairs by iteratively refining the data pool\nthrough the collaboration between two models, the instruction generator and the\nnavigator, without any human-in-the-loop annotation. Specifically, SRDF starts\nwith using a base generator to create an initial data pool for training a base\nnavigator, followed by applying the trained navigator to filter the data pool.\nThis leads to higher-fidelity data to train a better generator, which can, in\nturn, produce higher-quality data for training the next-round navigator. Such a\nflywheel establishes a data self-refining process, yielding a continuously\nimproved and highly effective dataset for large-scale language-guided\nnavigation learning. Our experiments demonstrate that after several flywheel\nrounds, the navigator elevates the performance boundary from 70% to 78% SPL on\nthe classic R2R test set, surpassing human performance (76%) for the first\ntime. Meanwhile, this process results in a superior generator, evidenced by a\nSPICE increase from 23.5 to 26.2, better than all previous VLN instruction\ngeneration methods. Finally, we demonstrate the scalability of our method\nthrough increasing environment and instruction diversity, and the\ngeneralization ability of our pre-trained navigator across various downstream\nnavigation tasks, surpassing state-of-the-art methods by a large margin in all\ncases.\n","authors":["Zun Wang","Jialu Li","Yicong Hong","Songze Li","Kunchang Li","Shoubin Yu","Yi Wang","Yu Qiao","Yali Wang","Mohit Bansal","Limin Wang"],"pdf_url":"https://arxiv.org/pdf/2412.08467v1.pdf","comment":"28 pages, Code and data are available at\n  https://github.com/wz0919/VLN-SRDF"},{"id":"http://arxiv.org/abs/2410.07095v3","updated":"2024-12-11T15:02:22Z","published":"2024-10-09T17:34:27Z","title":"MLE-bench: Evaluating Machine Learning Agents on Machine Learning\n  Engineering","summary":"  We introduce MLE-bench, a benchmark for measuring how well AI agents perform\nat machine learning engineering. To this end, we curate 75 ML\nengineering-related competitions from Kaggle, creating a diverse set of\nchallenging tasks that test real-world ML engineering skills such as training\nmodels, preparing datasets, and running experiments. We establish human\nbaselines for each competition using Kaggle's publicly available leaderboards.\nWe use open-source agent scaffolds to evaluate several frontier language models\non our benchmark, finding that the best-performing setup--OpenAI's o1-preview\nwith AIDE scaffolding--achieves at least the level of a Kaggle bronze medal in\n16.9% of competitions. In addition to our main results, we investigate various\nforms of resource scaling for AI agents and the impact of contamination from\npre-training. We open-source our benchmark code (github.com/openai/mle-bench/)\nto facilitate future research in understanding the ML engineering capabilities\nof AI agents.\n","authors":["Jun Shern Chan","Neil Chowdhury","Oliver Jaffe","James Aung","Dane Sherburn","Evan Mays","Giulio Starace","Kevin Liu","Leon Maksin","Tejal Patwardhan","Lilian Weng","Aleksander Mądry"],"pdf_url":"https://arxiv.org/pdf/2410.07095v3.pdf","comment":"10 pages, 17 pages appendix. Equal contribution by first seven\n  authors, authors randomized. Corrected footnote 4"},{"id":"http://arxiv.org/abs/2412.08434v1","updated":"2024-12-11T14:55:48Z","published":"2024-12-11T14:55:48Z","title":"Mitigating Out-of-Entity Errors in Named Entity Recognition: A\n  Sentence-Level Strategy","summary":"  Many previous models of named entity recognition (NER) suffer from the\nproblem of Out-of-Entity (OOE), i.e., the tokens in the entity mentions of the\ntest samples have not appeared in the training samples, which hinders the\nachievement of satisfactory performance. To improve OOE-NER performance, in\nthis paper, we propose a new framework, namely S+NER, which fully leverages\nsentence-level information. Our S+NER achieves better OOE-NER performance\nmainly due to the following two particular designs. 1) It first exploits the\npre-trained language model's capability of understanding the target entity's\nsentence-level context with a template set. 2) Then, it refines the\nsentence-level representation based on the positive and negative templates,\nthrough a contrastive learning strategy and template pooling method, to obtain\nbetter NER results. Our extensive experiments on five benchmark datasets have\ndemonstrated that, our S+NER outperforms some state-of-the-art OOE-NER models.\n","authors":["Guochao Jiang","Ziqin Luo","Chengwei Hu","Zepeng Ding","Deqing Yang"],"pdf_url":"https://arxiv.org/pdf/2412.08434v1.pdf","comment":"Accepted by COLING 2025"},{"id":"http://arxiv.org/abs/2412.08430v1","updated":"2024-12-11T14:51:13Z","published":"2024-12-11T14:51:13Z","title":"Assessing Personalized AI Mentoring with Large Language Models in the\n  Computing Field","summary":"  This paper provides an in-depth evaluation of three state-of-the-art Large\nLanguage Models (LLMs) for personalized career mentoring in the computing\nfield, using three distinct student profiles that consider gender, race, and\nprofessional levels. We evaluated the performance of GPT-4, LLaMA 3, and Palm 2\nusing a zero-shot learning approach without human intervention. A quantitative\nevaluation was conducted through a custom natural language processing analytics\npipeline to highlight the uniqueness of the responses and to identify words\nreflecting each student's profile, including race, gender, or professional\nlevel. The analysis of frequently used words in the responses indicates that\nGPT-4 offers more personalized mentoring compared to the other two LLMs.\nAdditionally, a qualitative evaluation was performed to see if human experts\nreached similar conclusions. The analysis of survey responses shows that GPT-4\noutperformed the other two LLMs in delivering more accurate and useful\nmentoring while addressing specific challenges with encouragement languages.\nOur work establishes a foundation for developing personalized mentoring tools\nbased on LLMs, incorporating human mentors in the process to deliver a more\nimpactful and tailored mentoring experience.\n","authors":["Xiao Luo","Sean O'Connell","Shamima Mithun"],"pdf_url":"https://arxiv.org/pdf/2412.08430v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07303v2","updated":"2024-12-11T14:43:31Z","published":"2024-12-10T08:31:52Z","title":"Filipino Benchmarks for Measuring Sexist and Homophobic Bias in\n  Multilingual Language Models from Southeast Asia","summary":"  Bias studies on multilingual models confirm the presence of gender-related\nstereotypes in masked models processing languages with high NLP resources. We\nexpand on this line of research by introducing Filipino CrowS-Pairs and\nFilipino WinoQueer: benchmarks that assess both sexist and anti-queer biases in\npretrained language models (PLMs) handling texts in Filipino, a low-resource\nlanguage from the Philippines. The benchmarks consist of 7,074 new challenge\npairs resulting from our cultural adaptation of English bias evaluation\ndatasets, a process that we document in detail to guide similar forthcoming\nefforts. We apply the Filipino benchmarks on masked and causal multilingual\nmodels, including those pretrained on Southeast Asian data, and find that they\ncontain considerable amounts of bias. We also find that for multilingual\nmodels, the extent of bias learned for a particular language is influenced by\nhow much pretraining data in that language a model was exposed to. Our\nbenchmarks and insights can serve as a foundation for future work analyzing and\nmitigating bias in multilingual models.\n","authors":["Lance Calvin Lim Gamboa","Mark Lee"],"pdf_url":"https://arxiv.org/pdf/2412.07303v2.pdf","comment":"Accepted for presentation at The First Workshop on Language Models\n  for Low-Resource Languages (LoResLM) at The 31st International Conference on\n  Computational Linguistics (COLING 2025)"},{"id":"http://arxiv.org/abs/2412.08414v1","updated":"2024-12-11T14:31:39Z","published":"2024-12-11T14:31:39Z","title":"Detecting Conversational Mental Manipulation with Intent-Aware Prompting","summary":"  Mental manipulation severely undermines mental wellness by covertly and\nnegatively distorting decision-making. While there is an increasing interest in\nmental health care within the natural language processing community, progress\nin tackling manipulation remains limited due to the complexity of detecting\nsubtle, covert tactics in conversations. In this paper, we propose Intent-Aware\nPrompting (IAP), a novel approach for detecting mental manipulations using\nlarge language models (LLMs), providing a deeper understanding of manipulative\ntactics by capturing the underlying intents of participants. Experimental\nresults on the MentalManip dataset demonstrate superior effectiveness of IAP\nagainst other advanced prompting strategies. Notably, our approach\nsubstantially reduces false negatives, helping detect more instances of mental\nmanipulation with minimal misjudgment of positive cases. The code of this paper\nis available at https://github.com/Anton-Jiayuan-MA/Manip-IAP.\n","authors":["Jiayuan Ma","Hongbin Na","Zimu Wang","Yining Hua","Yue Liu","Wei Wang","Ling Chen"],"pdf_url":"https://arxiv.org/pdf/2412.08414v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08393v1","updated":"2024-12-11T14:05:04Z","published":"2024-12-11T14:05:04Z","title":"Learning to Reason via Self-Iterative Process Feedback for Small\n  Language Models","summary":"  Small language models (SLMs) are more efficient, cost-effective, and\ncustomizable than large language models (LLMs), though they often underperform\nin specific areas like reasoning. Past methods for enhancing SLMs' reasoning,\nsuch as supervised fine-tuning and distillation, often depend on costly\nexternal signals, resulting in SLMs being overly confident with limited\nsupervision signals, thus limiting their abilities. Therefore, this study\nenables SLMs to learn to reason from self-iterative feedback. By combining odds\nratio preference optimization (ORPO), we fine-tune and align SLMs using\npositive and negative signals generated by themselves. Additionally, we\nintroduce process supervision for rewards in preference alignment by\nsampling-based inference simulation and process reward models. Compared to\nSupervised Fine-Tuning (SFT), our method improves the performance of Gemma-2B\nby 12.43 (Acc) on GSM8K and 3.95 (Pass@1) on MBPP. Furthermore, the proposed\nmethod also demonstrated superior out-of-domain generalization capabilities on\nMMLU_Math and HumanEval.\n","authors":["Kaiyuan Chen","Jin Wang","Xuejie Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.08393v1.pdf","comment":"Accepted by COLING 2025"},{"id":"http://arxiv.org/abs/2412.08392v1","updated":"2024-12-11T14:02:55Z","published":"2024-12-11T14:02:55Z","title":"The Roles of English in Evaluating Multilingual Language Models","summary":"  Multilingual natural language processing is getting increased attention, with\nnumerous models, benchmarks, and methods being released for many languages.\nEnglish is often used in multilingual evaluation to prompt language models\n(LMs), mainly to overcome the lack of instruction tuning data in other\nlanguages. In this position paper, we lay out two roles of English in\nmultilingual LM evaluations: as an interface and as a natural language. We\nargue that these roles have different goals: task performance versus language\nunderstanding. This discrepancy is highlighted with examples from datasets and\nevaluation setups. Numerous works explicitly use English as an interface to\nboost task performance. We recommend to move away from this imprecise method\nand instead focus on furthering language understanding.\n","authors":["Wessel Poelman","Miryam de Lhoneux"],"pdf_url":"https://arxiv.org/pdf/2412.08392v1.pdf","comment":"NoDaLiDa 2025"},{"id":"http://arxiv.org/abs/2412.08389v1","updated":"2024-12-11T13:56:04Z","published":"2024-12-11T13:56:04Z","title":"SweetieChat: A Strategy-Enhanced Role-playing Framework for Diverse\n  Scenarios Handling Emotional Support Agent","summary":"  Large Language Models (LLMs) have demonstrated promising potential in\nproviding empathetic support during interactions. However, their responses\noften become verbose or overly formulaic, failing to adequately address the\ndiverse emotional support needs of real-world scenarios. To tackle this\nchallenge, we propose an innovative strategy-enhanced role-playing framework,\ndesigned to simulate authentic emotional support conversations. Specifically,\nour approach unfolds in two steps: (1) Strategy-Enhanced Role-Playing\nInteractions, which involve three pivotal roles -- Seeker, Strategy Counselor,\nand Supporter -- engaging in diverse scenarios to emulate real-world\ninteractions and promote a broader range of dialogues; and (2) Emotional\nSupport Agent Training, achieved through fine-tuning LLMs using our specially\nconstructed dataset. Within this framework, we develop the \\textbf{ServeForEmo}\ndataset, comprising an extensive collection of 3.7K+ multi-turn dialogues and\n62.8K+ utterances. We further present \\textbf{SweetieChat}, an emotional\nsupport agent capable of handling diverse open-domain scenarios. Extensive\nexperiments and human evaluations confirm the framework's effectiveness in\nenhancing emotional support, highlighting its unique ability to provide more\nnuanced and tailored assistance.\n","authors":["Jing Ye","Lu Xiang","Yaping Zhang","Chengqing Zong"],"pdf_url":"https://arxiv.org/pdf/2412.08389v1.pdf","comment":"24 pages. Accepted by COLING 2025"},{"id":"http://arxiv.org/abs/2412.08385v1","updated":"2024-12-11T13:50:17Z","published":"2024-12-11T13:50:17Z","title":"NyayaAnumana & INLegalLlama: The Largest Indian Legal Judgment\n  Prediction Dataset and Specialized Language Model for Enhanced Decision\n  Analysis","summary":"  The integration of artificial intelligence (AI) in legal judgment prediction\n(LJP) has the potential to transform the legal landscape, particularly in\njurisdictions like India, where a significant backlog of cases burdens the\nlegal system. This paper introduces NyayaAnumana, the largest and most diverse\ncorpus of Indian legal cases compiled for LJP, encompassing a total of 7,02,945\npreprocessed cases. NyayaAnumana, which combines the words \"Nyay\" (judgment)\nand \"Anuman\" (prediction or inference) respectively for most major Indian\nlanguages, includes a wide range of cases from the Supreme Court, High Courts,\nTribunal Courts, District Courts, and Daily Orders and, thus, provides\nunparalleled diversity and coverage. Our dataset surpasses existing datasets\nlike PredEx and ILDC, offering a comprehensive foundation for advanced AI\nresearch in the legal domain.\n  In addition to the dataset, we present INLegalLlama, a domain-specific\ngenerative large language model (LLM) tailored to the intricacies of the Indian\nlegal system. It is developed through a two-phase training approach over a base\nLLaMa model. First, Indian legal documents are injected using continual\npretraining. Second, task-specific supervised finetuning is done. This method\nallows the model to achieve a deeper understanding of legal contexts.\n  Our experiments demonstrate that incorporating diverse court data\nsignificantly boosts model accuracy, achieving approximately 90% F1-score in\nprediction tasks. INLegalLlama not only improves prediction accuracy but also\noffers comprehensible explanations, addressing the need for explainability in\nAI-assisted legal decisions.\n","authors":["Shubham Kumar Nigam","Balaramamahanthi Deepak Patnaik","Shivam Mishra","Noel Shallum","Kripabandhu Ghosh","Arnab Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2412.08385v1.pdf","comment":"Accepted on COLING 2025"},{"id":"http://arxiv.org/abs/2406.01468v2","updated":"2024-12-11T13:22:12Z","published":"2024-06-03T15:57:29Z","title":"Understanding Token Probability Encoding in Output Embeddings","summary":"  In this paper, we investigate the output token probability information in the\noutput embedding of language models. We find an approximate common log-linear\nencoding of output token probabilities within the output embedding vectors and\nempirically demonstrate that it is accurate and sparse. As a causality\nexamination, we steer the encoding in output embedding to modify the output\nprobability distribution accurately. Moreover, the sparsity we find in output\nprobability encoding suggests that a large number of dimensions in the output\nembedding do not contribute to causal language modeling. Therefore, we attempt\nto delete the output-unrelated dimensions and find more than 30% of the\ndimensions can be deleted without significant movement in output distribution\nand sequence generation. Additionally, in the pre-training dynamics of language\nmodels, we find that the output embeddings capture the corpus token frequency\ninformation in early steps, even before an obvious convergence of parameters\nstarts.\n","authors":["Hakaze Cho","Yoshihiro Sakai","Kenshiro Tanaka","Mariko Kato","Naoya Inoue"],"pdf_url":"https://arxiv.org/pdf/2406.01468v2.pdf","comment":"15 pages, 17 figures, 3 tables. COLING 2025 Accepted"},{"id":"http://arxiv.org/abs/2412.07646v2","updated":"2024-12-11T12:50:03Z","published":"2024-12-10T16:32:19Z","title":"Searching for Structure: Investigating Emergent Communication with Large\n  Language Models","summary":"  Human languages have evolved to be structured through repeated language\nlearning and use. These processes introduce biases that operate during language\nacquisition and shape linguistic systems toward communicative efficiency. In\nthis paper, we investigate whether the same happens if artificial languages are\noptimised for implicit biases of Large Language Models (LLMs). To this end, we\nsimulate a classical referential game in which LLMs learn and use artificial\nlanguages. Our results show that initially unstructured holistic languages are\nindeed shaped to have some structural properties that allow two LLM agents to\ncommunicate successfully. Similar to observations in human experiments,\ngenerational transmission increases the learnability of languages, but can at\nthe same time result in non-humanlike degenerate vocabularies. Taken together,\nthis work extends experimental findings, shows that LLMs can be used as tools\nin simulations of language evolution, and opens possibilities for future\nhuman-machine experiments in this field.\n","authors":["Tom Kouwenhoven","Max Peeperkorn","Tessa Verhoef"],"pdf_url":"https://arxiv.org/pdf/2412.07646v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.00894v2","updated":"2024-12-11T12:47:09Z","published":"2024-07-01T01:31:41Z","title":"How to Leverage Digit Embeddings to Represent Numbers?","summary":"  Within numerical reasoning, understanding numbers themselves is still a\nchallenge for existing language models. Simple generalisations, such as solving\n100+200 instead of 1+2, can substantially affect model performance (Sivakumar\nand Moosavi, 2023). Among various techniques, character-level embeddings of\nnumbers have emerged as a promising approach to improve number representation.\nHowever, this method has limitations as it leaves the task of aggregating digit\nrepresentations to the model, which lacks direct supervision for this process.\nIn this paper, we explore the use of mathematical priors to compute aggregated\ndigit embeddings and explicitly incorporate these aggregates into transformer\nmodels. This can be achieved either by adding a special token to the input\nembeddings or by introducing an additional loss function to enhance correct\npredictions. We evaluate the effectiveness of incorporating this explicit\naggregation, analysing its strengths and shortcomings, and discuss future\ndirections to better benefit from this approach. Our methods, while simple, are\ncompatible with any pretrained model, easy to implement, and have been made\npublicly available.\n","authors":["Jasivan Alex Sivakumar","Nafise Sadat Moosavi"],"pdf_url":"https://arxiv.org/pdf/2407.00894v2.pdf","comment":"Accepted at COLING 2025"},{"id":"http://arxiv.org/abs/2412.08347v1","updated":"2024-12-11T12:41:36Z","published":"2024-12-11T12:41:36Z","title":"SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better\n  Reasoning in SLMs","summary":"  We present SmolTulu-1.7b-Instruct, referenced in this report as\nSmolTulu-DPO-1130, an instruction-tuned language model that adapts AllenAI's\nTulu 3 post-training pipeline to enhance Huggingface's SmolLM2-1.7B base model.\nThrough comprehensive empirical analysis using a 135M parameter model, we\ndemonstrate that the relationship between learning rate and batch size\nsignificantly impacts model performance in a task-dependent manner. Our\nfindings reveal a clear split: reasoning tasks like ARC and GSM8K benefit from\nhigher learning rate to batch size ratios, while pattern recognition tasks such\nas HellaSwag and IFEval show optimal performance with lower ratios. These\ninsights informed the development of SmolTulu, which achieves state-of-the-art\nperformance among sub-2B parameter models on instruction following, scoring\n67.7% on IFEval ($\\Delta$11%), and mathematical reasoning with 51.6% on GSM8K\n($\\Delta$3.4%), with an alternate version achieving scoring 57.1% on ARC\n($\\Delta5.4%$). We release our model, training recipes, and ablation studies to\nfacilitate further research in efficient model alignment, demonstrating that\ncareful adaptation of optimization dynamics can help bridge the capability gap\nbetween small and large language models.\n","authors":["Sultan Alrashed"],"pdf_url":"https://arxiv.org/pdf/2412.08347v1.pdf","comment":"10 pages, 4 figures, and 13 tables. For the SmolTulu-1.7b-instruct\n  model, see: https://huggingface.co/SultanR/SmolTulu-1.7b-Instruct"},{"id":"http://arxiv.org/abs/2412.06843v2","updated":"2024-12-11T12:35:25Z","published":"2024-12-07T16:35:14Z","title":"Semantic Loss Guided Data Efficient Supervised Fine Tuning for Safe\n  Responses in LLMs","summary":"  Large Language Models (LLMs) generating unsafe responses to toxic prompts is\na significant issue in their applications. While various efforts aim to address\nthis safety concern, previous approaches often demand substantial human data\ncollection or rely on the less dependable option of using another LLM to\ngenerate corrective data. In this paper, we aim to take this problem and\novercome limitations of requiring significant high-quality human data. Our\nmethod requires only a small set of unsafe responses to toxic prompts, easily\nobtained from the unsafe LLM itself. By employing a semantic cost combined with\na negative Earth Mover Distance (EMD) loss, we guide the LLM away from\ngenerating unsafe responses. Additionally, we propose a novel lower bound for\nEMD loss, enabling more efficient optimization. Our results demonstrate\nsuperior performance and data efficiency compared to baselines, and we further\nexamine the nuanced effects of over-alignment and potential degradation of\nlanguage capabilities when using contrastive data.\n","authors":["Yuxiao Lu","Arunesh Sinha","Pradeep Varakantham"],"pdf_url":"https://arxiv.org/pdf/2412.06843v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08329v1","updated":"2024-12-11T12:15:57Z","published":"2024-12-11T12:15:57Z","title":"BEIR-NL: Zero-shot Information Retrieval Benchmark for the Dutch\n  Language","summary":"  Zero-shot evaluation of information retrieval (IR) models is often performed\nusing BEIR; a large and heterogeneous benchmark composed of multiple datasets,\ncovering different retrieval tasks across various domains. Although BEIR has\nbecome a standard benchmark for the zero-shot setup, its exclusively English\ncontent reduces its utility for underrepresented languages in IR, including\nDutch. To address this limitation and encourage the development of Dutch IR\nmodels, we introduce BEIR-NL by automatically translating the publicly\naccessible BEIR datasets into Dutch. Using BEIR-NL, we evaluated a wide range\nof multilingual dense ranking and reranking models, as well as the lexical BM25\nmethod. Our experiments show that BM25 remains a competitive baseline, and is\nonly outperformed by the larger dense models trained for retrieval. When\ncombined with reranking models, BM25 achieves performance on par with the best\ndense ranking models. In addition, we explored the impact of translation on the\ndata by back-translating a selection of datasets to English, and observed a\nperformance drop for both dense and lexical methods, indicating the limitations\nof translation for creating benchmarks. BEIR-NL is publicly available on the\nHugging Face hub.\n","authors":["Nikolay Banar","Ehsan Lotfi","Walter Daelemans"],"pdf_url":"https://arxiv.org/pdf/2412.08329v1.pdf","comment":"To be presented at BUCC 2025 (COLING)"},{"id":"http://arxiv.org/abs/2412.08317v1","updated":"2024-12-11T11:53:26Z","published":"2024-12-11T11:53:26Z","title":"Large Language Models Still Face Challenges in Multi-Hop Reasoning with\n  External Knowledge","summary":"  We carry out a series of experiments to test large language models' multi-hop\nreasoning ability from three aspects: selecting and combining external\nknowledge, dealing with non-sequential reasoning tasks and generalising to data\nsamples with larger numbers of hops. We test the GPT-3.5 model on four\nreasoning benchmarks with Chain-of-Thought prompting (and its variations). Our\nresults reveal that despite the amazing performance achieved by large language\nmodels on various reasoning tasks, models still suffer from severe drawbacks\nwhich shows a large gap with humans.\n","authors":["Haotong Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.08317v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08316v1","updated":"2024-12-11T11:53:14Z","published":"2024-12-11T11:53:14Z","title":"Rumor Detection on Social Media with Temporal Propagation Structure\n  Optimization","summary":"  Traditional methods for detecting rumors on social media primarily focus on\nanalyzing textual content, often struggling to capture the complexity of online\ninteractions. Recent research has shifted towards leveraging graph neural\nnetworks to model the hierarchical conversation structure that emerges during\nrumor propagation. However, these methods tend to overlook the temporal aspect\nof rumor propagation and may disregard potential noise within the propagation\nstructure. In this paper, we propose a novel approach that incorporates\ntemporal information by constructing a weighted propagation tree, where the\nweight of each edge represents the time interval between connected posts.\nDrawing upon the theory of structural entropy, we transform this tree into a\ncoding tree. This transformation aims to preserve the essential structure of\nrumor propagation while reducing noise. Finally, we introduce a recursive\nneural network to learn from the coding tree for rumor veracity prediction.\nExperimental results on two common datasets demonstrate the superiority of our\napproach.\n","authors":["Xingyu Peng","Junran Wu","Ruomei Liu","Ke Xu"],"pdf_url":"https://arxiv.org/pdf/2412.08316v1.pdf","comment":"COLING'25"},{"id":"http://arxiv.org/abs/2406.00380v3","updated":"2024-12-11T11:52:58Z","published":"2024-06-01T09:36:16Z","title":"HonestLLM: Toward an Honest and Helpful Large Language Model","summary":"  Large Language Models (LLMs) have achieved remarkable success across various\nindustries due to their exceptional generative capabilities. However, for safe\nand effective real-world deployments, ensuring honesty and helpfulness is\ncritical. This paper addresses the question: Can we prioritize the helpfulness\nof LLMs while preserving their honesty? To begin with, we establish exhaustive\nprinciples aimed at guaranteeing the honesty of LLM. Additionally, we introduce\na novel dataset, referred to as HoneSet, comprising 930 queries spanning six\ncategories meticulously crafted to assess an LLM's capacity for maintaining\nhonesty. Subsequently, we present two approaches to augmenting honesty and\nhelpfulness in LLMs: a training-free enhancement and a fine-tuning-based\nimprovement. The training-free approach, which is based on curiosity-driven\nprompting, empowers LLMs to articulate internal confusion and uncertainty\nregarding queries, thereby optimizing their responses. Conversely, the\nfine-tuning-based method employs a two-stage process inspired by curriculum\nlearning: initially instructing LLMs to discern between honest and dishonest\nresponses, then refining their training to enhance helpfulness. Experiments\nconducted on nine prominent LLMs demonstrate a significant improvement in\nalignment with honesty across all models through the implementation of our\nproposed enhancements. Particularly noteworthy is the 65.3% enhancement\nobserved in Llama3-8b and the remarkable 124.7% improvement in Mistral-7b, as\nmeasured by the H$^{2}$ (honest and helpful) assessment. We believe that our\nwork can pave the way for developing more trustworthy LLMs for real-world\napplications.\n","authors":["Chujie Gao","Siyuan Wu","Yue Huang","Dongping Chen","Qihui Zhang","Zhengyan Fu","Yao Wan","Lichao Sun","Xiangliang Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.00380v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06798v2","updated":"2024-12-11T11:10:22Z","published":"2024-11-11T08:51:18Z","title":"LA4SR: illuminating the dark proteome with generative AI","summary":"  AI language models (LMs) show promise for biological sequence analysis. We\nre-engineered open-source LMs (GPT-2, BLOOM, DistilRoBERTa, ELECTRA, and Mamba,\nranging from 70M to 12B parameters) for microbial sequence classification. The\nmodels achieved F1 scores up to 95 and operated 16,580x faster and at 2.9x the\nrecall of BLASTP. They effectively classified the algal dark proteome -\nuncharacterized proteins comprising about 65% of total proteins - validated on\nnew data including a new, complete Hi-C/Pacbio Chlamydomonas genome. Larger\n(>1B) LA4SR models reached high accuracy (F1 > 86) when trained on less than 2%\nof available data, rapidly achieving strong generalization capacity. High\naccuracy was achieved when training data had intact or scrambled terminal\ninformation, demonstrating robust generalization to incomplete sequences.\nFinally, we provide custom AI explainability software tools for attributing\namino acid patterns to AI generative processes and interpret their outputs in\nevolutionary and biophysical contexts.\n","authors":["David R. Nelson","Ashish Kumar Jaiswal","Noha Ismail","Alexandra Mystikou","Kourosh Salehi-Ashtiani"],"pdf_url":"https://arxiv.org/pdf/2411.06798v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.06588v3","updated":"2024-12-11T11:08:18Z","published":"2023-10-10T12:53:48Z","title":"FTFT: Efficient and Robust Fine-Tuning by Transferring Training Dynamics","summary":"  Despite the massive success of fine-tuning Pre-trained Language Models\n(PLMs), they remain susceptible to out-of-distribution input. Dataset\ncartography is a simple yet effective dual-model approach that improves the\nrobustness of fine-tuned PLMs. It involves fine-tuning a model on the original\ntraining set (i.e. reference model), selecting a subset of important training\ninstances based on the training dynamics, and fine-tuning again only on these\nselected examples (i.e. main model). However, this approach requires\nfine-tuning the same model twice, which is computationally expensive for large\nPLMs. In this paper, we show that (1) training dynamics are highly transferable\nacross model sizes and pre-training methods, and that (2) fine-tuning main\nmodels using these selected training instances achieves higher training\nefficiency than empirical risk minimization (ERM). Building on these\nobservations, we propose a novel fine-tuning approach: Fine-Tuning by\ntransFerring Training dynamics (FTFT). Compared with dataset cartography, FTFT\nuses more efficient reference models and aggressive early stopping. FTFT\nachieves robustness improvements over ERM while lowering the training cost by\nup to $\\sim 50\\%$.\n","authors":["Yupei Du","Albert Gatt","Dong Nguyen"],"pdf_url":"https://arxiv.org/pdf/2310.06588v3.pdf","comment":"COLING 2025 Camera-Ready"},{"id":"http://arxiv.org/abs/2412.08291v1","updated":"2024-12-11T11:07:50Z","published":"2024-12-11T11:07:50Z","title":"Code LLMs: A Taxonomy-based Survey","summary":"  Large language models (LLMs) have demonstrated remarkable capabilities across\nvarious NLP tasks and have recently expanded their impact to coding tasks,\nbridging the gap between natural languages (NL) and programming languages (PL).\nThis taxonomy-based survey provides a comprehensive analysis of LLMs in the\nNL-PL domain, investigating how these models are utilized in coding tasks and\nexamining their methodologies, architectures, and training processes. We\npropose a taxonomy-based framework that categorizes relevant concepts,\nproviding a unified classification system to facilitate a deeper understanding\nof this rapidly evolving field. This survey offers insights into the current\nstate and future directions of LLMs in coding tasks, including their\napplications and limitations.\n","authors":["Nishat Raihan","Christian Newman","Marcos Zampieri"],"pdf_url":"https://arxiv.org/pdf/2412.08291v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08285v1","updated":"2024-12-11T11:00:33Z","published":"2024-12-11T11:00:33Z","title":"Adaptive Prompting for Continual Relation Extraction: A Within-Task\n  Variance Perspective","summary":"  To address catastrophic forgetting in Continual Relation Extraction (CRE),\nmany current approaches rely on memory buffers to rehearse previously learned\nknowledge while acquiring new tasks. Recently, prompt-based methods have\nemerged as potent alternatives to rehearsal-based strategies, demonstrating\nstrong empirical performance. However, upon analyzing existing prompt-based\napproaches for CRE, we identified several critical limitations, such as\ninaccurate prompt selection, inadequate mechanisms for mitigating forgetting in\nshared parameters, and suboptimal handling of cross-task and within-task\nvariances. To overcome these challenges, we draw inspiration from the\nrelationship between prefix-tuning and mixture of experts, proposing a novel\napproach that employs a prompt pool for each task, capturing variations within\neach task while enhancing cross-task variances. Furthermore, we incorporate a\ngenerative model to consolidate prior knowledge within shared parameters,\neliminating the need for explicit data storage. Extensive experiments validate\nthe efficacy of our approach, demonstrating superior performance over\nstate-of-the-art prompt-based and rehearsal-free methods in continual relation\nextraction.\n","authors":["Minh Le","Tien Ngoc Luu","An Nguyen The","Thanh-Thien Le","Trang Nguyen","Thanh Tung Nguyen","Linh Ngo Van","Thien Huu Nguyen"],"pdf_url":"https://arxiv.org/pdf/2412.08285v1.pdf","comment":"Accepted to AAAI 2025"},{"id":"http://arxiv.org/abs/2412.08283v1","updated":"2024-12-11T10:58:14Z","published":"2024-12-11T10:58:14Z","title":"A Preliminary Analysis of Automatic Word and Syllable Prominence\n  Detection in Non-Native Speech With Text-to-Speech Prosody Embeddings","summary":"  Automatic detection of prominence at the word and syllable-levels is critical\nfor building computer-assisted language learning systems. It has been shown\nthat prosody embeddings learned by the current state-of-the-art (SOTA)\ntext-to-speech (TTS) systems could generate word- and syllable-level prominence\nin the synthesized speech as natural as in native speech. To understand the\neffectiveness of prosody embeddings from TTS for prominence detection under\nnonnative context, a comparative analysis is conducted on the embeddings\nextracted from native and non-native speech considering the prominence-related\nembeddings: duration, energy, and pitch from a SOTA TTS named FastSpeech2.\nThese embeddings are extracted under two conditions considering: 1) only text,\n2) both speech and text. For the first condition, the embeddings are extracted\ndirectly from the TTS inference mode, whereas for the second condition, we\npropose to extract from the TTS under training mode. Experiments are conducted\non native speech corpus: Tatoeba, and non-native speech corpus: ISLE. For\nexperimentation, word-level prominence locations are manually annotated for\nboth corpora. The highest relative improvement on word \\& syllable-level\nprominence detection accuracies with the TTS embeddings are found to be 13.7% &\n5.9% and 16.2% & 6.9% compared to those with the heuristic-based features and\nself-supervised Wav2Vec-2.0 representations, respectively.\n","authors":["Anindita Mondal","Rangavajjala Sankara Bharadwaj","Jhansi Mallela","Anil Kumar Vuppala","Chiranjeevi Yarra"],"pdf_url":"https://arxiv.org/pdf/2412.08283v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19670v4","updated":"2024-12-11T10:56:03Z","published":"2024-05-30T03:44:54Z","title":"One Token Can Help! Learning Scalable and Pluggable Virtual Tokens for\n  Retrieval-Augmented Large Language Models","summary":"  Retrieval-augmented generation (RAG) is a promising way to improve large\nlanguage models (LLMs) for generating more factual, accurate, and up-to-date\ncontent. Existing methods either optimize prompts to guide LLMs in leveraging\nretrieved information or directly fine-tune LLMs to adapt to RAG scenarios.\nAlthough fine-tuning can yield better performance, it often compromises the\nLLMs' general generation capabilities by modifying their parameters. This\nlimitation poses challenges in practical applications, especially when LLMs are\nalready deployed, as parameter adjustments may affect their original\nfunctionality. To address this, we propose a novel method that involves\nlearning scalable and pluggable virtual tokens for RAG. By maintaining the\nLLMs' original parameters and fine-tuning only the embeddings of these\npluggable tokens, our approach not only enhances LLMs' performance but also\npreserves their general generation capabilities. Furthermore, we design several\ntraining strategies to improve the scalability, flexibility, and\ngeneralizability of our method. Comprehensive experiments across 12\nquestion-answering tasks demonstrate the superiority of our approach.\n","authors":["Yutao Zhu","Zhaoheng Huang","Zhicheng Dou","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2405.19670v4.pdf","comment":"Accepted by AAAI 2025, repo: https://github.com/DaoD/SPRING/"},{"id":"http://arxiv.org/abs/2412.08279v1","updated":"2024-12-11T10:52:29Z","published":"2024-12-11T10:52:29Z","title":"Y-NQ: English-Yorùbá Evaluation dataset for Open-Book Reading\n  Comprehension and Text Generation","summary":"  The purpose of this work is to share an English-Yor\\`ub\\'a evaluation dataset\nfor open-book reading comprehension and text generation to assess the\nperformance of models both in a high- and a low- resource language. The dataset\ncontains 358 questions and answers on 338 English documents and 208 Yor\\`ub\\'a\ndocuments. The average document length is ~ 10k words for English and 430 words\nfor Yor\\`ub\\'a. Experiments show a consistent disparity in performance between\nthe two languages, with Yor\\`ub\\'a falling behind English for automatic metrics\neven if documents are much shorter for this language. For a small set of\ndocuments with comparable length, performance of Yor\\`ub\\'a drops by x2.5\ntimes. When analyzing performance by length, we observe that Yor\\`ub\\'a\ndecreases performance dramatically for documents that reach 1500 words while\nEnglish performance is barely affected at that length. Our dataset opens the\ndoor to showcasing if English LLM reading comprehension capabilities extend to\nYor\\`ub\\'a, which for the evaluated LLMs is not the case.\n","authors":["Marta R. Costa-jussà","Joy Chen","Ifeoluwanimi Adebara","Joe Chuang","Christophe Ropers","Eduardo Sánchez"],"pdf_url":"https://arxiv.org/pdf/2412.08279v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08274v1","updated":"2024-12-11T10:46:21Z","published":"2024-12-11T10:46:21Z","title":"2M-BELEBELE: Highly Multilingual Speech and American Sign Language\n  Comprehension Dataset","summary":"  We introduce the first highly multilingual speech and American Sign Language\n(ASL) comprehension dataset by extending BELEBELE. Our dataset covers 74 spoken\nlanguages at the intersection of BELEBELE and FLEURS, and one sign language\n(ASL). We evaluate 2M-BELEBELE dataset for both 5-shot and zero-shot settings\nand across languages, the speech comprehension accuracy is ~ 8% average lower\ncompared to reading comprehension.\n","authors":["Marta R. Costa-jussà","Bokai Yu","Pierre Andrews","Belen Alastruey","Necati Cihan Camgoz","Joe Chuang","Jean Maillard","Christophe Ropers","Arina Turkantenko","Carleigh Wood"],"pdf_url":"https://arxiv.org/pdf/2412.08274v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08268v1","updated":"2024-12-11T10:35:45Z","published":"2024-12-11T10:35:45Z","title":"LCFO: Long Context and Long Form Output Dataset and Benchmarking","summary":"  This paper presents the Long Context and Form Output (LCFO) benchmark, a\nnovel evaluation framework for assessing gradual summarization and summary\nexpansion capabilities across diverse domains. LCFO consists of long input\ndocuments (5k words average length), each of which comes with three summaries\nof different lengths (20%, 10%, and 5% of the input text), as well as\napproximately 15 questions and answers (QA) related to the input content.\nNotably, LCFO also provides alignments between specific QA pairs and\ncorresponding summaries in 7 domains. The primary motivation behind providing\nsummaries of different lengths is to establish a controllable framework for\ngenerating long texts from shorter inputs, i.e. summary expansion. To establish\nan evaluation metric framework for summarization and summary expansion, we\nprovide human evaluation scores for human-generated outputs, as well as results\nfrom various state-of-the-art large language models (LLMs). GPT-4o-mini\nachieves best human scores among automatic systems in both summarization and\nsummary expansion tasks (~ +10% and +20%, respectively). It even surpasses\nhuman output quality in the case of short summaries (~ +7%). Overall automatic\nmetrics achieve low correlations with human evaluation scores (~ 0.4) but\nmoderate correlation on specific evaluation aspects such as fluency and\nattribution (~ 0.6). The LCFO benchmark offers a standardized platform for\nevaluating summarization and summary expansion performance, as well as\ncorresponding automatic metrics, thereby providing an important evaluation\nframework to advance generative AI.\n","authors":["Marta R. Costa-jussà","Pierre Andrews","Mariano Coria Meglioli","Joy Chen","Joe Chuang","David Dale","Christophe Ropers","Alexandre Mourachko","Eduardo Sánchez","Holger Schwenk","Tuan Tran","Arina Turkatenko","Carleigh Wood"],"pdf_url":"https://arxiv.org/pdf/2412.08268v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08263v1","updated":"2024-12-11T10:18:37Z","published":"2024-12-11T10:18:37Z","title":"Discrete Subgraph Sampling for Interpretable Graph based Visual Question\n  Answering","summary":"  Explainable artificial intelligence (XAI) aims to make machine learning\nmodels more transparent. While many approaches focus on generating explanations\npost-hoc, interpretable approaches, which generate the explanations\nintrinsically alongside the predictions, are relatively rare. In this work, we\nintegrate different discrete subset sampling methods into a graph-based visual\nquestion answering system to compare their effectiveness in generating\ninterpretable explanatory subgraphs intrinsically. We evaluate the methods on\nthe GQA dataset and show that the integrated methods effectively mitigate the\nperformance trade-off between interpretability and answer accuracy, while also\nachieving strong co-occurrences between answer and question tokens.\nFurthermore, we conduct a human evaluation to assess the interpretability of\nthe generated subgraphs using a comparative setting with the extended\nBradley-Terry model, showing that the answer and question token co-occurrence\nmetrics strongly correlate with human preferences. Our source code is publicly\navailable.\n","authors":["Pascal Tilli","Ngoc Thang Vu"],"pdf_url":"https://arxiv.org/pdf/2412.08263v1.pdf","comment":"Accepted at COLING 2025"},{"id":"http://arxiv.org/abs/2408.05074v5","updated":"2024-12-11T10:14:32Z","published":"2024-08-09T14:02:24Z","title":"Improving Mortality Prediction After Radiotherapy with Large Language\n  Model Structuring of Large-Scale Unstructured Electronic Health Records","summary":"  Accurate survival prediction in radiotherapy (RT) is critical for optimizing\ntreatment decisions. This study developed and validated the RT-Surv framework,\nwhich integrates general-domain, open-source large language models (LLMs) to\nstructure unstructured electronic health records alongside structured clinical\ndata. Using data from 34,276 patients and an external cohort of 852, the\nframework successfully transformed unstructured clinical information into\nstructured formats. Incorporating LLM-structured clinical features improved the\nconcordance index from 0.779 to 0.842 during external validation, demonstrating\na significant performance enhancement. Key LLM-structured features, such as\ndisease extent, general condition, and RT purpose, showed high predictive\nimportance and aligned closely with statistically significant predictors\nidentified through conventional statistical analyses, thereby improving model\ninterpretability. Furthermore, the framework enhanced risk stratification,\nenabling more distinct differentiation among low-, intermediate-, and high-risk\ngroups (p < 0.001) using LLM-structured clinical features. These findings\nhighlight the potential of LLMs to convert unstructured data into actionable\ninsights, improving predictive modeling and patient outcomes in clinics.\n","authors":["Sangjoon Park","Chan Woo Wee","Seo Hee Choi","Kyung Hwan Kim","Jee Suk Chang","Hong In Yoon","Ik Jae Lee","Yong Bae Kim","Jaeho Cho","Ki Chang Keum","Chang Geol Lee","Hwa Kyung Byun","Woong Sub Koom"],"pdf_url":"https://arxiv.org/pdf/2408.05074v5.pdf","comment":"23 pages, 2 tables, 4 figures"},{"id":"http://arxiv.org/abs/2409.18193v2","updated":"2024-12-11T10:13:12Z","published":"2024-09-26T18:10:26Z","title":"GrEmLIn: A Repository of Green Baseline Embeddings for 87 Low-Resource\n  Languages Injected with Multilingual Graph Knowledge","summary":"  Contextualized embeddings based on large language models (LLMs) are available\nfor various languages, but their coverage is often limited for lower resourced\nlanguages. Using LLMs for such languages is often difficult due to a high\ncomputational cost; not only during training, but also during inference. Static\nword embeddings are much more resource-efficient (\"green\"), and thus still\nprovide value, particularly for very low-resource languages. There is, however,\na notable lack of comprehensive repositories with such embeddings for diverse\nlanguages. To address this gap, we present GrEmLIn, a centralized repository of\ngreen, static baseline embeddings for 87 mid- and low-resource languages. We\ncompute GrEmLIn embeddings with a novel method that enhances GloVe embeddings\nby integrating multilingual graph knowledge, which makes our static embeddings\ncompetitive with LLM representations, while being parameter-free at inference\ntime. Our experiments demonstrate that GrEmLIn embeddings outperform\nstate-of-the-art contextualized embeddings from E5 on the task of lexical\nsimilarity. They remain competitive in extrinsic evaluation tasks like\nsentiment analysis and natural language inference, with average performance\ngaps of just 5-10\\% or less compared to state-of-the-art models, given a\nsufficient vocabulary overlap with the target task, and underperform only on\ntopic classification. Our code and embeddings are publicly available at\nhttps://huggingface.co/DFKI.\n","authors":["Daniil Gurgurov","Rishu Kumar","Simon Ostermann"],"pdf_url":"https://arxiv.org/pdf/2409.18193v2.pdf","comment":"Long paper, preview"},{"id":"http://arxiv.org/abs/2412.08255v1","updated":"2024-12-11T10:06:57Z","published":"2024-12-11T10:06:57Z","title":"Accurate Medical Named Entity Recognition Through Specialized NLP Models","summary":"  This study evaluated the effect of BioBERT in medical text processing for the\ntask of medical named entity recognition. Through comparative experiments with\nmodels such as BERT, ClinicalBERT, SciBERT, and BlueBERT, the results showed\nthat BioBERT achieved the best performance in both precision and F1 score,\nverifying its applicability and superiority in the medical field. BioBERT\nenhances its ability to understand professional terms and complex medical texts\nthrough pre-training on biomedical data, providing a powerful tool for medical\ninformation extraction and clinical decision support. The study also explored\nthe privacy and compliance challenges of BioBERT when processing medical data,\nand proposed future research directions for combining other medical-specific\nmodels to improve generalization and robustness. With the development of deep\nlearning technology, the potential of BioBERT in application fields such as\nintelligent medicine, personalized treatment, and disease prediction will be\nfurther expanded. Future research can focus on the real-time and\ninterpretability of the model to promote its widespread application in the\nmedical field.\n","authors":["Jiacheng Hu","Runyuan Bao","Yang Lin","Hanchao Zhang","Yanlin Xiang"],"pdf_url":"https://arxiv.org/pdf/2412.08255v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14035v3","updated":"2024-12-11T09:56:15Z","published":"2024-06-20T06:56:19Z","title":"Using Game Play to Investigate Multimodal and Conversational Grounding\n  in Large Multimodal Models","summary":"  While the situation has improved for text-only models, it again seems to be\nthe case currently that multimodal (text and image) models develop faster than\nways to evaluate them. In this paper, we bring a recently developed evaluation\nparadigm from text models to multimodal models, namely evaluation through the\ngoal-oriented game (self) play, complementing reference-based and\npreference-based evaluation. Specifically, we define games that challenge a\nmodel's capability to represent a situation from visual information and align\nsuch representations through dialogue. We find that the largest closed models\nperform rather well on the games that we define, while even the best\nopen-weight models struggle with them. On further analysis, we find that the\nexceptional deep captioning capabilities of the largest models drive some of\nthe performance. There is still room to grow for both kinds of models, ensuring\nthe continued relevance of the benchmark.\n","authors":["Sherzod Hakimov","Yerkezhan Abdullayeva","Kushal Koshti","Antonia Schmidt","Yan Weiser","Anne Beyer","David Schlangen"],"pdf_url":"https://arxiv.org/pdf/2406.14035v3.pdf","comment":"Accepted at COLING 2025"},{"id":"http://arxiv.org/abs/2412.08237v1","updated":"2024-12-11T09:38:50Z","published":"2024-12-11T09:38:50Z","title":"TouchTTS: An Embarrassingly Simple TTS Framework that Everyone Can Touch","summary":"  It is well known that LLM-based systems are data-hungry. Recent LLM-based TTS\nworks typically employ complex data processing pipelines to obtain high-quality\ntraining data. These sophisticated pipelines require excellent models at each\nstage (e.g., speech denoising, speech enhancement, speaker diarization, and\npunctuation models), which themselves demand high-quality training data and are\nrarely open-sourced. Even with state-of-the-art models, issues persist, such as\nincomplete background noise removal and misalignment between punctuation and\nactual speech pauses. Moreover, the stringent filtering strategies often retain\nonly 10-30\\% of the original data, significantly impeding data scaling efforts.\nIn this work, we leverage a noise-robust audio tokenizer (S3Tokenizer) to\ndesign a simplified yet effective TTS data processing pipeline that maintains\ndata quality while substantially reducing data acquisition costs, achieving a\ndata retention rate of over 50\\%. Beyond data scaling challenges, LLM-based TTS\nsystems also incur higher deployment costs compared to conventional approaches.\nCurrent systems typically use LLMs solely for text-to-token generation, while\nrequiring separate models (e.g., flow matching models) for token-to-waveform\ngeneration, which cannot be directly executed by LLM inference engines, further\ncomplicating deployment. To address these challenges, we eliminate redundant\nmodules in both LLM and flow components, replacing the flow model backbone with\nan LLM architecture. Building upon this simplified flow backbone, we propose a\nunified architecture for both streaming and non-streaming inference,\nsignificantly reducing deployment costs. Finally, we explore the feasibility of\nunifying TTS and ASR tasks using the same data for training, thanks to the\nsimplified pipeline and the S3Tokenizer that reduces the quality requirements\nfor TTS training data.\n","authors":["Xingchen Song","Mengtao Xing","Changwei Ma","Shengqiang Li","Di Wu","Binbin Zhang","Fuping Pan","Dinghao Zhou","Yuekai Zhang","Shun Lei","Zhendong Peng","Zhiyong Wu"],"pdf_url":"https://arxiv.org/pdf/2412.08237v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2412.02819v3","updated":"2024-12-11T09:15:06Z","published":"2024-12-03T20:35:57Z","title":"CNNSum: Exploring Long-Context Summarization with Large Language Models\n  in Chinese Novels","summary":"  Large Language Models (LLMs) have been well-researched in many long-context\ntasks. However, due to high annotation costs, high-quality long-context summary\ndatasets for training or evaluation are scarce, limiting further research. In\nthis work, we introduce CNNSum, a new multi-scale Chinese long-context novel\nsummarization benchmark, including four subsets, length covering 16k to 128k,\n695 samples in total, the annotations are human-driven. We evaluate commercial\nand open-source models on CNNSum and conduct a detailed analysis. Based on the\nobservations, we further conduct fine-tuning exploration with short-context\nsummary data. In our study: (1) GPT-4o underperformed, due to excessive\nsubjective commentary. (2) Currently, long-context summarization mainly relies\non memory ability, small LLMs with stable longer context lengths are the most\ncost-effective. Using long data concatenated from short-context summaries makes\na significant improvement. (3) Prompt templates may cause a large performance\ngap but can be mitigated through fine-tuning. (4) Fine-tuned Chat or\nInstruction versions may harm the Base model and further fine-tuning cannot\nbridge performance gap. (5) while models with RoPE base scaling exhibit strong\nextrapolation potential, their performance may vary significantly when combined\nwith other interpolation methods and need careful selection. (6) CNNSum\nprovides more reliable and insightful evaluation results than other benchmarks.\nWe release CNNSum to advance research in this field\n(https://github.com/CxsGhost/CNNSum).\n","authors":["Lingxiao Wei","He Yan","Xiangju Lu","Junmin Zhu","Jun Wang","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.02819v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.11553v3","updated":"2024-12-11T09:04:18Z","published":"2024-04-17T16:53:16Z","title":"Language Ranker: A Metric for Quantifying LLM Performance Across High\n  and Low-Resource Languages","summary":"  The development of Large Language Models (LLMs) relies on extensive text\ncorpora, which are often unevenly distributed across languages. This imbalance\nresults in LLMs performing significantly better on high-resource languages like\nEnglish, German, and French, while their capabilities in low-resource languages\nremain inadequate. Currently, there is a lack of quantitative methods to\nevaluate the performance of LLMs in these low-resource languages. To address\nthis gap, we propose the Language Ranker, an intrinsic metric designed to\nbenchmark and rank languages based on LLM performance using internal\nrepresentations. By comparing the LLM's internal representation of various\nlanguages against a baseline derived from English, we can assess the model's\nmultilingual capabilities in a robust and language-agnostic manner. Our\nanalysis reveals that high-resource languages exhibit higher similarity scores\nwith English, demonstrating superior performance, while low-resource languages\nshow lower similarity scores, underscoring the effectiveness of our metric in\nassessing language-specific capabilities. Besides, the experiments show that\nthere is a strong correlation between the LLM's performance in different\nlanguages and the proportion of those languages in its pre-training corpus.\nThese insights underscore the efficacy of the Language Ranker as a tool for\nevaluating LLM performance across different languages, particularly those with\nlimited resources.\n","authors":["Zihao Li","Yucheng Shi","Zirui Liu","Fan Yang","Ali Payani","Ninghao Liu","Mengnan Du"],"pdf_url":"https://arxiv.org/pdf/2404.11553v3.pdf","comment":"Accepted by AAAI 2025 (Social Impact Track)"},{"id":"http://arxiv.org/abs/2412.08196v1","updated":"2024-12-11T08:36:50Z","published":"2024-12-11T08:36:50Z","title":"DocSum: Domain-Adaptive Pre-training for Document Abstractive\n  Summarization","summary":"  Abstractive summarization has made significant strides in condensing and\nrephrasing large volumes of text into coherent summaries. However, summarizing\nadministrative documents presents unique challenges due to domain-specific\nterminology, OCR-generated errors, and the scarcity of annotated datasets for\nmodel fine-tuning. Existing models often struggle to adapt to the intricate\nstructure and specialized content of such documents. To address these\nlimitations, we introduce DocSum, a domain-adaptive abstractive summarization\nframework tailored for administrative documents. Leveraging pre-training on\nOCR-transcribed text and fine-tuning with an innovative integration of\nquestion-answer pairs, DocSum enhances summary accuracy and relevance. This\napproach tackles the complexities inherent in administrative content, ensuring\noutputs that align with real-world business needs. To evaluate its\ncapabilities, we define a novel downstream task setting-Document Abstractive\nSummarization-which reflects the practical requirements of business and\norganizational settings. Comprehensive experiments demonstrate DocSum's\neffectiveness in producing high-quality summaries, showcasing its potential to\nimprove decision-making and operational workflows across the public and private\nsectors.\n","authors":["Phan Phuong Mai Chau","Souhail Bakkali","Antoine Doucet"],"pdf_url":"https://arxiv.org/pdf/2412.08196v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08187v1","updated":"2024-12-11T08:27:25Z","published":"2024-12-11T08:27:25Z","title":"From communities to interpretable network and word embedding: an unified\n  approach","summary":"  Modelling information from complex systems such as humans social interaction\nor words co-occurrences in our languages can help to understand how these\nsystems are organized and function. Such systems can be modelled by networks,\nand network theory provides a useful set of methods to analyze them. Among\nthese methods, graph embedding is a powerful tool to summarize the interactions\nand topology of a network in a vectorized feature space. When used in input of\nmachine learning algorithms, embedding vectors help with common graph problems\nsuch as link prediction, graph matching, etc. Word embedding has the goal of\nrepresenting the sense of words, extracting it from large text corpora. Despite\ndifferences in the structure of information in input of embedding algorithms,\nmany graph embedding approaches are adapted and inspired from methods in NLP.\nLimits of these methods are observed in both domains. Most of these methods\nrequire long and resource greedy training. Another downside to most methods is\nthat they are black-box, from which understanding how the information is\nstructured is rather complex. Interpretability of a model allows understanding\nhow the vector space is structured without the need for external information,\nand thus can be audited more easily. With both these limitations in mind, we\npropose a novel framework to efficiently embed network vertices in an\ninterpretable vector space. Our Lower Dimension Bipartite Framework (LDBGF)\nleverages the bipartite projection of a network using cliques to reduce\ndimensionality. Along with LDBGF, we introduce two implementations of this\nframework that rely on communities instead of cliques: SINr-NR and SINr-MF. We\nshow that SINr-MF can perform well on classical graphs and SINr-NR can produce\nhigh-quality graph and word embeddings that are interpretable and stable across\nruns.\n","authors":["Thibault Prouteau","Nicolas Dugué","Simon Guillot"],"pdf_url":"https://arxiv.org/pdf/2412.08187v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.11464v3","updated":"2024-12-11T08:03:56Z","published":"2024-05-19T06:43:12Z","title":"Efficient Prompt Tuning by Multi-Space Projection and Prompt Fusion","summary":"  Prompt tuning is a promising method to fine-tune a pre-trained language model\nwithout retraining its large-scale parameters. Instead, it attaches a soft\nprompt to the input text, whereby downstream tasks can be well adapted by\nmerely learning the embeddings of prompt tokens. Nevertheless, existing methods\nstill suffer from two challenges: (i) they are hard to balance accuracy and\nefficiency. A longer (shorter) soft prompt generally leads to a better(worse)\naccuracy but at the cost of more (less) training time. (ii)The performance may\nnot be consistent when adapting to different downstream tasks. We attribute it\nto the same embedding space but responsible for different requirements of\ndownstream tasks. To address these issues, we propose an Efficient Prompt\nTuning method (EPT) by multi-space projection and prompt fusion. Specifically,\nit decomposes a given soft prompt into a shorter prompt and two low-rank\nmatrices, significantly reducing the training time. Accuracy is also enhanced\nby leveraging low-rank matrices and the short prompt as additional knowledge\nsources to enrich the semantics of the original short prompt. In addition, we\nproject the soft prompt into multiple subspaces to improve the performance\nconsistency, and then adaptively learn the combination weights of different\nspaces through a gating network. Experiments on 13 natural language processing\ndownstream tasks show that our method significantly and consistently\noutperforms 11 comparison methods with the relative percentage of improvements\nup to 12.9%, and training time decreased by 14%.\n","authors":["Pengxiang Lan","Enneng Yang","Yuting Liu","Guibing Guo","Jianzhe Zhao","Xingwei Wang"],"pdf_url":"https://arxiv.org/pdf/2405.11464v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06394v2","updated":"2024-12-11T07:52:06Z","published":"2024-12-09T11:22:59Z","title":"GameArena: Evaluating LLM Reasoning through Live Computer Games","summary":"  Evaluating the reasoning abilities of large language models (LLMs) is\nchallenging. Existing benchmarks often depend on static datasets, which are\nvulnerable to data contamination and may get saturated over time, or on binary\nlive human feedback that conflates reasoning with other abilities. As the most\nprominent dynamic benchmark, Chatbot Arena evaluates open-ended questions in\nreal-world settings, but lacks the granularity in assessing specific reasoning\ncapabilities. We introduce GameArena, a dynamic benchmark designed to evaluate\nLLM reasoning capabilities through interactive gameplay with humans. GameArena\nconsists of three games designed to test specific reasoning capabilities (e.g.,\ndeductive and inductive reasoning), while keeping participants entertained and\nengaged. We analyze the gaming data retrospectively to uncover the underlying\nreasoning processes of LLMs and measure their fine-grained reasoning\ncapabilities. We collect over 2000 game sessions and provide detailed\nassessments of various reasoning capabilities for five state-of-the-art LLMs.\nOur user study with 100 participants suggests that GameArena improves user\nengagement compared to Chatbot Arena. For the first time, GameArena enables the\ncollection of step-by-step LLM reasoning data in the wild.\n","authors":["Lanxiang Hu","Qiyu Li","Anze Xie","Nan Jiang","Ion Stoica","Haojian Jin","Hao Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.06394v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08169v1","updated":"2024-12-11T07:51:18Z","published":"2024-12-11T07:51:18Z","title":"Illusory VQA: Benchmarking and Enhancing Multimodal Models on Visual\n  Illusions","summary":"  In recent years, Visual Question Answering (VQA) has made significant\nstrides, particularly with the advent of multimodal models that integrate\nvision and language understanding. However, existing VQA datasets often\noverlook the complexities introduced by image illusions, which pose unique\nchallenges for both human perception and model interpretation. In this study,\nwe introduce a novel task called Illusory VQA, along with four specialized\ndatasets: IllusionMNIST, IllusionFashionMNIST, IllusionAnimals, and\nIllusionChar. These datasets are designed to evaluate the performance of\nstate-of-the-art multimodal models in recognizing and interpreting visual\nillusions. We assess the zero-shot performance of various models, fine-tune\nselected models on our datasets, and propose a simple yet effective solution\nfor illusion detection using Gaussian and blur low-pass filters. We show that\nthis method increases the performance of models significantly and in the case\nof BLIP-2 on IllusionAnimals without any fine-tuning, it outperforms humans.\nOur findings highlight the disparity between human and model perception of\nillusions and demonstrate that fine-tuning and specific preprocessing\ntechniques can significantly enhance model robustness. This work contributes to\nthe development of more human-like visual understanding in multimodal models\nand suggests future directions for adapting filters using learnable parameters.\n","authors":["Mohammadmostafa Rostamkhani","Baktash Ansari","Hoorieh Sabzevari","Farzan Rahmani","Sauleh Eetemadi"],"pdf_url":"https://arxiv.org/pdf/2412.08169v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.19453v4","updated":"2024-12-11T07:41:18Z","published":"2024-10-25T10:28:59Z","title":"ShifCon: Enhancing Non-Dominant Language Capabilities with a Shift-based\n  Contrastive Framework","summary":"  Although fine-tuning Large Language Models (LLMs) with multilingual data can\nrapidly enhance the multilingual capabilities of LLMs, they still exhibit a\nperformance gap between the dominant language (e.g., English) and non-dominant\nones due to the imbalance of training data across languages. To further enhance\nthe performance of non-dominant languages, we propose ShifCon, a Shift-based\nContrastive framework that aligns the internal forward process of other\nlanguages toward that of the dominant one. Specifically, it shifts the\nrepresentations of non-dominant languages into the dominant language subspace,\nallowing them to access relatively rich information encoded in the model\nparameters. The enriched representations are then shifted back into their\noriginal language subspace before generation. Moreover, we introduce a subspace\ndistance metric to pinpoint the optimal layer area for shifting representations\nand employ multilingual contrastive learning to further enhance the alignment\nof representations within this area. Experiments demonstrate that our ShifCon\nframework significantly enhances the performance of non-dominant languages,\nparticularly for low-resource ones. Further analysis offers extra insights to\nverify the effectiveness of ShifCon and propel future research\n","authors":["Hengyuan Zhang","Chenming Shang","Sizhe Wang","Dongdong Zhang","Feng Yao","Renliang Sun","Yiyao Yu","Yujiu Yang","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2410.19453v4.pdf","comment":"23 pages, 11 figures"},{"id":"http://arxiv.org/abs/2412.08163v1","updated":"2024-12-11T07:37:26Z","published":"2024-12-11T07:37:26Z","title":"NLPineers@ NLU of Devanagari Script Languages 2025: Hate Speech\n  Detection using Ensembling of BERT-based models","summary":"  This paper explores hate speech detection in Devanagari-scripted languages,\nfocusing on Hindi and Nepali, for Subtask B of the CHIPSAL@COLING 2025 Shared\nTask. Using a range of transformer-based models such as XLM-RoBERTa, MURIL, and\nIndicBERT, we examine their effectiveness in navigating the nuanced boundary\nbetween hate speech and free expression. Our best performing model, implemented\nas ensemble of multilingual BERT models achieve Recall of 0.7762 (Rank 3/31 in\nterms of recall) and F1 score of 0.6914 (Rank 17/31). To address class\nimbalance, we used backtranslation for data augmentation, and cosine similarity\nto preserve label consistency after augmentation. This work emphasizes the need\nfor hate speech detection in Devanagari-scripted languages and presents a\nfoundation for further research.\n","authors":["Anmol Guragain","Nadika Poudel","Rajesh Piryani","Bishesh Khanal"],"pdf_url":"https://arxiv.org/pdf/2412.08163v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08158v1","updated":"2024-12-11T07:29:04Z","published":"2024-12-11T07:29:04Z","title":"How Vision-Language Tasks Benefit from Large Pre-trained Models: A\n  Survey","summary":"  The exploration of various vision-language tasks, such as visual captioning,\nvisual question answering, and visual commonsense reasoning, is an important\narea in artificial intelligence and continuously attracts the research\ncommunity's attention. Despite the improvements in overall performance, classic\nchallenges still exist in vision-language tasks and hinder the development of\nthis area. In recent years, the rise of pre-trained models is driving the\nresearch on vision-language tasks. Thanks to the massive scale of training data\nand model parameters, pre-trained models have exhibited excellent performance\nin numerous downstream tasks. Inspired by the powerful capabilities of\npre-trained models, new paradigms have emerged to solve the classic challenges.\nSuch methods have become mainstream in current research with increasing\nattention and rapid advances. In this paper, we present a comprehensive\noverview of how vision-language tasks benefit from pre-trained models. First,\nwe review several main challenges in vision-language tasks and discuss the\nlimitations of previous solutions before the era of pre-training. Next, we\nsummarize the recent advances in incorporating pre-trained models to address\nthe challenges in vision-language tasks. Finally, we analyze the potential\nrisks associated with the inherent limitations of pre-trained models and\ndiscuss possible solutions, attempting to provide future research directions.\n","authors":["Yayun Qi","Hongxi Li","Yiqi Song","Xinxiao Wu","Jiebo Luo"],"pdf_url":"https://arxiv.org/pdf/2412.08158v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2412.00218v3","updated":"2024-12-11T07:18:10Z","published":"2024-11-29T19:25:00Z","title":"NushuRescue: Revitalization of the Endangered Nushu Language with AI","summary":"  The preservation and revitalization of endangered and extinct languages is a\nmeaningful endeavor, conserving cultural heritage while enriching fields like\nlinguistics and anthropology. However, these languages are typically\nlow-resource, making their reconstruction labor-intensive and costly. This\nchallenge is exemplified by Nushu, a rare script historically used by Yao women\nin China for self-expression within a patriarchal society. To address this\nchallenge, we introduce NushuRescue, an AI-driven framework designed to train\nlarge language models (LLMs) on endangered languages with minimal data.\nNushuRescue automates evaluation and expands target corpora to accelerate\nlinguistic revitalization. As a foundational component, we developed NCGold, a\n500-sentence Nushu-Chinese parallel corpus, the first publicly available\ndataset of its kind. Leveraging GPT-4-Turbo, with no prior exposure to Nushu\nand only 35 short examples from NCGold, NushuRescue achieved 48.69% translation\naccuracy on 50 withheld sentences and generated NCSilver, a set of 98 newly\ntranslated modern Chinese sentences of varying lengths. A sample of both NCGold\nand NCSilver is included in the Supplementary Materials. Additionally, we\ndeveloped FastText-based and Seq2Seq models to further support research on\nNushu. NushuRescue provides a versatile and scalable tool for the\nrevitalization of endangered languages, minimizing the need for extensive human\ninput.\n","authors":["Ivory Yang","Weicheng Ma","Soroush Vosoughi"],"pdf_url":"https://arxiv.org/pdf/2412.00218v3.pdf","comment":"Accepted to COLING 2025"},{"id":"http://arxiv.org/abs/2409.15827v2","updated":"2024-12-11T07:05:21Z","published":"2024-09-24T07:40:33Z","title":"Unveiling Language Competence Neurons: A Psycholinguistic Approach to\n  Model Interpretability","summary":"  As large language models (LLMs) advance in their linguistic capacity,\nunderstanding how they capture aspects of language competence remains a\nsignificant challenge. This study therefore employs psycholinguistic paradigms\nin English, which are well-suited for probing deeper cognitive aspects of\nlanguage processing, to explore neuron-level representations in language model\nacross three tasks: sound-shape association, sound-gender association, and\nimplicit causality. Our findings indicate that while GPT-2-XL struggles with\nthe sound-shape task, it demonstrates human-like abilities in both sound-gender\nassociation and implicit causality. Targeted neuron ablation and activation\nmanipulation reveal a crucial relationship: When GPT-2-XL displays a linguistic\nability, specific neurons correspond to that competence; conversely, the\nabsence of such an ability indicates a lack of specialized neurons. This study\nis the first to utilize psycholinguistic experiments to investigate deep\nlanguage competence at the neuron level, providing a new level of granularity\nin model interpretability and insights into the internal mechanisms driving\nlanguage ability in the transformer-based LLM.\n","authors":["Xufeng Duan","Xinyu Zhou","Bei Xiao","Zhenguang G. Cai"],"pdf_url":"https://arxiv.org/pdf/2409.15827v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17972v2","updated":"2024-12-11T06:39:43Z","published":"2024-06-25T23:07:18Z","title":"LABOR-LLM: Language-Based Occupational Representations with Large\n  Language Models","summary":"  Vafa et al. (2024) introduced a transformer-based econometric model, CAREER,\nthat predicts a worker's next job as a function of career history (an\n\"occupation model\"). CAREER was initially estimated (\"pre-trained\") using a\nlarge, unrepresentative resume dataset, which served as a \"foundation model,\"\nand parameter estimation was continued (\"fine-tuned\") using data from a\nrepresentative survey. CAREER had better predictive performance than\nbenchmarks. This paper considers an alternative where the resume-based\nfoundation model is replaced by a large language model (LLM). We convert\ntabular data from the survey into text files that resemble resumes and\nfine-tune the LLMs using these text files with the objective to predict the\nnext token (word). The resulting fine-tuned LLM is used as an input to an\noccupation model. Its predictive performance surpasses all prior models. We\ndemonstrate the value of fine-tuning and further show that by adding more\ncareer data from a different population, fine-tuning smaller LLMs surpasses the\nperformance of fine-tuning larger models.\n","authors":["Susan Athey","Herman Brunborg","Tianyu Du","Ayush Kanodia","Keyon Vafa"],"pdf_url":"https://arxiv.org/pdf/2406.17972v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08127v1","updated":"2024-12-11T06:22:44Z","published":"2024-12-11T06:22:44Z","title":"Evil twins are not that evil: Qualitative insights into\n  machine-generated prompts","summary":"  It has been widely observed that language models (LMs) respond in predictable\nways to algorithmically generated prompts that are seemingly unintelligible.\nThis is both a sign that we lack a full understanding of how LMs work, and a\npractical challenge, because opaqueness can be exploited for harmful uses of\nLMs, such as jailbreaking. We present the first thorough analysis of opaque\nmachine-generated prompts, or autoprompts, pertaining to 3 LMs of different\nsizes and families. We find that machine-generated prompts are characterized by\na last token that is often intelligible and strongly affects the generation. A\nsmall but consistent proportion of the previous tokens are fillers that\nprobably appear in the prompt as a by-product of the fact that the optimization\nprocess fixes the number of tokens. The remaining tokens tend to have at least\na loose semantic relation with the generation, although they do not engage in\nwell-formed syntactic relations with it. We find moreover that some of the\nablations we applied to machine-generated prompts can also be applied to\nnatural language sequences, leading to similar behavior, suggesting that\nautoprompts are a direct consequence of the way in which LMs process linguistic\ninputs in general.\n","authors":["Nathanaël Carraz Rakotonirina","Corentin Kervadec","Francesca Franzon","Marco Baroni"],"pdf_url":"https://arxiv.org/pdf/2412.08127v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08125v1","updated":"2024-12-11T06:21:33Z","published":"2024-12-11T06:21:33Z","title":"Progressive Multi-granular Alignments for Grounded Reasoning in Large\n  Vision-Language Models","summary":"  Existing Large Vision-Language Models (LVLMs) excel at matching concepts\nacross multi-modal inputs but struggle with compositional concepts and\nhigh-level relationships between entities. This paper introduces Progressive\nmulti-granular Vision-Language alignments (PromViL), a novel framework to\nenhance LVLMs' ability in performing grounded compositional visual reasoning\ntasks. Our approach constructs a hierarchical structure of multi-modal\nalignments, ranging from simple to complex concepts. By progressively aligning\ntextual descriptions with corresponding visual regions, our model learns to\nleverage contextual information from lower levels to inform higher-level\nreasoning. To facilitate this learning process, we introduce a data generation\nprocess that creates a novel dataset derived from Visual Genome, providing a\nwide range of nested compositional vision-language pairs. Experimental results\ndemonstrate that our PromViL framework significantly outperforms baselines on\nvarious visual grounding and compositional question answering tasks.\n","authors":["Quang-Hung Le","Long Hoang Dang","Ngan Le","Truyen Tran","Thao Minh Le"],"pdf_url":"https://arxiv.org/pdf/2412.08125v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.00958v5","updated":"2024-12-11T06:01:38Z","published":"2024-07-01T04:29:35Z","title":"Dynamic Universal Approximation Theory: The Basic Theory for\n  Transformer-based Large Language Models","summary":"  Language models have emerged as a critical area of focus in artificial\nintelligence, particularly with the introduction of groundbreaking innovations\nlike ChatGPT. Large-scale Transformer networks have quickly become the leading\napproach for advancing natural language processing algorithms. Built on the\nTransformer architecture, these models enable interactions that closely mimic\nhuman communication and, equipped with extensive knowledge, can even assist in\nguiding human tasks. Despite their impressive capabilities and growing\ncomplexity, a key question remains-the theoretical foundations of large\nlanguage models (LLMs). What makes Transformer so effective for powering\nintelligent language applications, such as translation and coding? What\nunderlies LLMs' ability for In-Context Learning (ICL)? How does the LoRA scheme\nenhance the fine-tuning of LLMs? And what supports the practicality of pruning\nLLMs? To address these critical questions and explore the technological\nstrategies within LLMs, we leverage the Universal Approximation Theory (UAT) to\noffer a theoretical backdrop, shedding light on the mechanisms that underpin\nthese advancements.\n","authors":["Wei Wang","Qing Li"],"pdf_url":"https://arxiv.org/pdf/2407.00958v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08117v1","updated":"2024-12-11T05:55:06Z","published":"2024-12-11T05:55:06Z","title":"LatentSpeech: Latent Diffusion for Text-To-Speech Generation","summary":"  Diffusion-based Generative AI gains significant attention for its superior\nperformance over other generative techniques like Generative Adversarial\nNetworks and Variational Autoencoders. While it has achieved notable\nadvancements in fields such as computer vision and natural language processing,\ntheir application in speech generation remains under-explored. Mainstream\nText-to-Speech systems primarily map outputs to Mel-Spectrograms in the\nspectral space, leading to high computational loads due to the sparsity of\nMelSpecs. To address these limitations, we propose LatentSpeech, a novel TTS\ngeneration approach utilizing latent diffusion models. By using latent\nembeddings as the intermediate representation, LatentSpeech reduces the target\ndimension to 5% of what is required for MelSpecs, simplifying the processing\nfor the TTS encoder and vocoder and enabling efficient high-quality speech\ngeneration. This study marks the first integration of latent diffusion models\nin TTS, enhancing the accuracy and naturalness of generated speech.\nExperimental results on benchmark datasets demonstrate that LatentSpeech\nachieves a 25% improvement in Word Error Rate and a 24% improvement in Mel\nCepstral Distortion compared to existing models, with further improvements\nrising to 49.5% and 26%, respectively, with additional training data. These\nfindings highlight the potential of LatentSpeech to advance the\nstate-of-the-art in TTS technology\n","authors":["Haowei Lou","Helen Paik","Pari Delir Haghighi","Wen Hu","Lina Yao"],"pdf_url":"https://arxiv.org/pdf/2412.08117v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08112v1","updated":"2024-12-11T05:39:12Z","published":"2024-12-11T05:39:12Z","title":"Aligner-Guided Training Paradigm: Advancing Text-to-Speech Models with\n  Aligner Guided Duration","summary":"  Recent advancements in text-to-speech (TTS) systems, such as FastSpeech and\nStyleSpeech, have significantly improved speech generation quality. However,\nthese models often rely on duration generated by external tools like the\nMontreal Forced Aligner, which can be time-consuming and lack flexibility. The\nimportance of accurate duration is often underestimated, despite their crucial\nrole in achieving natural prosody and intelligibility. To address these\nlimitations, we propose a novel Aligner-Guided Training Paradigm that\nprioritizes accurate duration labelling by training an aligner before the TTS\nmodel. This approach reduces dependence on external tools and enhances\nalignment accuracy. We further explore the impact of different acoustic\nfeatures, including Mel-Spectrograms, MFCCs, and latent features, on TTS model\nperformance. Our experimental results show that aligner-guided duration\nlabelling can achieve up to a 16\\% improvement in word error rate and\nsignificantly enhance phoneme and tone alignment. These findings highlight the\neffectiveness of our approach in optimizing TTS systems for more natural and\nintelligible speech generation.\n","authors":["Haowei Lou","Helen Paik","Wen Hu","Lina Yao"],"pdf_url":"https://arxiv.org/pdf/2412.08112v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08111v1","updated":"2024-12-11T05:37:04Z","published":"2024-12-11T05:37:04Z","title":"Seeing Syntax: Uncovering Syntactic Learning Limitations in\n  Vision-Language Models","summary":"  Vision-language models (VLMs), serve as foundation models for multi-modal\napplications such as image captioning and text-to-image generation. Recent\nstudies have highlighted limitations in VLM text encoders, particularly in\nareas like compositionality and semantic understanding, though the underlying\nreasons for these limitations remain unclear. In this work, we aim to address\nthis gap by analyzing the syntactic information, one of the fundamental\nlinguistic properties, encoded by the text encoders of VLMs. We perform a\nthorough analysis comparing VLMs with different objective functions, parameter\nsize and training data size, and with uni-modal language models (ULMs) in their\nability to encode syntactic knowledge. Our findings suggest that ULM text\nencoders acquire syntactic information more effectively than those in VLMs. The\nsyntactic information learned by VLM text encoders is shaped primarily by the\npre-training objective, which plays a more crucial role than other factors such\nas model architecture, model size, or the volume of pre-training data. Models\nexhibit different layer-wise trends where CLIP performance dropped across\nlayers while for other models, middle layers are rich in encoding syntactic\nknowledge.\n","authors":["Sri Harsha Dumpala","David Arps","Sageev Oore","Laura Kallmeyer","Hassan Sajjad"],"pdf_url":"https://arxiv.org/pdf/2412.08111v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08110v1","updated":"2024-12-11T05:36:18Z","published":"2024-12-11T05:36:18Z","title":"Barking Up The Syntactic Tree: Enhancing VLM Training with Syntactic\n  Losses","summary":"  Vision-Language Models (VLMs) achieved strong performance on a variety of\ntasks (e.g., image-text retrieval, visual question answering). However, most\nVLMs rely on coarse-grained image-caption pairs for alignment, relying on data\nvolume to resolve ambiguities and ground linguistic concepts in images. The\nricher semantic and syntactic structure within text is largely overlooked. To\naddress this, we propose HIerarchically STructured Learning (HIST) that\nenhances VLM training without any additional supervision, by hierarchically\ndecomposing captions into the constituent Subject, Noun Phrases, and Composite\nPhrases. Entailment between these constituent components allows us to formulate\nadditional regularization constraints on the VLM attention maps. Specifically,\nwe introduce two novel loss functions: (1) Subject Loss, which aligns image\ncontent with the subject of corresponding phrase, acting as an entailment of\nstandard contrastive/matching losses at the Phrase level; (2) Addition Loss, to\nbalance attention across multiple objects. HIST is general, and can be applied\nto any VLM for which attention between vision and language can be computed; we\nillustrate its efficacy on BLIP and ALBEF. HIST outperforms baseline VLMs,\nachieving up to +9.8% improvement in visual grounding, +6.3% in multi-object\nreferring segmentation, +1.1% in image-text retrieval, and +0.2% in visual\nquestion answering, underscoring the value of structuring learning in VLMs.\n","authors":["Jiayun Luo","Mir Rayat Imtiaz Hossain","Boyang Li","Leonid Sigal"],"pdf_url":"https://arxiv.org/pdf/2412.08110v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08108v1","updated":"2024-12-11T05:23:34Z","published":"2024-12-11T05:23:34Z","title":"Doubly-Universal Adversarial Perturbations: Deceiving Vision-Language\n  Models Across Both Images and Text with a Single Perturbation","summary":"  Large Vision-Language Models (VLMs) have demonstrated remarkable performance\nacross multimodal tasks by integrating vision encoders with large language\nmodels (LLMs). However, these models remain vulnerable to adversarial attacks.\nAmong such attacks, Universal Adversarial Perturbations (UAPs) are especially\npowerful, as a single optimized perturbation can mislead the model across\nvarious input images. In this work, we introduce a novel UAP specifically\ndesigned for VLMs: the Doubly-Universal Adversarial Perturbation (Doubly-UAP),\ncapable of universally deceiving VLMs across both image and text inputs. To\nsuccessfully disrupt the vision encoder's fundamental process, we analyze the\ncore components of the attention mechanism. After identifying value vectors in\nthe middle-to-late layers as the most vulnerable, we optimize Doubly-UAP in a\nlabel-free manner with a frozen model. Despite being developed as a black-box\nto the LLM, Doubly-UAP achieves high attack success rates on VLMs, consistently\noutperforming baseline methods across vision-language tasks. Extensive ablation\nstudies and analyses further demonstrate the robustness of Doubly-UAP and\nprovide insights into how it influences internal attention mechanisms.\n","authors":["Hee-Seon Kim","Minbeom Kim","Changick Kim"],"pdf_url":"https://arxiv.org/pdf/2412.08108v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.00385v2","updated":"2024-12-11T05:14:28Z","published":"2023-09-30T14:04:22Z","title":"Dynamic Demonstrations Controller for In-Context Learning","summary":"  In-context learning (ICL) is a new paradigm for natural language processing\n(NLP), where a large language model (LLM) observes a small number of\ndemonstrations and a test instance as its input, and directly makes predictions\nwithout updating model parameters. Previous studies have revealed that ICL is\nsensitive to the selection and the ordering of demonstrations. However, there\nare few studies regarding the impact of the demonstration number on the ICL\nperformance within a limited input length of LLM, because it is commonly\nbelieved that the number of demonstrations is positively correlated with model\nperformance. In this paper, we found this conclusion does not always hold true.\nThrough pilot experiments, we discover that increasing the number of\ndemonstrations does not necessarily lead to improved performance. Building upon\nthis insight, we propose a Dynamic Demonstrations Controller (D$^2$Controller),\nwhich can improve the ICL performance by adjusting the number of demonstrations\ndynamically. The experimental results show that D$^2$Controller yields a 4.6%\nrelative improvement on ten different sizes of LLMs across ten datasets.\nMoreover, we also extend our method to previous ICL models and achieve\ncompetitive results.\n","authors":["Fei Zhao","Taotian Pang","Zhen Wu","Zheng Ma","Shujian Huang","Xinyu Dai"],"pdf_url":"https://arxiv.org/pdf/2310.00385v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08099v1","updated":"2024-12-11T04:53:15Z","published":"2024-12-11T04:53:15Z","title":"Adversarial Vulnerabilities in Large Language Models for Time Series\n  Forecasting","summary":"  Large Language Models (LLMs) have recently demonstrated significant potential\nin the field of time series forecasting, offering impressive capabilities in\nhandling complex temporal data. However, their robustness and reliability in\nreal-world applications remain under-explored, particularly concerning their\nsusceptibility to adversarial attacks. In this paper, we introduce a targeted\nadversarial attack framework for LLM-based time series forecasting. By\nemploying both gradient-free and black-box optimization methods, we generate\nminimal yet highly effective perturbations that significantly degrade the\nforecasting accuracy across multiple datasets and LLM architectures. Our\nexperiments, which include models like TimeGPT and LLM-Time with GPT-3.5,\nGPT-4, LLaMa, and Mistral, show that adversarial attacks lead to much more\nsevere performance degradation than random noise, and demonstrate the broad\neffectiveness of our attacks across different LLMs. The results underscore the\ncritical vulnerabilities of LLMs in time series forecasting, highlighting the\nneed for robust defense mechanisms to ensure their reliable deployment in\npractical applications.\n","authors":["Fuqiang Liu","Sicong Jiang","Luis Miranda-Moreno","Seongjin Choi","Lijun Sun"],"pdf_url":"https://arxiv.org/pdf/2412.08099v1.pdf","comment":"11 pages, 5 figures"},{"id":"http://arxiv.org/abs/2412.06769v2","updated":"2024-12-11T04:52:56Z","published":"2024-12-09T18:55:56Z","title":"Training Large Language Models to Reason in a Continuous Latent Space","summary":"  Large language models (LLMs) are restricted to reason in the \"language\nspace\", where they typically express the reasoning process with a\nchain-of-thought (CoT) to solve a complex reasoning problem. However, we argue\nthat language space may not always be optimal for reasoning. For example, most\nword tokens are primarily for textual coherence and not essential for\nreasoning, while some critical tokens require complex planning and pose huge\nchallenges to LLMs. To explore the potential of LLM reasoning in an\nunrestricted latent space instead of using natural language, we introduce a new\nparadigm Coconut (Chain of Continuous Thought). We utilize the last hidden\nstate of the LLM as a representation of the reasoning state (termed \"continuous\nthought\"). Rather than decoding this into a word token, we feed it back to the\nLLM as the subsequent input embedding directly in the continuous space.\nExperiments show that Coconut can effectively augment the LLM on several\nreasoning tasks. This novel latent reasoning paradigm leads to emergent\nadvanced reasoning patterns: the continuous thought can encode multiple\nalternative next reasoning steps, allowing the model to perform a breadth-first\nsearch (BFS) to solve the problem, rather than prematurely committing to a\nsingle deterministic path like CoT. Coconut outperforms CoT in certain logical\nreasoning tasks that require substantial backtracking during planning, with\nfewer thinking tokens during inference. These findings demonstrate the promise\nof latent reasoning and offer valuable insights for future research.\n","authors":["Shibo Hao","Sainbayar Sukhbaatar","DiJia Su","Xian Li","Zhiting Hu","Jason Weston","Yuandong Tian"],"pdf_url":"https://arxiv.org/pdf/2412.06769v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08090v1","updated":"2024-12-11T04:16:39Z","published":"2024-12-11T04:16:39Z","title":"Multilingual LLMs Inherently Reward In-Language Time-Sensitive Semantic\n  Alignment for Low-Resource Languages","summary":"  The unwavering disparity in labeled resources between resource-rich languages\nand those considered low-resource remains a significant impediment for Large\nLanguage Models (LLMs). Recent strides in cross-lingual in-context learning\n(X-ICL), mainly through semantically aligned examples retrieved from\nmultilingual pre-trained transformers, have shown promise in mitigating this\nissue. However, our investigation reveals that LLMs intrinsically reward\nin-language semantically aligned cross-lingual instances over direct\ncross-lingual semantic alignments, with a pronounced disparity in handling\ntime-sensitive queries in the X-ICL setup. Such queries demand sound temporal\nreasoning ability from LLMs, yet the advancements have predominantly focused on\nEnglish. This study aims to bridge this gap by improving temporal reasoning\ncapabilities in low-resource languages. To this end, we introduce mTEMPREASON a\ntemporal reasoning dataset aimed at the varied degrees of low-resource\nlanguages and propose Cross-Lingual Time-Sensitive Semantic Alignment\n(CLiTSSA), a novel method to improve temporal reasoning in these contexts. To\nfacilitate this, we construct an extension of mTEMPREASON comprising pairs of\nparallel cross-language temporal queries along with their anticipated\nin-language semantic similarity scores. Our empirical evidence underscores the\nsuperior performance of CLiTSSA compared to established baselines across three\nlanguages - Romanian, German, and French, encompassing three temporal tasks and\nincluding a diverse set of four contemporaneous LLMs. This marks a significant\nstep forward in addressing resource disparity in the context of temporal\nreasoning across languages.\n","authors":["Ashutosh Bajpai","Tanmoy Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2412.08090v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.02387v6","updated":"2024-12-11T04:12:39Z","published":"2024-09-04T02:30:12Z","title":"Large Language Models and Cognitive Science: A Comprehensive Review of\n  Similarities, Differences, and Challenges","summary":"  This comprehensive review explores the intersection of Large Language Models\n(LLMs) and cognitive science, examining similarities and differences between\nLLMs and human cognitive processes. We analyze methods for evaluating LLMs\ncognitive abilities and discuss their potential as cognitive models. The review\ncovers applications of LLMs in various cognitive fields, highlighting insights\ngained for cognitive science research. We assess cognitive biases and\nlimitations of LLMs, along with proposed methods for improving their\nperformance. The integration of LLMs with cognitive architectures is examined,\nrevealing promising avenues for enhancing artificial intelligence (AI)\ncapabilities. Key challenges and future research directions are identified,\nemphasizing the need for continued refinement of LLMs to better align with\nhuman cognition. This review provides a balanced perspective on the current\nstate and future potential of LLMs in advancing our understanding of both\nartificial and human intelligence.\n","authors":["Qian Niu","Junyu Liu","Ziqian Bi","Pohsun Feng","Benji Peng","Keyu Chen","Ming Li","Lawrence KQ Yan","Yichao Zhang","Caitlyn Heqi Yin","Cheng Fei","Tianyang Wang","Yunze Wang","Silin Chen","Ming Liu"],"pdf_url":"https://arxiv.org/pdf/2409.02387v6.pdf","comment":"10 pages, 1 figure"},{"id":"http://arxiv.org/abs/2411.01084v3","updated":"2024-12-11T03:23:44Z","published":"2024-11-01T23:53:00Z","title":"Plentiful Jailbreaks with String Compositions","summary":"  Large language models (LLMs) remain vulnerable to a slew of adversarial\nattacks and jailbreaking methods. One common approach employed by white-hat\nattackers, or red-teamers, is to process model inputs and outputs using\nstring-level obfuscations, which can include leetspeak, rotary ciphers, Base64,\nASCII, and more. Our work extends these encoding-based attacks by unifying them\nin a framework of invertible string transformations. With invertibility, we can\ndevise arbitrary string compositions, defined as sequences of transformations,\nthat we can encode and decode end-to-end programmatically. We devise a\nautomated best-of-n attack that samples from a combinatorially large number of\nstring compositions. Our jailbreaks obtain competitive attack success rates on\nseveral leading frontier models when evaluated on HarmBench, highlighting that\nencoding-based attacks remain a persistent vulnerability even in advanced LLMs.\n","authors":["Brian R. Y. Huang"],"pdf_url":"https://arxiv.org/pdf/2411.01084v3.pdf","comment":"NeurIPS SoLaR Workshop 2024"},{"id":"http://arxiv.org/abs/2412.08054v1","updated":"2024-12-11T03:00:24Z","published":"2024-12-11T03:00:24Z","title":"Federated In-Context LLM Agent Learning","summary":"  Large Language Models (LLMs) have revolutionized intelligent services by\nenabling logical reasoning, tool use, and interaction with external systems as\nagents. The advancement of LLMs is frequently hindered by the scarcity of\nhigh-quality data, much of which is inherently sensitive. Federated learning\n(FL) offers a potential solution by facilitating the collaborative training of\ndistributed LLMs while safeguarding private data. However, FL frameworks face\nsignificant bandwidth and computational demands, along with challenges from\nheterogeneous data distributions. The emerging in-context learning capability\nof LLMs offers a promising approach by aggregating natural language rather than\nbulky model parameters. Yet, this method risks privacy leakage, as it\nnecessitates the collection and presentation of data samples from various\nclients during aggregation. In this paper, we propose a novel\nprivacy-preserving Federated In-Context LLM Agent Learning (FICAL) algorithm,\nwhich to our best knowledge for the first work unleashes the power of\nin-context learning to train diverse LLM agents through FL. In our design,\nknowledge compendiums generated by a novel LLM-enhanced Knowledge Compendiums\nGeneration (KCG) module are transmitted between clients and the server instead\nof model parameters in previous FL methods. Apart from that, an incredible\nRetrieval Augmented Generation (RAG) based Tool Learning and Utilizing (TLU)\nmodule is designed and we incorporate the aggregated global knowledge\ncompendium as a teacher to teach LLM agents the usage of tools. We conducted\nextensive experiments and the results show that FICAL has competitive\nperformance compared to other SOTA baselines with a significant communication\ncost decrease of $\\mathbf{3.33\\times10^5}$ times.\n","authors":["Panlong Wu","Kangshuo Li","Junbao Nan","Fangxin Wang"],"pdf_url":"https://arxiv.org/pdf/2412.08054v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08049v1","updated":"2024-12-11T02:55:00Z","published":"2024-12-11T02:55:00Z","title":"M2SE: A Multistage Multitask Instruction Tuning Strategy for Unified\n  Sentiment and Emotion Analysis","summary":"  Sentiment analysis and emotion recognition are crucial for applications such\nas human-computer interaction and depression detection. Traditional unimodal\nmethods often fail to capture the complexity of emotional expressions due to\nconflicting signals from different modalities. Current Multimodal Large\nLanguage Models (MLLMs) also face challenges in detecting subtle facial\nexpressions and addressing a wide range of emotion-related tasks. To tackle\nthese issues, we propose M2SE, a Multistage Multitask Sentiment and Emotion\nInstruction Tuning Strategy for general-purpose MLLMs. It employs a combined\napproach to train models on tasks such as multimodal sentiment analysis,\nemotion recognition, facial expression recognition, emotion reason inference,\nand emotion cause-pair extraction. We also introduce the Emotion Multitask\ndataset (EMT), a custom dataset that supports these five tasks. Our model,\nEmotion Universe (EmoVerse), is built on a basic MLLM framework without\nmodifications, yet it achieves substantial improvements across these tasks when\ntrained with the M2SE strategy. Extensive experiments demonstrate that EmoVerse\noutperforms existing methods, achieving state-of-the-art results in sentiment\nand emotion tasks. These results highlight the effectiveness of M2SE in\nenhancing multimodal emotion perception. The dataset and code are available at\nhttps://github.com/xiaoyaoxinyi/M2SE.\n","authors":["Ao Li","Longwei Xu","Chen Ling","Jinghui Zhang","Pengwei Wang"],"pdf_url":"https://arxiv.org/pdf/2412.08049v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.16045v2","updated":"2024-12-11T02:46:29Z","published":"2023-10-24T17:58:07Z","title":"Woodpecker: Hallucination Correction for Multimodal Large Language\n  Models","summary":"  Hallucination is a big shadow hanging over the rapidly evolving Multimodal\nLarge Language Models (MLLMs), referring to the phenomenon that the generated\ntext is inconsistent with the image content. In order to mitigate\nhallucinations, existing studies mainly resort to an instruction-tuning manner\nthat requires retraining the models with specific data. In this paper, we pave\na different way, introducing a training-free method named Woodpecker. Like a\nwoodpecker heals trees, it picks out and corrects hallucinations from the\ngenerated text. Concretely, Woodpecker consists of five stages: key concept\nextraction, question formulation, visual knowledge validation, visual claim\ngeneration, and hallucination correction. Implemented in a post-remedy manner,\nWoodpecker can easily serve different MLLMs, while being interpretable by\naccessing intermediate outputs of the five stages. We evaluate Woodpecker both\nquantitatively and qualitatively and show the huge potential of this new\nparadigm. On the POPE benchmark, our method obtains a 30.66%/24.33% improvement\nin accuracy over the baseline MiniGPT-4/mPLUG-Owl. The source code is released\nat https://github.com/BradyFU/Woodpecker.\n","authors":["Shukang Yin","Chaoyou Fu","Sirui Zhao","Tong Xu","Hao Wang","Dianbo Sui","Yunhang Shen","Ke Li","Xing Sun","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2310.16045v2.pdf","comment":"Accepted by Science China Information Sciences (SCIS)"},{"id":"http://arxiv.org/abs/2412.08038v1","updated":"2024-12-11T02:37:32Z","published":"2024-12-11T02:37:32Z","title":"Bootstrapping Heterogeneous Graph Representation Learning via Large\n  Language Models: A Generalized Approach","summary":"  Graph representation learning methods are highly effective in handling\ncomplex non-Euclidean data by capturing intricate relationships and features\nwithin graph structures. However, traditional methods face challenges when\ndealing with heterogeneous graphs that contain various types of nodes and edges\ndue to the diverse sources and complex nature of the data. Existing\nHeterogeneous Graph Neural Networks (HGNNs) have shown promising results but\nrequire prior knowledge of node and edge types and unified node feature\nformats, which limits their applicability. Recent advancements in graph\nrepresentation learning using Large Language Models (LLMs) offer new solutions\nby integrating LLMs' data processing capabilities, enabling the alignment of\nvarious graph representations. Nevertheless, these methods often overlook\nheterogeneous graph data and require extensive preprocessing. To address these\nlimitations, we propose a novel method that leverages the strengths of both LLM\nand GNN, allowing for the processing of graph data with any format and type of\nnodes and edges without the need for type information or special preprocessing.\nOur method employs LLM to automatically summarize and classify different data\nformats and types, aligns node features, and uses a specialized GNN for\ntargeted learning, thus obtaining effective graph representations for\ndownstream tasks. Theoretical analysis and experimental validation have\ndemonstrated the effectiveness of our method.\n","authors":["Hang Gao","Chenhao Zhang","Fengge Wu","Junsuo Zhao","Changwen Zheng","Huaping Liu"],"pdf_url":"https://arxiv.org/pdf/2412.08038v1.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2412.07289v2","updated":"2024-12-11T02:31:45Z","published":"2024-12-10T08:18:29Z","title":"Enhancing Relation Extraction via Supervised Rationale Verification and\n  Feedback","summary":"  Despite the rapid progress that existing automated feedback methods have made\nin correcting the output of large language models (LLMs), these methods cannot\nbe well applied to the relation extraction (RE) task due to their designated\nfeedback objectives and correction manner. To address this problem, we propose\na novel automated feedback framework for RE, which presents a rationale\nsupervisor to verify the rationale and provides re-selected demonstrations as\nfeedback to correct the initial prediction. Specifically, we first design a\ncausal intervention and observation method to collect biased/unbiased\nrationales for contrastive training the rationale supervisor. Then, we present\na verification-feedback-correction procedure to iteratively enhance LLMs'\ncapability of handling the RE task. Extensive experiments prove that our\nproposed framework significantly outperforms existing methods.\n","authors":["Yongqi Li","Xin Miao","Shen Zhou","Mayi Xu","Yuyang Ren","Tieyun Qian"],"pdf_url":"https://arxiv.org/pdf/2412.07289v2.pdf","comment":"Accepted to AAAI 2025, camera ready version"},{"id":"http://arxiv.org/abs/2412.08024v1","updated":"2024-12-11T02:05:42Z","published":"2024-12-11T02:05:42Z","title":"TinyThinker: Distilling Reasoning through Coarse-to-Fine Knowledge\n  Internalization with Self-Reflection","summary":"  Large Language Models exhibit impressive reasoning capabilities across\ndiverse tasks, motivating efforts to distill these capabilities into smaller\nmodels through generated reasoning data. However, direct training on such\nsynthesized reasoning data may lead to superficial imitation of reasoning\nprocess, rather than fostering a genuine integration of reasoning capabilities\nwith underlying knowledge. To address this, we propose TinyThinker, a framework\nintroducing two novel approaches. First, we introduce a three-stage process\nthat incrementally guides the student model through the reasoning process,\nprogressively refining knowledge from coarse to fine granularity. Second, we\ndevelop a two-phase training framework comprising an initial reasoning\nacquisition phase followed by a self-reflection phase utilizing self-generated\ndata. Experiments on commonsense reasoning benchmarks demonstrate that\nTinyThinker achieves superior performance compared to baselines. Ablation\nstudies further validate the effectiveness of each component in our framework.\nTinyThinker is extendable to other knowledge-intensive reasoning tasks,\noffering an alternative strategy for developing effective reasoning\ncapabilities in smaller language models. Codes are available at\nhttps://github.com/shengminp/TinyThinker\n","authors":["Shengmin Piao","Sanghyun Park"],"pdf_url":"https://arxiv.org/pdf/2412.08024v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.15504v2","updated":"2024-12-11T01:59:36Z","published":"2024-07-22T09:40:13Z","title":"Fundamental Limits of Prompt Compression: A Rate-Distortion Framework\n  for Black-Box Language Models","summary":"  We formalize the problem of prompt compression for large language models\n(LLMs) and present a framework to unify token-level prompt compression methods\nwhich create hard prompts for black-box models. We derive the distortion-rate\nfunction for this setup as a linear program, and provide an efficient algorithm\nto compute this fundamental limit via the dual of the linear program. Using the\ndistortion-rate function as the baseline, we study the performance of existing\ncompression schemes on a synthetic dataset consisting of prompts generated from\na Markov chain, natural language queries, and their respective answers. Our\nempirical analysis demonstrates the criticality of query-aware prompt\ncompression, where the compressor has knowledge of the downstream task/query\nfor the black-box LLM. We show that there is a large gap between the\nperformance of current prompt compression methods and the optimal strategy, and\npropose Adaptive QuerySelect, a query-aware, variable-rate adaptation of a\nprior work to close the gap. We extend our experiments to a small natural\nlanguage dataset to further confirm our findings on our synthetic dataset.\n","authors":["Alliot Nagle","Adway Girish","Marco Bondaschi","Michael Gastpar","Ashok Vardhan Makkuva","Hyeji Kim"],"pdf_url":"https://arxiv.org/pdf/2407.15504v2.pdf","comment":"42 pages, 17 figures. Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.11694v2","updated":"2024-12-11T01:32:08Z","published":"2024-11-18T16:15:17Z","title":"Technical Report: Enhancing LLM Reasoning with Reward-guided Tree Search","summary":"  Recently, test-time scaling has garnered significant attention from the\nresearch community, largely due to the substantial advancements of the o1 model\nreleased by OpenAI. By allocating more computational resources during the\ninference phase, large language models~(LLMs) can extensively explore the\nsolution space by generating more thought tokens or diverse solutions, thereby\nproducing more accurate responses. However, developing an o1-like reasoning\napproach is challenging, and researchers have been making various attempts to\nadvance this open area of research. In this paper, we present a preliminary\nexploration into enhancing the reasoning abilities of LLMs through\nreward-guided tree search algorithms. This framework is implemented by\nintegrating the policy model, reward model, and search algorithm. It is\nprimarily constructed around a tree search algorithm, where the policy model\nnavigates a dynamically expanding tree guided by a specially trained reward\nmodel. We thoroughly explore various design considerations necessary for\nimplementing this framework and provide a detailed report of the technical\naspects. To assess the effectiveness of our approach, we focus on mathematical\nreasoning tasks and conduct extensive evaluations on four challenging datasets,\nsignificantly enhancing the reasoning abilities of LLMs.\n","authors":["Jinhao Jiang","Zhipeng Chen","Yingqian Min","Jie Chen","Xiaoxue Cheng","Jiapeng Wang","Yiru Tang","Haoxiang Sun","Jia Deng","Wayne Xin Zhao","Zheng Liu","Dong Yan","Jian Xie","Zhongyuan Wang","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2411.11694v2.pdf","comment":"Technical Report on Slow Thinking with LLMs: I"},{"id":"http://arxiv.org/abs/2412.07992v1","updated":"2024-12-11T00:04:10Z","published":"2024-12-11T00:04:10Z","title":"Concept Bottleneck Large Language Models","summary":"  We introduce the Concept Bottleneck Large Language Model (CB-LLM), a\npioneering approach to creating inherently interpretable Large Language Models\n(LLMs). Unlike traditional black-box LLMs that rely on post-hoc interpretation\nmethods with limited neuron function insights, CB-LLM sets a new standard with\nits built-in interpretability, scalability, and ability to provide clear,\naccurate explanations. We investigate two essential tasks in the NLP domain:\ntext classification and text generation. In text classification, CB-LLM narrows\nthe performance gap with traditional black-box models and provides clear\ninterpretability. In text generation, we show how interpretable neurons in\nCB-LLM can be used for concept detection and steering text generation. Our\nCB-LLMs enable greater interaction between humans and LLMs across a variety of\ntasks -- a feature notably absent in existing LLMs. Our code is available at\nhttps://github.com/Trustworthy-ML-Lab/CB-LLMs.\n","authors":["Chung-En Sun","Tuomas Oikarinen","Berk Ustun","Tsui-Wei Weng"],"pdf_url":"https://arxiv.org/pdf/2412.07992v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2407.04307"},{"id":"http://arxiv.org/abs/2410.01600v2","updated":"2024-12-11T00:00:38Z","published":"2024-10-02T14:39:13Z","title":"ENTP: Encoder-only Next Token Prediction","summary":"  Next-token prediction is conventionally done using decoder-only Transformers\nwith causal attention, as this approach allows for efficient reuse of keys and\nvalues. What if we were not compute-limited, should we still use decoder-only\nTransformers? In this work, we introduce Encoder-only Next Token Prediction\n(ENTP). We use small scale experiments to explore the differences between ENTP\nand decoders, highlighting potential advantages of ENTP in setting with\nunbounded compute. We introduce the Count3 task and show, both theoretically\nand experimentally, that while ENTP can perform this task easily, a\ndecoder-only Transformer cannot. Finally, we empirically demonstrate ENTP's\nsuperior performance across various synthetic tasks, such as length\ngeneralization and in-context learning.\n","authors":["Ethan Ewer","Daewon Chae","Thomas Zeng","Jinkyu Kim","Kangwook Lee"],"pdf_url":"https://arxiv.org/pdf/2410.01600v2.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2412.08604v1","updated":"2024-12-11T18:26:55Z","published":"2024-12-11T18:26:55Z","title":"Preference Discerning with LLM-Enhanced Generative Retrieval","summary":"  Sequential recommendation systems aim to provide personalized recommendations\nfor users based on their interaction history. To achieve this, they often\nincorporate auxiliary information, such as textual descriptions of items and\nauxiliary tasks, like predicting user preferences and intent. Despite numerous\nefforts to enhance these models, they still suffer from limited\npersonalization. To address this issue, we propose a new paradigm, which we\nterm preference discerning. In preference dscerning, we explicitly condition a\ngenerative sequential recommendation system on user preferences within its\ncontext. To this end, we generate user preferences using Large Language Models\n(LLMs) based on user reviews and item-specific data. To evaluate preference\ndiscerning capabilities of sequential recommendation systems, we introduce a\nnovel benchmark that provides a holistic evaluation across various scenarios,\nincluding preference steering and sentiment following. We assess current\nstate-of-the-art methods using our benchmark and show that they struggle to\naccurately discern user preferences. Therefore, we propose a new method named\nMender ($\\textbf{M}$ultimodal Prefer$\\textbf{en}$ce\n$\\textbf{d}$iscern$\\textbf{er}$), which improves upon existing methods and\nachieves state-of-the-art performance on our benchmark. Our results show that\nMender can be effectively guided by human preferences even though they have not\nbeen observed during training, paving the way toward more personalized\nsequential recommendation systems. We will open-source the code and benchmarks\nupon publication.\n","authors":["Fabian Paischer","Liu Yang","Linfeng Liu","Shuai Shao","Kaveh Hassani","Jiacheng Li","Ricky Chen","Zhang Gabriel Li","Xialo Gao","Wei Shao","Xue Feng","Nima Noorshams","Sem Park","Bo Long","Hamid Eghbalzadeh"],"pdf_url":"https://arxiv.org/pdf/2412.08604v1.pdf","comment":"11 pages + references and appendix"},{"id":"http://arxiv.org/abs/2412.08593v1","updated":"2024-12-11T18:11:39Z","published":"2024-12-11T18:11:39Z","title":"Leveraging Graph-RAG and Prompt Engineering to Enhance LLM-Based\n  Automated Requirement Traceability and Compliance Checks","summary":"  Ensuring that Software Requirements Specifications (SRS) align with\nhigher-level organizational or national requirements is vital, particularly in\nregulated environments such as finance and aerospace. In these domains,\nmaintaining consistency, adhering to regulatory frameworks, minimizing errors,\nand meeting critical expectations are essential for the reliable functioning of\nsystems. The widespread adoption of large language models (LLMs) highlights\ntheir immense potential, yet there remains considerable scope for improvement\nin retrieving relevant information and enhancing reasoning capabilities. This\nstudy demonstrates that integrating a robust Graph-RAG framework with advanced\nprompt engineering techniques, such as Chain of Thought and Tree of Thought,\ncan significantly enhance performance. Compared to baseline RAG methods and\nsimple prompting strategies, this approach delivers more accurate and\ncontext-aware results. While this method demonstrates significant improvements\nin performance, it comes with challenges. It is both costly and more complex to\nimplement across diverse contexts, requiring careful adaptation to specific\nscenarios. Additionally, its effectiveness heavily relies on having complete\nand accurate input data, which may not always be readily available, posing\nfurther limitations to its scalability and practicality.\n","authors":["Arsalan Masoudifard","Mohammad Mowlavi Sorond","Moein Madadi","Mohammad Sabokrou","Elahe Habibi"],"pdf_url":"https://arxiv.org/pdf/2412.08593v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06954v2","updated":"2024-12-11T16:46:25Z","published":"2024-12-09T20:01:59Z","title":"CURE: A dataset for Clinical Understanding & Retrieval Evaluation","summary":"  Given the dominance of dense retrievers that do not generalize well beyond\ntheir training dataset distributions, domain-specific test sets are essential\nin evaluating retrieval. There are few test datasets for retrieval systems\nintended for use by healthcare providers in a point-of-care setting. To fill\nthis gap we have collaborated with medical professionals to create CURE, an\nad-hoc retrieval test dataset for passage ranking with 2000 queries spanning 10\nmedical domains with a monolingual (English) and two cross-lingual\n(French/Spanish -> English) conditions. In this paper, we describe how CURE was\nconstructed and provide baseline results to showcase its effectiveness as an\nevaluation tool. CURE is published with a Creative Commons Attribution Non\nCommercial 4.0 license and can be accessed on Hugging Face.\n","authors":["Nadia Sheikh","Anne-Laure Jousse","Daniel Buades Marcos","Akintunde Oladipo","Olivier Rousseau","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2412.06954v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08516v1","updated":"2024-12-11T16:28:18Z","published":"2024-12-11T16:28:18Z","title":"AltFS: Agency-light Feature Selection with Large Language Models in Deep\n  Recommender Systems","summary":"  Feature selection is crucial in recommender systems for improving model\nefficiency and predictive performance. Traditional methods rely on agency\nmodels, such as decision trees or neural networks, to estimate feature\nimportance. However, this approach is inherently limited, as the agency models\nmay fail to learn effectively in all scenarios due to suboptimal training\nconditions (e.g., feature collinearity, high-dimensional sparsity, and data\ninsufficiency). In this paper, we propose AltFS, an Agency-light Feature\nSelection method for deep recommender systems. AltFS integrates semantic\nreasoning from Large Language Models (LLMs) with task-specific learning from\nagency models. Initially, LLMs will generate a semantic ranking of feature\nimportance, which is then refined by an agency model, combining world knowledge\nwith task-specific insights. Extensive experiments on three public datasets\nfrom real-world recommender platforms demonstrate the effectiveness of AltFS.\nOur code is publicly available for reproducibility.\n","authors":["Pengyue Jia","Zhaocheng Du","Yichao Wang","Xiangyu Zhao","Xiaopeng Li","Yuhao Wang","Qidong Liu","Huifeng Guo","Ruiming Tang"],"pdf_url":"https://arxiv.org/pdf/2412.08516v1.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2412.08480v1","updated":"2024-12-11T15:47:11Z","published":"2024-12-11T15:47:11Z","title":"InvDiff: Invariant Guidance for Bias Mitigation in Diffusion Models","summary":"  As one of the most successful generative models, diffusion models have\ndemonstrated remarkable efficacy in synthesizing high-quality images. These\nmodels learn the underlying high-dimensional data distribution in an\nunsupervised manner. Despite their success, diffusion models are highly\ndata-driven and prone to inheriting the imbalances and biases present in\nreal-world data. Some studies have attempted to address these issues by\ndesigning text prompts for known biases or using bias labels to construct\nunbiased data. While these methods have shown improved results, real-world\nscenarios often contain various unknown biases, and obtaining bias labels is\nparticularly challenging. In this paper, we emphasize the necessity of\nmitigating bias in pre-trained diffusion models without relying on auxiliary\nbias annotations. To tackle this problem, we propose a framework, InvDiff,\nwhich aims to learn invariant semantic information for diffusion guidance.\nSpecifically, we propose identifying underlying biases in the training data and\ndesigning a novel debiasing training objective. Then, we employ a lightweight\ntrainable module that automatically preserves invariant semantic information\nand uses it to guide the diffusion model's sampling process toward unbiased\noutcomes simultaneously. Notably, we only need to learn a small number of\nparameters in the lightweight learnable module without altering the pre-trained\ndiffusion model. Furthermore, we provide a theoretical guarantee that the\nimplementation of InvDiff is equivalent to reducing the error upper bound of\ngeneralization. Extensive experimental results on three publicly available\nbenchmarks demonstrate that InvDiff effectively reduces biases while\nmaintaining the quality of image generation. Our code is available at\nhttps://github.com/Hundredl/InvDiff.\n","authors":["Min Hou","Yueying Wu","Chang Xu","Yu-Hao Huang","Chenxi Bai","Le Wu","Jiang Bian"],"pdf_url":"https://arxiv.org/pdf/2412.08480v1.pdf","comment":"KDD 2025"},{"id":"http://arxiv.org/abs/2207.11759v2","updated":"2024-12-11T14:47:01Z","published":"2022-07-24T15:13:45Z","title":"Spatial-Temporal Federated Learning for Lifelong Person\n  Re-identification on Distributed Edges","summary":"  Data drift is a thorny challenge when deploying person re-identification\n(ReID) models into real-world devices, where the data distribution is\nsignificantly different from that of the training environment and keeps\nchanging. To tackle this issue, we propose a federated spatial-temporal\nincremental learning approach, named FedSTIL, which leverages both lifelong\nlearning and federated learning to continuously optimize models deployed on\nmany distributed edge clients. Unlike previous efforts, FedSTIL aims to mine\nspatial-temporal correlations among the knowledge learnt from different edge\nclients. Specifically, the edge clients first periodically extract general\nrepresentations of drifted data to optimize their local models. Then, the\nlearnt knowledge from edge clients will be aggregated by centralized parameter\nserver, where the knowledge will be selectively and attentively distilled from\nspatial- and temporal-dimension with carefully designed mechanisms. Finally,\nthe distilled informative spatial-temporal knowledge will be sent back to\ncorrelated edge clients to further improve the recognition accuracy of each\nedge client with a lifelong learning method. Extensive experiments on a mixture\nof five real-world datasets demonstrate that our method outperforms others by\nnearly 4% in Rank-1 accuracy, while reducing communication cost by 62%. All\nimplementation codes are publicly available on\nhttps://github.com/MSNLAB/Federated-Lifelong-Person-ReID\n","authors":["Lei Zhang","Guanyu Gao","Huaizheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2207.11759v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08385v1","updated":"2024-12-11T13:50:17Z","published":"2024-12-11T13:50:17Z","title":"NyayaAnumana & INLegalLlama: The Largest Indian Legal Judgment\n  Prediction Dataset and Specialized Language Model for Enhanced Decision\n  Analysis","summary":"  The integration of artificial intelligence (AI) in legal judgment prediction\n(LJP) has the potential to transform the legal landscape, particularly in\njurisdictions like India, where a significant backlog of cases burdens the\nlegal system. This paper introduces NyayaAnumana, the largest and most diverse\ncorpus of Indian legal cases compiled for LJP, encompassing a total of 7,02,945\npreprocessed cases. NyayaAnumana, which combines the words \"Nyay\" (judgment)\nand \"Anuman\" (prediction or inference) respectively for most major Indian\nlanguages, includes a wide range of cases from the Supreme Court, High Courts,\nTribunal Courts, District Courts, and Daily Orders and, thus, provides\nunparalleled diversity and coverage. Our dataset surpasses existing datasets\nlike PredEx and ILDC, offering a comprehensive foundation for advanced AI\nresearch in the legal domain.\n  In addition to the dataset, we present INLegalLlama, a domain-specific\ngenerative large language model (LLM) tailored to the intricacies of the Indian\nlegal system. It is developed through a two-phase training approach over a base\nLLaMa model. First, Indian legal documents are injected using continual\npretraining. Second, task-specific supervised finetuning is done. This method\nallows the model to achieve a deeper understanding of legal contexts.\n  Our experiments demonstrate that incorporating diverse court data\nsignificantly boosts model accuracy, achieving approximately 90% F1-score in\nprediction tasks. INLegalLlama not only improves prediction accuracy but also\noffers comprehensible explanations, addressing the need for explainability in\nAI-assisted legal decisions.\n","authors":["Shubham Kumar Nigam","Balaramamahanthi Deepak Patnaik","Shivam Mishra","Noel Shallum","Kripabandhu Ghosh","Arnab Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2412.08385v1.pdf","comment":"Accepted on COLING 2025"},{"id":"http://arxiv.org/abs/2412.08300v1","updated":"2024-12-11T11:29:15Z","published":"2024-12-11T11:29:15Z","title":"Augmenting Sequential Recommendation with Balanced Relevance and\n  Diversity","summary":"  By generating new yet effective data, data augmentation has become a\npromising method to mitigate the data sparsity problem in sequential\nrecommendation. Existing works focus on augmenting the original data but rarely\nexplore the issue of imbalanced relevance and diversity for augmented data,\nleading to semantic drift problems or limited performance improvements. In this\npaper, we propose a novel Balanced data Augmentation Plugin for Sequential\nRecommendation (BASRec) to generate data that balance relevance and diversity.\nBASRec consists of two modules: Single-sequence Augmentation and Cross-sequence\nAugmentation. The former leverages the randomness of the heuristic operators to\ngenerate diverse sequences for a single user, after which the diverse and the\noriginal sequences are fused at the representation level to obtain relevance.\nFurther, we devise a reweighting strategy to enable the model to learn the\npreferences based on the two properties adaptively. The Cross-sequence\nAugmentation performs nonlinear mixing between different sequence\nrepresentations from two directions. It produces virtual sequence\nrepresentations that are diverse enough but retain the vital semantics of the\noriginal sequences. These two modules enhance the model to discover\nfine-grained preferences knowledge from single-user and cross-user\nperspectives. Extensive experiments verify the effectiveness of BASRec. The\naverage improvement is up to 72.0% on GRU4Rec, 33.8% on SASRec, and 68.5% on\nFMLP-Rec. We demonstrate that BASRec generates data with a better balance\nbetween relevance and diversity than existing methods. The source code is\navailable at https://github.com/KingGugu/BASRec.\n","authors":["Yizhou Dang","Jiahui Zhang","Yuting Liu","Enneng Yang","Yuliang Liang","Guibing Guo","Jianzhe Zhao","Xingwei Wang"],"pdf_url":"https://arxiv.org/pdf/2412.08300v1.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2412.08258v1","updated":"2024-12-11T10:11:41Z","published":"2024-12-11T10:11:41Z","title":"Large Language Models for Scholarly Ontology Generation: An Extensive\n  Analysis in the Engineering Field","summary":"  Ontologies of research topics are crucial for structuring scientific\nknowledge, enabling scientists to navigate vast amounts of research, and\nforming the backbone of intelligent systems such as search engines and\nrecommendation systems. However, manual creation of these ontologies is\nexpensive, slow, and often results in outdated and overly general\nrepresentations. As a solution, researchers have been investigating ways to\nautomate or semi-automate the process of generating these ontologies. This\npaper offers a comprehensive analysis of the ability of large language models\n(LLMs) to identify semantic relationships between different research topics,\nwhich is a critical step in the development of such ontologies. To this end, we\ndeveloped a gold standard based on the IEEE Thesaurus to evaluate the task of\nidentifying four types of relationships between pairs of topics: broader,\nnarrower, same-as, and other. Our study evaluates the performance of seventeen\nLLMs, which differ in scale, accessibility (open vs. proprietary), and model\ntype (full vs. quantised), while also assessing four zero-shot reasoning\nstrategies. Several models have achieved outstanding results, including\nMixtral-8x7B, Dolphin-Mistral-7B, and Claude 3 Sonnet, with F1-scores of 0.847,\n0.920, and 0.967, respectively. Furthermore, our findings demonstrate that\nsmaller, quantised models, when optimised through prompt engineering, can\ndeliver performance comparable to much larger proprietary models, while\nrequiring significantly fewer computational resources.\n","authors":["Tanay Aggarwal","Angelo Salatino","Francesco Osborne","Enrico Motta"],"pdf_url":"https://arxiv.org/pdf/2412.08258v1.pdf","comment":"submitted to Information Processing & Management"},{"id":"http://arxiv.org/abs/2310.15950v5","updated":"2024-12-11T08:40:48Z","published":"2023-10-24T15:51:13Z","title":"Representation Learning with Large Language Models for Recommendation","summary":"  Recommender systems have seen significant advancements with the influence of\ndeep learning and graph neural networks, particularly in capturing complex\nuser-item relationships. However, these graph-based recommenders heavily depend\non ID-based data, potentially disregarding valuable textual information\nassociated with users and items, resulting in less informative learned\nrepresentations. Moreover, the utilization of implicit feedback data introduces\npotential noise and bias, posing challenges for the effectiveness of user\npreference learning. While the integration of large language models (LLMs) into\ntraditional ID-based recommenders has gained attention, challenges such as\nscalability issues, limitations in text-only reliance, and prompt input\nconstraints need to be addressed for effective implementation in practical\nrecommender systems. To address these challenges, we propose a model-agnostic\nframework RLMRec that aims to enhance existing recommenders with LLM-empowered\nrepresentation learning. It proposes a recommendation paradigm that integrates\nrepresentation learning with LLMs to capture intricate semantic aspects of user\nbehaviors and preferences. RLMRec incorporates auxiliary textual signals,\ndevelops a user/item profiling paradigm empowered by LLMs, and aligns the\nsemantic space of LLMs with the representation space of collaborative\nrelational signals through a cross-view alignment framework. This work further\nestablish a theoretical foundation demonstrating that incorporating textual\nsignals through mutual information maximization enhances the quality of\nrepresentations. In our evaluation, we integrate RLMRec with state-of-the-art\nrecommender models, while also analyzing its efficiency and robustness to noise\ndata. Our implementation codes are available at\nhttps://github.com/HKUDS/RLMRec.\n","authors":["Xubin Ren","Wei Wei","Lianghao Xia","Lixin Su","Suqi Cheng","Junfeng Wang","Dawei Yin","Chao Huang"],"pdf_url":"https://arxiv.org/pdf/2310.15950v5.pdf","comment":"Published as a WWW'24 full paper"},{"id":"http://arxiv.org/abs/2412.08185v1","updated":"2024-12-11T08:24:15Z","published":"2024-12-11T08:24:15Z","title":"Exploring Multidimensional Checkworthiness: Designing AI-assisted Claim\n  Prioritization for Human Fact-checkers","summary":"  Given the massive volume of potentially false claims circulating online,\nclaim prioritization is essential in allocating limited human resources\navailable for fact-checking. In this study, we perceive claim prioritization as\nan information retrieval (IR) task: just as multidimensional IR relevance, with\nmany factors influencing which search results a user deems relevant,\ncheckworthiness is also multi-faceted, subjective, and even personal, with many\nfactors influencing how fact-checkers triage and select which claims to check.\nOur study investigates both the multidimensional nature of checkworthiness and\neffective tool support to assist fact-checkers in claim prioritization.\nMethodologically, we pursue Research through Design combined with mixed-method\nevaluation. We develop an AI-assisted claim prioritization prototype as a probe\nto explore how fact-checkers use multidimensional checkworthiness factors in\nclaim prioritization, simultaneously probing fact-checker needs while also\nexploring the design space to meet those needs.\n  Our study with 16 professional fact-checkers investigates: 1) how\nparticipants assessed the relative importance of different checkworthy\ndimensions and apply different priorities in claim selection; 2) how they\ncreated customized GPT-based search filters and the corresponding benefits and\nlimitations; and 3) their overall user experiences with our prototype. Our work\nmakes a conceptual contribution between multidimensional IR relevance and\nfact-checking checkworthiness, with findings demonstrating the value of\ncorresponding tooling support. Specifically, we uncovered a hierarchical\nprioritization strategy fact-checkers implicitly use, revealing an\nunderexplored aspect of their workflow, with actionable design recommendations\nfor improving claim triage across multi-dimensional checkworthiness and\ntailoring this process with LLM integration.\n","authors":["Houjiang Liu","Jacek Gwizdka","Matthew Lease"],"pdf_url":"https://arxiv.org/pdf/2412.08185v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08103v1","updated":"2024-12-11T05:08:19Z","published":"2024-12-11T05:08:19Z","title":"Multimodal Difference Learning for Sequential Recommendation","summary":"  Sequential recommendations have drawn significant attention in modeling the\nuser's historical behaviors to predict the next item. With the booming\ndevelopment of multimodal data (e.g., image, text) on internet platforms,\nsequential recommendation also benefits from the incorporation of multimodal\ndata. Most methods introduce modal features of items as side information and\nsimply concatenates them to learn unified user interests. Nevertheless, these\nmethods encounter the limitation in modeling multimodal differences. We argue\nthat user interests and item relationships vary across different modalities. To\naddress this problem, we propose a novel Multimodal Difference Learning\nframework for Sequential Recommendation, MDSRec for brevity. Specifically, we\nfirst explore the differences in item relationships by constructing modal-aware\nitem relation graphs with behavior signal to enhance item representations.\nThen, to capture the differences in user interests across modalities, we design\na interest-centralized attention mechanism to independently model user sequence\nrepresentations in different modalities. Finally, we fuse the user embeddings\nfrom multiple modalities to achieve accurate item recommendation. Experimental\nresults on five real-world datasets demonstrate the superiority of MDSRec over\nstate-of-the-art baselines and the efficacy of multimodal difference learning.\n","authors":["Changhong Li","Zhiqiang Guo"],"pdf_url":"https://arxiv.org/pdf/2412.08103v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08071v1","updated":"2024-12-11T03:33:51Z","published":"2024-12-11T03:33:51Z","title":"A Tutorial of Personalized Federated Recommender Systems: Recent\n  Advances and Future Directions","summary":"  Personalization stands as the cornerstone of recommender systems (RecSys),\nstriving to sift out redundant information and offer tailor-made services for\nusers. However, the conventional cloud-based RecSys necessitates centralized\ndata collection, posing significant risks of user privacy breaches. In response\nto this challenge, federated recommender systems (FedRecSys) have emerged,\ngarnering considerable attention. FedRecSys enable users to retain personal\ndata locally and solely share model parameters with low privacy sensitivity for\nglobal model training, significantly bolstering the system's privacy protection\ncapabilities. Within the distributed learning framework, the pronounced non-iid\nnature of user behavior data introduces fresh hurdles to federated\noptimization. Meanwhile, the ability of federated learning to concurrently\nlearn multiple models presents an opportunity for personalized user modeling.\nConsequently, the development of personalized FedRecSys (PFedRecSys) is crucial\nand holds substantial significance. This tutorial seeks to provide an\nintroduction to PFedRecSys, encompassing (1) an overview of existing studies on\nPFedRecSys, (2) a comprehensive taxonomy of PFedRecSys spanning four pivotal\nresearch directions-client-side adaptation, server-side aggregation,\ncommunication efficiency, privacy and protection, and (3) exploration of open\nchallenges and promising future directions in PFedRecSys. This tutorial aims to\nestablish a robust foundation and spark new perspectives for subsequent\nexploration and practical implementations in the evolving realm of RecSys.\n","authors":["Jing Jiang","Chunxu Zhang","Honglei Zhang","Zhiwei Li","Yidong Li","Bo Yang"],"pdf_url":"https://arxiv.org/pdf/2412.08071v1.pdf","comment":"A technical tutorial will appear at The Web Conference 2025"},{"id":"http://arxiv.org/abs/2412.08066v1","updated":"2024-12-11T03:22:04Z","published":"2024-12-11T03:22:04Z","title":"Cluster-Enhanced Federated Graph Neural Network for Recommendation","summary":"  Personal interaction data can be effectively modeled as individual graphs for\neach user in recommender systems.Graph Neural Networks (GNNs)-based\nrecommendation techniques have become extremely popular since they can capture\nhigh-order collaborative signals between users and items by aggregating the\nindividual graph into a global interactive graph.However, this centralized\napproach inherently poses a threat to user privacy and security. Recently,\nfederated GNN-based recommendation techniques have emerged as a promising\nsolution to mitigate privacy concerns. Nevertheless, current implementations\neither limit on-device training to an unaccompanied individual graphs or\nnecessitate reliance on an extra third-party server to touch other individual\ngraphs, which also increases the risk of privacy leakage. To address this\nchallenge, we propose a Cluster-enhanced Federated Graph Neural Network\nframework for Recommendation, named CFedGR, which introduces high-order\ncollaborative signals to augment individual graphs in a privacy preserving\nmanner. Specifically, the server clusters the pretrained user representations\nto identify high-order collaborative signals. In addition, two efficient\nstrategies are devised to reduce communication between devices and the server.\nExtensive experiments on three benchmark datasets validate the effectiveness of\nour proposed methods.\n","authors":["Haiyan Wang","Ye Yuan"],"pdf_url":"https://arxiv.org/pdf/2412.08066v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07998v1","updated":"2024-12-11T00:44:52Z","published":"2024-12-11T00:44:52Z","title":"RALI@TREC iKAT 2024: Achieving Personalization via Retrieval Fusion in\n  Conversational Search","summary":"  The Recherche Appliquee en Linguistique Informatique (RALI) team participated\nin the 2024 TREC Interactive Knowledge Assistance (iKAT) Track. In personalized\nconversational search, effectively capturing a user's complex search intent\nrequires incorporating both contextual information and key elements from the\nuser profile into query reformulation. The user profile often contains many\nrelevant pieces, and each could potentially complement the user's information\nneeds. It is difficult to disregard any of them, whereas introducing an\nexcessive number of these pieces risks drifting from the original query and\nhinders search performance. This is a challenge we denote as\nover-personalization. To address this, we propose different strategies by\nfusing ranking lists generated from the queries with different levels of\npersonalization.\n","authors":["Yuchen Hui","Fengran Mo","Milan Mao","Jian-Yun Nie"],"pdf_url":"https://arxiv.org/pdf/2412.07998v1.pdf","comment":"Work presented at NIST Text Retrieval Conference 2024.\n  https://www.nist.gov/news-events/events/2024/11/trec2024"},{"id":"http://arxiv.org/abs/2412.08802v1","updated":"2024-12-11T22:28:12Z","published":"2024-12-11T22:28:12Z","title":"jina-clip-v2: Multilingual Multimodal Embeddings for Text and Images","summary":"  Contrastive Language-Image Pretraining (CLIP) is a highly effective method\nfor aligning images and texts in a shared embedding space. These models are\nwidely used for tasks such as cross-modal information retrieval and multi-modal\nunderstanding. However, CLIP models often struggle with text-only tasks,\nunderperforming compared to specialized text models. This performance disparity\nforces retrieval systems to rely on separate models for text-only and\nmulti-modal tasks. In this work, we build upon our previous model,\njina-clip-v1, by introducing a refined framework that utilizes multi-task,\nmulti-stage contrastive learning across multiple languages, coupled with an\nimproved training recipe to enhance text-only retrieval. The resulting model,\njina-clip-v2, outperforms its predecessor on text-only and multimodal tasks,\nwhile adding multilingual support, better understanding of complex visual\ndocuments and efficiency gains thanks to Matryoshka Representation Learning and\nvector truncation. The model performs comparably to the state-of-the-art in\nboth multilingual-multimodal and multilingual text retrieval benchmarks,\naddressing the challenge of unifying text-only and multi-modal retrieval\nsystems.\n","authors":["Andreas Koukounas","Georgios Mastrapas","Bo Wang","Mohammad Kalim Akram","Sedigheh Eslami","Michael Günther","Isabelle Mohr","Saba Sturua","Scott Martens","Nan Wang","Han Xiao"],"pdf_url":"https://arxiv.org/pdf/2412.08802v1.pdf","comment":"21 pages, 1-10 main paper, 10-12 refs, 12-21 benchmarks"},{"id":"http://arxiv.org/abs/2412.08780v1","updated":"2024-12-11T21:16:37Z","published":"2024-12-11T21:16:37Z","title":"Reducing Popularity Influence by Addressing Position Bias","summary":"  Position bias poses a persistent challenge in recommender systems, with much\nof the existing research focusing on refining ranking relevance and driving\nuser engagement. However, in practical applications, the mitigation of position\nbias does not always result in detectable short-term improvements in ranking\nrelevance. This paper provides an alternative, practically useful view of what\nposition bias reduction methods can achieve. It demonstrates that position\ndebiasing can spread visibility and interactions more evenly across the\nassortment, effectively reducing a skew in the popularity of items induced by\nthe position bias through a feedback loop. We offer an explanation of how\nposition bias affects item popularity. This includes an illustrative model of\nthe item popularity histogram and the effect of the position bias on its\nskewness. Through offline and online experiments on our large-scale e-commerce\nplatform, we show that position debiasing can significantly improve assortment\nutilization, without any degradation in user engagement or financial metrics.\nThis makes the ranking fairer and helps attract more partners or content\nproviders, benefiting the customers and the business in the long term.\n","authors":["Andrii Dzhoha","Alexey Kurennoy","Vladimir Vlasov","Marjan Celikik"],"pdf_url":"https://arxiv.org/pdf/2412.08780v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.05348v2","updated":"2024-12-11T19:28:47Z","published":"2024-06-08T04:24:16Z","title":"Toward Reliable Ad-hoc Scientific Information Extraction: A Case Study\n  on Two Materials Datasets","summary":"  We explore the ability of GPT-4 to perform ad-hoc schema based information\nextraction from scientific literature. We assess specifically whether it can,\nwith a basic prompting approach, replicate two existing material science\ndatasets, given the manuscripts from which they were originally manually\nextracted. We employ materials scientists to perform a detailed manual error\nanalysis to assess where the model struggles to faithfully extract the desired\ninformation, and draw on their insights to suggest research directions to\naddress this broadly important task.\n","authors":["Satanu Ghosh","Neal R. Brodnik","Carolina Frey","Collin Holgate","Tresa M. Pollock","Samantha Daly","Samuel Carton"],"pdf_url":"https://arxiv.org/pdf/2406.05348v2.pdf","comment":"Update on 12/11/2024: Added some relevant literature that we missed\n  in previous version of the paper"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2412.08643v1","updated":"2024-12-11T18:59:51Z","published":"2024-12-11T18:59:51Z","title":"GPD-1: Generative Pre-training for Driving","summary":"  Modeling the evolutions of driving scenarios is important for the evaluation\nand decision-making of autonomous driving systems. Most existing methods focus\non one aspect of scene evolution such as map generation, motion prediction, and\ntrajectory planning. In this paper, we propose a unified Generative\nPre-training for Driving (GPD-1) model to accomplish all these tasks altogether\nwithout additional fine-tuning. We represent each scene with ego, agent, and\nmap tokens and formulate autonomous driving as a unified token generation\nproblem. We adopt the autoregressive transformer architecture and use a\nscene-level attention mask to enable intra-scene bi-directional interactions.\nFor the ego and agent tokens, we propose a hierarchical positional tokenizer to\neffectively encode both 2D positions and headings. For the map tokens, we train\na map vector-quantized autoencoder to efficiently compress ego-centric semantic\nmaps into discrete tokens. We pre-train our GPD-1 on the large-scale nuPlan\ndataset and conduct extensive experiments to evaluate its effectiveness. With\ndifferent prompts, our GPD-1 successfully generalizes to various tasks without\nfinetuning, including scene generation, traffic simulation, closed-loop\nsimulation, map prediction, and motion planning. Code:\nhttps://github.com/wzzheng/GPD.\n","authors":["Zixun Xie","Sicheng Zuo","Wenzhao Zheng","Yunpeng Zhang","Dalong Du","Jie Zhou","Jiwen Lu","Shanghang Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.08643v1.pdf","comment":"Code is available at: https://github.com/wzzheng/GPD"},{"id":"http://arxiv.org/abs/2412.08642v1","updated":"2024-12-11T18:59:50Z","published":"2024-12-11T18:59:50Z","title":"Generative Semantic Communication: Architectures, Technologies, and\n  Applications","summary":"  This paper delves into the applications of generative artificial intelligence\n(GAI) in semantic communication (SemCom) and presents a thorough study. Three\npopular SemCom systems enabled by classical GAI models are first introduced,\nincluding variational autoencoders, generative adversarial networks, and\ndiffusion models. For each system, the fundamental concept of the GAI model,\nthe corresponding SemCom architecture, and the associated literature review of\nrecent efforts are elucidated. Then, a novel generative SemCom system is\nproposed by incorporating the cutting-edge GAI technology-large language models\n(LLMs). This system features two LLM-based AI agents at both the transmitter\nand receiver, serving as \"brains\" to enable powerful information understanding\nand content regeneration capabilities, respectively. This innovative design\nallows the receiver to directly generate the desired content, instead of\nrecovering the bit stream, based on the coded semantic information conveyed by\nthe transmitter. Therefore, it shifts the communication mindset from\n\"information recovery\" to \"information regeneration\" and thus ushers in a new\nera of generative SemCom. A case study on point-to-point video retrieval is\npresented to demonstrate the superiority of the proposed generative SemCom\nsystem, showcasing a 99.98% reduction in communication overhead and a 53%\nimprovement in retrieval accuracy compared to the traditional communication\nsystem. Furthermore, four typical application scenarios for generative SemCom\nare delineated, followed by a discussion of three open issues warranting future\ninvestigation. In a nutshell, this paper provides a holistic set of guidelines\nfor applying GAI in SemCom, paving the way for the efficient implementation of\ngenerative SemCom in future wireless networks.\n","authors":["Jinke Ren","Yaping Sun","Hongyang Du","Weiwen Yuan","Chongjie Wang","Xianda Wang","Yingbin Zhou","Ziwei Zhu","Fangxin Wang","Shuguang Cui"],"pdf_url":"https://arxiv.org/pdf/2412.08642v1.pdf","comment":"18 pages, 8 figures"},{"id":"http://arxiv.org/abs/2412.08637v1","updated":"2024-12-11T18:58:40Z","published":"2024-12-11T18:58:40Z","title":"DMin: Scalable Training Data Influence Estimation for Diffusion Models","summary":"  Identifying the training data samples that most influence a generated image\nis a critical task in understanding diffusion models, yet existing influence\nestimation methods are constrained to small-scale or LoRA-tuned models due to\ncomputational limitations. As diffusion models scale up, these methods become\nimpractical. To address this challenge, we propose DMin (Diffusion Model\ninfluence), a scalable framework for estimating the influence of each training\ndata sample on a given generated image. By leveraging efficient gradient\ncompression and retrieval techniques, DMin reduces storage requirements from\n339.39 TB to only 726 MB and retrieves the top-k most influential training\nsamples in under 1 second, all while maintaining performance. Our empirical\nresults demonstrate DMin is both effective in identifying influential training\nsamples and efficient in terms of computational and storage requirements.\n","authors":["Huawei Lin","Yingjie Lao","Weijie Zhao"],"pdf_url":"https://arxiv.org/pdf/2412.08637v1.pdf","comment":"14 pages, 6 figures, 8 tables. Under Review"},{"id":"http://arxiv.org/abs/2412.08635v1","updated":"2024-12-11T18:57:32Z","published":"2024-12-11T18:57:32Z","title":"Multimodal Latent Language Modeling with Next-Token Diffusion","summary":"  Multimodal generative models require a unified approach to handle both\ndiscrete data (e.g., text and code) and continuous data (e.g., image, audio,\nvideo). In this work, we propose Latent Language Modeling (LatentLM), which\nseamlessly integrates continuous and discrete data using causal Transformers.\nSpecifically, we employ a variational autoencoder (VAE) to represent continuous\ndata as latent vectors and introduce next-token diffusion for autoregressive\ngeneration of these vectors. Additionally, we develop $\\sigma$-VAE to address\nthe challenges of variance collapse, which is crucial for autoregressive\nmodeling. Extensive experiments demonstrate the effectiveness of LatentLM\nacross various modalities. In image generation, LatentLM surpasses Diffusion\nTransformers in both performance and scalability. When integrated into\nmultimodal large language models, LatentLM provides a general-purpose interface\nthat unifies multimodal generation and understanding. Experimental results show\nthat LatentLM achieves favorable performance compared to Transfusion and vector\nquantized models in the setting of scaling up training tokens. In\ntext-to-speech synthesis, LatentLM outperforms the state-of-the-art VALL-E 2\nmodel in speaker similarity and robustness, while requiring 10x fewer decoding\nsteps. The results establish LatentLM as a highly effective and scalable\napproach to advance large multimodal models.\n","authors":["Yutao Sun","Hangbo Bao","Wenhui Wang","Zhiliang Peng","Li Dong","Shaohan Huang","Jianyong Wang","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2412.08635v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08633v1","updated":"2024-12-11T18:56:28Z","published":"2024-12-11T18:56:28Z","title":"MNIST-Fraction: Enhancing Math Education with AI-Driven Fraction\n  Detection and Analysis","summary":"  Mathematics education, a crucial and basic field, significantly influences\nstudents' learning in related subjects and their future careers. Utilizing\nartificial intelligence to interpret and comprehend math problems in education\nis not yet fully explored. This is due to the scarcity of quality datasets and\nthe intricacies of processing handwritten information. In this paper, we\npresent a novel contribution to the field of mathematics education through the\ndevelopment of MNIST-Fraction, a dataset inspired by the renowned MNIST,\nspecifically tailored for the recognition and understanding of handwritten math\nfractions. Our approach is the utilization of deep learning, specifically\nConvolutional Neural Networks (CNNs), for the recognition and understanding of\nhandwritten math fractions to effectively detect and analyze fractions, along\nwith their numerators and denominators. This capability is pivotal in\ncalculating the value of fractions, a fundamental aspect of math learning. The\nMNIST-Fraction dataset is designed to closely mimic real-world scenarios,\nproviding a reliable and relevant resource for AI-driven educational tools.\nFurthermore, we conduct a comprehensive comparison of our dataset with the\noriginal MNIST dataset using various classifiers, demonstrating the\neffectiveness and versatility of MNIST-Fraction in both detection and\nclassification tasks. This comparative analysis not only validates the\npractical utility of our dataset but also offers insights into its potential\napplications in math education. To foster collaboration and further research\nwithin the computational and educational communities. Our work aims to bridge\nthe gap in high-quality educational resources for math learning, offering a\nvaluable tool for both educators and researchers in the field.\n","authors":["Pegah Ahadian","Yunhe Feng","Karl Kosko","Richard Ferdig","Qiang Guan"],"pdf_url":"https://arxiv.org/pdf/2412.08633v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09111v4","updated":"2024-12-11T18:50:30Z","published":"2024-11-14T00:59:13Z","title":"Reducing Reasoning Costs -- The Path of Optimization for Chain of\n  Thought via Sparse Attention Mechanism","summary":"  In order to address the chain of thought in the large language model\ninference cost surge, this research proposes to use a sparse attention\nmechanism that only focuses on a few relevant tokens. The researcher\nconstructed a new attention mechanism and used GiantRabbit trained with custom\nGPTs as an experimental tool. The experiment tested and compared the reasoning\ntime, correctness score and chain of thought length of this model and o1\nPreview in solving the linear algebra test questions of MIT OpenCourseWare. The\nresults show that GiantRabbit's reasoning time and chain of thought length are\nsignificantly lower than o1 Preview. It verifies the feasibility of sparse\nattention mechanism for optimizing chain of thought reasoning. Detailed\narchitectural details and experimental process have been uploaded to Github,\nthe link is:https://github.com/brucewang123456789/GeniusTrail.git.\n","authors":["Libo Wang"],"pdf_url":"https://arxiv.org/pdf/2411.09111v4.pdf","comment":"The main text is 5 pages, totaling 9 pages; 4 figures, 1 table. It\n  have been submitted to NeurIPS 2024 Workshop MusIML and OpenReview"},{"id":"http://arxiv.org/abs/2412.08629v1","updated":"2024-12-11T18:50:29Z","published":"2024-12-11T18:50:29Z","title":"FlowEdit: Inversion-Free Text-Based Editing Using Pre-Trained Flow\n  Models","summary":"  Editing real images using a pre-trained text-to-image (T2I) diffusion/flow\nmodel often involves inverting the image into its corresponding noise map.\nHowever, inversion by itself is typically insufficient for obtaining\nsatisfactory results, and therefore many methods additionally intervene in the\nsampling process. Such methods achieve improved results but are not seamlessly\ntransferable between model architectures. Here, we introduce FlowEdit, a\ntext-based editing method for pre-trained T2I flow models, which is\ninversion-free, optimization-free and model agnostic. Our method constructs an\nODE that directly maps between the source and target distributions\n(corresponding to the source and target text prompts) and achieves a lower\ntransport cost than the inversion approach. This leads to state-of-the-art\nresults, as we illustrate with Stable Diffusion 3 and FLUX. Code and examples\nare available on the project's webpage.\n","authors":["Vladimir Kulikov","Matan Kleiner","Inbar Huberman-Spiegelglas","Tomer Michaeli"],"pdf_url":"https://arxiv.org/pdf/2412.08629v1.pdf","comment":"Project's webpage at https://matankleiner.github.io/flowedit/"},{"id":"http://arxiv.org/abs/2406.18814v3","updated":"2024-12-11T18:48:59Z","published":"2024-06-27T01:08:04Z","title":"Length Optimization in Conformal Prediction","summary":"  Conditional validity and length efficiency are two crucial aspects of\nconformal prediction (CP). Conditional validity ensures accurate uncertainty\nquantification for data subpopulations, while proper length efficiency ensures\nthat the prediction sets remain informative. Despite significant efforts to\naddress each of these issues individually, a principled framework that\nreconciles these two objectives has been missing in the CP literature. In this\npaper, we develop Conformal Prediction with Length-Optimization (CPL) - a novel\nand practical framework that constructs prediction sets with (near-) optimal\nlength while ensuring conditional validity under various classes of covariate\nshifts, including the key cases of marginal and group-conditional coverage. In\nthe infinite sample regime, we provide strong duality results which indicate\nthat CPL achieves conditional validity and length optimality. In the finite\nsample regime, we show that CPL constructs conditionally valid prediction sets.\nOur extensive empirical evaluations demonstrate the superior prediction set\nsize performance of CPL compared to state-of-the-art methods across diverse\nreal-world and synthetic datasets in classification, regression, and large\nlanguage model-based multiple choice question answering. An Implementation of\nour algorithm can be accessed at the following link:\nhttps://github.com/shayankiyani98/CP.\n","authors":["Shayan Kiyani","George Pappas","Hamed Hassani"],"pdf_url":"https://arxiv.org/pdf/2406.18814v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06090v2","updated":"2024-12-11T18:38:41Z","published":"2024-11-09T06:46:16Z","title":"Concept Bottleneck Language Models For protein design","summary":"  We introduce Concept Bottleneck Protein Language Models (CB-pLM), a\ngenerative masked language model with a layer where each neuron corresponds to\nan interpretable concept. Our architecture offers three key benefits: i)\nControl: We can intervene on concept values to precisely control the properties\nof generated proteins, achieving a 3 times larger change in desired concept\nvalues compared to baselines. ii) Interpretability: A linear mapping between\nconcept values and predicted tokens allows transparent analysis of the model's\ndecision-making process. iii) Debugging: This transparency facilitates easy\ndebugging of trained models. Our models achieve pre-training perplexity and\ndownstream task performance comparable to traditional masked protein language\nmodels, demonstrating that interpretability does not compromise performance.\nWhile adaptable to any language model, we focus on masked protein language\nmodels due to their importance in drug discovery and the ability to validate\nour model's capabilities through real-world experiments and expert knowledge.\nWe scale our CB-pLM from 24 million to 3 billion parameters, making them the\nlargest Concept Bottleneck Models trained and the first capable of generative\nlanguage modeling.\n","authors":["Aya Abdelsalam Ismail","Tuomas Oikarinen","Amy Wang","Julius Adebayo","Samuel Stanton","Taylor Joren","Joseph Kleinhenz","Allen Goodman","Héctor Corrada Bravo","Kyunghyun Cho","Nathan C. Frey"],"pdf_url":"https://arxiv.org/pdf/2411.06090v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07762v2","updated":"2024-12-11T18:32:48Z","published":"2024-12-10T18:57:12Z","title":"Efficient Online Reinforcement Learning Fine-Tuning Need Not Retain\n  Offline Data","summary":"  The modern paradigm in machine learning involves pre-training on diverse\ndata, followed by task-specific fine-tuning. In reinforcement learning (RL),\nthis translates to learning via offline RL on a diverse historical dataset,\nfollowed by rapid online RL fine-tuning using interaction data. Most RL\nfine-tuning methods require continued training on offline data for stability\nand performance. However, this is undesirable because training on diverse\noffline data is slow and expensive for large datasets, and in principle, also\nlimit the performance improvement possible because of constraints or pessimism\non offline data. In this paper, we show that retaining offline data is\nunnecessary as long as we use a properly-designed online RL approach for\nfine-tuning offline RL initializations. To build this approach, we start by\nanalyzing the role of retaining offline data in online fine-tuning. We find\nthat continued training on offline data is mostly useful for preventing a\nsudden divergence in the value function at the onset of fine-tuning, caused by\na distribution mismatch between the offline data and online rollouts. This\ndivergence typically results in unlearning and forgetting the benefits of\noffline pre-training. Our approach, Warm-start RL (WSRL), mitigates the\ncatastrophic forgetting of pre-trained initializations using a very simple\nidea. WSRL employs a warmup phase that seeds the online RL run with a very\nsmall number of rollouts from the pre-trained policy to do fast online RL. The\ndata collected during warmup helps ``recalibrate'' the offline Q-function to\nthe online distribution, allowing us to completely discard offline data without\ndestabilizing the online RL fine-tuning. We show that WSRL is able to fine-tune\nwithout retaining any offline data, and is able to learn faster and attains\nhigher performance than existing algorithms irrespective of whether they retain\noffline data or not.\n","authors":["Zhiyuan Zhou","Andy Peng","Qiyang Li","Sergey Levine","Aviral Kumar"],"pdf_url":"https://arxiv.org/pdf/2412.07762v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04842v3","updated":"2024-12-11T18:32:36Z","published":"2024-08-09T03:35:53Z","title":"Counterfactual Explanations with Probabilistic Guarantees on their\n  Robustness to Model Change","summary":"  Counterfactual explanations (CFEs) guide users on how to adjust inputs to\nmachine learning models to achieve desired outputs. While existing research\nprimarily addresses static scenarios, real-world applications often involve\ndata or model changes, potentially invalidating previously generated CFEs and\nrendering user-induced input changes ineffective. Current methods addressing\nthis issue often support only specific models or change types, require\nextensive hyperparameter tuning, or fail to provide probabilistic guarantees on\nCFE robustness to model changes. This paper proposes a novel approach for\ngenerating CFEs that provides probabilistic guarantees for any model and change\ntype, while offering interpretable and easy-to-select hyperparameters. We\nestablish a theoretical framework for probabilistically defining robustness to\nmodel change and demonstrate how our BetaRCE method directly stems from it.\nBetaRCE is a post-hoc method applied alongside a chosen base CFE generation\nmethod to enhance the quality of the explanation beyond robustness. It\nfacilitates a transition from the base explanation to a more robust one with\nuser-adjusted probability bounds. Through experimental comparisons with\nbaselines, we show that BetaRCE yields robust, most plausible, and closest to\nbaseline counterfactual explanations.\n","authors":["Ignacy Stępka","Mateusz Lango","Jerzy Stefanowski"],"pdf_url":"https://arxiv.org/pdf/2408.04842v3.pdf","comment":"Accepted at 31st SIGKDD Conference on Knowledge Discovery and Data\n  Mining 2025"},{"id":"http://arxiv.org/abs/2412.08604v1","updated":"2024-12-11T18:26:55Z","published":"2024-12-11T18:26:55Z","title":"Preference Discerning with LLM-Enhanced Generative Retrieval","summary":"  Sequential recommendation systems aim to provide personalized recommendations\nfor users based on their interaction history. To achieve this, they often\nincorporate auxiliary information, such as textual descriptions of items and\nauxiliary tasks, like predicting user preferences and intent. Despite numerous\nefforts to enhance these models, they still suffer from limited\npersonalization. To address this issue, we propose a new paradigm, which we\nterm preference discerning. In preference dscerning, we explicitly condition a\ngenerative sequential recommendation system on user preferences within its\ncontext. To this end, we generate user preferences using Large Language Models\n(LLMs) based on user reviews and item-specific data. To evaluate preference\ndiscerning capabilities of sequential recommendation systems, we introduce a\nnovel benchmark that provides a holistic evaluation across various scenarios,\nincluding preference steering and sentiment following. We assess current\nstate-of-the-art methods using our benchmark and show that they struggle to\naccurately discern user preferences. Therefore, we propose a new method named\nMender ($\\textbf{M}$ultimodal Prefer$\\textbf{en}$ce\n$\\textbf{d}$iscern$\\textbf{er}$), which improves upon existing methods and\nachieves state-of-the-art performance on our benchmark. Our results show that\nMender can be effectively guided by human preferences even though they have not\nbeen observed during training, paving the way toward more personalized\nsequential recommendation systems. We will open-source the code and benchmarks\nupon publication.\n","authors":["Fabian Paischer","Liu Yang","Linfeng Liu","Shuai Shao","Kaveh Hassani","Jiacheng Li","Ricky Chen","Zhang Gabriel Li","Xialo Gao","Wei Shao","Xue Feng","Nima Noorshams","Sem Park","Bo Long","Hamid Eghbalzadeh"],"pdf_url":"https://arxiv.org/pdf/2412.08604v1.pdf","comment":"11 pages + references and appendix"},{"id":"http://arxiv.org/abs/2412.08595v1","updated":"2024-12-11T18:13:55Z","published":"2024-12-11T18:13:55Z","title":"Numerical Analysis of HiPPO-LegS ODE for Deep State Space Models","summary":"  In deep learning, the recently introduced state space models utilize HiPPO\n(High-order Polynomial Projection Operators) memory units to approximate\ncontinuous-time trajectories of input functions using ordinary differential\nequations (ODEs), and these techniques have shown empirical success in\ncapturing long-range dependencies in long input sequences. However, the\nmathematical foundations of these ODEs, particularly the singular HiPPO-LegS\n(Legendre Scaled) ODE, and their corresponding numerical discretizations remain\nunexplored. In this work, we fill this gap by establishing that HiPPO-LegS ODE\nis well-posed despite its singularity, albeit without the freedom of arbitrary\ninitial conditions, and by establishing convergence of the associated numerical\ndiscretization schemes for Riemann-integrable input functions.\n","authors":["Jaesung R. Park","Jaewook J. Suh","Ernest K. Ryu"],"pdf_url":"https://arxiv.org/pdf/2412.08595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.12151v3","updated":"2024-12-11T18:12:43Z","published":"2024-03-18T18:08:44Z","title":"Fusing Domain-Specific Content from Large Language Models into Knowledge\n  Graphs for Enhanced Zero Shot Object State Classification","summary":"  Domain-specific knowledge can significantly contribute to addressing a wide\nvariety of vision tasks. However, the generation of such knowledge entails\nconsiderable human labor and time costs. This study investigates the potential\nof Large Language Models (LLMs) in generating and providing domain-specific\ninformation through semantic embeddings. To achieve this, an LLM is integrated\ninto a pipeline that utilizes Knowledge Graphs and pre-trained semantic vectors\nin the context of the Vision-based Zero-shot Object State Classification task.\nWe thoroughly examine the behavior of the LLM through an extensive ablation\nstudy. Our findings reveal that the integration of LLM-based embeddings, in\ncombination with general-purpose pre-trained embeddings, leads to substantial\nperformance improvements. Drawing insights from this ablation study, we conduct\na comparative analysis against competing models, thereby highlighting the\nstate-of-the-art performance achieved by the proposed approach.\n","authors":["Filippos Gouidis","Katerina Papantoniou","Konstantinos Papoutsakis","Theodore Patkos","Antonis Argyros","Dimitris Plexousakis"],"pdf_url":"https://arxiv.org/pdf/2403.12151v3.pdf","comment":"Accepted at the AAAI-MAKE 2024"},{"id":"http://arxiv.org/abs/2412.08592v1","updated":"2024-12-11T18:11:21Z","published":"2024-12-11T18:11:21Z","title":"Adaptive Principal Components Allocation with the\n  $\\ell_{2,g}$-regularized Gaussian Graphical Model for Efficient Fine-Tuning\n  Large Models","summary":"  In this work, we propose a novel Parameter-Efficient Fine-Tuning (PEFT)\napproach based on Gaussian Graphical Models (GGMs), marking the first\napplication of GGMs to PEFT tasks, to the best of our knowledge. The proposed\nmethod utilizes the $\\ell_{2,g}$-norm to effectively select critical parameters\nand capture global dependencies. The resulting non-convex optimization problem\nis efficiently solved using a Block Coordinate Descent (BCD) algorithm.\nExperimental results on the GLUE benchmark [24] for fine-tuning RoBERTa-Base\n[18] demonstrate the effectiveness of the proposed approach, achieving\ncompetitive performance with significantly fewer trainable parameters. The code\nfor this work is available at: https://github.com/jzheng20/Course projects.git.\n","authors":["Jingjing Zheng","Yankai Cao"],"pdf_url":"https://arxiv.org/pdf/2412.08592v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08590v1","updated":"2024-12-11T18:10:04Z","published":"2024-12-11T18:10:04Z","title":"Preventing Conflicting Gradients in Neural Marked Temporal Point\n  Processes","summary":"  Neural Marked Temporal Point Processes (MTPP) are flexible models to capture\ncomplex temporal inter-dependencies between labeled events. These models\ninherently learn two predictive distributions: one for the arrival times of\nevents and another for the types of events, also known as marks. In this study,\nwe demonstrate that learning a MTPP model can be framed as a two-task learning\nproblem, where both tasks share a common set of trainable parameters that are\noptimized jointly. We show that this often leads to the emergence of\nconflicting gradients during training, where task-specific gradients are\npointing in opposite directions. When such conflicts arise, following the\naverage gradient can be detrimental to the learning of each individual tasks,\nresulting in overall degraded performance. To overcome this issue, we introduce\nnovel parametrizations for neural MTPP models that allow for separate modeling\nand training of each task, effectively avoiding the problem of conflicting\ngradients. Through experiments on multiple real-world event sequence datasets,\nwe demonstrate the benefits of our framework compared to the original model\nformulations.\n","authors":["Tanguy Bosser","Souhaib Ben Taieb"],"pdf_url":"https://arxiv.org/pdf/2412.08590v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08589v1","updated":"2024-12-11T18:08:06Z","published":"2024-12-11T18:08:06Z","title":"SPACE-SUIT: An Artificial Intelligence based chromospheric feature\n  extractor and classifier for SUIT","summary":"  The Solar Ultraviolet Imaging Telescope(SUIT) onboard Aditya-L1 is an imager\nthat observes the solar photosphere and chromosphere through observations in\nthe wavelength range of 200-400 nm. A comprehensive understanding of the plasma\nand thermodynamic properties of chromospheric and photospheric morphological\nstructures requires a large sample statistical study, necessitating the\ndevelopment of automatic feature detection methods. To this end, we develop the\nfeature detection algorithm SPACE-SUIT: Solar Phenomena Analysis and\nClassification using Enhanced vision techniques for SUIT, to detect and\nclassify the solar chromospheric features to be observed from SUIT's Mg II k\nfilter. Specifically, we target plage regions, sunspots, filaments, and\noff-limb structures. SPACE uses You Only Look Once(YOLO), a neural\nnetwork-based model to identify regions of interest. We train and validate\nSPACE using mock-SUIT images developed from Interface Region Imaging\nSpectrometer(IRIS) full-disk mosaic images in Mg II k line, while we also\nperform detection on Level-1 SUIT data. SPACE achieves an approximate precision\nof 0.788, recall 0.863 and MAP of 0.874 on the validation mock SUIT FITS\ndataset. Given the manual labeling of our dataset, we perform \"self-validation\"\nby applying statistical measures and Tamura features on the ground truth and\npredicted bounding boxes. We find the distributions of entropy, contrast,\ndissimilarity, and energy to show differences in the features. These\ndifferences are qualitatively captured by the detected regions predicted by\nSPACE and validated with the observed SUIT images, even in the absence of\nlabeled ground truth. This work not only develops a chromospheric feature\nextractor but also demonstrates the effectiveness of statistical metrics and\nTamura features for distinguishing chromospheric features, offering independent\nvalidation for future detection schemes.\n","authors":["Pranava Seth","Vishal Upendran","Megha Anand","Janmejoy Sarkar","Soumya Roy","Priyadarshan Chaki","Pratyay Chowdhury","Borishan Ghosh","Durgesh Tripathi"],"pdf_url":"https://arxiv.org/pdf/2412.08589v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.16822v3","updated":"2024-12-11T18:07:25Z","published":"2024-02-26T18:47:27Z","title":"Rainbow Teaming: Open-Ended Generation of Diverse Adversarial Prompts","summary":"  As large language models (LLMs) become increasingly prevalent across many\nreal-world applications, understanding and enhancing their robustness to\nadversarial attacks is of paramount importance. Existing methods for\nidentifying adversarial prompts tend to focus on specific domains, lack\ndiversity, or require extensive human annotations. To address these\nlimitations, we present Rainbow Teaming, a novel black-box approach for\nproducing a diverse collection of adversarial prompts. Rainbow Teaming casts\nadversarial prompt generation as a quality-diversity problem and uses\nopen-ended search to generate prompts that are both effective and diverse.\nFocusing on the safety domain, we use Rainbow Teaming to target various\nstate-of-the-art LLMs, including the Llama 2 and Llama 3 models. Our approach\nreveals hundreds of effective adversarial prompts, with an attack success rate\nexceeding 90% across all tested models. Furthermore, we demonstrate that\nprompts generated by Rainbow Teaming are highly transferable and that\nfine-tuning models with synthetic data generated by our method significantly\nenhances their safety without sacrificing general performance or helpfulness.\nWe additionally explore the versatility of Rainbow Teaming by applying it to\nquestion answering and cybersecurity, showcasing its potential to drive robust\nopen-ended self-improvement in a wide range of applications.\n","authors":["Mikayel Samvelyan","Sharath Chandra Raparthy","Andrei Lupu","Eric Hambro","Aram H. Markosyan","Manish Bhatt","Yuning Mao","Minqi Jiang","Jack Parker-Holder","Jakob Foerster","Tim Rocktäschel","Roberta Raileanu"],"pdf_url":"https://arxiv.org/pdf/2402.16822v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08585v1","updated":"2024-12-11T18:03:05Z","published":"2024-12-11T18:03:05Z","title":"TURBOATTENTION: Efficient Attention Approximation For High Throughputs\n  LLMs","summary":"  Large language model (LLM) inference demands significant amount of\ncomputation and memory, especially in the key attention mechanism. While\ntechniques, such as quantization and acceleration algorithms, like\nFlashAttention, have improved efficiency of the overall inference, they address\ndifferent aspects of the problem: quantization focuses on weight-activation\noperations, while FlashAttention improves execution but requires high-precision\nformats. Recent Key-value (KV) cache quantization reduces memory bandwidth but\nstill needs floating-point dequantization for attention operation.\n  We present TurboAttention, a comprehensive approach to enable quantized\nexecution of attention that simultaneously addresses both memory and\ncomputational efficiency. Our solution introduces two key innovations: FlashQ,\na headwise attention quantization technique that enables both compression of KV\ncache and quantized execution of activation-activation multiplication, and\nSparsity-based Softmax Approximation (SAS), which eliminates the need for\ndequantization to FP32 during exponentiation operation in attention.\nExperimental results demonstrate that TurboAttention achieves 1.2-1.8x speedup\nin attention, reduces the KV cache size by over 4.4x, and enables up to 2.37x\nmaximum throughput over the FP16 baseline while outperforming state-of-the-art\nquantization and compression techniques across various datasets and models.\n","authors":["Hao Kang","Srikant Bharadwaj","James Hensman","Tushar Krishna","Victor Ruhle","Saravan Rajmohan"],"pdf_url":"https://arxiv.org/pdf/2412.08585v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.16906v2","updated":"2024-12-11T17:56:00Z","published":"2024-05-27T07:55:27Z","title":"Harnessing the Power of Vicinity-Informed Analysis for Classification\n  under Covariate Shift","summary":"  Transfer learning enhances prediction accuracy on a target distribution by\nleveraging data from a source distribution, demonstrating significant benefits\nin various applications. This paper introduces a novel dissimilarity measure\nthat utilizes vicinity information, i.e., the local structure of data points,\nto analyze the excess error in classification under covariate shift, a transfer\nlearning setting where marginal feature distributions differ but conditional\nlabel distributions remain the same. We characterize the excess error using the\nproposed measure and demonstrate faster or competitive convergence rates\ncompared to previous techniques. Notably, our approach is effective in the\nsupport non-containment assumption, which often appears in real-world\napplications, holds. Our theoretical analysis bridges the gap between current\ntheoretical findings and empirical observations in transfer learning,\nparticularly in scenarios with significant differences between source and\ntarget distributions.\n","authors":["Mitsuhiro Fujikawa","Yohei Akimoto","Jun Sakuma","Kazuto Fukuchi"],"pdf_url":"https://arxiv.org/pdf/2405.16906v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08565v1","updated":"2024-12-11T17:32:33Z","published":"2024-12-11T17:32:33Z","title":"GenPlan: Generative sequence models as adaptive planners","summary":"  Offline reinforcement learning has shown tremendous success in behavioral\nplanning by learning from previously collected demonstrations. However,\ndecision-making in multitask missions still presents significant challenges.\nFor instance, a mission might require an agent to explore an unknown\nenvironment, discover goals, and navigate to them, even if it involves\ninteracting with obstacles along the way. Such behavioral planning problems are\ndifficult to solve due to: a) agents failing to adapt beyond the single task\nlearned through their reward function, and b) the inability to generalize to\nnew environments not covered in the training demonstrations, e.g., environments\nwhere all doors were unlocked in the demonstrations. Consequently,\nstate-of-the-art decision making methods are limited to missions where the\nrequired tasks are well-represented in the training demonstrations and can be\nsolved within a short (temporal) planning horizon. To address this, we propose\nGenPlan: a stochastic and adaptive planner that leverages discrete-flow models\nfor generative sequence modeling, enabling sample-efficient exploration and\nexploitation. This framework relies on an iterative denoising procedure to\ngenerate a sequence of goals and actions. This approach captures multi-modal\naction distributions and facilitates goal and task discovery, thereby enhancing\ngeneralization to out-of-distribution tasks and environments, i.e., missions\nnot part of the training data. We demonstrate the effectiveness of our method\nthrough multiple simulation environments. Notably, GenPlan outperforms the\nstate-of-the-art methods by over 10% on adaptive planning tasks, where the\nagent adapts to multi-task missions while leveraging demonstrations on\nsingle-goal-reaching tasks.\n","authors":["Akash Karthikeyan","Yash Vardhan Pant"],"pdf_url":"https://arxiv.org/pdf/2412.08565v1.pdf","comment":"Accepted in AAAI 2025. Project page:\n  https://aku02.github.io/projects/genplan/"},{"id":"http://arxiv.org/abs/2402.04436v3","updated":"2024-12-11T17:22:54Z","published":"2024-02-06T22:13:51Z","title":"Continuous Multidimensional Scaling","summary":"  Multidimensional scaling (MDS) is the act of embedding proximity information\nabout a set of $n$ objects in $d$-dimensional Euclidean space. As originally\nconceived by the psychometric community, MDS was concerned with embedding a\nfixed set of proximities associated with a fixed set of objects. Modern\nconcerns, e.g., that arise in developing asymptotic theories for statistical\ninference on random graphs, more typically involve studying the limiting\nbehavior of a sequence of proximities associated with an increasing set of\nobjects. Here we are concerned with embedding dissimilarities by minimizing\nKruskal's (1964) raw stress criterion. Standard results from the theory of\npoint-to-set maps can be used to establish that, if $n$ is fixed and a sequence\nof dissimilarity matrices converges, then the limit of their embedded\nstructures is the embedded structure of the limiting dissimilarity matrix. But\nwhat if $n$ increases? It then becomes necessary to reformulate MDS so that the\nentire sequence of embedding problems can be viewed as a sequence of\noptimization problems in a fixed space. We present such a reformulation, {\\em\ncontinuous MDS}. Within the continuous MDS framework, we derive two $L^p$\nconsistency results, one for embedding without constraints on the\nconfiguration, the other for embedding subject to {\\em approximate Lipschitz\nconstraints}\\/ that encourage smoothness of the embedding function. The latter\napproach, {\\em Approximate Lipschitz Embedding}\\/ (ALE) is new. Finally, we\ndemonstrate that embedded structures produced by ALE can be interpolated in a\nway that results in uniform convergence.\n","authors":["Michael W. Trosset","Carey E. Priebe"],"pdf_url":"https://arxiv.org/pdf/2402.04436v3.pdf","comment":"25 pages. Modified previous material for greater clarity; added new\n  material about approximate Lipschitz constraints, Approximate Lipschitz\n  Embedding (ALE), and uniform convergence; added material on constrained\n  minimization of raw stress to the appendix"},{"id":"http://arxiv.org/abs/2412.08559v1","updated":"2024-12-11T17:22:07Z","published":"2024-12-11T17:22:07Z","title":"Underestimated Privacy Risks for Minority Populations in Large Language\n  Model Unlearning","summary":"  Large Language Models are trained on extensive datasets that often contain\nsensitive, human-generated information, raising significant concerns about\nprivacy breaches. While certified unlearning approaches offer strong privacy\nguarantees, they rely on restrictive model assumptions that are not applicable\nto LLMs. As a result, various unlearning heuristics have been proposed, with\nthe associated privacy risks assessed only empirically. The standard evaluation\npipelines typically randomly select data for removal from the training set,\napply unlearning techniques, and use membership inference attacks to compare\nthe unlearned models against models retrained without the to-be-unlearned data.\nHowever, since every data point is subject to the right to be forgotten,\nunlearning should be considered in the worst-case scenario from the privacy\nperspective. Prior work shows that data outliers may exhibit higher\nmemorization effects. Intuitively, they are harder to be unlearn and thus the\nprivacy risk of unlearning them is underestimated in the current evaluation. In\nthis paper, we leverage minority data to identify such a critical flaw in\npreviously widely adopted evaluations. We substantiate this claim through\ncarefully designed experiments, including unlearning canaries related to\nminority groups, inspired by privacy auditing literature. Using personally\nidentifiable information as a representative minority identifier, we\ndemonstrate that minority groups experience at least 20% more privacy leakage\nin most cases across six unlearning approaches, three MIAs, three benchmark\ndatasets, and two LLMs of different scales. Given that the right to be\nforgotten should be upheld for every individual, we advocate for a more\nrigorous evaluation of LLM unlearning methods. Our minority-aware evaluation\nframework represents an initial step toward ensuring more equitable assessments\nof LLM unlearning efficacy.\n","authors":["Rongzhe Wei","Mufei Li","Mohsen Ghassemi","Eleonora Kreačić","Yifan Li","Xiang Yue","Bo Li","Vamsi K. Potluru","Pan Li","Eli Chien"],"pdf_url":"https://arxiv.org/pdf/2412.08559v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08555v1","updated":"2024-12-11T17:17:02Z","published":"2024-12-11T17:17:02Z","title":"Grimm: A Plug-and-Play Perturbation Rectifier for Graph Neural Networks\n  Defending against Poisoning Attacks","summary":"  End-to-end training with global optimization have popularized graph neural\nnetworks (GNNs) for node classification, yet inadvertently introduced\nvulnerabilities to adversarial edge-perturbing attacks. Adversaries can exploit\nthe inherent opened interfaces of GNNs' input and output, perturbing critical\nedges and thus manipulating the classification results. Current defenses, due\nto their persistent utilization of global-optimization-based end-to-end\ntraining schemes, inherently encapsulate the vulnerabilities of GNNs. This is\nspecifically evidenced in their inability to defend against targeted secondary\nattacks. In this paper, we propose the Graph Agent Network (GAgN) to address\nthe aforementioned vulnerabilities of GNNs. GAgN is a graph-structured agent\nnetwork in which each node is designed as an 1-hop-view agent. Through the\ndecentralized interactions between agents, they can learn to infer global\nperceptions to perform tasks including inferring embeddings, degrees and\nneighbor relationships for given nodes. This empowers nodes to filtering\nadversarial edges while carrying out classification tasks. Furthermore, agents'\nlimited view prevents malicious messages from propagating globally in GAgN,\nthereby resisting global-optimization-based secondary attacks. We prove that\nsingle-hidden-layer multilayer perceptrons (MLPs) are theoretically sufficient\nto achieve these functionalities. Experimental results show that GAgN\neffectively implements all its intended capabilities and, compared to\nstate-of-the-art defenses, achieves optimal classification accuracy on the\nperturbed datasets.\n","authors":["Ao Liu","Wenshan Li","Beibei Li","Wengang Ma","Tao Li","Pan Zhou"],"pdf_url":"https://arxiv.org/pdf/2412.08555v1.pdf","comment":"19 pages, 13 figures"},{"id":"http://arxiv.org/abs/2412.08549v1","updated":"2024-12-11T17:10:44Z","published":"2024-12-11T17:10:44Z","title":"Watermarking Training Data of Music Generation Models","summary":"  Generative Artificial Intelligence (Gen-AI) models are increasingly used to\nproduce content across domains, including text, images, and audio. While these\nmodels represent a major technical breakthrough, they gain their generative\ncapabilities from being trained on enormous amounts of human-generated content,\nwhich often includes copyrighted material. In this work, we investigate whether\naudio watermarking techniques can be used to detect an unauthorized usage of\ncontent to train a music generation model. We compare outputs generated by a\nmodel trained on watermarked data to a model trained on non-watermarked data.\nWe study factors that impact the model's generation behaviour: the watermarking\ntechnique, the proportion of watermarked samples in the training set, and the\nrobustness of the watermarking technique against the model's tokenizer. Our\nresults show that audio watermarking techniques, including some that are\nimperceptible to humans, can lead to noticeable shifts in the model's outputs.\nWe also study the robustness of a state-of-the-art watermarking technique to\nremoval techniques.\n","authors":["Pascal Epple","Igor Shilov","Bozhidar Stevanovski","Yves-Alexandre de Montjoye"],"pdf_url":"https://arxiv.org/pdf/2412.08549v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.01517v2","updated":"2024-12-11T17:06:21Z","published":"2022-03-03T05:03:28Z","title":"Correct-N-Contrast: A Contrastive Approach for Improving Robustness to\n  Spurious Correlations","summary":"  Spurious correlations pose a major challenge for robust machine learning.\nModels trained with empirical risk minimization (ERM) may learn to rely on\ncorrelations between class labels and spurious attributes, leading to poor\nperformance on data groups without these correlations. This is particularly\nchallenging to address when spurious attribute labels are unavailable. To\nimprove worst-group performance on spuriously correlated data without training\nattribute labels, we propose Correct-N-Contrast (CNC), a contrastive approach\nto directly learn representations robust to spurious correlations. As ERM\nmodels can be good spurious attribute predictors, CNC works by (1) using a\ntrained ERM model's outputs to identify samples with the same class but\ndissimilar spurious features, and (2) training a robust model with contrastive\nlearning to learn similar representations for same-class samples. To support\nCNC, we introduce new connections between worst-group error and a\nrepresentation alignment loss that CNC aims to minimize. We empirically observe\nthat worst-group error closely tracks with alignment loss, and prove that the\nalignment loss over a class helps upper-bound the class's worst-group vs.\naverage error gap. On popular benchmarks, CNC reduces alignment loss\ndrastically, and achieves state-of-the-art worst-group accuracy by 3.6% average\nabsolute lift. CNC is also competitive with oracle methods that require group\nlabels.\n","authors":["Michael Zhang","Nimit S. Sohoni","Hongyang R. Zhang","Chelsea Finn","Christopher Ré"],"pdf_url":"https://arxiv.org/pdf/2203.01517v2.pdf","comment":"38 pages, 14 figures. ICML 2022 Long Talk"},{"id":"http://arxiv.org/abs/2412.08544v1","updated":"2024-12-11T17:00:29Z","published":"2024-12-11T17:00:29Z","title":"Training Data Reconstruction: Privacy due to Uncertainty?","summary":"  Being able to reconstruct training data from the parameters of a neural\nnetwork is a major privacy concern. Previous works have shown that\nreconstructing training data, under certain circumstances, is possible. In this\nwork, we analyse such reconstructions empirically and propose a new formulation\nof the reconstruction as a solution to a bilevel optimisation problem. We\ndemonstrate that our formulation as well as previous approaches highly depend\non the initialisation of the training images $x$ to reconstruct. In particular,\nwe show that a random initialisation of $x$ can lead to reconstructions that\nresemble valid training samples while not being part of the actual training\ndataset. Thus, our experiments on affine and one-hidden layer networks suggest\nthat when reconstructing natural images, yet an adversary cannot identify\nwhether reconstructed images have indeed been part of the set of training\nsamples.\n","authors":["Christina Runkel","Kanchana Vaishnavi Gandikota","Jonas Geiping","Carola-Bibiane Schönlieb","Michael Moeller"],"pdf_url":"https://arxiv.org/pdf/2412.08544v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.06140v2","updated":"2024-12-11T16:59:51Z","published":"2024-10-08T15:40:22Z","title":"Estimating the Number of HTTP/3 Responses in QUIC Using Deep Learning","summary":"  QUIC, a new and increasingly used transport protocol, enhances TCP by\noffering improved security, performance, and stream multiplexing. These\nfeatures, however, also impose challenges for network middle-boxes that need to\nmonitor and analyze web traffic. This paper proposes a novel method to estimate\nthe number of HTTP/3 responses in a given QUIC connection by an observer. This\nestimation reveals server behavior, client-server interactions, and data\ntransmission efficiency, which is crucial for various applications such as\ndesigning a load balancing solution and detecting HTTP/3 flood attacks. The\nproposed scheme transforms QUIC connection traces into image sequences and uses\nmachine learning (ML) models, guided by a tailored loss function, to predict\nresponse counts. Evaluations on more than seven million images-derived from\n100,000 traces collected across 44,000 websites over four months-achieve up to\n97% accuracy in both known and unknown server settings and 92% accuracy on\npreviously unseen complete QUIC traces.\n","authors":["Barak Gahtan","Robert J. Shahla","Reuven Cohen","Alex M. Bronstein"],"pdf_url":"https://arxiv.org/pdf/2410.06140v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2410.03728"},{"id":"http://arxiv.org/abs/2306.10715v5","updated":"2024-12-11T16:59:50Z","published":"2023-06-19T06:22:02Z","title":"Robust Multi-Agent Control via Maximum Entropy Heterogeneous-Agent\n  Reinforcement Learning","summary":"  In multi-agent reinforcement learning, optimal control with robustness\nguarantees are critical for its deployment in real world. However, existing\nmethods face challenges related to sample complexity, training instability,\npotential suboptimal Nash Equilibrium convergence and non-robustness to\nmultiple perturbations. In this paper, we propose a unified framework for\nlearning \\emph{stochastic} policies to resolve these issues. We embed\ncooperative MARL problems into probabilistic graphical models, from which we\nderive the maximum entropy (MaxEnt) objective optimal for MARL. Based on the\nMaxEnt framework, we propose \\emph{Heterogeneous-Agent Soft Actor-Critic}\n(HASAC) algorithm. Theoretically, we prove the monotonic improvement and\nconvergence to \\emph{quantal response equilibrium} (QRE) properties of HASAC.\nFurthermore, HASAC is provably robust against a wide range of real-world\nuncertainties, including perturbations in rewards, environment dynamics,\nstates, and actions. Finally, we generalize a unified template for MaxEnt\nalgorithmic design named \\emph{Maximum Entropy Heterogeneous-Agent Mirror\nLearning} (MEHAML), which provides any induced method with the same guarantees\nas HASAC. We evaluate HASAC on seven benchmarks: Bi-DexHands, Multi-Agent\nMuJoCo, Pursuit-Evade, StarCraft Multi-Agent Challenge, Google Research\nFootball, Multi-Agent Particle Environment, Light Aircraft Game. Results show\nthat HASAC consistently outperforms strong baselines in 34 out of 38 tasks,\nexhibiting improved training stability, better sample efficiency and sufficient\nexploration. The robustness of HASAC was further validated when encountering\nuncertainties in rewards, dynamics, states, and actions of 14 magnitudes, and\nreal-world deployment in a multi-robot arena against these four types of\nuncertainties. See our page at \\url{https://sites.google.com/view/meharl}.\n","authors":["Simin Li","Yifan Zhong","Jiarong Liu","Jianing Guo","Siyuan Qi","Ruixiao Xu","Xin Yu","Siyi Hu","Haobo Fu","Qiang Fu","Xiaojun Chang","Yujing Hu","Bo An","Xianglong Liu","Yaodong Yang"],"pdf_url":"https://arxiv.org/pdf/2306.10715v5.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2412.08542v1","updated":"2024-12-11T16:59:31Z","published":"2024-12-11T16:59:31Z","title":"MaestroMotif: Skill Design from Artificial Intelligence Feedback","summary":"  Describing skills in natural language has the potential to provide an\naccessible way to inject human knowledge about decision-making into an AI\nsystem. We present MaestroMotif, a method for AI-assisted skill design, which\nyields high-performing and adaptable agents. MaestroMotif leverages the\ncapabilities of Large Language Models (LLMs) to effectively create and reuse\nskills. It first uses an LLM's feedback to automatically design rewards\ncorresponding to each skill, starting from their natural language description.\nThen, it employs an LLM's code generation abilities, together with\nreinforcement learning, for training the skills and combining them to implement\ncomplex behaviors specified in language. We evaluate MaestroMotif using a suite\nof complex tasks in the NetHack Learning Environment (NLE), demonstrating that\nit surpasses existing approaches in both performance and usability.\n","authors":["Martin Klissarov","Mikael Henaff","Roberta Raileanu","Shagun Sodhani","Pascal Vincent","Amy Zhang","Pierre-Luc Bacon","Doina Precup","Marlos C. Machado","Pierluca D'Oro"],"pdf_url":"https://arxiv.org/pdf/2412.08542v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08541v1","updated":"2024-12-11T16:59:09Z","published":"2024-12-11T16:59:09Z","title":"Euclidean Fast Attention: Machine Learning Global Atomic Representations\n  at Linear Cost","summary":"  Long-range correlations are essential across numerous machine learning tasks,\nespecially for data embedded in Euclidean space, where the relative positions\nand orientations of distant components are often critical for accurate\npredictions. Self-attention offers a compelling mechanism for capturing these\nglobal effects, but its quadratic complexity presents a significant practical\nlimitation. This problem is particularly pronounced in computational chemistry,\nwhere the stringent efficiency requirements of machine learning force fields\n(MLFFs) often preclude accurately modeling long-range interactions. To address\nthis, we introduce Euclidean fast attention (EFA), a linear-scaling\nattention-like mechanism designed for Euclidean data, which can be easily\nincorporated into existing model architectures. A core component of EFA are\nnovel Euclidean rotary positional encodings (ERoPE), which enable efficient\nencoding of spatial information while respecting essential physical symmetries.\nWe empirically demonstrate that EFA effectively captures diverse long-range\neffects, enabling EFA-equipped MLFFs to describe challenging chemical\ninteractions for which conventional MLFFs yield incorrect results.\n","authors":["J. Thorben Frank","Stefan Chmiela","Klaus-Robert Müller","Oliver T. Unke"],"pdf_url":"https://arxiv.org/pdf/2412.08541v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.05467v3","updated":"2024-12-11T16:49:22Z","published":"2024-12-06T23:43:59Z","title":"The BrowserGym Ecosystem for Web Agent Research","summary":"  The BrowserGym ecosystem addresses the growing need for efficient evaluation\nand benchmarking of web agents, particularly those leveraging automation and\nLarge Language Models (LLMs) for web interaction tasks. Many existing\nbenchmarks suffer from fragmentation and inconsistent evaluation methodologies,\nmaking it challenging to achieve reliable comparisons and reproducible results.\nBrowserGym aims to solve this by providing a unified, gym-like environment with\nwell-defined observation and action spaces, facilitating standardized\nevaluation across diverse benchmarks. Combined with AgentLab, a complementary\nframework that aids in agent creation, testing, and analysis, BrowserGym offers\nflexibility for integrating new benchmarks while ensuring consistent evaluation\nand comprehensive experiment management. This standardized approach seeks to\nreduce the time and complexity of developing web agents, supporting more\nreliable comparisons and facilitating in-depth analysis of agent behaviors, and\ncould result in more adaptable, capable agents, ultimately accelerating\ninnovation in LLM-driven automation. As a supporting evidence, we conduct the\nfirst large-scale, multi-benchmark web agent experiment and compare the\nperformance of 6 state-of-the-art LLMs across all benchmarks currently\navailable in BrowserGym. Among other findings, our results highlight a large\ndiscrepancy between OpenAI and Anthropic's latests models, with\nClaude-3.5-Sonnet leading the way on almost all benchmarks, except on\nvision-related tasks where GPT-4o is superior. Despite these advancements, our\nresults emphasize that building robust and efficient web agents remains a\nsignificant challenge, due to the inherent complexity of real-world web\nenvironments and the limitations of current models.\n","authors":["Thibault Le Sellier De Chezelles","Maxime Gasse","Alexandre Drouin","Massimo Caccia","Léo Boisvert","Megh Thakkar","Tom Marty","Rim Assouel","Sahar Omidi Shayegan","Lawrence Keunho Jang","Xing Han Lù","Ori Yoran","Dehan Kong","Frank F. Xu","Siva Reddy","Quentin Cappart","Graham Neubig","Ruslan Salakhutdinov","Nicolas Chapados","Alexandre Lacoste"],"pdf_url":"https://arxiv.org/pdf/2412.05467v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08534v1","updated":"2024-12-11T16:48:18Z","published":"2024-12-11T16:48:18Z","title":"Protecting Confidentiality, Privacy and Integrity in Collaborative\n  Learning","summary":"  A collaboration between dataset owners and model owners is needed to\nfacilitate effective machine learning (ML) training. During this collaboration,\nhowever, dataset owners and model owners want to protect the confidentiality of\ntheir respective assets (i.e., datasets, models and training code), with the\ndataset owners also caring about the privacy of individual users whose data is\nin their datasets. Existing solutions either provide limited confidentiality\nfor models and training code, or suffer from privacy issues due to collusion.\n  We present Citadel++, a scalable collaborative ML training system designed to\nsimultaneously protect the confidentiality of datasets, models and training\ncode, as well as the privacy of individual users. Citadel++ enhances\ndifferential privacy techniques to safeguard the privacy of individual user\ndata while maintaining model utility. By employing Virtual Machine-level\nTrusted Execution Environments (TEEs) and improved integrity protection\ntechniques through various OS-level mechanisms, Citadel++ effectively preserves\nthe confidentiality of datasets, models and training code, and enforces our\nprivacy mechanisms even when the models and training code have been maliciously\ndesigned. Our experiments show that Citadel++ provides privacy, model utility\nand performance while adhering to confidentiality and privacy requirements of\ndataset owners and model owners, outperforming the state-of-the-art\nprivacy-preserving training systems by up to 543x on CPU and 113x on GPU TEEs.\n","authors":["Dong Chen","Alice Dethise","Istemi Ekin Akkus","Ivica Rimac","Klaus Satzke","Antti Koskela","Marco Canini","Wei Wang","Ruichuan Chen"],"pdf_url":"https://arxiv.org/pdf/2412.08534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.17148v3","updated":"2024-12-11T16:38:15Z","published":"2023-05-26T02:50:55Z","title":"Differentially Private Low-dimensional Synthetic Data from\n  High-dimensional Datasets","summary":"  Differentially private synthetic data provide a powerful mechanism to enable\ndata analysis while protecting sensitive information about individuals.\nHowever, when the data lie in a high-dimensional space, the accuracy of the\nsynthetic data suffers from the curse of dimensionality. In this paper, we\npropose a differentially private algorithm to generate low-dimensional\nsynthetic data efficiently from a high-dimensional dataset with a utility\nguarantee with respect to the Wasserstein distance. A key step of our algorithm\nis a private principal component analysis (PCA) procedure with a near-optimal\naccuracy bound that circumvents the curse of dimensionality. Unlike the\nstandard perturbation analysis, our analysis of private PCA works without\nassuming the spectral gap for the covariance matrix.\n","authors":["Yiyun He","Thomas Strohmer","Roman Vershynin","Yizhe Zhu"],"pdf_url":"https://arxiv.org/pdf/2305.17148v3.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2412.08526v1","updated":"2024-12-11T16:37:44Z","published":"2024-12-11T16:37:44Z","title":"Spend More to Save More (SM2): An Energy-Aware Implementation of\n  Successive Halving for Sustainable Hyperparameter Optimization","summary":"  A fundamental step in the development of machine learning models commonly\ninvolves the tuning of hyperparameters, often leading to multiple model\ntraining runs to work out the best-performing configuration. As machine\nlearning tasks and models grow in complexity, there is an escalating need for\nsolutions that not only improve performance but also address sustainability\nconcerns. Existing strategies predominantly focus on maximizing the performance\nof the model without considering energy efficiency. To bridge this gap, in this\npaper, we introduce Spend More to Save More (SM2), an energy-aware\nhyperparameter optimization implementation based on the widely adopted\nsuccessive halving algorithm. Unlike conventional approaches including\nenergy-intensive testing of individual hyperparameter configurations, SM2\nemploys exploratory pretraining to identify inefficient configurations with\nminimal energy expenditure. Incorporating hardware characteristics and\nreal-time energy consumption tracking, SM2 identifies an optimal configuration\nthat not only maximizes the performance of the model but also enables\nenergy-efficient training. Experimental validations across various datasets,\nmodels, and hardware setups confirm the efficacy of SM2 to prevent the waste of\nenergy during the training of hyperparameter configurations.\n","authors":["Daniel Geissler","Bo Zhou","Sungho Suh","Paul Lukowicz"],"pdf_url":"https://arxiv.org/pdf/2412.08526v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17490v3","updated":"2024-12-11T16:31:21Z","published":"2024-09-26T02:54:19Z","title":"MathDSL: A Domain-Specific Language for Concise Mathematical Solutions\n  Via Program Synthesis","summary":"  We present MathDSL, a Domain-Specific Language (DSL) for mathematical\nequation solving, which, when deployed in program synthesis models, outperforms\nstate-of-the-art reinforcement-learning-based methods. We also introduce a\nquantitative metric for measuring the conciseness of a mathematical solution\nand demonstrate the improvement in the quality of generated solutions compared\nto other methods. Our system demonstrates that a program synthesis system\n(DreamCoder) using MathDSL can generate programs that solve linear equations\nwith greater accuracy and conciseness than using reinforcement learning\nsystems. Additionally, we demonstrate that if we use the action spaces of\nprevious reinforcement learning systems as DSLs, MathDSL outperforms the\naction-space-DSLs. We use DreamCoder to store equation-solving strategies as\nlearned abstractions in its program library and demonstrate that by using\nMathDSL, these can be converted into human-interpretable solution strategies\nthat could have applications in mathematical education.\n","authors":["Sagnik Anupam","Maddy Bowers","Omar Costilla-Reyes","Armando Solar-Lezama"],"pdf_url":"https://arxiv.org/pdf/2409.17490v3.pdf","comment":"There was a typo in Figure 1 (a step in the Lemma solution was\n  accidentally included twice). Additionally, our final experiment runs have\n  MathDSL using one less step for this question, and ConPoLe using one more\n  step to differentiate a division and a fraction in its final solution. Figure\n  1 has been updated to provide an exact copy of the experiment runs in the\n  GitHub repository"},{"id":"http://arxiv.org/abs/2412.06597v2","updated":"2024-12-11T16:28:18Z","published":"2024-12-09T15:47:36Z","title":"Self-Interested Agents in Collaborative Learning: An Incentivized\n  Adaptive Data-Centric Framework","summary":"  We propose a framework for adaptive data-centric collaborative learning among\nself-interested agents, coordinated by an arbiter. Designed to handle the\nincremental nature of real-world data, the framework operates in an online\nmanner: at each step, the arbiter collects a batch of data from agents, trains\na machine learning model, and provides each agent with a distinct model\nreflecting its data contributions. This setup establishes a feedback loop where\nshared data influence model updates, and the resulting models guide future\ndata-sharing strategies. Agents evaluate and partition their data, selecting a\npartition to share using a stochastic parameterized policy optimized via policy\ngradient methods to optimize the utility of the received model as defined by\nagent-specific evaluation functions. On the arbiter side, the expected loss\nfunction over the true data distribution is optimized, incorporating\nagent-specific weights to account for distributional differences arising from\ndiverse sources and selective sharing. A bilevel optimization algorithm jointly\nlearns the model parameters and agent-specific weights. Mean-zero noise,\ncomputed using a distortion function that adjusts these agent-specific weights,\nis introduced to generate distinct agent-specific models, promoting valuable\ndata sharing without requiring separate training. Our framework is underpinned\nby non-asymptotic analyses, ensuring convergence of the agent-side policy\noptimization to an approximate stationary point of the evaluation functions and\nconvergence of the arbiter-side optimization to an approximate stationary point\nof the expected loss function.\n","authors":["Nithia Vijayan","Bryan Kian Hsiang Low"],"pdf_url":"https://arxiv.org/pdf/2412.06597v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08515v1","updated":"2024-12-11T16:25:17Z","published":"2024-12-11T16:25:17Z","title":"Enhancing Interpretability Through Loss-Defined Classification Objective\n  in Structured Latent Spaces","summary":"  Supervised machine learning often operates on the data-driven paradigm,\nwherein internal model parameters are autonomously optimized to converge\npredicted outputs with the ground truth, devoid of explicitly programming rules\nor a priori assumptions. Although data-driven methods have yielded notable\nsuccesses across various benchmark datasets, they inherently treat models as\nopaque entities, thereby limiting their interpretability and yielding a lack of\nexplanatory insights into their decision-making processes. In this work, we\nintroduce Latent Boost, a novel approach that integrates advanced distance\nmetric learning into supervised classification tasks, enhancing both\ninterpretability and training efficiency. Thus during training, the model is\nnot only optimized for classification metrics of the discrete data points but\nalso adheres to the rule that the collective representation zones of each class\nshould be sharply clustered. By leveraging the rich structural insights of\nintermediate model layer latent representations, Latent Boost improves\nclassification interpretability, as demonstrated by higher Silhouette scores,\nwhile accelerating training convergence. These performance and latent\nstructural benefits are achieved with minimum additional cost, making it\nbroadly applicable across various datasets without requiring data-specific\nadjustments. Furthermore, Latent Boost introduces a new paradigm for aligning\nclassification performance with improved model transparency to address the\nchallenges of black-box models.\n","authors":["Daniel Geissler","Bo Zhou","Mengxi Liu","Paul Lukowicz"],"pdf_url":"https://arxiv.org/pdf/2412.08515v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08514v1","updated":"2024-12-11T16:25:06Z","published":"2024-12-11T16:25:06Z","title":"Image-Based Malware Classification Using QR and Aztec Codes","summary":"  In recent years, the use of image-based techniques for malware detection has\ngained prominence, with numerous studies demonstrating the efficacy of deep\nlearning approaches such as Convolutional Neural Networks (CNN) in classifying\nimages derived from executable files. In this paper, we consider an innovative\nmethod that relies on an image conversion process that consists of transforming\nfeatures extracted from executable files into QR and Aztec codes. These codes\ncapture structural patterns in a format that may enhance the learning\ncapabilities of CNNs. We design and implement CNN architectures tailored to the\nunique properties of these codes and apply them to a comprehensive analysis\ninvolving two extensive malware datasets, both of which include a significant\ncorpus of benign samples. Our results yield a split decision, with CNNs trained\non QR and Aztec codes outperforming the state of the art on one of the\ndatasets, but underperforming more typical techniques on the other dataset.\nThese results indicate that the use of QR and Aztec codes as a form of feature\nengineering holds considerable promise in the malware domain, and that\nadditional research is needed to better understand the relative strengths and\nweaknesses of such an approach.\n","authors":["Atharva Khadilkar","Mark Stamp"],"pdf_url":"https://arxiv.org/pdf/2412.08514v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08513v1","updated":"2024-12-11T16:24:31Z","published":"2024-12-11T16:24:31Z","title":"REPEAT: Improving Uncertainty Estimation in Representation Learning\n  Explainability","summary":"  Incorporating uncertainty is crucial to provide trustworthy explanations of\ndeep learning models. Recent works have demonstrated how uncertainty modeling\ncan be particularly important in the unsupervised field of representation\nlearning explainable artificial intelligence (R-XAI). Current R-XAI methods\nprovide uncertainty by measuring variability in the importance score. However,\nthey fail to provide meaningful estimates of whether a pixel is certainly\nimportant or not. In this work, we propose a new R-XAI method called REPEAT\nthat addresses the key question of whether or not a pixel is \\textit{certainly}\nimportant. REPEAT leverages the stochasticity of current R-XAI methods to\nproduce multiple estimates of importance, thus considering each pixel in an\nimage as a Bernoulli random variable that is either important or unimportant.\nFrom these Bernoulli random variables we can directly estimate the importance\nof a pixel and its associated certainty, thus enabling users to determine\ncertainty in pixel importance. Our extensive evaluation shows that REPEAT gives\ncertainty estimates that are more intuitive, better at detecting\nout-of-distribution data, and more concise.\n","authors":["Kristoffer K. Wickstrøm","Thea Brüsch","Michael C. Kampffmeyer","Robert Jenssen"],"pdf_url":"https://arxiv.org/pdf/2412.08513v1.pdf","comment":"Accepted at AAAI 2025. Code available at:\n  https://github.com/Wickstrom/REPEAT"},{"id":"http://arxiv.org/abs/2312.08977v4","updated":"2024-12-11T16:18:16Z","published":"2023-12-14T14:26:57Z","title":"Weighted Ensemble Models Are Strong Continual Learners","summary":"  In this work, we study the problem of continual learning (CL) where the goal\nis to learn a model on a sequence of tasks, such that the data from the\nprevious tasks becomes unavailable while learning on the current task data. CL\nis essentially a balancing act between being able to learn on the new task\n(i.e., plasticity) and maintaining the performance on the previously learned\nconcepts (i.e., stability). Intending to address the stability-plasticity\ntrade-off, we propose to perform weight-ensembling of the model parameters of\nthe previous and current tasks. This weighted-ensembled model, which we call\nContinual Model Averaging (or CoMA), attains high accuracy on the current task\nby leveraging plasticity, while not deviating too far from the previous weight\nconfiguration, ensuring stability. We also propose an improved variant of CoMA,\nnamed Continual Fisher-weighted Model Averaging (or CoFiMA), that selectively\nweighs each parameter in the weights ensemble by leveraging the Fisher\ninformation of the weights of the model. Both variants are conceptually simple,\neasy to implement, and effective in attaining state-of-the-art performance on\nseveral standard CL benchmarks. Code is available at:\nhttps://github.com/IemProg/CoFiMA.\n","authors":["Imad Eddine Marouf","Subhankar Roy","Enzo Tartaglione","Stéphane Lathuilière"],"pdf_url":"https://arxiv.org/pdf/2312.08977v4.pdf","comment":"Accepted for ECCV2024, Code: https://github.com/IemProg/CoFiMA"},{"id":"http://arxiv.org/abs/2412.08501v1","updated":"2024-12-11T16:07:58Z","published":"2024-12-11T16:07:58Z","title":"GradStop: Exploring Training Dynamics in Unsupervised Outlier Detection\n  through Gradient Cohesion","summary":"  Unsupervised Outlier Detection (UOD) is a critical task in data mining and\nmachine learning, aiming to identify instances that significantly deviate from\nthe majority. Without any label, deep UOD methods struggle with the\nmisalignment between the model's direct optimization goal and the final\nperformance goal of Outlier Detection (OD) task. Through the perspective of\ntraining dynamics, this paper proposes an early stopping algorithm to optimize\nthe training of deep UOD models, ensuring they perform optimally in OD rather\nthan overfitting the entire contaminated dataset.\n  Inspired by UOD mechanism and inlier priority phenomenon, where intuitively\nmodels fit inliers more quickly than outliers, we propose GradStop, a\nsampling-based label-free algorithm to estimate model's real-time performance\nduring training. First, a sampling method generates two sets: one likely\ncontaining more outliers and the other more inliers, then a metric based on\ngradient cohesion is applied to probe into current training dynamics, which\nreflects model's performance on OD task.\n  Experimental results on 4 deep UOD algorithms and 47 real-world datasets and\ntheoretical proofs demonstrate the effectiveness of our proposed early stopping\nalgorithm in enhancing the performance of deep UOD models. Auto Encoder (AE)\nenhanced by GradStop achieves better performance than itself, other SOTA UOD\nmethods, and even ensemble AEs. Our method provides a robust and effective\nsolution to the problem of performance degradation during training, enabling\ndeep UOD models to achieve better potential in anomaly detection tasks.\n","authors":["Yuang Zhang","Liping Wang","Yihong Huang","Yuanxing Zheng"],"pdf_url":"https://arxiv.org/pdf/2412.08501v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07000v2","updated":"2024-12-11T15:58:46Z","published":"2024-12-09T21:10:22Z","title":"Extreme AutoML: Analysis of Classification, Regression, and NLP\n  Performance","summary":"  Utilizing machine learning techniques has always required choosing\nhyperparameters. This is true whether one uses a classical technique such as a\nKNN or very modern neural networks such as Deep Learning. Though in many\napplications, hyperparameters are chosen by hand, automated methods have become\nincreasingly more common. These automated methods have become collectively\nknown as automated machine learning, or AutoML. Several automated selection\nalgorithms have shown similar or improved performance over state-of-the-art\nmethods. This breakthrough has led to the development of cloud-based services\nlike Google AutoML, which is based on Deep Learning and is widely considered to\nbe the industry leader in AutoML services. Extreme Learning Machines (ELMs) use\na fundamentally different type of neural architecture, producing better results\nat a significantly discounted computational cost. We benchmark the Extreme\nAutoML technology against Google's AutoML using several popular classification\ndata sets from the University of California at Irvine's (UCI) repository, and\nseveral other data sets, observing significant advantages for Extreme AutoML in\naccuracy, Jaccard Indices, the variance of Jaccard Indices across classes (i.e.\nclass variance) and training times.\n","authors":["Edward Ratner","Elliot Farmer","Brandon Warner","Christopher Douglas","Amaury Lendasse"],"pdf_url":"https://arxiv.org/pdf/2412.07000v2.pdf","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2402.02225v4","updated":"2024-12-11T15:50:56Z","published":"2024-02-03T17:58:43Z","title":"Rethinking the Starting Point: Collaborative Pre-Training for Federated\n  Downstream Tasks","summary":"  A few recent studies have demonstrated that leveraging centrally pre-trained\nmodels can offer advantageous initializations for federated learning (FL).\nHowever, existing pre-training methods do not generalize well when faced with\nan arbitrary set of downstream FL tasks. Specifically, they often (i) achieve\nlimited average accuracy, particularly when there are unseen downstream labels,\nand (ii) result in significant accuracy variance, failing to provide a balanced\nperformance across clients. To address these challenges, we propose CoPreFL, a\ncollaborative/distributed pre-training approach which provides a robust\ninitialization for downstream FL tasks. The key idea of CoPreFL is a\nmodel-agnostic meta-learning (MAML) procedure that tailors the global model to\nclosely mimic heterogeneous and unseen FL scenarios, resulting in a pre-trained\nmodel that is rapidly adaptable to arbitrary FL tasks. Our MAML procedure\nincorporates performance variance into the meta-objective function, balancing\nperformance across clients rather than solely optimizing for accuracy. Through\nextensive experiments, we demonstrate that CoPreFL obtains significant\nimprovements in both average accuracy and variance across arbitrary downstream\nFL tasks with unseen/seen labels, compared with various pre-training baselines.\nWe also show how CoPreFL is compatible with different well-known FL algorithms\napplied by the downstream tasks, enhancing performance in each case.\n","authors":["Yun-Wei Chu","Dong-Jun Han","Seyyedali Hosseinalipour","Christopher G. Brinton"],"pdf_url":"https://arxiv.org/pdf/2402.02225v4.pdf","comment":"AAAI 2025"},{"id":"http://arxiv.org/abs/2412.08480v1","updated":"2024-12-11T15:47:11Z","published":"2024-12-11T15:47:11Z","title":"InvDiff: Invariant Guidance for Bias Mitigation in Diffusion Models","summary":"  As one of the most successful generative models, diffusion models have\ndemonstrated remarkable efficacy in synthesizing high-quality images. These\nmodels learn the underlying high-dimensional data distribution in an\nunsupervised manner. Despite their success, diffusion models are highly\ndata-driven and prone to inheriting the imbalances and biases present in\nreal-world data. Some studies have attempted to address these issues by\ndesigning text prompts for known biases or using bias labels to construct\nunbiased data. While these methods have shown improved results, real-world\nscenarios often contain various unknown biases, and obtaining bias labels is\nparticularly challenging. In this paper, we emphasize the necessity of\nmitigating bias in pre-trained diffusion models without relying on auxiliary\nbias annotations. To tackle this problem, we propose a framework, InvDiff,\nwhich aims to learn invariant semantic information for diffusion guidance.\nSpecifically, we propose identifying underlying biases in the training data and\ndesigning a novel debiasing training objective. Then, we employ a lightweight\ntrainable module that automatically preserves invariant semantic information\nand uses it to guide the diffusion model's sampling process toward unbiased\noutcomes simultaneously. Notably, we only need to learn a small number of\nparameters in the lightweight learnable module without altering the pre-trained\ndiffusion model. Furthermore, we provide a theoretical guarantee that the\nimplementation of InvDiff is equivalent to reducing the error upper bound of\ngeneralization. Extensive experimental results on three publicly available\nbenchmarks demonstrate that InvDiff effectively reduces biases while\nmaintaining the quality of image generation. Our code is available at\nhttps://github.com/Hundredl/InvDiff.\n","authors":["Min Hou","Yueying Wu","Chang Xu","Yu-Hao Huang","Chenxi Bai","Le Wu","Jiang Bian"],"pdf_url":"https://arxiv.org/pdf/2412.08480v1.pdf","comment":"KDD 2025"},{"id":"http://arxiv.org/abs/2405.20313v2","updated":"2024-12-11T15:42:13Z","published":"2024-05-30T17:53:50Z","title":"Sequence-Augmented SE(3)-Flow Matching For Conditional Protein Backbone\n  Generation","summary":"  Proteins are essential for almost all biological processes and derive their\ndiverse functions from complex 3D structures, which are in turn determined by\ntheir amino acid sequences. In this paper, we exploit the rich biological\ninductive bias of amino acid sequences and introduce FoldFlow-2, a novel\nsequence-conditioned SE(3)-equivariant flow matching model for protein\nstructure generation. FoldFlow-2 presents substantial new architectural\nfeatures over the previous FoldFlow family of models including a protein large\nlanguage model to encode sequence, a new multi-modal fusion trunk that combines\nstructure and sequence representations, and a geometric transformer based\ndecoder. To increase diversity and novelty of generated samples -- crucial for\nde-novo drug design -- we train FoldFlow-2 at scale on a new dataset that is an\norder of magnitude larger than PDB datasets of prior works, containing both\nknown proteins in PDB and high-quality synthetic structures achieved through\nfiltering. We further demonstrate the ability to align FoldFlow-2 to arbitrary\nrewards, e.g. increasing secondary structures diversity, by introducing a\nReinforced Finetuning (ReFT) objective. We empirically observe that FoldFlow-2\noutperforms previous state-of-the-art protein structure-based generative\nmodels, improving over RFDiffusion in terms of unconditional generation across\nall metrics including designability, diversity, and novelty across all protein\nlengths, as well as exhibiting generalization on the task of equilibrium\nconformation sampling. Finally, we demonstrate that a fine-tuned FoldFlow-2\nmakes progress on challenging conditional design tasks such as designing\nscaffolds for the VHH nanobody.\n","authors":["Guillaume Huguet","James Vuckovic","Kilian Fatras","Eric Thibodeau-Laufer","Pablo Lemos","Riashat Islam","Cheng-Hao Liu","Jarrid Rector-Brooks","Tara Akhound-Sadegh","Michael Bronstein","Alexander Tong","Avishek Joey Bose"],"pdf_url":"https://arxiv.org/pdf/2405.20313v2.pdf","comment":"Presented at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2405.12910v2","updated":"2024-12-11T15:40:54Z","published":"2024-05-21T16:30:25Z","title":"Topic Classification of Case Law Using a Large Language Model and a New\n  Taxonomy for UK Law: AI Insights into Summary Judgment","summary":"  This paper addresses a critical gap in legal analytics by developing and\napplying a novel taxonomy for topic classification of summary judgment cases in\nthe United Kingdom. Using a curated dataset of summary judgment cases, we use\nthe Large Language Model Claude 3 Opus to explore functional topics and trends.\nWe find that Claude 3 Opus correctly classified the topic with an accuracy of\n87.13% and an F1 score of 0.87. The analysis reveals distinct patterns in the\napplication of summary judgments across various legal domains. As case law in\nthe United Kingdom is not originally labelled with keywords or a topic\nfiltering option, the findings not only refine our understanding of the\nthematic underpinnings of summary judgments but also illustrate the potential\nof combining traditional and AI-driven approaches in legal classification.\nTherefore, this paper provides a new and general taxonomy for UK law. The\nimplications of this work serve as a foundation for further research and policy\ndiscussions in the field of judicial administration and computational legal\nresearch methodologies.\n","authors":["Holli Sargeant","Ahmed Izzidien","Felix Steffek"],"pdf_url":"https://arxiv.org/pdf/2405.12910v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08463v1","updated":"2024-12-11T15:28:04Z","published":"2024-12-11T15:28:04Z","title":"IRL for Restless Multi-Armed Bandits with Applications in Maternal and\n  Child Health","summary":"  Public health practitioners often have the goal of monitoring patients and\nmaximizing patients' time spent in \"favorable\" or healthy states while being\nconstrained to using limited resources. Restless multi-armed bandits (RMAB) are\nan effective model to solve this problem as they are helpful to allocate\nlimited resources among many agents under resource constraints, where patients\nbehave differently depending on whether they are intervened on or not. However,\nRMABs assume the reward function is known. This is unrealistic in many public\nhealth settings because patients face unique challenges and it is impossible\nfor a human to know who is most deserving of any intervention at such a large\nscale. To address this shortcoming, this paper is the first to present the use\nof inverse reinforcement learning (IRL) to learn desired rewards for RMABs, and\nwe demonstrate improved outcomes in a maternal and child health telehealth\nprogram. First we allow public health experts to specify their goals at an\naggregate or population level and propose an algorithm to design expert\ntrajectories at scale based on those goals. Second, our algorithm WHIRL uses\ngradient updates to optimize the objective, allowing for efficient and accurate\nlearning of RMAB rewards. Third, we compare with existing baselines and\noutperform those in terms of run-time and accuracy. Finally, we evaluate and\nshow the usefulness of WHIRL on thousands on beneficiaries from a real-world\nmaternal and child health setting in India. We publicly release our code here:\nhttps://github.com/Gjain234/WHIRL.\n","authors":["Gauri Jain","Pradeep Varakantham","Haifeng Xu","Aparna Taneja","Prashant Doshi","Milind Tambe"],"pdf_url":"https://arxiv.org/pdf/2412.08463v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08460v1","updated":"2024-12-11T15:25:38Z","published":"2024-12-11T15:25:38Z","title":"Federated Learning for Traffic Flow Prediction with Synthetic Data\n  Augmentation","summary":"  Deep-learning based traffic prediction models require vast amounts of data to\nlearn embedded spatial and temporal dependencies. The inherent privacy and\ncommercial sensitivity of such data has encouraged a shift towards\ndecentralised data-driven methods, such as Federated Learning (FL). Under a\ntraditional Machine Learning paradigm, traffic flow prediction models can\ncapture spatial and temporal relationships within centralised data. In reality,\ntraffic data is likely distributed across separate data silos owned by multiple\nstakeholders. In this work, a cross-silo FL setting is motivated to facilitate\nstakeholder collaboration for optimal traffic flow prediction applications.\nThis work introduces an FL framework, referred to as FedTPS, to generate\nsynthetic data to augment each client's local dataset by training a\ndiffusion-based trajectory generation model through FL. The proposed framework\nis evaluated on a large-scale real world ride-sharing dataset using various FL\nmethods and Traffic Flow Prediction models, including a novel prediction model\nwe introduce, which leverages Temporal and Graph Attention mechanisms to learn\nthe Spatio-Temporal dependencies embedded within regional traffic flow data.\nExperimental results show that FedTPS outperforms multiple other FL baselines\nwith respect to global model performance.\n","authors":["Fermin Orozco","Pedro Porto Buarque de Gusmão","Hongkai Wen","Johan Wahlström","Man Luo"],"pdf_url":"https://arxiv.org/pdf/2412.08460v1.pdf","comment":"11 pages, 7 figures, 6 tables, ACM format"},{"id":"http://arxiv.org/abs/2412.08457v1","updated":"2024-12-11T15:24:07Z","published":"2024-12-11T15:24:07Z","title":"Efficient Rectification of Neuro-Symbolic Reasoning Inconsistencies by\n  Abductive Reflection","summary":"  Neuro-Symbolic (NeSy) AI could be regarded as an analogy to human\ndual-process cognition, modeling the intuitive System 1 with neural networks\nand the algorithmic System 2 with symbolic reasoning. However, for complex\nlearning targets, NeSy systems often generate outputs inconsistent with domain\nknowledge and it is challenging to rectify them. Inspired by the human\nCognitive Reflection, which promptly detects errors in our intuitive response\nand revises them by invoking the System 2 reasoning, we propose to improve NeSy\nsystems by introducing Abductive Reflection (ABL-Refl) based on the Abductive\nLearning (ABL) framework. ABL-Refl leverages domain knowledge to abduce a\nreflection vector during training, which can then flag potential errors in the\nneural network outputs and invoke abduction to rectify them and generate\nconsistent outputs during inference. ABL-Refl is highly efficient in contrast\nto previous ABL implementations. Experiments show that ABL-Refl outperforms\nstate-of-the-art NeSy methods, achieving excellent accuracy with fewer training\nresources and enhanced efficiency.\n","authors":["Wen-Chao Hu","Wang-Zhou Dai","Yuan Jiang","Zhi-Hua Zhou"],"pdf_url":"https://arxiv.org/pdf/2412.08457v1.pdf","comment":"Accepted to AAAI 2025"},{"id":"http://arxiv.org/abs/2410.21453v2","updated":"2024-12-11T15:23:23Z","published":"2024-10-28T18:57:15Z","title":"Inverting Gradient Attacks Makes Powerful Data Poisoning","summary":"  Gradient attacks and data poisoning tamper with the training of machine\nlearning algorithms to maliciously alter them and have been proven to be\nequivalent in convex settings. The extent of harm these attacks can produce in\nnon-convex settings is still to be determined. Gradient attacks can affect far\nless systems than data poisoning but have been argued to be more harmful since\nthey can be arbitrary, whereas data poisoning reduces the attacker's power to\nonly being able to inject data points to training sets, via e.g. legitimate\nparticipation in a collaborative dataset. This raises the question of whether\nthe harm made by gradient attacks can be matched by data poisoning in\nnon-convex settings. In this work, we provide a positive answer in a worst-case\nscenario and show how data poisoning can mimic a gradient attack to perform an\navailability attack on (non-convex) neural networks. Through gradient\ninversion, commonly used to reconstruct data points from actual gradients, we\nshow how reconstructing data points out of malicious gradients can be\nsufficient to perform a range of attacks. This allows us to show, for the first\ntime, an availability attack on neural networks through data poisoning, that\ndegrades the model's performances to random-level through a minority (as low as\n1%) of poisoned points.\n","authors":["Wassim Bouaziz","El-Mahdi El-Mhamdi","Nicolas Usunier"],"pdf_url":"https://arxiv.org/pdf/2410.21453v2.pdf","comment":"12 pages, 11 figures"},{"id":"http://arxiv.org/abs/2304.14385v3","updated":"2024-12-11T15:22:52Z","published":"2023-04-27T17:52:06Z","title":"Dynamic Pricing and Advertising with Demand Learning","summary":"  We consider a novel pricing and advertising framework, where a seller not\nonly sets product price but also designs flexible 'advertising schemes' to\ninfluence customers' valuation of the product. We impose no structural\nrestriction on the seller's feasible advertising strategies and allow her to\nadvertise the product by disclosing or concealing any information. Following\nthe literature in information design, this fully flexible advertising can be\nmodeled as the seller being able to choose any information policy that signals\nthe product quality/characteristic to the customers. Customers observe the\nadvertising signal and infer a Bayesian belief over the products. We aim to\ninvestigate two questions in this work: (1) What is the value of advertising?\nTo what extent can advertising enhance a seller's revenue? (2) Without any\napriori knowledge of the customers' demand function, how can a seller\nadaptively learn and optimize both pricing and advertising strategies using\npast purchase responses?\n  To study the first question, we introduce and study the value of advertising\n- a revenue gap between using advertising vs not advertising, and we provide a\ncrisp tight characterization for this notion for a broad family of problems.\nFor the second question, we study the seller's dynamic pricing and advertising\nproblem with demand uncertainty. Our main result for this question is a\ncomputationally efficient online algorithm that achieves an optimal\n$O(T^{2/3}(m\\log T)^{1/3})$ regret rate when the valuation function is linear\nin the product quality. Here $m$ is the cardinality of the discrete product\nquality domain and $T$ is the time horizon. This result requires some mild\nregularity assumptions on the valuation function, but no Lipschitz or\nsmoothness assumption on the customers' demand function. We also obtain several\nimproved results for the widely considered special case of additive valuations.\n","authors":["Shipra Agrawal","Yiding Feng","Wei Tang"],"pdf_url":"https://arxiv.org/pdf/2304.14385v3.pdf","comment":"Added new results, including a new section for detailed analysis of\n  value of advertising, a section for numerical results. Also rewrite the\n  introduction and setting section"},{"id":"http://arxiv.org/abs/2412.02730v2","updated":"2024-12-11T15:22:32Z","published":"2024-12-03T16:29:37Z","title":"Shaping AI's Impact on Billions of Lives","summary":"  Artificial Intelligence (AI), like any transformative technology, has the\npotential to be a double-edged sword, leading either toward significant\nadvancements or detrimental outcomes for society as a whole. As is often the\ncase when it comes to widely-used technologies in market economies (e.g., cars\nand semiconductor chips), commercial interest tends to be the predominant\nguiding factor. The AI community is at risk of becoming polarized to either\ntake a laissez-faire attitude toward AI development, or to call for government\noverregulation. Between these two poles we argue for the community of AI\npractitioners to consciously and proactively work for the common good. This\npaper offers a blueprint for a new type of innovation infrastructure including\n18 concrete milestones to guide AI research in that direction. Our view is that\nwe are still in the early days of practical AI, and focused efforts by\npractitioners, policymakers, and other stakeholders can still maximize the\nupsides of AI and minimize its downsides.\n  We talked to luminaries such as recent Nobelist John Jumper on science,\nPresident Barack Obama on governance, former UN Ambassador and former National\nSecurity Advisor Susan Rice on security, philanthropist Eric Schmidt on several\ntopics, and science fiction novelist Neal Stephenson on entertainment. This\nongoing dialogue and collaborative effort has produced a comprehensive,\nrealistic view of what the actual impact of AI could be, from a diverse\nassembly of thinkers with deep understanding of this technology and these\ndomains. From these exchanges, five recurring guidelines emerged, which form\nthe cornerstone of a framework for beginning to harness AI in service of the\npublic good. They not only guide our efforts in discovery but also shape our\napproach to deploying this transformative technology responsibly and ethically.\n","authors":["Mariano-Florentino Cuéllar","Jeff Dean","Finale Doshi-Velez","John Hennessy","Andy Konwinski","Sanmi Koyejo","Pelonomi Moiloa","Emma Pierson","David Patterson"],"pdf_url":"https://arxiv.org/pdf/2412.02730v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08453v1","updated":"2024-12-11T15:16:16Z","published":"2024-12-11T15:16:16Z","title":"On best approximation by multivariate ridge functions with applications\n  to generalized translation networks","summary":"  We prove sharp upper and lower bounds for the approximation of Sobolev\nfunctions by sums of multivariate ridge functions, i.e., functions of the form\n$\\mathbb{R}^d \\ni x \\mapsto \\sum_{k=1}^n h_k(A_k x) \\in \\mathbb{R}$ with $h_k :\n\\mathbb{R}^\\ell \\to \\mathbb{R}$ and $A_k \\in \\mathbb{R}^{\\ell \\times d}$. We\nshow that the order of approximation asymptotically behaves as\n$n^{-r/(d-\\ell)}$, where $r$ is the regularity of the Sobolev functions to be\napproximated. Our lower bound even holds when approximating $L^\\infty$-Sobolev\nfunctions of regularity $r$ with error measured in $L^1$, while our upper bound\napplies to the approximation of $L^p$-Sobolev functions in $L^p$ for any $1\n\\leq p \\leq \\infty$. These bounds generalize well-known results about the\napproximation properties of univariate ridge functions to the multivariate\ncase. Moreover, we use these bounds to obtain sharp asymptotic bounds for the\napproximation of Sobolev functions using generalized translation networks and\ncomplex-valued neural networks.\n","authors":["Paul Geuchen","Palina Salanevich","Olov Schavemaker","Felix Voigtlaender"],"pdf_url":"https://arxiv.org/pdf/2412.08453v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.16866v3","updated":"2024-12-11T15:14:05Z","published":"2024-04-18T09:37:54Z","title":"Annotation-guided Protein Design with Multi-Level Domain Alignment","summary":"  The core challenge of de novo protein design lies in creating proteins with\nspecific functions or properties, guided by certain conditions. Current models\nexplore to generate protein using structural and evolutionary guidance, which\nonly provide indirect conditions concerning functions and properties. However,\ntextual annotations of proteins, especially the annotations for protein\ndomains, which directly describe the protein's high-level functionalities,\nproperties, and their correlation with target amino acid sequences, remain\nunexplored in the context of protein design tasks. In this paper, we propose\nProtein-Annotation Alignment Generation, PAAG, a multi-modality protein design\nframework that integrates the textual annotations extracted from protein\ndatabase for controllable generation in sequence space. Specifically, within a\nmulti-level alignment module, PAAG can explicitly generate proteins containing\nspecific domains conditioned on the corresponding domain annotations, and can\neven design novel proteins with flexible combinations of different kinds of\nannotations. Our experimental results underscore the superiority of the aligned\nprotein representations from PAAG over 7 prediction tasks. Furthermore, PAAG\ndemonstrates a significant increase in generation success rate (24.7% vs 4.7%\nin zinc finger, and 54.3% vs 22.0% in the immunoglobulin domain) in comparison\nto the existing model. We anticipate that PAAG will broaden the horizons of\nprotein design by leveraging the knowledge from between textual annotation and\nproteins.\n","authors":["Chaohao Yuan","Songyou Li","Geyan Ye","Yikun Zhang","Long-Kai Huang","Wenbing Huang","Wei Liu","Jianhua Yao","Yu Rong"],"pdf_url":"https://arxiv.org/pdf/2404.16866v3.pdf","comment":"Accepted by KDD 2025"},{"id":"http://arxiv.org/abs/2412.08442v1","updated":"2024-12-11T15:06:25Z","published":"2024-12-11T15:06:25Z","title":"From Multimodal LLMs to Generalist Embodied Agents: Methods and Lessons","summary":"  We examine the capability of Multimodal Large Language Models (MLLMs) to\ntackle diverse domains that extend beyond the traditional language and vision\ntasks these models are typically trained on. Specifically, our focus lies in\nareas such as Embodied AI, Games, UI Control, and Planning. To this end, we\nintroduce a process of adapting an MLLM to a Generalist Embodied Agent (GEA).\nGEA is a single unified model capable of grounding itself across these varied\ndomains through a multi-embodiment action tokenizer. GEA is trained with\nsupervised learning on a large dataset of embodied experiences and with online\nRL in interactive simulators. We explore the data and algorithmic choices\nnecessary to develop such a model. Our findings reveal the importance of\ntraining with cross-domain data and online RL for building generalist agents.\nThe final GEA model achieves strong generalization performance to unseen tasks\nacross diverse benchmarks compared to other generalist models and\nbenchmark-specific approaches.\n","authors":["Andrew Szot","Bogdan Mazoure","Omar Attia","Aleksei Timofeev","Harsh Agrawal","Devon Hjelm","Zhe Gan","Zsolt Kira","Alexander Toshev"],"pdf_url":"https://arxiv.org/pdf/2412.08442v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.00420v2","updated":"2024-12-11T15:03:08Z","published":"2024-03-01T10:16:46Z","title":"Robust Deep Reinforcement Learning Through Adversarial Attacks and\n  Training : A Survey","summary":"  Deep Reinforcement Learning (DRL) is a subfield of machine learning for\ntraining autonomous agents that take sequential actions across complex\nenvironments. Despite its significant performance in well-known environments,\nit remains susceptible to minor condition variations, raising concerns about\nits reliability in real-world applications. To improve usability, DRL must\ndemonstrate trustworthiness and robustness. A way to improve the robustness of\nDRL to unknown changes in the environmental conditions and possible\nperturbations is through Adversarial Training, by training the agent against\nwell-suited adversarial attacks on the observations and the dynamics of the\nenvironment. Addressing this critical issue, our work presents an in-depth\nanalysis of contemporary adversarial attack and training methodologies,\nsystematically categorizing them and comparing their objectives and operational\nmechanisms.\n","authors":["Lucas Schott","Josephine Delas","Hatem Hajri","Elies Gherbi","Reda Yaich","Nora Boulahia-Cuppens","Frederic Cuppens","Sylvain Lamprier"],"pdf_url":"https://arxiv.org/pdf/2403.00420v2.pdf","comment":"61 pages, 17 figues, 1 table"},{"id":"http://arxiv.org/abs/2412.08435v1","updated":"2024-12-11T14:57:10Z","published":"2024-12-11T14:57:10Z","title":"Proactive Model Adaptation Against Concept Drift for Online Time Series\n  Forecasting","summary":"  Time series forecasting always faces the challenge of concept drift, where\ndata distributions evolve over time, leading to a decline in forecast model\nperformance. Existing solutions are based on online learning, which continually\norganize recent time series observations as new training samples and update\nmodel parameters according to the forecasting feedback on recent data. However,\nthey overlook a critical issue: obtaining ground-truth future values of each\nsample should be delayed until after the forecast horizon. This delay creates a\ntemporal gap between the training samples and the test sample. Our empirical\nanalysis reveals that the gap can introduce concept drift, causing forecast\nmodels to adapt to outdated concepts. In this paper, we present\n\\textsc{Proceed}, a novel proactive model adaptation framework for online time\nseries forecasting. \\textsc{Proceed} first operates by estimating the concept\ndrift between the recently used training samples and the current test sample.\nIt then employs an adaptation generator to efficiently translate the estimated\ndrift into parameter adjustments, proactively adapting the model to the test\nsample. To enhance the generalization capability of the framework,\n\\textsc{Proceed} is trained on synthetic diverse concept drifts. We conduct\nextensive experiments on five real-world datasets across various forecast\nmodels. The empirical study demonstrates that our proposed \\textsc{Proceed}\nbrings more performance improvements than the state-of-the-art online learning\nmethods, significantly facilitating forecast models' resilience against concept\ndrifts.\n","authors":["Lifan Zhao","Yanyan Shen"],"pdf_url":"https://arxiv.org/pdf/2412.08435v1.pdf","comment":"Accepted by KDD 2025. Preprint version"},{"id":"http://arxiv.org/abs/2307.08558v3","updated":"2024-12-11T14:53:27Z","published":"2023-07-17T15:15:47Z","title":"Nonlinear optical encoding enabled by recurrent linear scattering","summary":"  Optical information processing and computing can potentially offer enhanced\nperformance, scalability and energy efficiency. However, achieving\nnonlinearity-a critical component of computation-remains challenging in the\noptical domain. Here we introduce a design that leverages a multiple-scattering\ncavity to passively induce optical nonlinear random mapping with a\ncontinuous-wave laser at a low power. Each scattering event effectively mixes\ninformation from different areas of a spatial light modulator, resulting in a\nhighly nonlinear mapping between the input data and output pattern. We\ndemonstrate that our design retains vital information even when the readout\ndimensionality is reduced, thereby enabling optical data compression. This\ncapability allows our optical platforms to offer efficient optical information\nprocessing solutions across applications. We demonstrate our design's efficacy\nacross tasks, including classification, image reconstruction, keypoint\ndetection and object detection, all of which are achieved through optical data\ncompression combined with a digital decoder. In particular, high performance at\nextreme compression ratios is observed in real-time pedestrian detection. Our\nfindings open pathways for novel algorithms and unconventional architectural\ndesigns for optical computing.\n","authors":["Fei Xia","Kyungduk Kim","Yaniv Eliezer","SeungYun Han","Liam Shaughnessy","Sylvain Gigan","Hui Cao"],"pdf_url":"https://arxiv.org/pdf/2307.08558v3.pdf","comment":"14 pages, 4 figures"},{"id":"http://arxiv.org/abs/2412.08426v1","updated":"2024-12-11T14:47:19Z","published":"2024-12-11T14:47:19Z","title":"Koopman Theory-Inspired Method for Learning Time Advancement Operators\n  in Unstable Flame Front Evolution","summary":"  Predicting the evolution of complex systems governed by partial differential\nequations (PDEs) remains challenging, especially for nonlinear, chaotic\nbehaviors. This study introduces Koopman-inspired Fourier Neural Operators\n(kFNO) and Convolutional Neural Networks (kCNN) to learn solution advancement\noperators for flame front instabilities. By transforming data into a\nhigh-dimensional latent space, these models achieve more accurate multi-step\npredictions compared to traditional methods. Benchmarking across one- and\ntwo-dimensional flame front scenarios demonstrates the proposed approaches'\nsuperior performance in short-term accuracy and long-term statistical\nreproduction, offering a promising framework for modeling complex dynamical\nsystems.\n","authors":["Rixin Yu","Marco Herbert","Markus Klein","Erdzan Hodzic"],"pdf_url":"https://arxiv.org/pdf/2412.08426v1.pdf","comment":"28 pages, 12 figures"},{"id":"http://arxiv.org/abs/2207.11759v2","updated":"2024-12-11T14:47:01Z","published":"2022-07-24T15:13:45Z","title":"Spatial-Temporal Federated Learning for Lifelong Person\n  Re-identification on Distributed Edges","summary":"  Data drift is a thorny challenge when deploying person re-identification\n(ReID) models into real-world devices, where the data distribution is\nsignificantly different from that of the training environment and keeps\nchanging. To tackle this issue, we propose a federated spatial-temporal\nincremental learning approach, named FedSTIL, which leverages both lifelong\nlearning and federated learning to continuously optimize models deployed on\nmany distributed edge clients. Unlike previous efforts, FedSTIL aims to mine\nspatial-temporal correlations among the knowledge learnt from different edge\nclients. Specifically, the edge clients first periodically extract general\nrepresentations of drifted data to optimize their local models. Then, the\nlearnt knowledge from edge clients will be aggregated by centralized parameter\nserver, where the knowledge will be selectively and attentively distilled from\nspatial- and temporal-dimension with carefully designed mechanisms. Finally,\nthe distilled informative spatial-temporal knowledge will be sent back to\ncorrelated edge clients to further improve the recognition accuracy of each\nedge client with a lifelong learning method. Extensive experiments on a mixture\nof five real-world datasets demonstrate that our method outperforms others by\nnearly 4% in Rank-1 accuracy, while reducing communication cost by 62%. All\nimplementation codes are publicly available on\nhttps://github.com/MSNLAB/Federated-Lifelong-Person-ReID\n","authors":["Lei Zhang","Guanyu Gao","Huaizheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2207.11759v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08424v1","updated":"2024-12-11T14:43:39Z","published":"2024-12-11T14:43:39Z","title":"From Logistic Regression to the Perceptron Algorithm: Exploring Gradient\n  Descent with Large Step Sizes","summary":"  We focus on the classification problem with a separable dataset, one of the\nmost important and classical problems from machine learning. The standard\napproach to this task is logistic regression with gradient descent (LR+GD).\nRecent studies have observed that LR+GD can find a solution with arbitrarily\nlarge step sizes, defying conventional optimization theory. Our work\ninvestigates this phenomenon and makes three interconnected key observations\nabout LR+GD with large step sizes. First, we find a remarkably simple\nexplanation of why LR+GD with large step sizes solves the classification\nproblem: LR+GD reduces to a batch version of the celebrated perceptron\nalgorithm when the step size $\\gamma \\to \\infty.$ Second, we observe that\nlarger step sizes lead LR+GD to higher logistic losses when it tends to the\nperceptron algorithm, but larger step sizes also lead to faster convergence to\na solution for the classification problem, meaning that logistic loss is an\nunreliable metric of the proximity to a solution. Surprisingly, high loss\nvalues can actually indicate faster convergence. Third, since the convergence\nrate in terms of loss function values of LR+GD is unreliable, we examine the\niteration complexity required by LR+GD with large step sizes to solve the\nclassification problem and prove that this complexity is suboptimal. To address\nthis, we propose a new method, Normalized LR+GD - based on the connection\nbetween LR+GD and the perceptron algorithm - with much better theoretical\nguarantees.\n","authors":["Alexander Tyurin"],"pdf_url":"https://arxiv.org/pdf/2412.08424v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.05185v2","updated":"2024-12-11T14:43:02Z","published":"2024-12-06T17:04:42Z","title":"LinVT: Empower Your Image-level Large Language Model to Understand\n  Videos","summary":"  Large Language Models (LLMs) have been widely used in various tasks,\nmotivating us to develop an LLM-based assistant for videos. Instead of training\nfrom scratch, we propose a module to transform arbitrary well-trained\nimage-based LLMs into video-LLMs (after being trained on video data). To better\nadapt image-LLMs for processing videos, we introduce two design principles:\nlinear transformation to preserve the original visual-language alignment and\nrepresentative information condensation from redundant video content. Guided by\nthese principles, we propose a plug-and-play Linear Video Tokenizer(LinVT),\nwhich enables existing image-LLMs to understand videos. We benchmark LinVT with\nsix recent visual LLMs: Aquila, Blip-3, InternVL2, Mipha, Molmo and Qwen2-VL,\nshowcasing the high compatibility of LinVT. LinVT-based LLMs achieve\nstate-of-the-art performance across various video benchmarks, illustrating the\neffectiveness of LinVT in multi-modal video understanding.\n","authors":["Lishuai Gao","Yujie Zhong","Yingsen Zeng","Haoxian Tan","Dengjie Li","Zheng Zhao"],"pdf_url":"https://arxiv.org/pdf/2412.05185v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.01745v3","updated":"2024-12-11T14:40:46Z","published":"2023-09-04T18:01:42Z","title":"Benchmarking Autoregressive Conditional Diffusion Models for Turbulent\n  Flow Simulation","summary":"  Simulating turbulent flows is crucial for a wide range of applications, and\nmachine learning-based solvers are gaining increasing relevance. However,\nachieving temporal stability when generalizing to longer rollout horizons\nremains a persistent challenge for learned PDE solvers. In this work, we\nanalyze if fully data-driven fluid solvers that utilize an autoregressive\nrollout based on conditional diffusion models are a viable option to address\nthis challenge. We investigate accuracy, posterior sampling, spectral behavior,\nand temporal stability, while requiring that methods generalize to flow\nparameters beyond the training regime. To quantitatively and qualitatively\nbenchmark the performance of various flow prediction approaches, three\nchallenging 2D scenarios including incompressible and transonic flows, as well\nas isotropic turbulence are employed. We find that even simple diffusion-based\napproaches can outperform multiple established flow prediction methods in terms\nof accuracy and temporal stability, while being on par with state-of-the-art\nstabilization techniques like unrolling at training time. Such traditional\narchitectures are superior in terms of inference speed, however, the\nprobabilistic nature of diffusion approaches allows for inferring multiple\npredictions that align with the statistics of the underlying physics. Overall,\nour benchmark contains three carefully chosen data sets that are suitable for\nprobabilistic evaluation alongside various established flow prediction\narchitectures.\n","authors":["Georg Kohl","Li-Wei Chen","Nils Thuerey"],"pdf_url":"https://arxiv.org/pdf/2309.01745v3.pdf","comment":"Source code available at\n  https://github.com/tum-pbs/autoreg-pde-diffusion and further information and\n  videos at https://ge.in.tum.de/publications/2023-acdm-kohl"},{"id":"http://arxiv.org/abs/2412.08419v1","updated":"2024-12-11T14:35:37Z","published":"2024-12-11T14:35:37Z","title":"Robustness of Graph Classification: failure modes, causes, and\n  noise-resistant loss in Graph Neural Networks","summary":"  Graph Neural Networks (GNNs) are powerful at solving graph classification\ntasks, yet applied problems often contain noisy labels. In this work, we study\nGNN robustness to label noise, demonstrate GNN failure modes when models\nstruggle to generalise on low-order graphs, low label coverage, or when a model\nis over-parameterized. We establish both empirical and theoretical links\nbetween GNN robustness and the reduction of the total Dirichlet Energy of\nlearned node representations, which encapsulates the hypothesized GNN\nsmoothness inductive bias. Finally, we introduce two training strategies to\nenhance GNN robustness: (1) by incorporating a novel inductive bias in the\nweight matrices through the removal of negative eigenvalues, connected to\nDirichlet Energy minimization; (2) by extending to GNNs a loss penalty that\npromotes learned smoothness. Importantly, neither approach negatively impacts\nperformance in noise-free settings, supporting our hypothesis that the source\nof GNNs robustness is their smoothness inductive bias.\n","authors":["Farooq Ahmad Wani","Maria Sofia Bucarelli","Andrea Giuseppe Di Francesco","Oleksandr Pryymak","Fabrizio Silvestri"],"pdf_url":"https://arxiv.org/pdf/2412.08419v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04877v3","updated":"2024-12-11T14:30:20Z","published":"2023-06-08T02:17:29Z","title":"TRIGS: Trojan Identification from Gradient-based Signatures","summary":"  Training machine learning models can be very expensive or even unaffordable.\nThis may be, for example, due to data limitations, such as unavailability or\nbeing too large, or computational power limitations. Therefore, it is a common\npractice to rely on open-source pre-trained models whenever possible.However,\nthis practice is alarming from a security perspective. Pre-trained models can\nbe infected with Trojan attacks, in which the attacker embeds a trigger in the\nmodel such that the model's behavior can be controlled by the attacker when the\ntrigger is present in the input. In this paper, we present a novel method for\ndetecting Trojan models. Our method creates a signature for a model based on\nactivation optimization. A classifier is then trained to detect a Trojan model\ngiven its signature. We call our method TRIGS for TRojan Identification from\nGradient-based Signatures. TRIGS achieves state-of-the-art performance on two\npublic datasets of convolutional models. Additionally, we introduce a new\nchallenging dataset of ImageNet models based on the vision transformer\narchitecture. TRIGS delivers the best performance on the new dataset,\nsurpassing the baseline methods by a large margin. Our experiments also show\nthat TRIGS requires only a small amount of clean samples to achieve good\nperformance, and works reasonably well even if the defender does not have prior\nknowledge about the attacker's model architecture. Our code and data are\npublicly available.\n","authors":["Mohamed E. Hussein","Sudharshan Subramaniam Janakiraman","Wael AbdAlmageed"],"pdf_url":"https://arxiv.org/pdf/2306.04877v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.05305v2","updated":"2024-12-11T14:26:35Z","published":"2024-11-26T20:26:14Z","title":"A Robust Clustering Framework Combining Minimum Description Length and\n  Genetic Optimization","summary":"  Clustering algorithms are fundamental in data analysis, enabling the\norganization of data into meaningful groups. However, individual clustering\nmethods often face limitations and biases, making it challenging to develop a\nuniversal solution for diverse datasets. To address this, we propose a novel\nclustering framework that combines the Minimum Description Length (MDL)\nprinciple with a genetic optimization algorithm. This approach begins with an\nensemble clustering solution as a baseline, which is refined using MDL-based\nevaluation functions and optimized with a genetic algorithm. By leveraging the\nMDL principle, the method adapts to the intrinsic properties of datasets,\nminimizing dependence on input clusters and ensuring a data-driven process. The\nproposed method was evaluated on thirteen benchmark datasets using four\nvalidation metrics: accuracy, normalized mutual information (NMI), Fisher\nscore, and adjusted Rand index (ARI). Results show that the method consistently\noutperforms traditional clustering algorithms, achieving higher accuracy,\ngreater stability, and reduced biases. Its adaptability makes it a reliable\ntool for clustering complex and varied datasets. This study demonstrates the\npotential of combining MDL and genetic optimization to create a robust and\nversatile clustering framework, advancing the field of data analysis and\noffering a scalable solution for diverse applications.\n","authors":["H. Jahani","F. Zamio"],"pdf_url":"https://arxiv.org/pdf/2412.05305v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08398v1","updated":"2024-12-11T14:17:17Z","published":"2024-12-11T14:17:17Z","title":"Grasp Diffusion Network: Learning Grasp Generators from Partial Point\n  Clouds with Diffusion Models in SO(3)xR3","summary":"  Grasping objects successfully from a single-view camera is crucial in many\nrobot manipulation tasks. An approach to solve this problem is to leverage\nsimulation to create large datasets of pairs of objects and grasp poses, and\nthen learn a conditional generative model that can be prompted quickly during\ndeployment. However, the grasp pose data is highly multimodal since there are\nseveral ways to grasp an object. Hence, in this work, we learn a grasp\ngenerative model with diffusion models to sample candidate grasp poses given a\npartial point cloud of an object. A novel aspect of our method is to consider\ndiffusion in the manifold space of rotations and to propose a\ncollision-avoidance cost guidance to improve the grasp success rate during\ninference. To accelerate grasp sampling we use recent techniques from the\ndiffusion literature to achieve faster inference times. We show in simulation\nand real-world experiments that our approach can grasp several objects from raw\ndepth images with $90\\%$ success rate and benchmark it against several\nbaselines.\n","authors":["Joao Carvalho","An T. Le","Philipp Jahr","Qiao Sun","Julen Urain","Dorothea Koert","Jan Peters"],"pdf_url":"https://arxiv.org/pdf/2412.08398v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.01329v2","updated":"2024-12-11T14:15:21Z","published":"2024-09-02T15:30:27Z","title":"Assessing the Impact of Image Dataset Features on Privacy-Preserving\n  Machine Learning","summary":"  Machine Learning (ML) is crucial in many sectors, including computer vision.\nHowever, ML models trained on sensitive data face security challenges, as they\ncan be attacked and leak information. Privacy-Preserving Machine Learning\n(PPML) addresses this by using Differential Privacy (DP) to balance utility and\nprivacy. This study identifies image dataset characteristics that affect the\nutility and vulnerability of private and non-private Convolutional Neural\nNetwork (CNN) models. Through analyzing multiple datasets and privacy budgets,\nwe find that imbalanced datasets increase vulnerability in minority classes,\nbut DP mitigates this issue. Datasets with fewer classes improve both model\nutility and privacy, while high entropy or low Fisher Discriminant Ratio (FDR)\ndatasets deteriorate the utility-privacy trade-off. These insights offer\nvaluable guidance for practitioners and researchers in estimating and\noptimizing the utility-privacy trade-off in image datasets, helping to inform\ndata and privacy modifications for better outcomes based on dataset\ncharacteristics.\n","authors":["Lucas Lange","Maurice-Maximilian Heykeroth","Erhard Rahm"],"pdf_url":"https://arxiv.org/pdf/2409.01329v2.pdf","comment":"Accepted at 21st Conference on Database Systems for Business,\n  Technology and Web (BTW 2025)"},{"id":"http://arxiv.org/abs/2412.08394v1","updated":"2024-12-11T14:14:02Z","published":"2024-12-11T14:14:02Z","title":"Adversarial Purification by Consistency-aware Latent Space Optimization\n  on Data Manifolds","summary":"  Deep neural networks (DNNs) are vulnerable to adversarial samples crafted by\nadding imperceptible perturbations to clean data, potentially leading to\nincorrect and dangerous predictions. Adversarial purification has been an\neffective means to improve DNNs robustness by removing these perturbations\nbefore feeding the data into the model. However, it faces significant\nchallenges in preserving key structural and semantic information of data, as\nthe imperceptible nature of adversarial perturbations makes it hard to avoid\nover-correcting, which can destroy important information and degrade model\nperformance. In this paper, we break away from traditional adversarial\npurification methods by focusing on the clean data manifold. To this end, we\nreveal that samples generated by a well-trained generative model are close to\nclean ones but far from adversarial ones. Leveraging this insight, we propose\nConsistency Model-based Adversarial Purification (CMAP), which optimizes\nvectors within the latent space of a pre-trained consistency model to generate\nsamples for restoring clean data. Specifically, 1) we propose a\n\\textit{Perceptual consistency restoration} mechanism by minimizing the\ndiscrepancy between generated samples and input samples in both pixel and\nperceptual spaces. 2) To maintain the optimized latent vectors within the valid\ndata manifold, we introduce a \\textit{Latent distribution consistency\nconstraint} strategy to align generated samples with the clean data\ndistribution. 3) We also apply a \\textit{Latent vector consistency prediction}\nscheme via an ensemble approach to enhance prediction reliability. CMAP\nfundamentally addresses adversarial perturbations at their source, providing a\nrobust purification. Extensive experiments on CIFAR-10 and ImageNet-100 show\nthat our CMAP significantly enhances robustness against strong adversarial\nattacks while preserving high natural accuracy.\n","authors":["Shuhai Zhang","Jiahao Yang","Hui Luo","Jie Chen","Li Wang","Feng Liu","Bo Han","Mingkui Tan"],"pdf_url":"https://arxiv.org/pdf/2412.08394v1.pdf","comment":"17 pages, 8 figures"},{"id":"http://arxiv.org/abs/2310.19319v2","updated":"2024-12-11T14:10:25Z","published":"2023-10-30T07:29:17Z","title":"Dual-Directed Algorithm Design for Efficient Pure Exploration","summary":"  We consider pure-exploration problems in the context of stochastic sequential\nadaptive experiments with a finite set of alternatives. The central objective\nis to answer a query regarding the alternatives with high confidence while\nminimizing measurement efforts. One canonical example is identifying the\nbest-performing alternative, a problem known as ranking and selection in\nsimulation or best-arm identification in machine learning. We formulate the\nproblem complexity measure as a maximin optimization problem for the static\nfixed-budget, fixed-confidence, and posterior convergence rate settings. By\nincorporating dual variables directly into the analysis, we derive necessary\nand sufficient conditions for an allocation's optimality. The introduction of\ndual variables allows us to sidestep the combinatorial complexity that arises\nwhen considering only primal variables. These optimality conditions enable the\nextension of the top-two algorithm design principle to more general\npure-exploration problems. Moreover, our analysis yields a straightforward and\neffective information-directed selection rule that adaptively chooses from a\ncandidate set based on the informational value of the candidates. We\ndemonstrate the broad range of contexts in which our design principle can be\nimplemented. In particular, when combined with information-directed selection,\ntop-two Thompson sampling achieves asymptotic optimality in Gaussian best-arm\nidentification, resolving a notable open question in the pure-exploration\nliterature. Our algorithm attains optimality in $\\varepsilon$-best-arm\nidentification (or ranking and selection with a probability of good selection\nguarantee) and thresholding bandits. Our results provide a general principle\nfor adapting Thompson sampling to general pure-exploration problems. Numerical\nexperiments highlight the efficiency of our proposed algorithms compared to\nexisting methods.\n","authors":["Chao Qin","Wei You"],"pdf_url":"https://arxiv.org/pdf/2310.19319v2.pdf","comment":"An earlier version of this paper appeared as an extended abstract in\n  the Proceedings of the 36th Annual Conference on Learning Theory, COLT'23,\n  with the title \"Information-Directed Selection for Top-Two Algorithms.''"},{"id":"http://arxiv.org/abs/2306.06909v5","updated":"2024-12-11T14:08:57Z","published":"2023-06-12T07:27:31Z","title":"Graph Agent Network: Empowering Nodes with Inference Capabilities for\n  Adversarial Resilience","summary":"  End-to-end training with global optimization have popularized graph neural\nnetworks (GNNs) for node classification, yet inadvertently introduced\nvulnerabilities to adversarial edge-perturbing attacks. Adversaries can exploit\nthe inherent opened interfaces of GNNs' input and output, perturbing critical\nedges and thus manipulating the classification results. Current defenses, due\nto their persistent utilization of global-optimization-based end-to-end\ntraining schemes, inherently encapsulate the vulnerabilities of GNNs. This is\nspecifically evidenced in their inability to defend against targeted secondary\nattacks. In this paper, we propose the Graph Agent Network (GAgN) to address\nthe aforementioned vulnerabilities of GNNs. GAgN is a graph-structured agent\nnetwork in which each node is designed as an 1-hop-view agent. Through the\ndecentralized interactions between agents, they can learn to infer global\nperceptions to perform tasks including inferring embeddings, degrees and\nneighbor relationships for given nodes. This empowers nodes to filtering\nadversarial edges while carrying out classification tasks. Furthermore, agents'\nlimited view prevents malicious messages from propagating globally in GAgN,\nthereby resisting global-optimization-based secondary attacks. We prove that\nsingle-hidden-layer multilayer perceptrons (MLPs) are theoretically sufficient\nto achieve these functionalities. Experimental results show that GAgN\neffectively implements all its intended capabilities and, compared to\nstate-of-the-art defenses, achieves optimal classification accuracy on the\nperturbed datasets.\n","authors":["Ao Liu","Wenshan Li","Tao Li","Beibei Li","Guangquan Xu","Pan Zhou","Wengang Ma","Hanyuan Huang"],"pdf_url":"https://arxiv.org/pdf/2306.06909v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08385v1","updated":"2024-12-11T13:50:17Z","published":"2024-12-11T13:50:17Z","title":"NyayaAnumana & INLegalLlama: The Largest Indian Legal Judgment\n  Prediction Dataset and Specialized Language Model for Enhanced Decision\n  Analysis","summary":"  The integration of artificial intelligence (AI) in legal judgment prediction\n(LJP) has the potential to transform the legal landscape, particularly in\njurisdictions like India, where a significant backlog of cases burdens the\nlegal system. This paper introduces NyayaAnumana, the largest and most diverse\ncorpus of Indian legal cases compiled for LJP, encompassing a total of 7,02,945\npreprocessed cases. NyayaAnumana, which combines the words \"Nyay\" (judgment)\nand \"Anuman\" (prediction or inference) respectively for most major Indian\nlanguages, includes a wide range of cases from the Supreme Court, High Courts,\nTribunal Courts, District Courts, and Daily Orders and, thus, provides\nunparalleled diversity and coverage. Our dataset surpasses existing datasets\nlike PredEx and ILDC, offering a comprehensive foundation for advanced AI\nresearch in the legal domain.\n  In addition to the dataset, we present INLegalLlama, a domain-specific\ngenerative large language model (LLM) tailored to the intricacies of the Indian\nlegal system. It is developed through a two-phase training approach over a base\nLLaMa model. First, Indian legal documents are injected using continual\npretraining. Second, task-specific supervised finetuning is done. This method\nallows the model to achieve a deeper understanding of legal contexts.\n  Our experiments demonstrate that incorporating diverse court data\nsignificantly boosts model accuracy, achieving approximately 90% F1-score in\nprediction tasks. INLegalLlama not only improves prediction accuracy but also\noffers comprehensible explanations, addressing the need for explainability in\nAI-assisted legal decisions.\n","authors":["Shubham Kumar Nigam","Balaramamahanthi Deepak Patnaik","Shivam Mishra","Noel Shallum","Kripabandhu Ghosh","Arnab Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2412.08385v1.pdf","comment":"Accepted on COLING 2025"},{"id":"http://arxiv.org/abs/2406.18038v3","updated":"2024-12-11T13:44:19Z","published":"2024-06-26T03:12:07Z","title":"MT2ST: Adaptive Multi-Task to Single-Task Learning","summary":"  Efficient machine learning (ML) has become increasingly important as models\ngrow larger and data volumes expand. In this work, we address the trade-off\nbetween generalization in multi-task learning (MTL) and precision in\nsingle-task learning (STL) by introducing the Multi-Task to Single-Task (MT2ST)\nframework. MT2ST is designed to enhance training efficiency and accuracy in\nword embedding tasks, showcasing its value as a practical application of\nefficient ML.\n  Our framework employs two strategies: *Diminish*, which gradually reduces the\ninfluence of auxiliary tasks, and *Switch*, which transitions training from MTL\nto STL at a specific point. Empirical results show that MT2ST reduces training\ntime by 67\\% compared to STL and by 13\\% compared to traditional MTL, while\nmaintaining high accuracy. These findings highlight MT2ST as an efficient ML\nsolution tailored for optimizing word embedding training. Code is available at\nhttps://github.com/NoakLiu/MT2ST.\n","authors":["Dong Liu","Yanxuan Yu"],"pdf_url":"https://arxiv.org/pdf/2406.18038v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.01468v2","updated":"2024-12-11T13:22:12Z","published":"2024-06-03T15:57:29Z","title":"Understanding Token Probability Encoding in Output Embeddings","summary":"  In this paper, we investigate the output token probability information in the\noutput embedding of language models. We find an approximate common log-linear\nencoding of output token probabilities within the output embedding vectors and\nempirically demonstrate that it is accurate and sparse. As a causality\nexamination, we steer the encoding in output embedding to modify the output\nprobability distribution accurately. Moreover, the sparsity we find in output\nprobability encoding suggests that a large number of dimensions in the output\nembedding do not contribute to causal language modeling. Therefore, we attempt\nto delete the output-unrelated dimensions and find more than 30% of the\ndimensions can be deleted without significant movement in output distribution\nand sequence generation. Additionally, in the pre-training dynamics of language\nmodels, we find that the output embeddings capture the corpus token frequency\ninformation in early steps, even before an obvious convergence of parameters\nstarts.\n","authors":["Hakaze Cho","Yoshihiro Sakai","Kenshiro Tanaka","Mariko Kato","Naoya Inoue"],"pdf_url":"https://arxiv.org/pdf/2406.01468v2.pdf","comment":"15 pages, 17 figures, 3 tables. COLING 2025 Accepted"},{"id":"http://arxiv.org/abs/2412.08366v1","updated":"2024-12-11T13:15:06Z","published":"2024-12-11T13:15:06Z","title":"Backdoor attacks on DNN and GBDT -- A Case Study from the insurance\n  domain","summary":"  Machine learning (ML) will likely play a large role in many processes in the\nfuture, also for insurance companies. However, ML models are at risk of being\nattacked and manipulated. In this work, the robustness of Gradient Boosted\nDecision Tree (GBDT) models and Deep Neural Networks (DNN) within an insurance\ncontext will be evaluated. Therefore, two GBDT models and two DNNs are trained\non two different tabular datasets from an insurance context. Past research in\nthis domain mainly used homogenous data and there are comparably few insights\nregarding heterogenous tabular data. The ML tasks performed on the datasets are\nclaim prediction (regression) and fraud detection (binary classification). For\nthe backdoor attacks different samples containing a specific pattern were\ncrafted and added to the training data. It is shown, that this type of attack\ncan be highly successful, even with a few added samples. The backdoor attacks\nworked well on the models trained on one dataset but poorly on the models\ntrained on the other. In real-world scenarios the attacker will have to face\nseveral obstacles but as attacks can work with very few added samples this risk\nshould be evaluated.\n","authors":["Robin Kühlem","Daniel Otten","Daniel Ludwig","Anselm Hudde","Alexander Rosenbaum","Andreas Mauthe"],"pdf_url":"https://arxiv.org/pdf/2412.08366v1.pdf","comment":"40 pages, 14 figures"},{"id":"http://arxiv.org/abs/2412.08356v1","updated":"2024-12-11T13:00:49Z","published":"2024-12-11T13:00:49Z","title":"Zero-Shot Mono-to-Binaural Speech Synthesis","summary":"  We present ZeroBAS, a neural method to synthesize binaural audio from\nmonaural audio recordings and positional information without training on any\nbinaural data. To our knowledge, this is the first published zero-shot neural\napproach to mono-to-binaural audio synthesis. Specifically, we show that a\nparameter-free geometric time warping and amplitude scaling based on source\nlocation suffices to get an initial binaural synthesis that can be refined by\niteratively applying a pretrained denoising vocoder. Furthermore, we find this\nleads to generalization across room conditions, which we measure by introducing\na new dataset, TUT Mono-to-Binaural, to evaluate state-of-the-art\nmonaural-to-binaural synthesis methods on unseen conditions. Our zero-shot\nmethod is perceptually on-par with the performance of supervised methods on the\nstandard mono-to-binaural dataset, and even surpasses them on our\nout-of-distribution TUT Mono-to-Binaural dataset. Our results highlight the\npotential of pretrained generative audio models and zero-shot learning to\nunlock robust binaural audio synthesis.\n","authors":["Alon Levkovitch","Julian Salazar","Soroosh Mariooryad","RJ Skerry-Ryan","Nadav Bar","Bastiaan Kleijn","Eliya Nachmani"],"pdf_url":"https://arxiv.org/pdf/2412.08356v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07169v2","updated":"2024-12-11T12:50:45Z","published":"2024-12-10T04:03:46Z","title":"Rate-In: Information-Driven Adaptive Dropout Rates for Improved\n  Inference-Time Uncertainty Estimation","summary":"  Accurate uncertainty estimation is crucial for deploying neural networks in\nrisk-sensitive applications such as medical diagnosis. Monte Carlo Dropout is a\nwidely used technique for approximating predictive uncertainty by performing\nstochastic forward passes with dropout during inference. However, using static\ndropout rates across all layers and inputs can lead to suboptimal uncertainty\nestimates, as it fails to adapt to the varying characteristics of individual\ninputs and network layers. Existing approaches optimize dropout rates during\ntraining using labeled data, resulting in fixed inference-time parameters that\ncannot adjust to new data distributions, compromising uncertainty estimates in\nMonte Carlo simulations.\n  In this paper, we propose Rate-In, an algorithm that dynamically adjusts\ndropout rates during inference by quantifying the information loss induced by\ndropout in each layer's feature maps. By treating dropout as controlled noise\ninjection and leveraging information-theoretic principles, Rate-In adapts\ndropout rates per layer and per input instance without requiring ground truth\nlabels. By quantifying the functional information loss in feature maps, we\nadaptively tune dropout rates to maintain perceptual quality across diverse\nmedical imaging tasks and architectural configurations. Our extensive empirical\nstudy on synthetic data and real-world medical imaging tasks demonstrates that\nRate-In improves calibration and sharpens uncertainty estimates compared to\nfixed or heuristic dropout rates without compromising predictive performance.\nRate-In offers a practical, unsupervised, inference-time approach to optimizing\ndropout for more reliable predictive uncertainty estimation in critical\napplications.\n","authors":["Tal Zeevi","Ravid Shwartz-Ziv","Yann LeCun","Lawrence H. Staib","John A. Onofrey"],"pdf_url":"https://arxiv.org/pdf/2412.07169v2.pdf","comment":"Updated author affiliation"},{"id":"http://arxiv.org/abs/2412.08350v1","updated":"2024-12-11T12:45:17Z","published":"2024-12-11T12:45:17Z","title":"Benchmarking learned algorithms for computed tomography image\n  reconstruction tasks","summary":"  Computed tomography (CT) is a widely used non-invasive diagnostic method in\nvarious fields, and recent advances in deep learning have led to significant\nprogress in CT image reconstruction. However, the lack of large-scale,\nopen-access datasets has hindered the comparison of different types of learned\nmethods. To address this gap, we use the 2DeteCT dataset, a real-world\nexperimental computed tomography dataset, for benchmarking machine learning\nbased CT image reconstruction algorithms. We categorize these methods into\npost-processing networks, learned/unrolled iterative methods, learned\nregularizer methods, and plug-and-play methods, and provide a pipeline for easy\nimplementation and evaluation. Using key performance metrics, including SSIM\nand PSNR, our benchmarking results showcase the effectiveness of various\nalgorithms on tasks such as full data reconstruction, limited-angle\nreconstruction, sparse-angle reconstruction, low-dose reconstruction, and\nbeam-hardening corrected reconstruction. With this benchmarking study, we\nprovide an evaluation of a range of algorithms representative for different\ncategories of learned reconstruction methods on a recently published dataset of\nreal-world experimental CT measurements. The reproducible setup of methods and\nCT image reconstruction tasks in an open-source toolbox enables straightforward\naddition and comparison of new methods later on. The toolbox also provides the\noption to load the 2DeteCT dataset differently for extensions to other problems\nand different CT reconstruction tasks.\n","authors":["Maximilian B. Kiss","Ander Biguri","Zakhar Shumaylov","Ferdia Sherry","K. Joost Batenburg","Carola-Bibiane Schönlieb","Felix Lucka"],"pdf_url":"https://arxiv.org/pdf/2412.08350v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08341v1","updated":"2024-12-11T12:31:30Z","published":"2024-12-11T12:31:30Z","title":"ALoRE: Efficient Visual Adaptation via Aggregating Low Rank Experts","summary":"  Parameter-efficient transfer learning (PETL) has become a promising paradigm\nfor adapting large-scale vision foundation models to downstream tasks. Typical\nmethods primarily leverage the intrinsic low rank property to make\ndecomposition, learning task-specific weights while compressing parameter size.\nHowever, such approaches predominantly manipulate within the original feature\nspace utilizing a single-branch structure, which might be suboptimal for\ndecoupling the learned representations and patterns. In this paper, we propose\nALoRE, a novel PETL method that reuses the hypercomplex parameterized space\nconstructed by Kronecker product to Aggregate Low Rank Experts using a\nmulti-branch paradigm, disentangling the learned cognitive patterns during\ntraining. Thanks to the artful design, ALoRE maintains negligible extra\nparameters and can be effortlessly merged into the frozen backbone via\nre-parameterization in a sequential manner, avoiding additional inference\nlatency. We conduct extensive experiments on 24 image classification tasks\nusing various backbone variants. Experimental results demonstrate that ALoRE\noutperforms the full fine-tuning strategy and other state-of-the-art PETL\nmethods in terms of performance and parameter efficiency. For instance, ALoRE\nobtains 3.06% and 9.97% Top-1 accuracy improvement on average compared to full\nfine-tuning on the FGVC datasets and VTAB-1k benchmark by only updating 0.15M\nparameters.\n","authors":["Sinan Du","Guosheng Zhang","Keyao Wang","Yuanrui Wang","Haixiao Yue","Gang Zhang","Errui Ding","Jingdong Wang","Zhengzhuo Xu","Chun Yuan"],"pdf_url":"https://arxiv.org/pdf/2412.08341v1.pdf","comment":"23 pages, 7 figures"},{"id":"http://arxiv.org/abs/2409.08262v2","updated":"2024-12-11T12:23:37Z","published":"2024-09-12T17:55:44Z","title":"Learning incomplete factorization preconditioners for GMRES","summary":"  Incomplete LU factorizations of sparse matrices are widely used as\npreconditioners in Krylov subspace methods to speed up solving linear systems.\nUnfortunately, computing the preconditioner itself can be time-consuming and\nsensitive to hyper-parameters. Instead, we replace the hand-engineered\nalgorithm with a graph neural network that is trained to approximate the matrix\nfactorization directly. To apply the output of the neural network as a\npreconditioner, we propose an output activation function that guarantees that\nthe predicted factorization is invertible. Further, applying a graph neural\nnetwork architecture allows us to ensure that the output itself is sparse which\nis desirable from a computational standpoint. We theoretically analyze and\nempirically evaluate different loss functions to train the learned\npreconditioners and show their effectiveness in decreasing the number of GMRES\niterations and improving the spectral properties on synthetic data. The code is\navailable at https://github.com/paulhausner/neural-incomplete-factorization.\n","authors":["Paul Häusner","Aleix Nieto Juscafresa","Jens Sjölund"],"pdf_url":"https://arxiv.org/pdf/2409.08262v2.pdf","comment":"The first two authors contributed equally, Northern Lights Deep\n  Learning Conference, 15 pages"},{"id":"http://arxiv.org/abs/2302.04686v4","updated":"2024-12-11T12:06:10Z","published":"2023-02-09T15:04:35Z","title":"Global and Preference-based Optimization with Mixed Variables using\n  Piecewise Affine Surrogates","summary":"  Optimization problems involving mixed variables (i.e., variables of numerical\nand categorical nature) can be challenging to solve, especially in the presence\nof mixed-variable constraints. Moreover, when the objective function is the\nresult of a complicated simulation or experiment, it may be\nexpensive-to-evaluate. This paper proposes a novel surrogate-based global\noptimization algorithm to solve linearly constrained mixed-variable problems up\nto medium size (around 100 variables after encoding). The proposed approach is\nbased on constructing a piecewise affine surrogate of the objective function\nover feasible samples. We assume the objective function is black-box and\nexpensive-to-evaluate, while the linear constraints are quantifiable,\nunrelaxable, a priori known, and are cheap to evaluate. We introduce two types\nof exploration functions to efficiently search the feasible domain via\nmixed-integer linear programming solvers. We also provide a preference-based\nversion of the algorithm designed for situations where only pairwise\ncomparisons between samples can be acquired, while the underlying objective\nfunction to minimize remains unquantified. The two algorithms are evaluated on\nseveral unconstrained and constrained mixed-variable benchmark problems. The\nresults show that, within a small number of required experiments/simulations,\nthe proposed algorithms can often achieve better or comparable results than\nother existing methods.\n","authors":["Mengjia Zhu","Alberto Bemporad"],"pdf_url":"https://arxiv.org/pdf/2302.04686v4.pdf","comment":"code available at https://github.com/mjzhu-p/PWAS"},{"id":"http://arxiv.org/abs/2410.20356v2","updated":"2024-12-11T11:58:06Z","published":"2024-10-27T07:09:31Z","title":"Uncovering Capabilities of Model Pruning in Graph Contrastive Learning","summary":"  Graph contrastive learning has achieved great success in pre-training graph\nneural networks without ground-truth labels. Leading graph contrastive learning\nfollows the classical scheme of contrastive learning, forcing model to identify\nthe essential information from augmented views. However, general augmented\nviews are produced via random corruption or learning, which inevitably leads to\nsemantics alteration. Although domain knowledge guided augmentations alleviate\nthis issue, the generated views are domain specific and undermine the\ngeneralization. In this work, motivated by the firm representation ability of\nsparse model from pruning, we reformulate the problem of graph contrastive\nlearning via contrasting different model versions rather than augmented views.\nWe first theoretically reveal the superiority of model pruning in contrast to\ndata augmentations. In practice, we take original graph as input and\ndynamically generate a perturbed graph encoder to contrast with the original\nencoder by pruning its transformation weights. Furthermore, considering the\nintegrity of node embedding in our method, we are capable of developing a local\ncontrastive loss to tackle the hard negative samples that disturb the model\ntraining. We extensively validate our method on various benchmarks regarding\ngraph classification via unsupervised and transfer learning. Compared to the\nstate-of-the-art (SOTA) works, better performance can always be obtained by the\nproposed method.\n","authors":["Junran Wu","Xueyuan Chen","Shangzhe Li"],"pdf_url":"https://arxiv.org/pdf/2410.20356v2.pdf","comment":"MM' 24"},{"id":"http://arxiv.org/abs/2411.12010v2","updated":"2024-12-11T11:52:24Z","published":"2024-11-18T19:49:51Z","title":"Active learning for efficient discovery of optimal gene combinations in\n  the combinatorial perturbation space","summary":"  The advancement of novel combinatorial CRISPR screening technologies enables\nthe identification of synergistic gene combinations on a large scale. This is\ncrucial for developing novel and effective combination therapies, but the\ncombinatorial space makes exhaustive experimentation infeasible. We introduce\nNAIAD, an active learning framework that efficiently discovers optimal gene\npairs capable of driving cells toward desired cellular phenotypes. NAIAD\nleverages single-gene perturbation effects and adaptive gene embeddings that\nscale with the training data size, mitigating overfitting in small-sample\nlearning while capturing complex gene interactions as more data is collected.\nEvaluated on four CRISPR combinatorial perturbation datasets totaling over\n350,000 genetic interactions, NAIAD, trained on small datasets, outperforms\nexisting models by up to 40\\% relative to the second-best. NAIAD's\nrecommendation system prioritizes gene pairs with the maximum predicted\neffects, resulting in the highest marginal gain in each AI-experiment round and\naccelerating discovery with fewer CRISPR experimental iterations. Our NAIAD\nframework (https://github.com/NeptuneBio/NAIAD) improves the identification of\nnovel, effective gene combinations, enabling more efficient CRISPR library\ndesign and offering promising applications in genomics research and therapeutic\ndevelopment.\n","authors":["Jason Qin","Hans-Hermann Wessels","Carlos Fernandez-Granda","Yuhan Hao"],"pdf_url":"https://arxiv.org/pdf/2411.12010v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08313v1","updated":"2024-12-11T11:50:06Z","published":"2024-12-11T11:50:06Z","title":"Post-Hoc MOTS: Exploring the Capabilities of Time-Symmetric Multi-Object\n  Tracking","summary":"  Temporal forward-tracking has been the dominant approach for multi-object\nsegmentation and tracking (MOTS). However, a novel time-symmetric tracking\nmethodology has recently been introduced for the detection, segmentation, and\ntracking of budding yeast cells in pre-recorded samples. Although this\narchitecture has demonstrated a unique perspective on stable and consistent\ntracking, as well as missed instance re-interpolation, its evaluation has so\nfar been largely confined to settings related to videomicroscopic environments.\nIn this work, we aim to reveal the broader capabilities, advantages, and\npotential challenges of this architecture across various specifically designed\nscenarios, including a pedestrian tracking dataset. We also conduct an ablation\nstudy comparing the model against its restricted variants and the widely used\nKalman filter. Furthermore, we present an attention analysis of the tracking\narchitecture for both pretrained and non-pretrained models\n","authors":["Gergely Szabó","Zsófia Molnár","András Horváth"],"pdf_url":"https://arxiv.org/pdf/2412.08313v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.18562v3","updated":"2024-12-11T11:48:44Z","published":"2024-11-27T18:03:26Z","title":"DexHandDiff: Interaction-aware Diffusion Planning for Adaptive Dexterous\n  Manipulation","summary":"  Dexterous manipulation with contact-rich interactions is crucial for advanced\nrobotics. While recent diffusion-based planning approaches show promise for\nsimpler manipulation tasks, they often produce unrealistic ghost states (e.g.,\nthe object automatically moves without hand contact) or lack adaptability when\nhandling complex sequential interactions. In this work, we introduce\nDexHandDiff, an interaction-aware diffusion planning framework for adaptive\ndexterous manipulation. DexHandDiff models joint state-action dynamics through\na dual-phase diffusion process which consists of pre-interaction contact\nalignment and post-contact goal-directed control, enabling goal-adaptive\ngeneralizable dexterous manipulation. Additionally, we incorporate dynamics\nmodel-based dual guidance and leverage large language models for automated\nguidance function generation, enhancing generalizability for physical\ninteractions and facilitating diverse goal adaptation through language cues.\nExperiments on physical interaction tasks such as door opening, pen and block\nre-orientation, and hammer striking demonstrate DexHandDiff's effectiveness on\ngoals outside training distributions, achieving over twice the average success\nrate (59.2% vs. 29.5%) compared to existing methods. Our framework achieves\n70.0% success on 30-degree door opening, 40.0% and 36.7% on pen and block\nhalf-side re-orientation respectively, and 46.7% on hammer nail half drive,\nhighlighting its robustness and flexibility in contact-rich manipulation.\n","authors":["Zhixuan Liang","Yao Mu","Yixiao Wang","Tianxing Chen","Wenqi Shao","Wei Zhan","Masayoshi Tomizuka","Ping Luo","Mingyu Ding"],"pdf_url":"https://arxiv.org/pdf/2411.18562v3.pdf","comment":"27 pages (new name). Project page: https://dexdiffuser.github.io/"},{"id":"http://arxiv.org/abs/2412.08312v1","updated":"2024-12-11T11:47:39Z","published":"2024-12-11T11:47:39Z","title":"A Unified Model For Voice and Accent Conversion In Speech and Singing\n  using Self-Supervised Learning and Feature Extraction","summary":"  This paper presents a new voice conversion model capable of transforming both\nspeaking and singing voices. It addresses key challenges in current systems,\nsuch as conveying emotions, managing pronunciation and accent changes, and\nreproducing non-verbal sounds. One of the model's standout features is its\nability to perform accent conversion on hybrid voice samples that encompass\nboth speech and singing, allowing it to change the speaker's accent while\npreserving the original content and prosody. The proposed model uses an\nencoder-decoder architecture: the encoder is based on HuBERT to process the\nspeech's acoustic and linguistic content, while the HiFi-GAN decoder audio\nmatches the target speaker's voice. The model incorporates fundamental\nfrequency (f0) features and singer embeddings to enhance performance while\nensuring the pitch & tone accuracy and vocal identity are preserved during\ntransformation. This approach improves how naturally and flexibly voice style\ncan be transformed, showing strong potential for applications in voice dubbing,\ncontent creation, and technologies like Text-to-Speech (TTS) and Interactive\nVoice Response (IVR) systems.\n","authors":["Sowmya Cheripally"],"pdf_url":"https://arxiv.org/pdf/2412.08312v1.pdf","comment":"7 pages, 5 figures, 2 tables"},{"id":"http://arxiv.org/abs/2412.08310v1","updated":"2024-12-11T11:44:55Z","published":"2024-12-11T11:44:55Z","title":"Edge-Splitting MLP: Node Classification on Homophilic and Heterophilic\n  Graphs without Message Passing","summary":"  Message Passing Neural Networks (MPNNs) have demonstrated remarkable success\nin node classification on homophilic graphs. It has been shown that they do not\nsolely rely on homophily but on neighborhood distributions of nodes, i.e.,\nconsistency of the neighborhood label distribution within the same class.\nMLP-based models do not use message passing, \\eg Graph-MLP incorporates the\nneighborhood in a separate loss function. These models are faster and more\nrobust to edge noise. Graph-MLP maps adjacent nodes closer in the embedding\nspace but is unaware of the neighborhood pattern of the labels, i.e., relies\nsolely on homophily. Edge Splitting GNN (ES-GNN) is a model specialized for\nheterophilic graphs and splits the edges into task-relevant and\ntask-irrelevant, respectively. To mitigate the limitations of Graph-MLP on\nheterophilic graphs, we propose ES-MLP that combines Graph-MLP with an\nedge-splitting mechanism from ES-GNN. It incorporates the edge splitting into\nthe loss of Graph-MLP to learn two separate adjacency matrices based on\nrelevant and irrelevant feature pairs. Our experiments on seven datasets with\nsix baselines show that ES-MLP is on par with homophilic and heterophilic\nmodels on all datasets without using edges during inference. We show that\nES-MLP is robust to multiple types of edge noise during inference and that its\ninference time is two to five times faster than that of commonly used MPNNs.\nThe source code is available at https://github.com/MatthiasKohn/ES-MLP.\n","authors":["Matthias Kohn","Marcel Hoffmann","Ansgar Scherp"],"pdf_url":"https://arxiv.org/pdf/2412.08310v1.pdf","comment":"Published at Learning on Graphs, 2024"},{"id":"http://arxiv.org/abs/2409.01990v2","updated":"2024-12-11T11:39:41Z","published":"2024-09-03T15:35:01Z","title":"Efficient Large Foundation Model Inference: A Perspective From Model and\n  System Co-Design","summary":"  As Large Language Models (LLMs) become popular, the need for efficient design\nfor ML models on LLMs grows. We are amazed by the excellent output by the LLMs,\nyet we are still troubled with slow inference speed and large memory\nconsumption of contemporary LLMs. This paper focuses on modern efficient\ninference technologies on LLMs and illustrates them from two perspectives:\nmodel and system design. These methodologies optimize LLM inference from\ndifferent aspects to save computational resources, making LLMs more efficient,\naffordable, and more accessible.\n","authors":["Dong Liu","Zhixin Lai","Yite Wang","Jing Wu","Yanxuan Yu","Zhongwei Wan","Benjamin Lengerich","Ying Nian Wu"],"pdf_url":"https://arxiv.org/pdf/2409.01990v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08301v1","updated":"2024-12-11T11:31:05Z","published":"2024-12-11T11:31:05Z","title":"Enhancing Cybersecurity in IoT Networks: A Deep Learning Approach to\n  Anomaly Detection","summary":"  With the proliferation of the Internet and smart devices, IoT technology has\nseen significant advancements and has become an integral component of smart\nhomes, urban security, smart logistics, and other sectors. IoT facilitates\nreal-time monitoring of critical production indicators, enabling businesses to\ndetect potential quality issues, anticipate equipment malfunctions, and refine\nprocesses, thereby minimizing losses and reducing costs. Furthermore, IoT\nenhances real-time asset tracking, optimizing asset utilization and management.\nHowever, the expansion of IoT has also led to a rise in cybercrimes, with\ndevices increasingly serving as vectors for malicious attacks. As the number of\nIoT devices grows, there is an urgent need for robust network security measures\nto counter these escalating threats. This paper introduces a deep learning\nmodel incorporating LSTM and attention mechanisms, a pivotal strategy in\ncombating cybercrime in IoT networks. Our experiments, conducted on datasets\nincluding IoT-23, BoT-IoT, IoT network intrusion, MQTT, and MQTTset,\ndemonstrate that our proposed method outperforms existing baselines.\n","authors":["Yining Pang","Chenghan Li"],"pdf_url":"https://arxiv.org/pdf/2412.08301v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08296v1","updated":"2024-12-11T11:13:43Z","published":"2024-12-11T11:13:43Z","title":"GDSG: Graph Diffusion-based Solution Generation for Optimization\n  Problems in MEC Networks","summary":"  Optimization is crucial for MEC networks to function efficiently and\nreliably, most of which are NP-hard and lack efficient approximation\nalgorithms. This leads to a paucity of optimal solution, constraining the\neffectiveness of conventional deep learning approaches. Most existing\nlearning-based methods necessitate extensive optimal data and fail to exploit\nthe potential benefits of suboptimal data that can be obtained with greater\nefficiency and effectiveness. Taking the multi-server multi-user computation\noffloading (MSCO) problem, which is widely observed in systems like\nInternet-of-Vehicles (IoV) and Unmanned Aerial Vehicle (UAV) networks, as a\nconcrete scenario, we present a Graph Diffusion-based Solution Generation\n(GDSG) method. This approach is designed to work with suboptimal datasets while\nconverging to the optimal solution large probably. We transform the\noptimization issue into distribution-learning and offer a clear explanation of\nlearning from suboptimal training datasets. We build GDSG as a multi-task\ndiffusion model utilizing a Graph Neural Network (GNN) to acquire the\ndistribution of high-quality solutions. We use a simple and efficient heuristic\napproach to obtain a sufficient amount of training data composed entirely of\nsuboptimal solutions. In our implementation, we enhance the backbone GNN and\nachieve improved generalization. GDSG also reaches nearly 100\\% task\northogonality, ensuring no interference between the discrete and continuous\ngeneration tasks. We further reveal that this orthogonality arises from the\ndiffusion-related training loss, rather than the neural network architecture\nitself. The experiments demonstrate that GDSG surpasses other benchmark methods\non both the optimal and suboptimal training datasets. The MSCO datasets has\nopen-sourced at http://ieee-dataport.org/13824, as well as the GDSG algorithm\ncodes at https://github.com/qiyu3816/GDSG.\n","authors":["Ruihuai Liang","Bo Yang","Pengyu Chen","Zhiwen Yu","Xuelin Cao","Mérouane Debbah","H. Vincent Poor","Chau Yuen"],"pdf_url":"https://arxiv.org/pdf/2412.08296v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08293v1","updated":"2024-12-11T11:09:13Z","published":"2024-12-11T11:09:13Z","title":"SINERGYM -- A virtual testbed for building energy optimization with\n  Reinforcement Learning","summary":"  Simulation has become a crucial tool for Building Energy Optimization (BEO)\nas it enables the evaluation of different design and control strategies at a\nlow cost. Machine Learning (ML) algorithms can leverage large-scale simulations\nto learn optimal control from vast amounts of data without supervision,\nparticularly under the Reinforcement Learning (RL) paradigm. Unfortunately, the\nlack of open and standardized tools has hindered the widespread application of\nML and RL to BEO. To address this issue, this paper presents Sinergym, an\nopen-source Python-based virtual testbed for large-scale building simulation,\ndata collection, continuous control, and experiment monitoring. Sinergym\nprovides a consistent interface for training and running controllers,\npredefined benchmarks, experiment visualization and replication support, and\ncomprehensive documentation in a ready-to-use software library. This paper 1)\nhighlights the main features of Sinergym in comparison to other existing\nframeworks, 2) describes its basic usage, and 3) demonstrates its applicability\nfor RL-based BEO through several representative examples. By integrating\nsimulation, data, and control, Sinergym supports the development of\nintelligent, data-driven applications for more efficient and responsive\nbuilding operations, aligning with the objectives of digital twin technology.\n","authors":["Alejandro Campoy-Nieves","Antonio Manjavacas","Javier Jiménez-Raboso","Miguel Molina-Solana","Juan Gómez-Romero"],"pdf_url":"https://arxiv.org/pdf/2412.08293v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.06588v3","updated":"2024-12-11T11:08:18Z","published":"2023-10-10T12:53:48Z","title":"FTFT: Efficient and Robust Fine-Tuning by Transferring Training Dynamics","summary":"  Despite the massive success of fine-tuning Pre-trained Language Models\n(PLMs), they remain susceptible to out-of-distribution input. Dataset\ncartography is a simple yet effective dual-model approach that improves the\nrobustness of fine-tuned PLMs. It involves fine-tuning a model on the original\ntraining set (i.e. reference model), selecting a subset of important training\ninstances based on the training dynamics, and fine-tuning again only on these\nselected examples (i.e. main model). However, this approach requires\nfine-tuning the same model twice, which is computationally expensive for large\nPLMs. In this paper, we show that (1) training dynamics are highly transferable\nacross model sizes and pre-training methods, and that (2) fine-tuning main\nmodels using these selected training instances achieves higher training\nefficiency than empirical risk minimization (ERM). Building on these\nobservations, we propose a novel fine-tuning approach: Fine-Tuning by\ntransFerring Training dynamics (FTFT). Compared with dataset cartography, FTFT\nuses more efficient reference models and aggressive early stopping. FTFT\nachieves robustness improvements over ERM while lowering the training cost by\nup to $\\sim 50\\%$.\n","authors":["Yupei Du","Albert Gatt","Dong Nguyen"],"pdf_url":"https://arxiv.org/pdf/2310.06588v3.pdf","comment":"COLING 2025 Camera-Ready"},{"id":"http://arxiv.org/abs/2412.08292v1","updated":"2024-12-11T11:08:09Z","published":"2024-12-11T11:08:09Z","title":"Self-Refining Diffusion Samplers: Enabling Parallelization via Parareal\n  Iterations","summary":"  In diffusion models, samples are generated through an iterative refinement\nprocess, requiring hundreds of sequential model evaluations. Several recent\nmethods have introduced approximations (fewer discretization steps or\ndistillation) to trade off speed at the cost of sample quality. In contrast, we\nintroduce Self-Refining Diffusion Samplers (SRDS) that retain sample quality\nand can improve latency at the cost of additional parallel compute. We take\ninspiration from the Parareal algorithm, a popular numerical method for\nparallel-in-time integration of differential equations. In SRDS, a quick but\nrough estimate of a sample is first created and then iteratively refined in\nparallel through Parareal iterations. SRDS is not only guaranteed to accurately\nsolve the ODE and converge to the serial solution but also benefits from\nparallelization across the diffusion trajectory, enabling batched inference and\npipelining. As we demonstrate for pre-trained diffusion models, the early\nconvergence of this refinement procedure drastically reduces the number of\nsteps required to produce a sample, speeding up generation for instance by up\nto 1.7x on a 25-step StableDiffusion-v2 benchmark and up to 4.3x on longer\ntrajectories.\n","authors":["Nikil Roashan Selvam","Amil Merchant","Stefano Ermon"],"pdf_url":"https://arxiv.org/pdf/2412.08292v1.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2412.08289v1","updated":"2024-12-11T11:04:17Z","published":"2024-12-11T11:04:17Z","title":"k-HyperEdge Medoids for Clustering Ensemble","summary":"  Clustering ensemble has been a popular research topic in data science due to\nits ability to improve the robustness of the single clustering method. Many\nclustering ensemble methods have been proposed, most of which can be\ncategorized into clustering-view and sample-view methods. The clustering-view\nmethod is generally efficient, but it could be affected by the unreliability\nthat existed in base clustering results. The sample-view method shows good\nperformance, while the construction of the pairwise sample relation is\ntime-consuming. In this paper, the clustering ensemble is formulated as a\nk-HyperEdge Medoids discovery problem and a clustering ensemble method based on\nk-HyperEdge Medoids that considers the characteristics of the above two types\nof clustering ensemble methods is proposed. In the method, a set of hyperedges\nis selected from the clustering view efficiently, then the hyperedges are\ndiffused and adjusted from the sample view guided by a hyperedge loss function\nto construct an effective k-HyperEdge Medoid set. The loss function is mainly\nreduced by assigning samples to the hyperedge with the highest degree of\nbelonging. Theoretical analyses show that the solution can approximate the\noptimal, the assignment method can gradually reduce the loss function, and the\nestimation of the belonging degree is statistically reasonable. Experiments on\nartificial data show the working mechanism of the proposed method. The\nconvergence of the method is verified by experimental analysis of twenty data\nsets. The effectiveness and efficiency of the proposed method are also verified\non these data, with nine representative clustering ensemble algorithms as\nreference.\n","authors":["Feijiang Li","Jieting Wang","Liuya zhang","Yuhua Qian","Shuai jin","Tao Yan","Liang Du"],"pdf_url":"https://arxiv.org/pdf/2412.08289v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08287v1","updated":"2024-12-11T11:02:48Z","published":"2024-12-11T11:02:48Z","title":"DistrictNet: Decision-aware learning for geographical districting","summary":"  Districting is a complex combinatorial problem that consists in partitioning\na geographical area into small districts. In logistics, it is a major strategic\ndecision determining operating costs for several years. Solving districting\nproblems using traditional methods is intractable even for small geographical\nareas and existing heuristics often provide sub-optimal results. We present a\nstructured learning approach to find high-quality solutions to real-world\ndistricting problems in a few minutes. It is based on integrating a\ncombinatorial optimization layer, the capacitated minimum spanning tree\nproblem, into a graph neural network architecture. To train this pipeline in a\ndecision-aware fashion, we show how to construct target solutions embedded in a\nsuitable space and learn from target solutions. Experiments show that our\napproach outperforms existing methods as it can significantly reduce costs on\nreal-world cities.\n","authors":["Cheikh Ahmed","Alexandre Forel","Axel Parmentier","Thibaut Vidal"],"pdf_url":"https://arxiv.org/pdf/2412.08287v1.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2412.08286v1","updated":"2024-12-11T11:00:39Z","published":"2024-12-11T11:00:39Z","title":"Towards Precision in Bolted Joint Design: A Preliminary Machine\n  Learning-Based Parameter Prediction","summary":"  Bolted joints are critical in engineering for maintaining structural\nintegrity and reliability. Accurate prediction of parameters influencing their\nfunction and behavior is essential for optimal performance. Traditional methods\noften fail to capture the non-linear behavior of bolted joints or require\nsignificant computational resources, limiting accuracy and efficiency. This\nstudy addresses these limitations by combining empirical data with a\nfeed-forward neural network to predict load capacity and friction coefficients.\nLeveraging experimental data and systematic preprocessing, the model\neffectively captures nonlinear relationships, including rescaling output\nvariables to address scale discrepancies, achieving 95.24% predictive accuracy.\nWhile limited dataset size and diversity restrict generalizability, the\nfindings demonstrate the potential of neural networks as a reliable, efficient\nalternative for bolted joint design. Future work will focus on expanding\ndatasets and exploring hybrid modeling techniques to enhance applicability.\n","authors":["Ines Boujnah","Nehal Afifi","Andreas Wettstein","Sven Matthiesen"],"pdf_url":"https://arxiv.org/pdf/2412.08286v1.pdf","comment":"10 pages, 6 figures, submitted to: ICED25 - 25th International\n  Conference on Engineering Design, in Review"},{"id":"http://arxiv.org/abs/2412.08285v1","updated":"2024-12-11T11:00:33Z","published":"2024-12-11T11:00:33Z","title":"Adaptive Prompting for Continual Relation Extraction: A Within-Task\n  Variance Perspective","summary":"  To address catastrophic forgetting in Continual Relation Extraction (CRE),\nmany current approaches rely on memory buffers to rehearse previously learned\nknowledge while acquiring new tasks. Recently, prompt-based methods have\nemerged as potent alternatives to rehearsal-based strategies, demonstrating\nstrong empirical performance. However, upon analyzing existing prompt-based\napproaches for CRE, we identified several critical limitations, such as\ninaccurate prompt selection, inadequate mechanisms for mitigating forgetting in\nshared parameters, and suboptimal handling of cross-task and within-task\nvariances. To overcome these challenges, we draw inspiration from the\nrelationship between prefix-tuning and mixture of experts, proposing a novel\napproach that employs a prompt pool for each task, capturing variations within\neach task while enhancing cross-task variances. Furthermore, we incorporate a\ngenerative model to consolidate prior knowledge within shared parameters,\neliminating the need for explicit data storage. Extensive experiments validate\nthe efficacy of our approach, demonstrating superior performance over\nstate-of-the-art prompt-based and rehearsal-free methods in continual relation\nextraction.\n","authors":["Minh Le","Tien Ngoc Luu","An Nguyen The","Thanh-Thien Le","Trang Nguyen","Thanh Tung Nguyen","Linh Ngo Van","Thien Huu Nguyen"],"pdf_url":"https://arxiv.org/pdf/2412.08285v1.pdf","comment":"Accepted to AAAI 2025"},{"id":"http://arxiv.org/abs/2410.21302v4","updated":"2024-12-11T10:58:10Z","published":"2024-10-21T22:52:25Z","title":"Domain-Adaptive Pre-training of Self-Supervised Foundation Models for\n  Medical Image Classification in Gastrointestinal Endoscopy","summary":"  Video capsule endoscopy has transformed gastrointestinal endoscopy (GIE)\ndiagnostics by offering a non-invasive method for capturing detailed images of\nthe gastrointestinal tract, enabling early disease detection. However, its\npotential is limited by the sheer volume of images generated during the imaging\nprocedure, which can take anywhere from 6-8 hours and often produce up to 1\nmillion images, necessitating automated analysis. Additionally, the variability\nof these images, combined with the need for expert annotations and the scarcity\nof large, high-quality labeled datasets, constrains the effectiveness of\ncurrent medical image analysis models. To address this, we introduce a novel\nlarge GIE dataset, called EndoExtend24, created by merging ten existing public\nand private datasets, ensuring patient integrity across splits. EndoExtend24\nincludes over 226,000 labeled images, as well as dynamic class mappings, which\nallow unified training across datasets with differing labeling granularity,\nsupporting up to 123 distinct pathological findings. Further, we propose to\nleverage domain adaptive pre-training of foundation models trained with\nself-supervision on generic image data, to adapt them to the task of GIE\nmedical image diagnosis. Specifically, the EVA-02 model, which is based on the\nViT architecture and trained on ImageNet-22k with masked image modeling (using\nEVA-CLIP as a MIM teacher), is pre-trained on the EndoExtend24 dataset to\nachieve domain adaptation, and finally trained on the Capsule Endoscopy 2024\nChallenge dataset. Our model demonstrates robust performance, securing third\nplace in the Capsule Endoscopy 2024 Challenge. We achieved a macro AUC of 0.762\nand a balanced accuracy of 37.1% on the test set. These results emphasize the\neffectiveness of our domain-adaptive pre-training approach and the enriched\nEndoExtend24 dataset in advancing gastrointestinal endoscopy diagnostics.\n","authors":["Marcel Roth","Micha V. Nowak","Adrian Krenzer","Frank Puppe"],"pdf_url":"https://arxiv.org/pdf/2410.21302v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08282v1","updated":"2024-12-11T10:57:16Z","published":"2024-12-11T10:57:16Z","title":"How Does the Smoothness Approximation Method Facilitate Generalization\n  for Federated Adversarial Learning?","summary":"  Federated Adversarial Learning (FAL) is a robust framework for resisting\nadversarial attacks on federated learning. Although some FAL studies have\ndeveloped efficient algorithms, they primarily focus on convergence performance\nand overlook generalization. Generalization is crucial for evaluating algorithm\nperformance on unseen data. However, generalization analysis is more\nchallenging due to non-smooth adversarial loss functions. A common approach to\naddressing this issue is to leverage smoothness approximation. In this paper,\nwe develop algorithm stability measures to evaluate the generalization\nperformance of two popular FAL algorithms: \\textit{Vanilla FAL (VFAL)} and {\\it\nSlack FAL (SFAL)}, using three different smooth approximation methods: 1)\n\\textit{Surrogate Smoothness Approximation (SSA)}, (2) \\textit{Randomized\nSmoothness Approximation (RSA)}, and (3) \\textit{Over-Parameterized Smoothness\nApproximation (OPSA)}. Based on our in-depth analysis, we answer the question\nof how to properly set the smoothness approximation method to mitigate\ngeneralization error in FAL. Moreover, we identify RSA as the most effective\nmethod for reducing generalization error. In highly data-heterogeneous\nscenarios, we also recommend employing SFAL to mitigate the deterioration of\ngeneralization performance caused by heterogeneity. Based on our theoretical\nresults, we provide insights to help develop more efficient FAL algorithms,\nsuch as designing new metrics and dynamic aggregation rules to mitigate\nheterogeneity.\n","authors":["Wenjun Ding","Ying An","Lixing Chen","Shichao Kan","Fan Wu","Zhe Qu"],"pdf_url":"https://arxiv.org/pdf/2412.08282v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08261v1","updated":"2024-12-11T10:17:00Z","published":"2024-12-11T10:17:00Z","title":"FLIP: Flow-Centric Generative Planning for General-Purpose Manipulation\n  Tasks","summary":"  We aim to develop a model-based planning framework for world models that can\nbe scaled with increasing model and data budgets for general-purpose\nmanipulation tasks with only language and vision inputs. To this end, we\npresent FLow-centric generative Planning (FLIP), a model-based planning\nalgorithm on visual space that features three key modules: 1. a multi-modal\nflow generation model as the general-purpose action proposal module; 2. a\nflow-conditioned video generation model as the dynamics module; and 3. a\nvision-language representation learning model as the value module. Given an\ninitial image and language instruction as the goal, FLIP can progressively\nsearch for long-horizon flow and video plans that maximize the discounted\nreturn to accomplish the task. FLIP is able to synthesize long-horizon plans\nacross objects, robots, and tasks with image flows as the general action\nrepresentation, and the dense flow information also provides rich guidance for\nlong-horizon video generation. In addition, the synthesized flow and video\nplans can guide the training of low-level control policies for robot execution.\nExperiments on diverse benchmarks demonstrate that FLIP can improve both the\nsuccess rates and quality of long-horizon video plan synthesis and has the\ninteractive world model property, opening up wider applications for future\nworks.\n","authors":["Chongkai Gao","Haozhuo Zhang","Zhixuan Xu","Zhehao Cai","Lin Shao"],"pdf_url":"https://arxiv.org/pdf/2412.08261v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.00502v4","updated":"2024-12-11T09:53:49Z","published":"2023-12-01T11:06:00Z","title":"Which Augmentation Should I Use? An Empirical Investigation of\n  Augmentations for Self-Supervised Phonocardiogram Representation Learning","summary":"  Despite recent advancements in deep learning, its application in real-world\nmedical settings, such as phonocardiogram (PCG) classification, remains\nlimited. A significant barrier is the lack of high-quality annotated datasets,\nwhich hampers the development of robust, generalizable models that can perform\nwell on newly collected, out-of-distribution (OOD) data. Self-Supervised\nLearning (SSL) contrastive learning, has shown promise in mitigating the issue\nof data scarcity by using unlabeled data to enhance model robustness. Even\nthough SSL methods have been proposed and researched in other domains, works\nfocusing on the impact of data augmentations on model robustness for PCG\nclassification are limited. In particular, while augmentations are a key\ncomponent in SSL, selecting the most suitable policy during training is highly\nchallenging. Improper augmentations can lead to substantial performance\ndegradation and even hinder a network's ability to learn meaningful\nrepresentations. Addressing this gap, our research aims to explore and evaluate\na wide range of audio-based augmentations and uncover combinations that enhance\nSSL model performance in PCG classification. We conduct a comprehensive\ncomparative analysis across multiple datasets, assessing the impact of various\naugmentations on model performance. Our findings reveal that depending on the\ntraining distribution, augmentation choice significantly influences model\nrobustness, with fully-supervised models experiencing up to a 32\\% drop in\neffectiveness when evaluated on unseen data, while SSL models demonstrate\ngreater resilience, losing only 10\\% or even improving in some cases. This\nstudy also highlights the most promising and appropriate augmentations for PCG\nsignal processing, by calculating their effect size on training. These insights\nequip researchers with valuable guidelines for developing reliable models in\nPCG signal processing.\n","authors":["Aristotelis Ballas","Vasileios Papapanagiotou","Christos Diou"],"pdf_url":"https://arxiv.org/pdf/2312.00502v4.pdf","comment":"Accepted in IEEE ACCESS"},{"id":"http://arxiv.org/abs/2412.08240v1","updated":"2024-12-11T09:52:01Z","published":"2024-12-11T09:52:01Z","title":"Unified HT-CNNs Architecture: Transfer Learning for Segmenting Diverse\n  Brain Tumors in MRI from Gliomas to Pediatric Tumors","summary":"  Accurate segmentation of brain tumors from 3D multimodal MRI is vital for\ndiagnosis and treatment planning across diverse brain tumors. This paper\naddresses the challenges posed by the BraTS 2023, presenting a unified transfer\nlearning approach that applies to a broader spectrum of brain tumors. We\nintroduce HT-CNNs, an ensemble of Hybrid Transformers and Convolutional Neural\nNetworks optimized through transfer learning for varied brain tumor\nsegmentation. This method captures spatial and contextual details from MRI\ndata, fine-tuned on diverse datasets representing common tumor types. Through\ntransfer learning, HT-CNNs utilize the learned representations from one task to\nimprove generalization in another, harnessing the power of pre-trained models\non large datasets and fine-tuning them on specific tumor types. We preprocess\ndiverse datasets from multiple international distributions, ensuring\nrepresentativeness for the most common brain tumors. Our rigorous evaluation\nemploys standardized quantitative metrics across all tumor types, ensuring\nrobustness and generalizability. The proposed ensemble model achieves superior\nsegmentation results across the BraTS validation datasets over the previous\nwinning methods. Comprehensive quantitative evaluations using the DSC and HD95\ndemonstrate the effectiveness of our approach. Qualitative segmentation\npredictions further validate the high-quality outputs produced by our model.\nOur findings underscore the potential of transfer learning and ensemble\napproaches in medical image segmentation, indicating a substantial enhancement\nin clinical decision-making and patient care. Despite facing challenges related\nto post-processing and domain gaps, our study sets a new precedent for future\nresearch for brain tumor segmentation. The docker image for the code and models\nhas been made publicly available, https://hub.docker.com/r/razeineldin/ht-cnns.\n","authors":["Ramy A. Zeineldin","Franziska Mathis-Ullrich"],"pdf_url":"https://arxiv.org/pdf/2412.08240v1.pdf","comment":"Accepted in the Computer Assisted Radiology and Surgery (CARS 2024)\n  Conference"},{"id":"http://arxiv.org/abs/2409.04792v2","updated":"2024-12-11T09:40:27Z","published":"2024-09-07T11:08:20Z","title":"Improving Deep Reinforcement Learning by Reducing the Chain Effect of\n  Value and Policy Churn","summary":"  Deep neural networks provide Reinforcement Learning (RL) powerful function\napproximators to address large-scale decision-making problems. However, these\napproximators introduce challenges due to the non-stationary nature of RL\ntraining. One source of the challenges in RL is that output predictions can\nchurn, leading to uncontrolled changes after each batch update for states not\nincluded in the batch. Although such a churn phenomenon exists in each step of\nnetwork training, how churn occurs and impacts RL remains under-explored. In\nthis work, we start by characterizing churn in a view of Generalized Policy\nIteration with function approximation, and we discover a chain effect of churn\nthat leads to a cycle where the churns in value estimation and policy\nimprovement compound and bias the learning dynamics throughout the iteration.\nFurther, we concretize the study and focus on the learning issues caused by the\nchain effect in different settings, including greedy action deviation in\nvalue-based methods, trust region violation in proximal policy optimization,\nand dual bias of policy value in actor-critic methods. We then propose a method\nto reduce the chain effect across different settings, called Churn Approximated\nReductIoN (CHAIN), which can be easily plugged into most existing DRL\nalgorithms. Our experiments demonstrate the effectiveness of our method in both\nreducing churn and improving learning performance across online and offline,\nvalue-based and policy-based RL settings, as well as a scaling setting.\n","authors":["Hongyao Tang","Glen Berseth"],"pdf_url":"https://arxiv.org/pdf/2409.04792v2.pdf","comment":"Accepted to NeurIPS 2024. Project page:\n  https://bluecontra.github.io/CHAIN"},{"id":"http://arxiv.org/abs/2412.07003v2","updated":"2024-12-11T09:32:05Z","published":"2024-12-09T21:17:00Z","title":"Understanding Gradient Descent through the Training Jacobian","summary":"  We examine the geometry of neural network training using the Jacobian of\ntrained network parameters with respect to their initial values. Our analysis\nreveals low-dimensional structure in the training process which is dependent on\nthe input data but largely independent of the labels. We find that the singular\nvalue spectrum of the Jacobian matrix consists of three distinctive regions: a\n\"chaotic\" region of values orders of magnitude greater than one, a large \"bulk\"\nregion of values extremely close to one, and a \"stable\" region of values less\nthan one. Along each bulk direction, the left and right singular vectors are\nnearly identical, indicating that perturbations to the initialization are\ncarried through training almost unchanged. These perturbations have virtually\nno effect on the network's output in-distribution, yet do have an effect far\nout-of-distribution. While the Jacobian applies only locally around a single\ninitialization, we find substantial overlap in bulk subspaces for different\nrandom seeds. Our code is available at\nhttps://github.com/EleutherAI/training-jacobian\n","authors":["Nora Belrose","Adam Scherlis"],"pdf_url":"https://arxiv.org/pdf/2412.07003v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08228v1","updated":"2024-12-11T09:28:30Z","published":"2024-12-11T09:28:30Z","title":"Hierarchical Classification for Automated Image Annotation of Coral Reef\n  Benthic Structures","summary":"  Automated benthic image annotation is crucial to efficiently monitor and\nprotect coral reefs against climate change. Current machine learning approaches\nfail to capture the hierarchical nature of benthic organisms covering reef\nsubstrata, i.e., coral taxonomic levels and health condition. To address this\nlimitation, we propose to annotate benthic images using hierarchical\nclassification. Experiments on a custom dataset from a Northeast Brazilian\ncoral reef show that our approach outperforms flat classifiers, improving both\nF1 and hierarchical F1 scores by approximately 2\\% across varying amounts of\ntraining data. In addition, this hierarchical method aligns more closely with\necological objectives.\n","authors":["Célia Blondin","Joris Guérin","Kelly Inagaki","Guilherme Longo","Laure Berti-Équille"],"pdf_url":"https://arxiv.org/pdf/2412.08228v1.pdf","comment":"Poster at Tackling Climate Change with Machine Learning: workshop at\n  NeurIPS 2024"},{"id":"http://arxiv.org/abs/2412.08225v1","updated":"2024-12-11T09:19:20Z","published":"2024-12-11T09:19:20Z","title":"Improving Active Learning with a Bayesian Representation of Epistemic\n  Uncertainty","summary":"  A popular strategy for active learning is to specifically target a reduction\nin epistemic uncertainty, since aleatoric uncertainty is often considered as\nbeing intrinsic to the system of interest and therefore not reducible. Yet,\ndistinguishing these two types of uncertainty remains challenging and there is\nno single strategy that consistently outperforms the others. We propose to use\na particular combination of probability and possibility theories, with the aim\nof using the latter to specifically represent epistemic uncertainty, and we\nshow how this combination leads to new active learning strategies that have\ndesirable properties. In order to demonstrate the efficiency of these\nstrategies in non-trivial settings, we introduce the notion of a possibilistic\nGaussian process (GP) and consider GP-based multiclass and binary\nclassification problems, for which the proposed methods display a strong\nperformance for both simulated and real datasets.\n","authors":["Jake Thomas","Jeremie Houssineau"],"pdf_url":"https://arxiv.org/pdf/2412.08225v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08222v1","updated":"2024-12-11T09:17:45Z","published":"2024-12-11T09:17:45Z","title":"Structured IB: Improving Information Bottleneck with Structured Feature\n  Learning","summary":"  The Information Bottleneck (IB) principle has emerged as a promising approach\nfor enhancing the generalization, robustness, and interpretability of deep\nneural networks, demonstrating efficacy across image segmentation, document\nclustering, and semantic communication. Among IB implementations, the IB\nLagrangian method, employing Lagrangian multipliers, is widely adopted. While\nnumerous methods for the optimizations of IB Lagrangian based on variational\nbounds and neural estimators are feasible, their performance is highly\ndependent on the quality of their design, which is inherently prone to errors.\nTo address this limitation, we introduce Structured IB, a framework for\ninvestigating potential structured features. By incorporating auxiliary\nencoders to extract missing informative features, we generate more informative\nrepresentations. Our experiments demonstrate superior prediction accuracy and\ntask-relevant information preservation compared to the original IB Lagrangian\nmethod, even with reduced network size.\n","authors":["Hanzhe Yang","Youlong Wu","Dingzhu Wen","Yong Zhou","Yuanming Shi"],"pdf_url":"https://arxiv.org/pdf/2412.08222v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08221v1","updated":"2024-12-11T09:17:39Z","published":"2024-12-11T09:17:39Z","title":"Generate Any Scene: Evaluating and Improving Text-to-Vision Generation\n  with Scene Graph Programming","summary":"  DALL-E and Sora have gained attention by producing implausible images, such\nas \"astronauts riding a horse in space.\" Despite the proliferation of\ntext-to-vision models that have inundated the internet with synthetic visuals,\nfrom images to 3D assets, current benchmarks predominantly evaluate these\nmodels on real-world scenes paired with captions. We introduce Generate Any\nScene, a framework that systematically enumerates scene graphs representing a\nvast array of visual scenes, spanning realistic to imaginative compositions.\nGenerate Any Scene leverages 'scene graph programming', a method for\ndynamically constructing scene graphs of varying complexity from a structured\ntaxonomy of visual elements. This taxonomy includes numerous objects,\nattributes, and relations, enabling the synthesis of an almost infinite variety\nof scene graphs. Using these structured representations, Generate Any Scene\ntranslates each scene graph into a caption, enabling scalable evaluation of\ntext-to-vision models through standard metrics. We conduct extensive\nevaluations across multiple text-to-image, text-to-video, and text-to-3D\nmodels, presenting key findings on model performance. We find that DiT-backbone\ntext-to-image models align more closely with input captions than UNet-backbone\nmodels. Text-to-video models struggle with balancing dynamics and consistency,\nwhile both text-to-video and text-to-3D models show notable gaps in human\npreference alignment. We demonstrate the effectiveness of Generate Any Scene by\nconducting three practical applications leveraging captions generated by\nGenerate Any Scene: 1) a self-improving framework where models iteratively\nenhance their performance using generated data, 2) a distillation process to\ntransfer specific strengths from proprietary models to open-source\ncounterparts, and 3) improvements in content moderation by identifying and\ngenerating challenging synthetic data.\n","authors":["Ziqi Gao","Weikai Huang","Jieyu Zhang","Aniruddha Kembhavi","Ranjay Krishna"],"pdf_url":"https://arxiv.org/pdf/2412.08221v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.05285v3","updated":"2024-12-11T09:05:22Z","published":"2024-07-07T07:06:49Z","title":"Mjolnir: Breaking the Shield of Perturbation-Protected Gradients via\n  Adaptive Diffusion","summary":"  Perturbation-based mechanisms, such as differential privacy, mitigate\ngradient leakage attacks by introducing noise into the gradients, thereby\npreventing attackers from reconstructing clients' private data from the leaked\ngradients. However, can gradient perturbation protection mechanisms truly\ndefend against all gradient leakage attacks? In this paper, we present the\nfirst attempt to break the shield of gradient perturbation protection in\nFederated Learning for the extraction of private information. We focus on\ncommon noise distributions, specifically Gaussian and Laplace, and apply our\napproach to DNN and CNN models. We introduce Mjolnir, a perturbation-resilient\ngradient leakage attack that is capable of removing perturbations from\ngradients without requiring additional access to the original model structure\nor external data. Specifically, we leverage the inherent diffusion properties\nof gradient perturbation protection to develop a novel diffusion-based gradient\ndenoising model for Mjolnir. By constructing a surrogate client model that\ncaptures the structure of perturbed gradients, we obtain crucial gradient data\nfor training the diffusion model. We further utilize the insight that\nmonitoring disturbance levels during the reverse diffusion process can enhance\ngradient denoising capabilities, allowing Mjolnir to generate gradients that\nclosely approximate the original, unperturbed versions through adaptive\nsampling steps. Extensive experiments demonstrate that Mjolnir effectively\nrecovers the protected gradients and exposes the Federated Learning process to\nthe threat of gradient leakage, achieving superior performance in gradient\ndenoising and private data recovery.\n","authors":["Xuan Liu","Siqi Cai","Qihua Zhou","Song Guo","Ruibin Li","Kaiwei Lin"],"pdf_url":"https://arxiv.org/pdf/2407.05285v3.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2411.17251v3","updated":"2024-12-11T09:04:22Z","published":"2024-11-26T09:29:27Z","title":"DGNN-YOLO: Interpretable Dynamic Graph Neural Networks with YOLO11 for\n  Small Object Detection and Tracking in Traffic Surveillance","summary":"  Accurate detection and tracking of small objects, such as pedestrians,\ncyclists, and motorbikes, is critical for traffic surveillance systems, which\nare crucial for improving road safety and decision-making in intelligent\ntransportation systems. However, traditional methods face challenges such as\nocclusion, low resolution, and dynamic traffic conditions, necessitating\ninnovative approaches to address these limitations. This paper introduces\nDGNN-YOLO, a novel framework integrating dynamic graph neural networks (DGNN)\nwith YOLO11 to enhance small-object detection and tracking in traffic\nsurveillance systems. The framework leverages YOLO11's advanced spatial feature\nextraction capabilities for precise object detection and incorporates a DGNN to\nmodel spatial-temporal relationships for robust real-time tracking dynamically.\nBy constructing and updating graph structures, DGNN-YOLO effectively represents\nobjects as nodes and their interactions as edges, thereby ensuring adaptive and\naccurate tracking in complex and dynamic environments. Additionally, Grad-CAM,\nGrad-CAM++, and Eigen-CAM visualization techniques were applied to DGNN-YOLO to\nprovide model-agnostic interpretability and deeper insights into the model's\ndecision-making process, enhancing its transparency and trustworthiness.\nExtensive experiments demonstrated that DGNN-YOLO consistently outperformed\nstate-of-the-art methods in detecting and tracking small objects under diverse\ntraffic conditions, achieving the highest precision (0.8382), recall (0.6875),\nand mAP@0.5:0.95 (0.6476), showing its robustness and scalability, particularly\nin challenging scenarios involving small and occluded objects. This study\nprovides a scalable, real-time traffic surveillance and analysis solution,\nsignificantly contributing to intelligent transportation systems.\n","authors":["Shahriar Soudeep","M. F. Mridha","Md Abrar Jahin","Nilanjan Dey"],"pdf_url":"https://arxiv.org/pdf/2411.17251v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.11553v3","updated":"2024-12-11T09:04:18Z","published":"2024-04-17T16:53:16Z","title":"Language Ranker: A Metric for Quantifying LLM Performance Across High\n  and Low-Resource Languages","summary":"  The development of Large Language Models (LLMs) relies on extensive text\ncorpora, which are often unevenly distributed across languages. This imbalance\nresults in LLMs performing significantly better on high-resource languages like\nEnglish, German, and French, while their capabilities in low-resource languages\nremain inadequate. Currently, there is a lack of quantitative methods to\nevaluate the performance of LLMs in these low-resource languages. To address\nthis gap, we propose the Language Ranker, an intrinsic metric designed to\nbenchmark and rank languages based on LLM performance using internal\nrepresentations. By comparing the LLM's internal representation of various\nlanguages against a baseline derived from English, we can assess the model's\nmultilingual capabilities in a robust and language-agnostic manner. Our\nanalysis reveals that high-resource languages exhibit higher similarity scores\nwith English, demonstrating superior performance, while low-resource languages\nshow lower similarity scores, underscoring the effectiveness of our metric in\nassessing language-specific capabilities. Besides, the experiments show that\nthere is a strong correlation between the LLM's performance in different\nlanguages and the proportion of those languages in its pre-training corpus.\nThese insights underscore the efficacy of the Language Ranker as a tool for\nevaluating LLM performance across different languages, particularly those with\nlimited resources.\n","authors":["Zihao Li","Yucheng Shi","Zirui Liu","Fan Yang","Ali Payani","Ninghao Liu","Mengnan Du"],"pdf_url":"https://arxiv.org/pdf/2404.11553v3.pdf","comment":"Accepted by AAAI 2025 (Social Impact Track)"},{"id":"http://arxiv.org/abs/2412.08201v1","updated":"2024-12-11T08:44:15Z","published":"2024-12-11T08:44:15Z","title":"Model-Editing-Based Jailbreak against Safety-aligned Large Language\n  Models","summary":"  Large Language Models (LLMs) have transformed numerous fields by enabling\nadvanced natural language interactions but remain susceptible to critical\nvulnerabilities, particularly jailbreak attacks. Current jailbreak techniques,\nwhile effective, often depend on input modifications, making them detectable\nand limiting their stealth and scalability. This paper presents Targeted Model\nEditing (TME), a novel white-box approach that bypasses safety filters by\nminimally altering internal model structures while preserving the model's\nintended functionalities. TME identifies and removes safety-critical\ntransformations (SCTs) embedded in model matrices, enabling malicious queries\nto bypass restrictions without input modifications. By analyzing distinct\nactivation patterns between safe and unsafe queries, TME isolates and\napproximates SCTs through an optimization process. Implemented in the D-LLM\nframework, our method achieves an average Attack Success Rate (ASR) of 84.86%\non four mainstream open-source LLMs, maintaining high performance. Unlike\nexisting methods, D-LLM eliminates the need for specific triggers or harmful\nresponse collections, offering a stealthier and more effective jailbreak\nstrategy. This work reveals a covert and robust threat vector in LLM security\nand emphasizes the need for stronger safeguards in model safety alignment.\n","authors":["Yuxi Li","Zhibo Zhang","Kailong Wang","Ling Shi","Haoyu Wang"],"pdf_url":"https://arxiv.org/pdf/2412.08201v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.04653v2","updated":"2024-12-11T08:42:20Z","published":"2024-12-05T22:50:42Z","title":"Hidden in the Noise: Two-Stage Robust Watermarking for Images","summary":"  As the quality of image generators continues to improve, deepfakes become a\ntopic of considerable societal debate. Image watermarking allows responsible\nmodel owners to detect and label their AI-generated content, which can mitigate\nthe harm. Yet, current state-of-the-art methods in image watermarking remain\nvulnerable to forgery and removal attacks. This vulnerability occurs in part\nbecause watermarks distort the distribution of generated images,\nunintentionally revealing information about the watermarking techniques.\n  In this work, we first demonstrate a distortion-free watermarking method for\nimages, based on a diffusion model's initial noise. However, detecting the\nwatermark requires comparing the initial noise reconstructed for an image to\nall previously used initial noises. To mitigate these issues, we propose a\ntwo-stage watermarking framework for efficient detection. During generation, we\naugment the initial noise with generated Fourier patterns to embed information\nabout the group of initial noises we used. For detection, we (i) retrieve the\nrelevant group of noises, and (ii) search within the given group for an initial\nnoise that might match our image. This watermarking approach achieves\nstate-of-the-art robustness to forgery and removal against a large battery of\nattacks.\n","authors":["Kasra Arabi","Benjamin Feuer","R. Teal Witter","Chinmay Hegde","Niv Cohen"],"pdf_url":"https://arxiv.org/pdf/2412.04653v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08198v1","updated":"2024-12-11T08:41:41Z","published":"2024-12-11T08:41:41Z","title":"Adaptive$^2$: Adaptive Domain Mining for Fine-grained Domain Adaptation\n  Modeling","summary":"  Advertising systems often face the multi-domain challenge, where data\ndistributions vary significantly across scenarios. Existing domain adaptation\nmethods primarily focus on building domain-adaptive neural networks but often\nrely on hand-crafted domain information, e.g., advertising placement, which may\nbe sub-optimal. We think that fine-grained \"domain\" patterns exist that are\ndifficult to hand-craft in online advertisement. Thus, we propose Adaptive$^2$,\na novel framework that first learns domains adaptively using a domain mining\nmodule by self-supervision and then employs a shared&specific network to model\nshared and conflicting information. As a practice, we use VQ-VAE as the domain\nmining module and conduct extensive experiments on public benchmarks. Results\nshow that traditional domain adaptation methods with hand-crafted domains\nperform no better than single-domain models under fair FLOPS conditions,\nhighlighting the importance of domain definition. In contrast, Adaptive$^2$\noutperforms existing approaches, emphasizing the effectiveness of our method\nand the significance of domain mining. We also deployed Adaptive$^2$ in the\nlive streaming scenario of Kuaishou Advertising System, demonstrating its\ncommercial value and potential for automatic domain identification. To the best\nof our knowledge, Adaptive$^2$ is the first approach to automatically learn\nboth domain identification and adaptation in online advertising, opening new\nresearch directions for this area.\n","authors":["Wenxuan Sun","Zixuan Yang","Yunli Wang","Zhen Zhang","Zhiqiang Wang","Yu Li","Jian Yang","Yiming Yang","Shiyang Wen","Peng Jiang","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2412.08198v1.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2412.08194v1","updated":"2024-12-11T08:35:56Z","published":"2024-12-11T08:35:56Z","title":"Magneto: Combining Small and Large Language Models for Schema Matching","summary":"  Recent advances in language models opened new opportunities to address\ncomplex schema matching tasks. Schema matching approaches have been proposed\nthat demonstrate the usefulness of language models, but they have also\nuncovered important limitations: Small language models (SLMs) require training\ndata (which can be both expensive and challenging to obtain), and large\nlanguage models (LLMs) often incur high computational costs and must deal with\nconstraints imposed by context windows. We present Magneto, a cost-effective\nand accurate solution for schema matching that combines the advantages of SLMs\nand LLMs to address their limitations. By structuring the schema matching\npipeline in two phases, retrieval and reranking, Magneto can use\ncomputationally efficient SLM-based strategies to derive candidate matches\nwhich can then be reranked by LLMs, thus making it possible to reduce runtime\nwithout compromising matching accuracy. We propose a self-supervised approach\nto fine-tune SLMs which uses LLMs to generate syntactically diverse training\ndata, and prompting strategies that are effective for reranking. We also\nintroduce a new benchmark, developed in collaboration with domain experts,\nwhich includes real biomedical datasets and presents new challenges to schema\nmatching methods. Through a detailed experimental evaluation, using both our\nnew and existing benchmarks, we show that Magneto is scalable and attains high\naccuracy for datasets from different domains.\n","authors":["Yurong Liu","Eduardo Pena","Aecio Santos","Eden Wu","Juliana Freire"],"pdf_url":"https://arxiv.org/pdf/2412.08194v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08193v1","updated":"2024-12-11T08:35:13Z","published":"2024-12-11T08:35:13Z","title":"Mixture of Experts Meets Decoupled Message Passing: Towards General and\n  Adaptive Node Classification","summary":"  Graph neural networks excel at graph representation learning but struggle\nwith heterophilous data and long-range dependencies. And graph transformers\naddress these issues through self-attention, yet face scalability and noise\nchallenges on large-scale graphs. To overcome these limitations, we propose\nGNNMoE, a universal model architecture for node classification. This\narchitecture flexibly combines fine-grained message-passing operations with a\nmixture-of-experts mechanism to build feature encoding blocks. Furthermore, by\nincorporating soft and hard gating layers to assign the most suitable expert\nnetworks to each node, we enhance the model's expressive power and adaptability\nto different graph types. In addition, we introduce adaptive residual\nconnections and an enhanced FFN module into GNNMoE, further improving the\nexpressiveness of node representation. Extensive experimental results\ndemonstrate that GNNMoE performs exceptionally well across various types of\ngraph data, effectively alleviating the over-smoothing issue and global noise,\nenhancing model robustness and adaptability, while also ensuring computational\nefficiency on large-scale graphs.\n","authors":["Xuanze Chen","Jiajun Zhou","Shanqing Yu","Qi Xuan"],"pdf_url":"https://arxiv.org/pdf/2412.08193v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2410.11189"},{"id":"http://arxiv.org/abs/2412.01849v2","updated":"2024-12-11T08:28:37Z","published":"2024-11-28T06:09:12Z","title":"Towards Data-centric Machine Learning on Directed Graphs: a Survey","summary":"  In recent years, Graph Neural Networks (GNNs) have made significant advances\nin processing structured data. However, most of them primarily adopted a\nmodel-centric approach, which simplifies graphs by converting them into\nundirected formats and emphasizes model designs. This approach is inherently\nlimited in real-world applications due to the unavoidable information loss in\nsimple undirected graphs and the model optimization challenges that arise when\nexceeding the upper bounds of this sub-optimal data representational capacity.\nAs a result, there has been a shift toward data-centric methods that prioritize\nimproving graph quality and representation. Specifically, various types of\ngraphs can be derived from naturally structured data, including heterogeneous\ngraphs, hypergraphs, and directed graphs. Among these, directed graphs offer\ndistinct advantages in topological systems by modeling causal relationships,\nand directed GNNs have been extensively studied in recent years. However, a\ncomprehensive survey of this emerging topic is still lacking. Therefore, we aim\nto provide a comprehensive review of directed graph learning, with a particular\nfocus on a data-centric perspective. Specifically, we first introduce a novel\ntaxonomy for existing studies. Subsequently, we re-examine these methods from\nthe data-centric perspective, with an emphasis on understanding and improving\ndata representation. It demonstrates that a deep understanding of directed\ngraphs and their quality plays a crucial role in model performance.\nAdditionally, we explore the diverse applications of directed GNNs across 10+\ndomains, highlighting their broad applicability. Finally, we identify key\nopportunities and challenges within the field, offering insights that can guide\nfuture research and development in directed graph learning.\n","authors":["Henan Sun","Xunkai Li","Daohan Su","Junyi Han","Rong-Hua Li","Guoren Wang"],"pdf_url":"https://arxiv.org/pdf/2412.01849v2.pdf","comment":"In Progress"},{"id":"http://arxiv.org/abs/2412.08187v1","updated":"2024-12-11T08:27:25Z","published":"2024-12-11T08:27:25Z","title":"From communities to interpretable network and word embedding: an unified\n  approach","summary":"  Modelling information from complex systems such as humans social interaction\nor words co-occurrences in our languages can help to understand how these\nsystems are organized and function. Such systems can be modelled by networks,\nand network theory provides a useful set of methods to analyze them. Among\nthese methods, graph embedding is a powerful tool to summarize the interactions\nand topology of a network in a vectorized feature space. When used in input of\nmachine learning algorithms, embedding vectors help with common graph problems\nsuch as link prediction, graph matching, etc. Word embedding has the goal of\nrepresenting the sense of words, extracting it from large text corpora. Despite\ndifferences in the structure of information in input of embedding algorithms,\nmany graph embedding approaches are adapted and inspired from methods in NLP.\nLimits of these methods are observed in both domains. Most of these methods\nrequire long and resource greedy training. Another downside to most methods is\nthat they are black-box, from which understanding how the information is\nstructured is rather complex. Interpretability of a model allows understanding\nhow the vector space is structured without the need for external information,\nand thus can be audited more easily. With both these limitations in mind, we\npropose a novel framework to efficiently embed network vertices in an\ninterpretable vector space. Our Lower Dimension Bipartite Framework (LDBGF)\nleverages the bipartite projection of a network using cliques to reduce\ndimensionality. Along with LDBGF, we introduce two implementations of this\nframework that rely on communities instead of cliques: SINr-NR and SINr-MF. We\nshow that SINr-MF can perform well on classical graphs and SINr-NR can produce\nhigh-quality graph and word embeddings that are interpretable and stable across\nruns.\n","authors":["Thibault Prouteau","Nicolas Dugué","Simon Guillot"],"pdf_url":"https://arxiv.org/pdf/2412.08187v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08175v1","updated":"2024-12-11T08:05:35Z","published":"2024-12-11T08:05:35Z","title":"Analyzing and Improving Model Collapse in Rectified Flow Models","summary":"  Generative models aim to produce synthetic data indistinguishable from real\ndistributions, but iterative training on self-generated data can lead to\n\\emph{model collapse (MC)}, where performance degrades over time. In this work,\nwe provide the first theoretical analysis of MC in Rectified Flow by framing it\nwithin the context of Denoising Autoencoders (DAEs). We show that when DAE\nmodels are trained on recursively generated synthetic data with small noise\nvariance, they suffer from MC with progressive diminishing generation quality.\nTo address this MC issue, we propose methods that strategically incorporate\nreal data into the training process, even when direct noise-image pairs are\nunavailable. Our proposed techniques, including Reverse Collapse-Avoiding (RCA)\nReflow and Online Collapse-Avoiding Reflow (OCAR), effectively prevent MC while\nmaintaining the efficiency benefits of Rectified Flow. Extensive experiments on\nstandard image datasets demonstrate that our methods not only mitigate MC but\nalso improve sampling efficiency, leading to higher-quality image generation\nwith fewer sampling steps.\n","authors":["Huminhao Zhu","Fangyikang Wang","Tianyu Ding","Qing Qu","Zhihui Zhu"],"pdf_url":"https://arxiv.org/pdf/2412.08175v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.11464v3","updated":"2024-12-11T08:03:56Z","published":"2024-05-19T06:43:12Z","title":"Efficient Prompt Tuning by Multi-Space Projection and Prompt Fusion","summary":"  Prompt tuning is a promising method to fine-tune a pre-trained language model\nwithout retraining its large-scale parameters. Instead, it attaches a soft\nprompt to the input text, whereby downstream tasks can be well adapted by\nmerely learning the embeddings of prompt tokens. Nevertheless, existing methods\nstill suffer from two challenges: (i) they are hard to balance accuracy and\nefficiency. A longer (shorter) soft prompt generally leads to a better(worse)\naccuracy but at the cost of more (less) training time. (ii)The performance may\nnot be consistent when adapting to different downstream tasks. We attribute it\nto the same embedding space but responsible for different requirements of\ndownstream tasks. To address these issues, we propose an Efficient Prompt\nTuning method (EPT) by multi-space projection and prompt fusion. Specifically,\nit decomposes a given soft prompt into a shorter prompt and two low-rank\nmatrices, significantly reducing the training time. Accuracy is also enhanced\nby leveraging low-rank matrices and the short prompt as additional knowledge\nsources to enrich the semantics of the original short prompt. In addition, we\nproject the soft prompt into multiple subspaces to improve the performance\nconsistency, and then adaptively learn the combination weights of different\nspaces through a gating network. Experiments on 13 natural language processing\ndownstream tasks show that our method significantly and consistently\noutperforms 11 comparison methods with the relative percentage of improvements\nup to 12.9%, and training time decreased by 14%.\n","authors":["Pengxiang Lan","Enneng Yang","Yuting Liu","Guibing Guo","Jianzhe Zhao","Xingwei Wang"],"pdf_url":"https://arxiv.org/pdf/2405.11464v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08174v1","updated":"2024-12-11T08:03:35Z","published":"2024-12-11T08:03:35Z","title":"Can Graph Neural Networks Learn Language with Extremely Weak Text\n  Supervision?","summary":"  While great success has been achieved in building vision models with\nContrastive Language-Image Pre-training (CLIP) over Internet-scale image-text\npairs, building transferable Graph Neural Networks (GNNs) with CLIP pipeline is\nchallenging because of three fundamental issues: the scarcity of labeled data\nand text supervision, different levels of downstream tasks, and the conceptual\ngaps between domains. In this work, to address these issues, we leverage\nmulti-modal prompt learning to effectively adapt pre-trained GNN to downstream\ntasks and data, given only a few semantically labeled samples, each with\nextremely weak text supervision. Our new paradigm embeds the graphs directly in\nthe same space as the Large Language Models (LLMs) by learning both graph\nprompts and text prompts simultaneously. To accomplish this, we improve\nstate-of-the-art graph prompt method, and then propose the first graph-language\nmulti-modal prompt learning approach for exploiting the knowledge in\npre-trained models. Notably, due to the insufficient supervision for\nfine-tuning, in our paradigm, the pre-trained GNN and the LLM are kept frozen,\nso the learnable parameters are much fewer than fine-tuning any pre-trained\nmodel. Through extensive experiments on real-world datasets, we demonstrate the\nsuperior performance of our paradigm in few-shot, multi-task-level, and\ncross-domain settings. Moreover, we build the first CLIP-style zero-shot\nclassification prototype that can generalize GNNs to unseen classes with\nextremely weak text supervision.\n","authors":["Zihao Li","Lecheng Zheng","Bowen Jin","Dongqi Fu","Baoyu Jing","Yikun Ban","Jingrui He","Jiawei Han"],"pdf_url":"https://arxiv.org/pdf/2412.08174v1.pdf","comment":"Preprint, 26 pages"},{"id":"http://arxiv.org/abs/2210.04398v2","updated":"2024-12-11T07:58:21Z","published":"2022-10-10T02:07:32Z","title":"Scaling Up Probabilistic Circuits by Latent Variable Distillation","summary":"  Probabilistic Circuits (PCs) are a unified framework for tractable\nprobabilistic models that support efficient computation of various\nprobabilistic queries (e.g., marginal probabilities). One key challenge is to\nscale PCs to model large and high-dimensional real-world datasets: we observe\nthat as the number of parameters in PCs increases, their performance\nimmediately plateaus. This phenomenon suggests that the existing optimizers\nfail to exploit the full expressive power of large PCs. We propose to overcome\nsuch bottleneck by latent variable distillation: we leverage the less tractable\nbut more expressive deep generative models to provide extra supervision over\nthe latent variables of PCs. Specifically, we extract information from\nTransformer-based generative models to assign values to latent variables of\nPCs, providing guidance to PC optimizers. Experiments on both image and\nlanguage modeling benchmarks (e.g., ImageNet and WikiText-2) show that latent\nvariable distillation substantially boosts the performance of large PCs\ncompared to their counterparts without latent variable distillation. In\nparticular, on the image modeling benchmarks, PCs achieve competitive\nperformance against some of the widely-used deep generative models, including\nvariational autoencoders and flow-based models, opening up new avenues for\ntractable generative modeling. Our code can be found at\nhttps://github.com/UCLA-StarAI/LVD.\n","authors":["Anji Liu","Honghua Zhang","Guy Van den Broeck"],"pdf_url":"https://arxiv.org/pdf/2210.04398v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19370v4","updated":"2024-12-11T07:53:57Z","published":"2024-06-27T17:50:05Z","title":"Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept\n  Space","summary":"  Modern generative models demonstrate impressive capabilities, likely stemming\nfrom an ability to identify and manipulate abstract concepts underlying their\ntraining data. However, fundamental questions remain: what determines the\nconcepts a model learns, the order in which it learns them, and its ability to\nmanipulate those concepts? To address these questions, we propose analyzing a\nmodel's learning dynamics via a framework we call the concept space, where each\naxis represents an independent concept underlying the data generating process.\nBy characterizing learning dynamics in this space, we identify how the speed at\nwhich a concept is learned, and hence the order of concept learning, is\ncontrolled by properties of the data we term concept signal. Further, we\nobserve moments of sudden turns in the direction of a model's learning dynamics\nin concept space. Surprisingly, these points precisely correspond to the\nemergence of hidden capabilities, i.e., where latent interventions show the\nmodel possesses the capability to manipulate a concept, but these capabilities\ncannot yet be elicited via naive input prompting. While our results focus on\nsynthetically defined toy datasets, we hypothesize a general claim on emergence\nof hidden capabilities may hold: generative models possess latent capabilities\nthat emerge suddenly and consistently during training, though a model might not\nexhibit these capabilities under naive input prompting.\n","authors":["Core Francisco Park","Maya Okawa","Andrew Lee","Hidenori Tanaka","Ekdeep Singh Lubana"],"pdf_url":"https://arxiv.org/pdf/2406.19370v4.pdf","comment":"NeurIPS 2024 (Spotlight)"},{"id":"http://arxiv.org/abs/2401.03349v2","updated":"2024-12-11T07:49:41Z","published":"2023-11-28T21:14:02Z","title":"Image Inpainting via Tractable Steering of Diffusion Models","summary":"  Diffusion models are the current state of the art for generating\nphotorealistic images. Controlling the sampling process for constrained image\ngeneration tasks such as inpainting, however, remains challenging since exact\nconditioning on such constraints is intractable. While existing methods use\nvarious techniques to approximate the constrained posterior, this paper\nproposes to exploit the ability of Tractable Probabilistic Models (TPMs) to\nexactly and efficiently compute the constrained posterior, and to leverage this\nsignal to steer the denoising process of diffusion models. Specifically, this\npaper adopts a class of expressive TPMs termed Probabilistic Circuits (PCs).\nBuilding upon prior advances, we further scale up PCs and make them capable of\nguiding the image generation process of diffusion models. Empirical results\nsuggest that our approach can consistently improve the overall quality and\nsemantic coherence of inpainted images across three natural image datasets\n(i.e., CelebA-HQ, ImageNet, and LSUN) with only $\\sim\\! 10 \\%$ additional\ncomputational overhead brought by the TPM. Further, with the help of an image\nencoder and decoder, our method can readily accept semantic constraints on\nspecific regions of the image, which opens up the potential for more controlled\nimage generation tasks. In addition to proposing a new framework for\nconstrained image generation, this paper highlights the benefit of more\ntractable models and motivates the development of expressive TPMs.\n","authors":["Anji Liu","Mathias Niepert","Guy Van den Broeck"],"pdf_url":"https://arxiv.org/pdf/2401.03349v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08167v1","updated":"2024-12-11T07:44:35Z","published":"2024-12-11T07:44:35Z","title":"Diversity Drives Fairness: Ensemble of Higher Order Mutants for\n  Intersectional Fairness of Machine Learning Software","summary":"  Intersectional fairness is a critical requirement for Machine Learning (ML)\nsoftware, demanding fairness across subgroups defined by multiple protected\nattributes. This paper introduces FairHOME, a novel ensemble approach using\nhigher order mutation of inputs to enhance intersectional fairness of ML\nsoftware during the inference phase. Inspired by social science theories\nhighlighting the benefits of diversity, FairHOME generates mutants representing\ndiverse subgroups for each input instance, thus broadening the array of\nperspectives to foster a fairer decision-making process. Unlike conventional\nensemble methods that combine predictions made by different models, FairHOME\ncombines predictions for the original input and its mutants, all generated by\nthe same ML model, to reach a final decision. Notably, FairHOME is even\napplicable to deployed ML software as it bypasses the need for training new\nmodels. We extensively evaluate FairHOME against seven state-of-the-art\nfairness improvement methods across 24 decision-making tasks using widely\nadopted metrics. FairHOME consistently outperforms existing methods across all\nmetrics considered. On average, it enhances intersectional fairness by 47.5%,\nsurpassing the currently best-performing method by 9.6 percentage points.\n","authors":["Zhenpeng Chen","Xinyue Li","Jie M. Zhang","Federica Sarro","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2412.08167v1.pdf","comment":"Accepted by the 47th International Conference on Software Engineering\n  (ICSE 2025). Please include ICSE in any citations"},{"id":"http://arxiv.org/abs/2412.08161v1","updated":"2024-12-11T07:33:18Z","published":"2024-12-11T07:33:18Z","title":"Collaborative Hybrid Propagator for Temporal Misalignment in\n  Audio-Visual Segmentation","summary":"  Audio-visual video segmentation (AVVS) aims to generate pixel-level maps of\nsound-producing objects that accurately align with the corresponding audio.\nHowever, existing methods often face temporal misalignment, where audio cues\nand segmentation results are not temporally coordinated. Audio provides two\ncritical pieces of information: i) target object-level details and ii) the\ntiming of when objects start and stop producing sounds. Current methods focus\nmore on object-level information but neglect the boundaries of audio semantic\nchanges, leading to temporal misalignment. To address this issue, we propose a\nCollaborative Hybrid Propagator Framework~(Co-Prop). This framework includes\ntwo main steps: Preliminary Audio Boundary Anchoring and Frame-by-Frame\nAudio-Insert Propagation. To Anchor the audio boundary, we employ\nretrieval-assist prompts with Qwen large language models to identify control\npoints of audio semantic changes. These control points split the audio into\nsemantically consistent audio portions. After obtaining the control point\nlists, we propose the Audio Insertion Propagator to process each audio portion\nusing a frame-by-frame audio insertion propagation and matching approach. We\ncurated a compact dataset comprising diverse source conversion cases and\ndevised a metric to assess alignment rates. Compared to traditional\nsimultaneous processing methods, our approach reduces memory requirements and\nfacilitates frame alignment. Experimental results demonstrate the effectiveness\nof our approach across three datasets and two backbones. Furthermore, our\nmethod can be integrated with existing AVVS approaches, offering plug-and-play\nfunctionality to enhance their performance.\n","authors":["Kexin Li","Zongxin Yang","Yi Yang","Jun Xiao"],"pdf_url":"https://arxiv.org/pdf/2412.08161v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.05996v2","updated":"2024-12-11T07:32:58Z","published":"2022-02-12T06:04:13Z","title":"Mixture of Online and Offline Experts for Non-stationary Time Series","summary":"  We consider a general and realistic scenario involving non-stationary time\nseries, consisting of several offline intervals with different distributions\nwithin a fixed offline time horizon, and an online interval that continuously\nreceives new samples. For non-stationary time series, the data distribution in\nthe current online interval may have appeared in previous offline intervals. We\ntheoretically explore the feasibility of applying knowledge from offline\nintervals to the current online interval. To this end, we propose the Mixture\nof Online and Offline Experts (MOOE). MOOE learns static offline experts from\noffline intervals and maintains a dynamic online expert for the current online\ninterval. It then adaptively combines the offline and online experts using a\nmeta expert to make predictions for the samples received in the online\ninterval. Specifically, we focus on theoretical analysis, deriving parameter\nconvergence, regret bounds, and generalization error bounds to prove the\neffectiveness of the algorithm.\n","authors":["Zhilin Zhao","Longbing Cao","Yuanyu Wan"],"pdf_url":"https://arxiv.org/pdf/2202.05996v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08160v1","updated":"2024-12-11T07:32:38Z","published":"2024-12-11T07:32:38Z","title":"DG-Mamba: Robust and Efficient Dynamic Graph Structure Learning with\n  Selective State Space Models","summary":"  Dynamic graphs exhibit intertwined spatio-temporal evolutionary patterns,\nwidely existing in the real world. Nevertheless, the structure incompleteness,\nnoise, and redundancy result in poor robustness for Dynamic Graph Neural\nNetworks (DGNNs). Dynamic Graph Structure Learning (DGSL) offers a promising\nway to optimize graph structures. However, aside from encountering unacceptable\nquadratic complexity, it overly relies on heuristic priors, making it hard to\ndiscover underlying predictive patterns. How to efficiently refine the dynamic\nstructures, capture intrinsic dependencies, and learn robust representations,\nremains under-explored. In this work, we propose the novel DG-Mamba, a robust\nand efficient Dynamic Graph structure learning framework with the Selective\nState Space Models (Mamba). To accelerate the spatio-temporal structure\nlearning, we propose a kernelized dynamic message-passing operator that reduces\nthe quadratic time complexity to linear. To capture global intrinsic dynamics,\nwe establish the dynamic graph as a self-contained system with State Space\nModel. By discretizing the system states with the cross-snapshot graph\nadjacency, we enable the long-distance dependencies capturing with the\nselective snapshot scan. To endow learned dynamic structures more expressive\nwith informativeness, we propose the self-supervised Principle of Relevant\nInformation for DGSL to regularize the most relevant yet least redundant\ninformation, enhancing global robustness. Extensive experiments demonstrate the\nsuperiority of the robustness and efficiency of our DG-Mamba compared with the\nstate-of-the-art baselines against adversarial attacks.\n","authors":["Haonan Yuan","Qingyun Sun","Zhaonan Wang","Xingcheng Fu","Cheng Ji","Yongjian Wang","Bo Jin","Jianxin Li"],"pdf_url":"https://arxiv.org/pdf/2412.08160v1.pdf","comment":"Accepted by the Main Technical Track of the 39th Annual AAAI\n  Conference on Artificial Intelligence (AAAI-2025)"},{"id":"http://arxiv.org/abs/2412.08158v1","updated":"2024-12-11T07:29:04Z","published":"2024-12-11T07:29:04Z","title":"How Vision-Language Tasks Benefit from Large Pre-trained Models: A\n  Survey","summary":"  The exploration of various vision-language tasks, such as visual captioning,\nvisual question answering, and visual commonsense reasoning, is an important\narea in artificial intelligence and continuously attracts the research\ncommunity's attention. Despite the improvements in overall performance, classic\nchallenges still exist in vision-language tasks and hinder the development of\nthis area. In recent years, the rise of pre-trained models is driving the\nresearch on vision-language tasks. Thanks to the massive scale of training data\nand model parameters, pre-trained models have exhibited excellent performance\nin numerous downstream tasks. Inspired by the powerful capabilities of\npre-trained models, new paradigms have emerged to solve the classic challenges.\nSuch methods have become mainstream in current research with increasing\nattention and rapid advances. In this paper, we present a comprehensive\noverview of how vision-language tasks benefit from pre-trained models. First,\nwe review several main challenges in vision-language tasks and discuss the\nlimitations of previous solutions before the era of pre-training. Next, we\nsummarize the recent advances in incorporating pre-trained models to address\nthe challenges in vision-language tasks. Finally, we analyze the potential\nrisks associated with the inherent limitations of pre-trained models and\ndiscuss possible solutions, attempting to provide future research directions.\n","authors":["Yayun Qi","Hongxi Li","Yiqi Song","Xinxiao Wu","Jiebo Luo"],"pdf_url":"https://arxiv.org/pdf/2412.08158v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2410.13190v2","updated":"2024-12-11T07:25:40Z","published":"2024-10-17T03:36:18Z","title":"CohEx: A Generalized Framework for Cohort Explanation","summary":"  eXplainable Artificial Intelligence (XAI) has garnered significant attention\nfor enhancing transparency and trust in machine learning models. However, the\nscopes of most existing explanation techniques focus either on offering a\nholistic view of the explainee model (global explanation) or on individual\ninstances (local explanation), while the middle ground, i.e., cohort-based\nexplanation, is less explored. Cohort explanations offer insights into the\nexplainee's behavior on a specific group or cohort of instances, enabling a\ndeeper understanding of model decisions within a defined context. In this\npaper, we discuss the unique challenges and opportunities associated with\nmeasuring cohort explanations, define their desired properties, and create a\ngeneralized framework for generating cohort explanations based on supervised\nclustering.\n","authors":["Fanyu Meng","Xin Liu","Zhaodan Kong","Xin Chen"],"pdf_url":"https://arxiv.org/pdf/2410.13190v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.00218v3","updated":"2024-12-11T07:18:10Z","published":"2024-11-29T19:25:00Z","title":"NushuRescue: Revitalization of the Endangered Nushu Language with AI","summary":"  The preservation and revitalization of endangered and extinct languages is a\nmeaningful endeavor, conserving cultural heritage while enriching fields like\nlinguistics and anthropology. However, these languages are typically\nlow-resource, making their reconstruction labor-intensive and costly. This\nchallenge is exemplified by Nushu, a rare script historically used by Yao women\nin China for self-expression within a patriarchal society. To address this\nchallenge, we introduce NushuRescue, an AI-driven framework designed to train\nlarge language models (LLMs) on endangered languages with minimal data.\nNushuRescue automates evaluation and expands target corpora to accelerate\nlinguistic revitalization. As a foundational component, we developed NCGold, a\n500-sentence Nushu-Chinese parallel corpus, the first publicly available\ndataset of its kind. Leveraging GPT-4-Turbo, with no prior exposure to Nushu\nand only 35 short examples from NCGold, NushuRescue achieved 48.69% translation\naccuracy on 50 withheld sentences and generated NCSilver, a set of 98 newly\ntranslated modern Chinese sentences of varying lengths. A sample of both NCGold\nand NCSilver is included in the Supplementary Materials. Additionally, we\ndeveloped FastText-based and Seq2Seq models to further support research on\nNushu. NushuRescue provides a versatile and scalable tool for the\nrevitalization of endangered languages, minimizing the need for extensive human\ninput.\n","authors":["Ivory Yang","Weicheng Ma","Soroush Vosoughi"],"pdf_url":"https://arxiv.org/pdf/2412.00218v3.pdf","comment":"Accepted to COLING 2025"},{"id":"http://arxiv.org/abs/2412.08147v1","updated":"2024-12-11T07:06:36Z","published":"2024-12-11T07:06:36Z","title":"How to Weight Multitask Finetuning? Fast Previews via Bayesian\n  Model-Merging","summary":"  When finetuning multiple tasks altogether, it is important to carefully weigh\nthem to get a good performance, but searching for good weights can be difficult\nand costly. Here, we propose to aid the search with fast previews to quickly\nget a rough idea of different reweighting options. We use model merging to\ncreate previews by simply reusing and averaging parameters of models trained on\neach task separately (no retraining required). To improve the quality of\npreviews, we propose a Bayesian approach to design new merging strategies by\nusing more flexible posteriors. We validate our findings on vision and\nnatural-language transformers. Our work shows the benefits of model merging via\nBayes to improve multitask finetuning.\n","authors":["Hugo Monzón Maldonado","Thomas Möllenhoff","Nico Daheim","Iryna Gurevych","Mohammad Emtiyaz Khan"],"pdf_url":"https://arxiv.org/pdf/2412.08147v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06853v2","updated":"2024-12-11T07:04:52Z","published":"2024-12-08T15:17:53Z","title":"Tube Loss: A Novel Approach for Prediction Interval Estimation and\n  probabilistic forecasting","summary":"  This paper proposes a novel loss function, called 'Tube Loss', for\nsimultaneous estimation of bounds of a Prediction Interval (PI) in the\nregression setup, and also for generating probabilistic forecasts from time\nseries data solving a single optimization problem. The PIs obtained by\nminimizing the empirical risk based on the Tube Loss are shown to be of better\nquality than the PIs obtained by the existing methods in the following sense.\nFirst, it yields intervals that attain the prespecified confidence level $t\n\\in(0,1)$ asymptotically. A theoretical proof of this fact is given. Secondly,\nthe user is allowed to move the interval up or down by controlling the value of\na parameter. This helps the user to choose a PI capturing denser regions of the\nprobability distribution of the response variable inside the interval, and\nthus, sharpening its width. This is shown to be especially useful when the\nconditional distribution of the response variable is skewed. Further, the Tube\nLoss based PI estimation method can trade-off between the coverage and the\naverage width by solving a single optimization problem. It enables further\nreduction of the average width of PI through re-calibration. Also, unlike a few\nexisting PI estimation methods the gradient descent (GD) method can be used for\nminimization of empirical risk. Finally, through extensive experimentation, we\nhave shown the efficacy of the Tube Loss based PI estimation in kernel\nmachines, neural networks and deep networks and also for probabilistic\nforecasting tasks. The codes of the experiments are available at\nhttps://github.com/ltpritamanand/Tube_loss\n","authors":["Pritam Anand","Tathagata Bandyopadhyay","Suresh Chandra"],"pdf_url":"https://arxiv.org/pdf/2412.06853v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08144v1","updated":"2024-12-11T07:04:35Z","published":"2024-12-11T07:04:35Z","title":"AGMixup: Adaptive Graph Mixup for Semi-supervised Node Classification","summary":"  Mixup is a data augmentation technique that enhances model generalization by\ninterpolating between data points using a mixing ratio $\\lambda$ in the image\ndomain. Recently, the concept of mixup has been adapted to the graph domain\nthrough node-centric interpolations. However, these approaches often fail to\naddress the complexity of interconnected relationships, potentially damaging\nthe graph's natural topology and undermining node interactions. Furthermore,\ncurrent graph mixup methods employ a one-size-fits-all strategy with a randomly\nsampled $\\lambda$ for all mixup pairs, ignoring the diverse needs of different\npairs. This paper proposes an Adaptive Graph Mixup (AGMixup) framework for\nsemi-supervised node classification. AGMixup introduces a subgraph-centric\napproach, which treats each subgraph similarly to how images are handled in\nEuclidean domains, thus facilitating a more natural integration of mixup into\ngraph-based learning. We also propose an adaptive mechanism to tune the mixing\nratio $\\lambda$ for diverse mixup pairs, guided by the contextual similarity\nand uncertainty of the involved subgraphs. Extensive experiments across seven\ndatasets on semi-supervised node classification benchmarks demonstrate\nAGMixup's superiority over state-of-the-art graph mixup methods. Source codes\nare available at \\url{https://github.com/WeigangLu/AGMixup}.\n","authors":["Weigang Lu","Ziyu Guan","Wei Zhao","Yaming Yang","Yibing Zhan","Yiheng Lu","Dapeng Tao"],"pdf_url":"https://arxiv.org/pdf/2412.08144v1.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2412.08139v1","updated":"2024-12-11T06:54:39Z","published":"2024-12-11T06:54:39Z","title":"Wasserstein Distance Rivals Kullback-Leibler Divergence for Knowledge\n  Distillation","summary":"  Since pioneering work of Hinton et al., knowledge distillation based on\nKullback-Leibler Divergence (KL-Div) has been predominant, and recently its\nvariants have achieved compelling performance. However, KL-Div only compares\nprobabilities of the corresponding category between the teacher and student\nwhile lacking a mechanism for cross-category comparison. Besides, KL-Div is\nproblematic when applied to intermediate layers, as it cannot handle\nnon-overlapping distributions and is unaware of geometry of the underlying\nmanifold. To address these downsides, we propose a methodology of Wasserstein\nDistance (WD) based knowledge distillation. Specifically, we propose a logit\ndistillation method called WKD-L based on discrete WD, which performs\ncross-category comparison of probabilities and thus can explicitly leverage\nrich interrelations among categories. Moreover, we introduce a feature\ndistillation method called WKD-F, which uses a parametric method for modeling\nfeature distributions and adopts continuous WD for transferring knowledge from\nintermediate layers. Comprehensive evaluations on image classification and\nobject detection have shown (1) for logit distillation WKD-L outperforms very\nstrong KL-Div variants; (2) for feature distillation WKD-F is superior to the\nKL-Div counterparts and state-of-the-art competitors. The source code is\navailable at https://peihuali.org/WKD\n","authors":["Jiaming Lv","Haoyuan Yang","Peihua Li"],"pdf_url":"https://arxiv.org/pdf/2412.08139v1.pdf","comment":"Accepted to NeurIPS 2024. Equal contribution from first two authors"},{"id":"http://arxiv.org/abs/2406.07540v2","updated":"2024-12-11T06:53:55Z","published":"2024-06-11T17:59:01Z","title":"Ctrl-X: Controlling Structure and Appearance for Text-To-Image\n  Generation Without Guidance","summary":"  Recent controllable generation approaches such as FreeControl and Diffusion\nSelf-Guidance bring fine-grained spatial and appearance control to\ntext-to-image (T2I) diffusion models without training auxiliary modules.\nHowever, these methods optimize the latent embedding for each type of score\nfunction with longer diffusion steps, making the generation process\ntime-consuming and limiting their flexibility and use. This work presents\nCtrl-X, a simple framework for T2I diffusion controlling structure and\nappearance without additional training or guidance. Ctrl-X designs feed-forward\nstructure control to enable the structure alignment with a structure image and\nsemantic-aware appearance transfer to facilitate the appearance transfer from a\nuser-input image. Extensive qualitative and quantitative experiments illustrate\nthe superior performance of Ctrl-X on various condition inputs and model\ncheckpoints. In particular, Ctrl-X supports novel structure and appearance\ncontrol with arbitrary condition images of any modality, exhibits superior\nimage quality and appearance transfer compared to existing works, and provides\ninstant plug-and-play functionality to any T2I and text-to-video (T2V)\ndiffusion model. See our project page for an overview of the results:\nhttps://genforce.github.io/ctrl-x\n","authors":["Kuan Heng Lin","Sicheng Mo","Ben Klingher","Fangzhou Mu","Bolei Zhou"],"pdf_url":"https://arxiv.org/pdf/2406.07540v2.pdf","comment":"22 pages, 17 figures, see project page at\n  https://genforce.github.io/ctrl-x"},{"id":"http://arxiv.org/abs/2412.08138v1","updated":"2024-12-11T06:51:45Z","published":"2024-12-11T06:51:45Z","title":"Learn How to Query from Unlabeled Data Streams in Federated Learning","summary":"  Federated learning (FL) enables collaborative learning among decentralized\nclients while safeguarding the privacy of their local data. Existing studies on\nFL typically assume offline labeled data available at each client when the\ntraining starts. Nevertheless, the training data in practice often arrive at\nclients in a streaming fashion without ground-truth labels. Given the expensive\nannotation cost, it is critical to identify a subset of informative samples for\nlabeling on clients. However, selecting samples locally while accommodating the\nglobal training objective presents a challenge unique to FL. In this work, we\ntackle this conundrum by framing the data querying process in FL as a\ncollaborative decentralized decision-making problem and proposing an effective\nsolution named LeaDQ, which leverages multi-agent reinforcement learning\nalgorithms. In particular, under the implicit guidance from global information,\nLeaDQ effectively learns the local policies for distributed clients and steers\nthem towards selecting samples that can enhance the global model's accuracy.\nExtensive simulations on image and text tasks show that LeaDQ advances the\nmodel performance in various FL scenarios, outperforming the benchmarking\nalgorithms.\n","authors":["Yuchang Sun","Xinran Li","Tao Lin","Jun Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.08138v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08135v1","updated":"2024-12-11T06:44:22Z","published":"2024-12-11T06:44:22Z","title":"DOGE: An Extrinsic Orientation and Gyroscope Bias Estimation for\n  Visual-Inertial Odometry Initialization","summary":"  Most existing visual-inertial odometry (VIO) initialization methods rely on\naccurate pre-calibrated extrinsic parameters. However, during long-term use,\nirreversible structural deformation caused by temperature changes, mechanical\nsqueezing, etc. will cause changes in extrinsic parameters, especially in the\nrotational part. Existing initialization methods that simultaneously estimate\nextrinsic parameters suffer from poor robustness, low precision, and long\ninitialization latency due to the need for sufficient translational motion. To\naddress these problems, we propose a novel VIO initialization method, which\njointly considers extrinsic orientation and gyroscope bias within the normal\nepipolar constraints, achieving higher precision and better robustness without\ndelayed rotational calibration. First, a rotation-only constraint is designed\nfor extrinsic orientation and gyroscope bias estimation, which tightly couples\ngyroscope measurements and visual observations and can be solved in\npure-rotation cases. Second, we propose a weighting strategy together with a\nfailure detection strategy to enhance the precision and robustness of the\nestimator. Finally, we leverage Maximum A Posteriori to refine the results\nbefore enough translation parallax comes. Extensive experiments have\ndemonstrated that our method outperforms the state-of-the-art methods in both\naccuracy and robustness while maintaining competitive efficiency.\n","authors":["Zewen Xu","Yijia He","Hao Wei","Yihong Wu"],"pdf_url":"https://arxiv.org/pdf/2412.08135v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17972v2","updated":"2024-12-11T06:39:43Z","published":"2024-06-25T23:07:18Z","title":"LABOR-LLM: Language-Based Occupational Representations with Large\n  Language Models","summary":"  Vafa et al. (2024) introduced a transformer-based econometric model, CAREER,\nthat predicts a worker's next job as a function of career history (an\n\"occupation model\"). CAREER was initially estimated (\"pre-trained\") using a\nlarge, unrepresentative resume dataset, which served as a \"foundation model,\"\nand parameter estimation was continued (\"fine-tuned\") using data from a\nrepresentative survey. CAREER had better predictive performance than\nbenchmarks. This paper considers an alternative where the resume-based\nfoundation model is replaced by a large language model (LLM). We convert\ntabular data from the survey into text files that resemble resumes and\nfine-tune the LLMs using these text files with the objective to predict the\nnext token (word). The resulting fine-tuned LLM is used as an input to an\noccupation model. Its predictive performance surpasses all prior models. We\ndemonstrate the value of fine-tuning and further show that by adding more\ncareer data from a different population, fine-tuning smaller LLMs surpasses the\nperformance of fine-tuning larger models.\n","authors":["Susan Athey","Herman Brunborg","Tianyu Du","Ayush Kanodia","Keyon Vafa"],"pdf_url":"https://arxiv.org/pdf/2406.17972v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08131v1","updated":"2024-12-11T06:36:55Z","published":"2024-12-11T06:36:55Z","title":"DiffRaman: A Conditional Latent Denoising Diffusion Probabilistic Model\n  for Bacterial Raman Spectroscopy Identification Under Limited Data Conditions","summary":"  Raman spectroscopy has attracted significant attention in various biochemical\ndetection fields, especially in the rapid identification of pathogenic\nbacteria. The integration of this technology with deep learning to facilitate\nautomated bacterial Raman spectroscopy diagnosis has emerged as a key focus in\nrecent research. However, the diagnostic performance of existing deep learning\nmethods largely depends on a sufficient dataset, and in scenarios where there\nis a limited availability of Raman spectroscopy data, it is inadequate to fully\noptimize the numerous parameters of deep neural networks. To address these\nchallenges, this paper proposes a data generation method utilizing deep\ngenerative models to expand the data volume and enhance the recognition\naccuracy of bacterial Raman spectra. Specifically, we introduce DiffRaman, a\nconditional latent denoising diffusion probability model for Raman spectra\ngeneration. Experimental results demonstrate that synthetic bacterial Raman\nspectra generated by DiffRaman can effectively emulate real experimental\nspectra, thereby enhancing the performance of diagnostic models, especially\nunder conditions of limited data. Furthermore, compared to existing generative\nmodels, the proposed DiffRaman offers improvements in both generation quality\nand computational efficiency. Our DiffRaman approach offers a well-suited\nsolution for automated bacteria Raman spectroscopy diagnosis in data-scarce\nscenarios, offering new insights into alleviating the labor of spectroscopic\nmeasurements and enhancing rare bacteria identification.\n","authors":["Haiming Yao","Wei Luo","Ang Gao","Tao Zhou","Xue Wang"],"pdf_url":"https://arxiv.org/pdf/2412.08131v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07322v2","updated":"2024-12-11T06:33:55Z","published":"2024-12-10T09:10:11Z","title":"ConceptSearch: Towards Efficient Program Search Using LLMs for\n  Abstraction and Reasoning Corpus (ARC)","summary":"  The Abstraction and Reasoning Corpus (ARC) poses a significant challenge to\nartificial intelligence, demanding broad generalization and few-shot learning\ncapabilities that remain elusive for current deep learning methods, including\nlarge language models (LLMs). While LLMs excel in program synthesis, their\ndirect application to ARC yields limited success. To address this, we introduce\nConceptSearch, a novel function-search algorithm that leverages LLMs for\nprogram generation and employs a concept-based scoring method to guide the\nsearch efficiently. Unlike simplistic pixel-based metrics like Hamming\ndistance, ConceptSearch evaluates programs on their ability to capture the\nunderlying transformation concept reflected in the input-output examples. We\nexplore three scoring functions: Hamming distance, a CNN-based scoring\nfunction, and an LLM-based natural language scoring function. Experimental\nresults demonstrate the effectiveness of ConceptSearch, achieving a significant\nperformance improvement over direct prompting with GPT-4. Moreover, our novel\nconcept-based scoring exhibits up to 30% greater efficiency compared to Hamming\ndistance, measured in terms of the number of iterations required to reach the\ncorrect solution. These findings highlight the potential of LLM-driven program\nsearch when integrated with concept-based guidance for tackling challenging\ngeneralization problems like ARC.\n","authors":["Kartik Singhal","Gautam Shroff"],"pdf_url":"https://arxiv.org/pdf/2412.07322v2.pdf","comment":"Pre-print of paper accepted at AAAI 2025"},{"id":"http://arxiv.org/abs/2412.08128v1","updated":"2024-12-11T06:31:06Z","published":"2024-12-11T06:31:06Z","title":"Why Does Dropping Edges Usually Outperform Adding Edges in Graph\n  Contrastive Learning?","summary":"  Graph contrastive learning (GCL) has been widely used as an effective\nself-supervised learning method for graph representation learning. However, how\nto apply adequate and stable graph augmentation to generating proper views for\ncontrastive learning remains an essential problem. Dropping edges is a primary\naugmentation in GCL while adding edges is not a common method due to its\nunstable performance. To our best knowledge, there is no theoretical analysis\nto study why dropping edges usually outperforms adding edges. To answer this\nquestion, we introduce a new metric, namely Error Passing Rate (EPR), to\nquantify how a graph fits the network. Inspired by the theoretical conclusions,\nwe propose a novel GCL algorithm, Error-PAssing-based Graph Contrastive\nLearning (EPAGCL), which uses both edge adding and edge dropping as its\naugmentation. To be specific, we generate views by adding and dropping edges\naccording to the weights derived from EPR. Extensive experiments on various\nreal-world datasets are conducted to validate the correctness of our\ntheoretical analysis and the effectiveness of our proposed algorithm.\n","authors":["Yanchen Xu","Siqi Huang","Hongyuan Zhang","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2412.08128v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08127v1","updated":"2024-12-11T06:22:44Z","published":"2024-12-11T06:22:44Z","title":"Evil twins are not that evil: Qualitative insights into\n  machine-generated prompts","summary":"  It has been widely observed that language models (LMs) respond in predictable\nways to algorithmically generated prompts that are seemingly unintelligible.\nThis is both a sign that we lack a full understanding of how LMs work, and a\npractical challenge, because opaqueness can be exploited for harmful uses of\nLMs, such as jailbreaking. We present the first thorough analysis of opaque\nmachine-generated prompts, or autoprompts, pertaining to 3 LMs of different\nsizes and families. We find that machine-generated prompts are characterized by\na last token that is often intelligible and strongly affects the generation. A\nsmall but consistent proportion of the previous tokens are fillers that\nprobably appear in the prompt as a by-product of the fact that the optimization\nprocess fixes the number of tokens. The remaining tokens tend to have at least\na loose semantic relation with the generation, although they do not engage in\nwell-formed syntactic relations with it. We find moreover that some of the\nablations we applied to machine-generated prompts can also be applied to\nnatural language sequences, leading to similar behavior, suggesting that\nautoprompts are a direct consequence of the way in which LMs process linguistic\ninputs in general.\n","authors":["Nathanaël Carraz Rakotonirina","Corentin Kervadec","Francesca Franzon","Marco Baroni"],"pdf_url":"https://arxiv.org/pdf/2412.08127v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08125v1","updated":"2024-12-11T06:21:33Z","published":"2024-12-11T06:21:33Z","title":"Progressive Multi-granular Alignments for Grounded Reasoning in Large\n  Vision-Language Models","summary":"  Existing Large Vision-Language Models (LVLMs) excel at matching concepts\nacross multi-modal inputs but struggle with compositional concepts and\nhigh-level relationships between entities. This paper introduces Progressive\nmulti-granular Vision-Language alignments (PromViL), a novel framework to\nenhance LVLMs' ability in performing grounded compositional visual reasoning\ntasks. Our approach constructs a hierarchical structure of multi-modal\nalignments, ranging from simple to complex concepts. By progressively aligning\ntextual descriptions with corresponding visual regions, our model learns to\nleverage contextual information from lower levels to inform higher-level\nreasoning. To facilitate this learning process, we introduce a data generation\nprocess that creates a novel dataset derived from Visual Genome, providing a\nwide range of nested compositional vision-language pairs. Experimental results\ndemonstrate that our PromViL framework significantly outperforms baselines on\nvarious visual grounding and compositional question answering tasks.\n","authors":["Quang-Hung Le","Long Hoang Dang","Ngan Le","Truyen Tran","Thao Minh Le"],"pdf_url":"https://arxiv.org/pdf/2412.08125v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07216v2","updated":"2024-12-11T06:15:45Z","published":"2024-12-10T06:14:31Z","title":"Learnable Sparse Customization in Heterogeneous Edge Computing","summary":"  To effectively manage and utilize massive distributed data at the network\nedge, Federated Learning (FL) has emerged as a promising edge computing\nparadigm across data silos. However, FL still faces two challenges: system\nheterogeneity (i.e., the diversity of hardware resources across edge devices)\nand statistical heterogeneity (i.e., non-IID data). Although sparsification can\nextract diverse submodels for diverse clients, most sparse FL works either\nsimply assign submodels with artificially-given rigid rules or prune partial\nparameters using heuristic strategies, resulting in inflexible sparsification\nand poor performance. In this work, we propose Learnable Personalized\nSparsification for heterogeneous Federated learning (FedLPS), which achieves\nthe learnable customization of heterogeneous sparse models with\nimportance-associated patterns and adaptive ratios to simultaneously tackle\nsystem and statistical heterogeneity. Specifically, FedLPS learns the\nimportance of model units on local data representation and further derives an\nimportance-based sparse pattern with minimal heuristics to accurately extract\npersonalized data features in non-IID settings. Furthermore, Prompt Upper\nConfidence Bound Variance (P-UCBV) is designed to adaptively determine sparse\nratios by learning the superimposed effect of diverse device capabilities and\nnon-IID data, aiming at resource self-adaptation with promising accuracy.\nExtensive experiments show that FedLPS outperforms status quo approaches in\naccuracy and training costs, which improves accuracy by 1.28%-59.34% while\nreducing running time by more than 68.80%.\n","authors":["Jingjing Xue","Sheng Sun","Min Liu","Yuwei Wang","Zhuotao Liu","Jingyuan Wang"],"pdf_url":"https://arxiv.org/pdf/2412.07216v2.pdf","comment":"There are some things to modify so we decided to withdraw first"},{"id":"http://arxiv.org/abs/2412.08120v1","updated":"2024-12-11T06:13:38Z","published":"2024-12-11T06:13:38Z","title":"Dense Depth from Event Focal Stack","summary":"  We propose a method for dense depth estimation from an event stream generated\nwhen sweeping the focal plane of the driving lens attached to an event camera.\nIn this method, a depth map is inferred from an ``event focal stack'' composed\nof the event stream using a convolutional neural network trained with\nsynthesized event focal stacks. The synthesized event stream is created from a\nfocal stack generated by Blender for any arbitrary 3D scene. This allows for\ntraining on scenes with diverse structures. Additionally, we explored methods\nto eliminate the domain gap between real event streams and synthetic event\nstreams. Our method demonstrates superior performance over a depth-from-defocus\nmethod in the image domain on synthetic and real datasets.\n","authors":["Kenta Horikawa","Mariko Isogawa","Hideo Saito","Shohei Mori"],"pdf_url":"https://arxiv.org/pdf/2412.08120v1.pdf","comment":"Accepted at WACV2025"},{"id":"http://arxiv.org/abs/2402.09173v3","updated":"2024-12-11T06:07:59Z","published":"2024-02-14T13:44:16Z","title":"Optimal and Efficient Algorithms for Decentralized Online Convex\n  Optimization","summary":"  We investigate decentralized online convex optimization (D-OCO), in which a\nset of local learners are required to minimize a sequence of global loss\nfunctions using only local computations and communications. Previous studies\nhave established $O(n^{5/4}\\rho^{-1/2}\\sqrt{T})$ and ${O}(n^{3/2}\\rho^{-1}\\log\nT)$ regret bounds for convex and strongly convex functions respectively, where\n$n$ is the number of local learners, $\\rho<1$ is the spectral gap of the\ncommunication matrix, and $T$ is the time horizon. However, there exist large\ngaps from the existing lower bounds, i.e., $\\Omega(n\\sqrt{T})$ for convex\nfunctions and $\\Omega(n)$ for strongly convex functions. To fill these gaps, in\nthis paper, we first develop a novel D-OCO algorithm that can respectively\nreduce the regret bounds for convex and strongly convex functions to\n$\\tilde{O}(n\\rho^{-1/4}\\sqrt{T})$ and $\\tilde{O}(n\\rho^{-1/2}\\log T)$. The\nprimary technique is to design an online accelerated gossip strategy that\nenjoys a faster average consensus among local learners. Furthermore, by\ncarefully exploiting spectral properties of a specific network topology, we\nenhance the lower bounds for convex and strongly convex functions to\n$\\Omega(n\\rho^{-1/4}\\sqrt{T})$ and $\\Omega(n\\rho^{-1/2}\\log T)$, respectively.\nThese results suggest that the regret of our algorithm is nearly optimal in\nterms of $T$, $n$, and $\\rho$ for both convex and strongly convex functions.\nFinally, we propose a projection-free variant of our algorithm to efficiently\nhandle practical applications with complex constraints. Our analysis reveals\nthat the projection-free variant can achieve ${O}(nT^{3/4})$ and\n${O}(nT^{2/3}(\\log T)^{1/3})$ regret bounds for convex and strongly convex\nfunctions with nearly optimal $\\tilde{O}(\\rho^{-1/2}\\sqrt{T})$ and\n$\\tilde{O}(\\rho^{-1/2}T^{1/3}(\\log T)^{2/3})$ communication rounds,\nrespectively.\n","authors":["Yuanyu Wan","Tong Wei","Bo Xue","Mingli Song","Lijun Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.09173v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23748v2","updated":"2024-12-11T06:06:31Z","published":"2024-10-31T09:07:08Z","title":"Exploring Consistency in Graph Representations:from Graph Kernels to\n  Graph Neural Networks","summary":"  Graph Neural Networks (GNNs) have emerged as a dominant approach in graph\nrepresentation learning, yet they often struggle to capture consistent\nsimilarity relationships among graphs. While graph kernel methods such as the\nWeisfeiler-Lehman subtree (WL-subtree) and Weisfeiler-Lehman optimal assignment\n(WLOA) kernels are effective in capturing similarity relationships, they rely\nheavily on predefined kernels and lack sufficient non-linearity for more\ncomplex data patterns. Our work aims to bridge the gap between neural network\nmethods and kernel approaches by enabling GNNs to consistently capture\nrelational structures in their learned representations. Given the analogy\nbetween the message-passing process of GNNs and WL algorithms, we thoroughly\ncompare and analyze the properties of WL-subtree and WLOA kernels. We find that\nthe similarities captured by WLOA at different iterations are asymptotically\nconsistent, ensuring that similar graphs remain similar in subsequent\niterations, thereby leading to superior performance over the WL-subtree kernel.\nInspired by these findings, we conjecture that the consistency in the\nsimilarities of graph representations across GNN layers is crucial in capturing\nrelational structures and enhancing graph classification performance. Thus, we\npropose a loss to enforce the similarity of graph representations to be\nconsistent across different layers. Our empirical analysis verifies our\nconjecture and shows that our proposed consistency loss can significantly\nenhance graph classification performance across several GNN backbones on\nvarious datasets.\n","authors":["Xuyuan Liu","Yinghao Cai","Qihui Yang","Yujun Yan"],"pdf_url":"https://arxiv.org/pdf/2410.23748v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2407.00958v5","updated":"2024-12-11T06:01:38Z","published":"2024-07-01T04:29:35Z","title":"Dynamic Universal Approximation Theory: The Basic Theory for\n  Transformer-based Large Language Models","summary":"  Language models have emerged as a critical area of focus in artificial\nintelligence, particularly with the introduction of groundbreaking innovations\nlike ChatGPT. Large-scale Transformer networks have quickly become the leading\napproach for advancing natural language processing algorithms. Built on the\nTransformer architecture, these models enable interactions that closely mimic\nhuman communication and, equipped with extensive knowledge, can even assist in\nguiding human tasks. Despite their impressive capabilities and growing\ncomplexity, a key question remains-the theoretical foundations of large\nlanguage models (LLMs). What makes Transformer so effective for powering\nintelligent language applications, such as translation and coding? What\nunderlies LLMs' ability for In-Context Learning (ICL)? How does the LoRA scheme\nenhance the fine-tuning of LLMs? And what supports the practicality of pruning\nLLMs? To address these critical questions and explore the technological\nstrategies within LLMs, we leverage the Universal Approximation Theory (UAT) to\noffer a theoretical backdrop, shedding light on the mechanisms that underpin\nthese advancements.\n","authors":["Wei Wang","Qing Li"],"pdf_url":"https://arxiv.org/pdf/2407.00958v5.pdf","comment":null}]," Artificial Intelligence":[{"id":"http://arxiv.org/abs/2412.08643v1","updated":"2024-12-11T18:59:51Z","published":"2024-12-11T18:59:51Z","title":"GPD-1: Generative Pre-training for Driving","summary":"  Modeling the evolutions of driving scenarios is important for the evaluation\nand decision-making of autonomous driving systems. Most existing methods focus\non one aspect of scene evolution such as map generation, motion prediction, and\ntrajectory planning. In this paper, we propose a unified Generative\nPre-training for Driving (GPD-1) model to accomplish all these tasks altogether\nwithout additional fine-tuning. We represent each scene with ego, agent, and\nmap tokens and formulate autonomous driving as a unified token generation\nproblem. We adopt the autoregressive transformer architecture and use a\nscene-level attention mask to enable intra-scene bi-directional interactions.\nFor the ego and agent tokens, we propose a hierarchical positional tokenizer to\neffectively encode both 2D positions and headings. For the map tokens, we train\na map vector-quantized autoencoder to efficiently compress ego-centric semantic\nmaps into discrete tokens. We pre-train our GPD-1 on the large-scale nuPlan\ndataset and conduct extensive experiments to evaluate its effectiveness. With\ndifferent prompts, our GPD-1 successfully generalizes to various tasks without\nfinetuning, including scene generation, traffic simulation, closed-loop\nsimulation, map prediction, and motion planning. Code:\nhttps://github.com/wzzheng/GPD.\n","authors":["Zixun Xie","Sicheng Zuo","Wenzhao Zheng","Yunpeng Zhang","Dalong Du","Jie Zhou","Jiwen Lu","Shanghang Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.08643v1.pdf","comment":"Code is available at: https://github.com/wzzheng/GPD"},{"id":"http://arxiv.org/abs/2412.08637v1","updated":"2024-12-11T18:58:40Z","published":"2024-12-11T18:58:40Z","title":"DMin: Scalable Training Data Influence Estimation for Diffusion Models","summary":"  Identifying the training data samples that most influence a generated image\nis a critical task in understanding diffusion models, yet existing influence\nestimation methods are constrained to small-scale or LoRA-tuned models due to\ncomputational limitations. As diffusion models scale up, these methods become\nimpractical. To address this challenge, we propose DMin (Diffusion Model\ninfluence), a scalable framework for estimating the influence of each training\ndata sample on a given generated image. By leveraging efficient gradient\ncompression and retrieval techniques, DMin reduces storage requirements from\n339.39 TB to only 726 MB and retrieves the top-k most influential training\nsamples in under 1 second, all while maintaining performance. Our empirical\nresults demonstrate DMin is both effective in identifying influential training\nsamples and efficient in terms of computational and storage requirements.\n","authors":["Huawei Lin","Yingjie Lao","Weijie Zhao"],"pdf_url":"https://arxiv.org/pdf/2412.08637v1.pdf","comment":"14 pages, 6 figures, 8 tables. Under Review"},{"id":"http://arxiv.org/abs/2406.18814v3","updated":"2024-12-11T18:48:59Z","published":"2024-06-27T01:08:04Z","title":"Length Optimization in Conformal Prediction","summary":"  Conditional validity and length efficiency are two crucial aspects of\nconformal prediction (CP). Conditional validity ensures accurate uncertainty\nquantification for data subpopulations, while proper length efficiency ensures\nthat the prediction sets remain informative. Despite significant efforts to\naddress each of these issues individually, a principled framework that\nreconciles these two objectives has been missing in the CP literature. In this\npaper, we develop Conformal Prediction with Length-Optimization (CPL) - a novel\nand practical framework that constructs prediction sets with (near-) optimal\nlength while ensuring conditional validity under various classes of covariate\nshifts, including the key cases of marginal and group-conditional coverage. In\nthe infinite sample regime, we provide strong duality results which indicate\nthat CPL achieves conditional validity and length optimality. In the finite\nsample regime, we show that CPL constructs conditionally valid prediction sets.\nOur extensive empirical evaluations demonstrate the superior prediction set\nsize performance of CPL compared to state-of-the-art methods across diverse\nreal-world and synthetic datasets in classification, regression, and large\nlanguage model-based multiple choice question answering. An Implementation of\nour algorithm can be accessed at the following link:\nhttps://github.com/shayankiyani98/CP.\n","authors":["Shayan Kiyani","George Pappas","Hamed Hassani"],"pdf_url":"https://arxiv.org/pdf/2406.18814v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08619v1","updated":"2024-12-11T18:40:16Z","published":"2024-12-11T18:40:16Z","title":"Synthetic Vision: Training Vision-Language Models to Understand Physics","summary":"  Physical reasoning, which involves the interpretation, understanding, and\nprediction of object behavior in dynamic environments, remains a significant\nchallenge for current Vision-Language Models (VLMs). In this work, we propose\ntwo methods to enhance VLMs' physical reasoning capabilities using simulated\ndata. First, we fine-tune a pre-trained VLM using question-answer (QA) pairs\ngenerated from simulations relevant to physical reasoning tasks. Second, we\nintroduce Physics Context Builders (PCBs), specialized VLMs fine-tuned to\ncreate scene descriptions enriched with physical properties and processes.\nDuring physical reasoning tasks, these PCBs can be leveraged as context to\nassist a Large Language Model (LLM) to improve its performance. We evaluate\nboth of our approaches using multiple benchmarks, including a new stability\ndetection QA dataset called Falling Tower, which includes both simulated and\nreal-world scenes, and CLEVRER. We demonstrate that a small QA fine-tuned VLM\ncan significantly outperform larger state-of-the-art foundational models. We\nalso show that integrating PCBs boosts the performance of foundational LLMs on\nphysical reasoning tasks. Using the real-world scenes from the Falling Tower\ndataset, we also validate the robustness of both approaches in Sim2Real\ntransfer. Our results highlight the utility that simulated data can have in the\ncreation of learning systems capable of advanced physical reasoning.\n","authors":["Vahid Balazadeh","Mohammadmehdi Ataei","Hyunmin Cheong","Amir Hosein Khasahmadi","Rahul G. Krishnan"],"pdf_url":"https://arxiv.org/pdf/2412.08619v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08618v1","updated":"2024-12-11T18:39:32Z","published":"2024-12-11T18:39:32Z","title":"Image Retrieval Methods in the Dissimilarity Space","summary":"  Image retrieval methods rely on metric learning to train backbone feature\nextraction models that can extract discriminant queries and reference (gallery)\nfeature representations for similarity matching. Although state-of-the-art\naccuracy has improved considerably with the advent of deep learning (DL) models\ntrained on large datasets, image retrieval remains challenging in many\nreal-world video analytics and surveillance applications, e.g., person\nre-identification. Using the Euclidean space for matching limits the\nperformance in real-world applications due to the curse of dimensionality,\noverfitting, and sensitivity to noisy data.\n  We argue that the feature dissimilarity space is more suitable for similarity\nmatching, and propose a dichotomy transformation to project query and reference\nembeddings into a single embedding in the dissimilarity space.\n  We also advocate for end-to-end training of a backbone and binary\nclassification models for pair-wise matching. As opposed to comparing the\ndistance between queries and reference embeddings, we show the benefits of\nclassifying the single dissimilarity space embedding (as similar or\ndissimilar), especially when trained end-to-end. We propose a method to train\nthe max-margin classifier together with the backbone feature extractor by\napplying constraints to the L2 norm of the classifier weights along with the\nhinge loss.\n  Our extensive experiments on challenging image retrieval datasets and using\ndiverse feature extraction backbones highlight the benefits of similarity\nmatching in the dissimilarity space. In particular, when jointly training the\nfeature extraction backbone and regularised classifier for matching, the\ndissimilarity space provides a higher level of accuracy.\n","authors":["Madhu Kiran","Kartikey Vishnu","Rafael M. O. Cruz","Eric Granger"],"pdf_url":"https://arxiv.org/pdf/2412.08618v1.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2412.08610v1","updated":"2024-12-11T18:34:31Z","published":"2024-12-11T18:34:31Z","title":"Competition and Diversity in Generative AI","summary":"  Recent evidence suggests that the use of generative artificial intelligence\nreduces the diversity of content produced. In this work, we develop a\ngame-theoretic model to explore the downstream consequences of content\nhomogeneity when producers use generative AI to compete with one another. At\nequilibrium, players indeed produce content that is less diverse than optimal.\nHowever, stronger competition mitigates homogeneity and induces more diverse\nproduction. Perhaps more surprisingly, we show that a generative AI model that\nperforms well in isolation (i.e., according to a benchmark) may fail to do so\nwhen faced with competition, and vice versa. We validate our results\nempirically by using language models to play Scattergories, a word game in\nwhich players are rewarded for producing answers that are both correct and\nunique. We discuss how the interplay between competition and homogeneity has\nimplications for the development, evaluation, and use of generative AI.\n","authors":["Manish Raghavan"],"pdf_url":"https://arxiv.org/pdf/2412.08610v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04842v3","updated":"2024-12-11T18:32:36Z","published":"2024-08-09T03:35:53Z","title":"Counterfactual Explanations with Probabilistic Guarantees on their\n  Robustness to Model Change","summary":"  Counterfactual explanations (CFEs) guide users on how to adjust inputs to\nmachine learning models to achieve desired outputs. While existing research\nprimarily addresses static scenarios, real-world applications often involve\ndata or model changes, potentially invalidating previously generated CFEs and\nrendering user-induced input changes ineffective. Current methods addressing\nthis issue often support only specific models or change types, require\nextensive hyperparameter tuning, or fail to provide probabilistic guarantees on\nCFE robustness to model changes. This paper proposes a novel approach for\ngenerating CFEs that provides probabilistic guarantees for any model and change\ntype, while offering interpretable and easy-to-select hyperparameters. We\nestablish a theoretical framework for probabilistically defining robustness to\nmodel change and demonstrate how our BetaRCE method directly stems from it.\nBetaRCE is a post-hoc method applied alongside a chosen base CFE generation\nmethod to enhance the quality of the explanation beyond robustness. It\nfacilitates a transition from the base explanation to a more robust one with\nuser-adjusted probability bounds. Through experimental comparisons with\nbaselines, we show that BetaRCE yields robust, most plausible, and closest to\nbaseline counterfactual explanations.\n","authors":["Ignacy Stępka","Mateusz Lango","Jerzy Stefanowski"],"pdf_url":"https://arxiv.org/pdf/2408.04842v3.pdf","comment":"Accepted at 31st SIGKDD Conference on Knowledge Discovery and Data\n  Mining 2025"},{"id":"http://arxiv.org/abs/2412.08608v1","updated":"2024-12-11T18:30:57Z","published":"2024-12-11T18:30:57Z","title":"AdvWave: Stealthy Adversarial Jailbreak Attack against Large\n  Audio-Language Models","summary":"  Recent advancements in large audio-language models (LALMs) have enabled\nspeech-based user interactions, significantly enhancing user experience and\naccelerating the deployment of LALMs in real-world applications. However,\nensuring the safety of LALMs is crucial to prevent risky outputs that may raise\nsocietal concerns or violate AI regulations. Despite the importance of this\nissue, research on jailbreaking LALMs remains limited due to their recent\nemergence and the additional technical challenges they present compared to\nattacks on DNN-based audio models. Specifically, the audio encoders in LALMs,\nwhich involve discretization operations, often lead to gradient shattering,\nhindering the effectiveness of attacks relying on gradient-based optimizations.\nThe behavioral variability of LALMs further complicates the identification of\neffective (adversarial) optimization targets. Moreover, enforcing stealthiness\nconstraints on adversarial audio waveforms introduces a reduced, non-convex\nfeasible solution space, further intensifying the challenges of the\noptimization process. To overcome these challenges, we develop AdvWave, the\nfirst jailbreak framework against LALMs. We propose a dual-phase optimization\nmethod that addresses gradient shattering, enabling effective end-to-end\ngradient-based optimization. Additionally, we develop an adaptive adversarial\ntarget search algorithm that dynamically adjusts the adversarial optimization\ntarget based on the response patterns of LALMs for specific queries. To ensure\nthat adversarial audio remains perceptually natural to human listeners, we\ndesign a classifier-guided optimization approach that generates adversarial\nnoise resembling common urban sounds. Extensive evaluations on multiple\nadvanced LALMs demonstrate that AdvWave outperforms baseline methods, achieving\na 40% higher average jailbreak attack success rate.\n","authors":["Mintong Kang","Chejian Xu","Bo Li"],"pdf_url":"https://arxiv.org/pdf/2412.08608v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07012v2","updated":"2024-12-11T18:28:00Z","published":"2024-12-09T21:44:02Z","title":"ProVision: Programmatically Scaling Vision-centric Instruction Data for\n  Multimodal Language Models","summary":"  With the rise of multimodal applications, instruction data has become\ncritical for training multimodal language models capable of understanding\ncomplex image-based queries. Existing practices rely on powerful but costly\nlarge language models (LLMs) or multimodal language models (MLMs) to produce\ninstruction data. These are often prone to hallucinations, licensing issues and\nthe generation process is often hard to scale and interpret. In this work, we\npresent a programmatic approach that employs scene graphs as symbolic\nrepresentations of images and human-written programs to systematically\nsynthesize vision-centric instruction data. Our approach ensures the\ninterpretability and controllability of the data generation process and scales\nefficiently while maintaining factual accuracy. By implementing a suite of 24\nsingle-image, 14 multi-image instruction generators, and a scene graph\ngeneration pipeline, we build a scalable, cost-effective system: ProVision\nwhich produces diverse question-answer pairs concerning objects, attributes,\nrelations, depth, etc., for any given image. Applied to Visual Genome and\nDataComp datasets, we generate over 10 million instruction data points,\nProVision-10M, and leverage them in both pretraining and instruction tuning\nstages of MLMs. When adopted in the instruction tuning stage, our single-image\ninstruction data yields up to a 7% improvement on the 2D split and 8% on the 3D\nsplit of CVBench, along with a 3% increase in performance on QBench2,\nRealWorldQA, and MMMU. Our multi-image instruction data leads to an 8%\nimprovement on Mantis-Eval. Incorporation of our data in both pre-training and\nfine-tuning stages of xGen-MM-4B leads to an averaged improvement of 1.6%\nacross 11 benchmarks.\n","authors":["Jieyu Zhang","Le Xue","Linxin Song","Jun Wang","Weikai Huang","Manli Shu","An Yan","Zixian Ma","Juan Carlos Niebles","silvio savarese","Caiming Xiong","Zeyuan Chen","Ranjay Krishna","Ran Xu"],"pdf_url":"https://arxiv.org/pdf/2412.07012v2.pdf","comment":"code: https://github.com/JieyuZ2/ProVision dataset:\n  https://huggingface.co/datasets/Salesforce/ProVision-10M"},{"id":"http://arxiv.org/abs/2412.08604v1","updated":"2024-12-11T18:26:55Z","published":"2024-12-11T18:26:55Z","title":"Preference Discerning with LLM-Enhanced Generative Retrieval","summary":"  Sequential recommendation systems aim to provide personalized recommendations\nfor users based on their interaction history. To achieve this, they often\nincorporate auxiliary information, such as textual descriptions of items and\nauxiliary tasks, like predicting user preferences and intent. Despite numerous\nefforts to enhance these models, they still suffer from limited\npersonalization. To address this issue, we propose a new paradigm, which we\nterm preference discerning. In preference dscerning, we explicitly condition a\ngenerative sequential recommendation system on user preferences within its\ncontext. To this end, we generate user preferences using Large Language Models\n(LLMs) based on user reviews and item-specific data. To evaluate preference\ndiscerning capabilities of sequential recommendation systems, we introduce a\nnovel benchmark that provides a holistic evaluation across various scenarios,\nincluding preference steering and sentiment following. We assess current\nstate-of-the-art methods using our benchmark and show that they struggle to\naccurately discern user preferences. Therefore, we propose a new method named\nMender ($\\textbf{M}$ultimodal Prefer$\\textbf{en}$ce\n$\\textbf{d}$iscern$\\textbf{er}$), which improves upon existing methods and\nachieves state-of-the-art performance on our benchmark. Our results show that\nMender can be effectively guided by human preferences even though they have not\nbeen observed during training, paving the way toward more personalized\nsequential recommendation systems. We will open-source the code and benchmarks\nupon publication.\n","authors":["Fabian Paischer","Liu Yang","Linfeng Liu","Shuai Shao","Kaveh Hassani","Jiacheng Li","Ricky Chen","Zhang Gabriel Li","Xialo Gao","Wei Shao","Xue Feng","Nima Noorshams","Sem Park","Bo Long","Hamid Eghbalzadeh"],"pdf_url":"https://arxiv.org/pdf/2412.08604v1.pdf","comment":"11 pages + references and appendix"},{"id":"http://arxiv.org/abs/2403.12151v3","updated":"2024-12-11T18:12:43Z","published":"2024-03-18T18:08:44Z","title":"Fusing Domain-Specific Content from Large Language Models into Knowledge\n  Graphs for Enhanced Zero Shot Object State Classification","summary":"  Domain-specific knowledge can significantly contribute to addressing a wide\nvariety of vision tasks. However, the generation of such knowledge entails\nconsiderable human labor and time costs. This study investigates the potential\nof Large Language Models (LLMs) in generating and providing domain-specific\ninformation through semantic embeddings. To achieve this, an LLM is integrated\ninto a pipeline that utilizes Knowledge Graphs and pre-trained semantic vectors\nin the context of the Vision-based Zero-shot Object State Classification task.\nWe thoroughly examine the behavior of the LLM through an extensive ablation\nstudy. Our findings reveal that the integration of LLM-based embeddings, in\ncombination with general-purpose pre-trained embeddings, leads to substantial\nperformance improvements. Drawing insights from this ablation study, we conduct\na comparative analysis against competing models, thereby highlighting the\nstate-of-the-art performance achieved by the proposed approach.\n","authors":["Filippos Gouidis","Katerina Papantoniou","Konstantinos Papoutsakis","Theodore Patkos","Antonis Argyros","Dimitris Plexousakis"],"pdf_url":"https://arxiv.org/pdf/2403.12151v3.pdf","comment":"Accepted at the AAAI-MAKE 2024"},{"id":"http://arxiv.org/abs/2412.08591v1","updated":"2024-12-11T18:10:21Z","published":"2024-12-11T18:10:21Z","title":"RoomTour3D: Geometry-Aware Video-Instruction Tuning for Embodied\n  Navigation","summary":"  Vision-and-Language Navigation (VLN) suffers from the limited diversity and\nscale of training data, primarily constrained by the manual curation of\nexisting simulators. To address this, we introduce RoomTour3D, a\nvideo-instruction dataset derived from web-based room tour videos that capture\nreal-world indoor spaces and human walking demonstrations. Unlike existing VLN\ndatasets, RoomTour3D leverages the scale and diversity of online videos to\ngenerate open-ended human walking trajectories and open-world navigable\ninstructions. To compensate for the lack of navigation data in online videos,\nwe perform 3D reconstruction and obtain 3D trajectories of walking paths\naugmented with additional information on the room types, object locations and\n3D shape of surrounding scenes. Our dataset includes $\\sim$100K open-ended\ndescription-enriched trajectories with $\\sim$200K instructions, and 17K\naction-enriched trajectories from 1847 room tour environments. We demonstrate\nexperimentally that RoomTour3D enables significant improvements across multiple\nVLN tasks including CVDN, SOON, R2R, and REVERIE. Moreover, RoomTour3D\nfacilitates the development of trainable zero-shot VLN agents, showcasing the\npotential and challenges of advancing towards open-world navigation.\n","authors":["Mingfei Han","Liang Ma","Kamila Zhumakhanova","Ekaterina Radionova","Jingyi Zhang","Xiaojun Chang","Xiaodan Liang","Ivan Laptev"],"pdf_url":"https://arxiv.org/pdf/2412.08591v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.16822v3","updated":"2024-12-11T18:07:25Z","published":"2024-02-26T18:47:27Z","title":"Rainbow Teaming: Open-Ended Generation of Diverse Adversarial Prompts","summary":"  As large language models (LLMs) become increasingly prevalent across many\nreal-world applications, understanding and enhancing their robustness to\nadversarial attacks is of paramount importance. Existing methods for\nidentifying adversarial prompts tend to focus on specific domains, lack\ndiversity, or require extensive human annotations. To address these\nlimitations, we present Rainbow Teaming, a novel black-box approach for\nproducing a diverse collection of adversarial prompts. Rainbow Teaming casts\nadversarial prompt generation as a quality-diversity problem and uses\nopen-ended search to generate prompts that are both effective and diverse.\nFocusing on the safety domain, we use Rainbow Teaming to target various\nstate-of-the-art LLMs, including the Llama 2 and Llama 3 models. Our approach\nreveals hundreds of effective adversarial prompts, with an attack success rate\nexceeding 90% across all tested models. Furthermore, we demonstrate that\nprompts generated by Rainbow Teaming are highly transferable and that\nfine-tuning models with synthetic data generated by our method significantly\nenhances their safety without sacrificing general performance or helpfulness.\nWe additionally explore the versatility of Rainbow Teaming by applying it to\nquestion answering and cybersecurity, showcasing its potential to drive robust\nopen-ended self-improvement in a wide range of applications.\n","authors":["Mikayel Samvelyan","Sharath Chandra Raparthy","Andrei Lupu","Eric Hambro","Aram H. Markosyan","Manish Bhatt","Yuning Mao","Minqi Jiang","Jack Parker-Holder","Jakob Foerster","Tim Rocktäschel","Roberta Raileanu"],"pdf_url":"https://arxiv.org/pdf/2402.16822v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08587v1","updated":"2024-12-11T18:06:44Z","published":"2024-12-11T18:06:44Z","title":"Advancing Single- and Multi-task Text Classification through Large\n  Language Model Fine-tuning","summary":"  Both encoder-only models (e.g., BERT, RoBERTa) and large language models\n(LLMs, e.g., Llama3) have been widely used for text classification tasks.\nHowever, there is a lack of systematic studies comparing the performance of\nencoder-based models and LLMs in text classification, particularly when\nfine-tuning is involved. This study employed a diverse range of models and\nmethods, varying in size and architecture, and including both fine-tuned and\npre-trained approaches. We first assessed the performances of these LLMs on the\n20 Newsgroups (20NG) and MASSIVE datasets, comparing them to encoder-only\nRoBERTa models. Additionally, we explored the multi-task capabilities of both\nmodel types by combining multiple classification tasks, including intent\ndetection and slot-filling, into a single model using data from both datasets.\nOur results indicate that fully fine-tuned Llama3-70B models outperform\nRoBERTa-large and other decoder LLMs across various classification tasks and\ndatasets. Moreover, the consolidated multi-task fine-tuned LLMs matched the\nperformance of dual-model setups in both tasks across both datasets. Overall,\nour study provides a comprehensive benchmark of encoder-only and LLM models on\ntext classification tasks and demonstrates a method to combine two or more\nfully fine-tuned decoder LLMs for reduced latency and equivalent performance.\n","authors":["Hang Zhao","Qile P. Chen","Yijing Barry Zhang","Gang Yang"],"pdf_url":"https://arxiv.org/pdf/2412.08587v1.pdf","comment":"9 pages, 3 tables"},{"id":"http://arxiv.org/abs/2412.08585v1","updated":"2024-12-11T18:03:05Z","published":"2024-12-11T18:03:05Z","title":"TURBOATTENTION: Efficient Attention Approximation For High Throughputs\n  LLMs","summary":"  Large language model (LLM) inference demands significant amount of\ncomputation and memory, especially in the key attention mechanism. While\ntechniques, such as quantization and acceleration algorithms, like\nFlashAttention, have improved efficiency of the overall inference, they address\ndifferent aspects of the problem: quantization focuses on weight-activation\noperations, while FlashAttention improves execution but requires high-precision\nformats. Recent Key-value (KV) cache quantization reduces memory bandwidth but\nstill needs floating-point dequantization for attention operation.\n  We present TurboAttention, a comprehensive approach to enable quantized\nexecution of attention that simultaneously addresses both memory and\ncomputational efficiency. Our solution introduces two key innovations: FlashQ,\na headwise attention quantization technique that enables both compression of KV\ncache and quantized execution of activation-activation multiplication, and\nSparsity-based Softmax Approximation (SAS), which eliminates the need for\ndequantization to FP32 during exponentiation operation in attention.\nExperimental results demonstrate that TurboAttention achieves 1.2-1.8x speedup\nin attention, reduces the KV cache size by over 4.4x, and enables up to 2.37x\nmaximum throughput over the FP16 baseline while outperforming state-of-the-art\nquantization and compression techniques across various datasets and models.\n","authors":["Hao Kang","Srikant Bharadwaj","James Hensman","Tushar Krishna","Victor Ruhle","Saravan Rajmohan"],"pdf_url":"https://arxiv.org/pdf/2412.08585v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08574v1","updated":"2024-12-11T17:45:31Z","published":"2024-12-11T17:45:31Z","title":"Learning Sketch Decompositions in Planning via Deep Reinforcement\n  Learning","summary":"  In planning and reinforcement learning, the identification of common subgoal\nstructures across problems is important when goals are to be achieved over long\nhorizons. Recently, it has been shown that such structures can be expressed as\nfeature-based rules, called sketches, over a number of classical planning\ndomains. These sketches split problems into subproblems which then become\nsolvable in low polynomial time by a greedy sequence of IW$(k)$ searches.\nMethods for learning sketches using feature pools and min-SAT solvers have been\ndeveloped, yet they face two key limitations: scalability and expressivity. In\nthis work, we address these limitations by formulating the problem of learning\nsketch decompositions as a deep reinforcement learning (DRL) task, where\ngeneral policies are sought in a modified planning problem where the successor\nstates of a state s are defined as those reachable from s through an IW$(k)$\nsearch. The sketch decompositions obtained through this method are\nexperimentally evaluated across various domains, and problems are regarded as\nsolved by the decomposition when the goal is reached through a greedy sequence\nof IW$(k)$ searches. While our DRL approach for learning sketch decompositions\ndoes not yield interpretable sketches in the form of rules, we demonstrate that\nthe resulting decompositions can often be understood in a crisp manner.\n","authors":["Michael Aichmüller","Hector Geffner"],"pdf_url":"https://arxiv.org/pdf/2412.08574v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08565v1","updated":"2024-12-11T17:32:33Z","published":"2024-12-11T17:32:33Z","title":"GenPlan: Generative sequence models as adaptive planners","summary":"  Offline reinforcement learning has shown tremendous success in behavioral\nplanning by learning from previously collected demonstrations. However,\ndecision-making in multitask missions still presents significant challenges.\nFor instance, a mission might require an agent to explore an unknown\nenvironment, discover goals, and navigate to them, even if it involves\ninteracting with obstacles along the way. Such behavioral planning problems are\ndifficult to solve due to: a) agents failing to adapt beyond the single task\nlearned through their reward function, and b) the inability to generalize to\nnew environments not covered in the training demonstrations, e.g., environments\nwhere all doors were unlocked in the demonstrations. Consequently,\nstate-of-the-art decision making methods are limited to missions where the\nrequired tasks are well-represented in the training demonstrations and can be\nsolved within a short (temporal) planning horizon. To address this, we propose\nGenPlan: a stochastic and adaptive planner that leverages discrete-flow models\nfor generative sequence modeling, enabling sample-efficient exploration and\nexploitation. This framework relies on an iterative denoising procedure to\ngenerate a sequence of goals and actions. This approach captures multi-modal\naction distributions and facilitates goal and task discovery, thereby enhancing\ngeneralization to out-of-distribution tasks and environments, i.e., missions\nnot part of the training data. We demonstrate the effectiveness of our method\nthrough multiple simulation environments. Notably, GenPlan outperforms the\nstate-of-the-art methods by over 10% on adaptive planning tasks, where the\nagent adapts to multi-task missions while leveraging demonstrations on\nsingle-goal-reaching tasks.\n","authors":["Akash Karthikeyan","Yash Vardhan Pant"],"pdf_url":"https://arxiv.org/pdf/2412.08565v1.pdf","comment":"Accepted in AAAI 2025. Project page:\n  https://aku02.github.io/projects/genplan/"},{"id":"http://arxiv.org/abs/2412.08556v1","updated":"2024-12-11T17:17:31Z","published":"2024-12-11T17:17:31Z","title":"Exact Algorithms for Multiagent Path Finding with Communication\n  Constraints on Tree-Like Structures","summary":"  Consider the scenario where multiple agents have to move in an optimal way\nthrough a network, each one towards their ending position while avoiding\ncollisions. By optimal, we mean as fast as possible, which is evaluated by a\nmeasure known as the makespan of the proposed solution. This is the setting\nstudied in the Multiagent Path Finding problem. In this work, we additionally\nprovide the agents with a way to communicate with each other. Due to size\nconstraints, it is reasonable to assume that the range of communication of each\nagent will be limited. What should be the trajectories of the agents to,\nadditionally, maintain a backbone of communication? In this work, we study the\nMultiagent Path Finding with Communication Constraint problem under the\nparameterized complexity framework.\n  Our main contribution is three exact algorithms that are efficient when\nconsidering particular structures for the input network. We provide such\nalgorithms for the case when the communication range and the number of agents\n(the makespan resp.) are provided in the input and the network has a tree\ntopology, or bounded maximum degree (has a tree-like topology, i.e., bounded\ntreewidth resp.). We complement these results by showing that it is highly\nunlikely to construct efficient algorithms when considering the number of\nagents as part of the input, even if the makespan is $3$ and the communication\nrange is $1$.\n","authors":["Foivos Fioravantes","Dušan Knop","Jan Matyáš Křišťan","Nikolaos Melissinos","Michal Opler"],"pdf_url":"https://arxiv.org/pdf/2412.08556v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08542v1","updated":"2024-12-11T16:59:31Z","published":"2024-12-11T16:59:31Z","title":"MaestroMotif: Skill Design from Artificial Intelligence Feedback","summary":"  Describing skills in natural language has the potential to provide an\naccessible way to inject human knowledge about decision-making into an AI\nsystem. We present MaestroMotif, a method for AI-assisted skill design, which\nyields high-performing and adaptable agents. MaestroMotif leverages the\ncapabilities of Large Language Models (LLMs) to effectively create and reuse\nskills. It first uses an LLM's feedback to automatically design rewards\ncorresponding to each skill, starting from their natural language description.\nThen, it employs an LLM's code generation abilities, together with\nreinforcement learning, for training the skills and combining them to implement\ncomplex behaviors specified in language. We evaluate MaestroMotif using a suite\nof complex tasks in the NetHack Learning Environment (NLE), demonstrating that\nit surpasses existing approaches in both performance and usability.\n","authors":["Martin Klissarov","Mikael Henaff","Roberta Raileanu","Shagun Sodhani","Pascal Vincent","Amy Zhang","Pierre-Luc Bacon","Doina Precup","Marlos C. Machado","Pierluca D'Oro"],"pdf_url":"https://arxiv.org/pdf/2412.08542v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.05467v3","updated":"2024-12-11T16:49:22Z","published":"2024-12-06T23:43:59Z","title":"The BrowserGym Ecosystem for Web Agent Research","summary":"  The BrowserGym ecosystem addresses the growing need for efficient evaluation\nand benchmarking of web agents, particularly those leveraging automation and\nLarge Language Models (LLMs) for web interaction tasks. Many existing\nbenchmarks suffer from fragmentation and inconsistent evaluation methodologies,\nmaking it challenging to achieve reliable comparisons and reproducible results.\nBrowserGym aims to solve this by providing a unified, gym-like environment with\nwell-defined observation and action spaces, facilitating standardized\nevaluation across diverse benchmarks. Combined with AgentLab, a complementary\nframework that aids in agent creation, testing, and analysis, BrowserGym offers\nflexibility for integrating new benchmarks while ensuring consistent evaluation\nand comprehensive experiment management. This standardized approach seeks to\nreduce the time and complexity of developing web agents, supporting more\nreliable comparisons and facilitating in-depth analysis of agent behaviors, and\ncould result in more adaptable, capable agents, ultimately accelerating\ninnovation in LLM-driven automation. As a supporting evidence, we conduct the\nfirst large-scale, multi-benchmark web agent experiment and compare the\nperformance of 6 state-of-the-art LLMs across all benchmarks currently\navailable in BrowserGym. Among other findings, our results highlight a large\ndiscrepancy between OpenAI and Anthropic's latests models, with\nClaude-3.5-Sonnet leading the way on almost all benchmarks, except on\nvision-related tasks where GPT-4o is superior. Despite these advancements, our\nresults emphasize that building robust and efficient web agents remains a\nsignificant challenge, due to the inherent complexity of real-world web\nenvironments and the limitations of current models.\n","authors":["Thibault Le Sellier De Chezelles","Maxime Gasse","Alexandre Drouin","Massimo Caccia","Léo Boisvert","Megh Thakkar","Tom Marty","Rim Assouel","Sahar Omidi Shayegan","Lawrence Keunho Jang","Xing Han Lù","Ori Yoran","Dehan Kong","Frank F. Xu","Siva Reddy","Quentin Cappart","Graham Neubig","Ruslan Salakhutdinov","Nicolas Chapados","Alexandre Lacoste"],"pdf_url":"https://arxiv.org/pdf/2412.05467v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.14654v2","updated":"2024-12-11T16:38:01Z","published":"2024-11-22T00:59:25Z","title":"Comparative Analysis of Pooling Mechanisms in LLMs: A Sentiment Analysis\n  Perspective","summary":"  Large Language Models (LLMs) have revolutionized natural language processing\n(NLP) by delivering state-of-the-art performance across a variety of tasks.\nAmong these, Transformer-based models like BERT and GPT rely on pooling layers\nto aggregate token-level embeddings into sentence-level representations. Common\npooling mechanisms such as Mean, Max, and Weighted Sum play a pivotal role in\nthis aggregation process. Despite their widespread use, the comparative\nperformance of these strategies on different LLM architectures remains\nunderexplored. To address this gap, this paper investigates the effects of\nthese pooling mechanisms on two prominent LLM families -- BERT and GPT, in the\ncontext of sentence-level sentiment analysis. Comprehensive experiments reveal\nthat each pooling mechanism exhibits unique strengths and weaknesses depending\non the task's specific requirements. Our findings underline the importance of\nselecting pooling methods tailored to the demands of particular applications,\nprompting a re-evaluation of common assumptions regarding pooling operations.\nBy offering actionable insights, this study contributes to the optimization of\nLLM-based models for downstream tasks.\n","authors":["Jinming Xing","Ruilin Xing","Yan Sun"],"pdf_url":"https://arxiv.org/pdf/2411.14654v2.pdf","comment":"4 figures"},{"id":"http://arxiv.org/abs/2412.08520v1","updated":"2024-12-11T16:34:23Z","published":"2024-12-11T16:34:23Z","title":"GR-NLP-TOOLKIT: An Open-Source NLP Toolkit for Modern Greek","summary":"  We present GR-NLP-TOOLKIT, an open-source natural language processing (NLP)\ntoolkit developed specifically for modern Greek. The toolkit provides\nstate-of-the-art performance in five core NLP tasks, namely part-of-speech\ntagging, morphological tagging, dependency parsing, named entity recognition,\nand Greeklishto-Greek transliteration. The toolkit is based on pre-trained\nTransformers, it is freely available, and can be easily installed in Python\n(pip install gr-nlp-toolkit). It is also accessible through a demonstration\nplatform on HuggingFace, along with a publicly available API for non-commercial\nuse. We discuss the functionality provided for each task, the underlying\nmethods, experiments against comparable open-source toolkits, and future\npossible enhancements. The toolkit is available at:\nhttps://github.com/nlpaueb/gr-nlp-toolkit\n","authors":["Lefteris Loukas","Nikolaos Smyrnioudis","Chrysa Dikonomaki","Spyros Barbakos","Anastasios Toumazatos","John Koutsikakis","Manolis Kyriakakis","Mary Georgiou","Stavros Vassos","John Pavlopoulos","Ion Androutsopoulos"],"pdf_url":"https://arxiv.org/pdf/2412.08520v1.pdf","comment":"Accepted Demo Paper @ COLING 2025 (Github:\n  https://github.com/nlpaueb/gr-nlp-toolkit/, Demo:\n  https://huggingface.co/spaces/AUEB-NLP/greek-nlp-toolkit-demo, API:\n  https://huggingface.co/spaces/AUEB-NLP/The-Greek-NLP-API)"},{"id":"http://arxiv.org/abs/2412.08515v1","updated":"2024-12-11T16:25:17Z","published":"2024-12-11T16:25:17Z","title":"Enhancing Interpretability Through Loss-Defined Classification Objective\n  in Structured Latent Spaces","summary":"  Supervised machine learning often operates on the data-driven paradigm,\nwherein internal model parameters are autonomously optimized to converge\npredicted outputs with the ground truth, devoid of explicitly programming rules\nor a priori assumptions. Although data-driven methods have yielded notable\nsuccesses across various benchmark datasets, they inherently treat models as\nopaque entities, thereby limiting their interpretability and yielding a lack of\nexplanatory insights into their decision-making processes. In this work, we\nintroduce Latent Boost, a novel approach that integrates advanced distance\nmetric learning into supervised classification tasks, enhancing both\ninterpretability and training efficiency. Thus during training, the model is\nnot only optimized for classification metrics of the discrete data points but\nalso adheres to the rule that the collective representation zones of each class\nshould be sharply clustered. By leveraging the rich structural insights of\nintermediate model layer latent representations, Latent Boost improves\nclassification interpretability, as demonstrated by higher Silhouette scores,\nwhile accelerating training convergence. These performance and latent\nstructural benefits are achieved with minimum additional cost, making it\nbroadly applicable across various datasets without requiring data-specific\nadjustments. Furthermore, Latent Boost introduces a new paradigm for aligning\nclassification performance with improved model transparency to address the\nchallenges of black-box models.\n","authors":["Daniel Geissler","Bo Zhou","Mengxi Liu","Paul Lukowicz"],"pdf_url":"https://arxiv.org/pdf/2412.08515v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08513v1","updated":"2024-12-11T16:24:31Z","published":"2024-12-11T16:24:31Z","title":"REPEAT: Improving Uncertainty Estimation in Representation Learning\n  Explainability","summary":"  Incorporating uncertainty is crucial to provide trustworthy explanations of\ndeep learning models. Recent works have demonstrated how uncertainty modeling\ncan be particularly important in the unsupervised field of representation\nlearning explainable artificial intelligence (R-XAI). Current R-XAI methods\nprovide uncertainty by measuring variability in the importance score. However,\nthey fail to provide meaningful estimates of whether a pixel is certainly\nimportant or not. In this work, we propose a new R-XAI method called REPEAT\nthat addresses the key question of whether or not a pixel is \\textit{certainly}\nimportant. REPEAT leverages the stochasticity of current R-XAI methods to\nproduce multiple estimates of importance, thus considering each pixel in an\nimage as a Bernoulli random variable that is either important or unimportant.\nFrom these Bernoulli random variables we can directly estimate the importance\nof a pixel and its associated certainty, thus enabling users to determine\ncertainty in pixel importance. Our extensive evaluation shows that REPEAT gives\ncertainty estimates that are more intuitive, better at detecting\nout-of-distribution data, and more concise.\n","authors":["Kristoffer K. Wickstrøm","Thea Brüsch","Michael C. Kampffmeyer","Robert Jenssen"],"pdf_url":"https://arxiv.org/pdf/2412.08513v1.pdf","comment":"Accepted at AAAI 2025. Code available at:\n  https://github.com/Wickstrom/REPEAT"},{"id":"http://arxiv.org/abs/2312.08977v4","updated":"2024-12-11T16:18:16Z","published":"2023-12-14T14:26:57Z","title":"Weighted Ensemble Models Are Strong Continual Learners","summary":"  In this work, we study the problem of continual learning (CL) where the goal\nis to learn a model on a sequence of tasks, such that the data from the\nprevious tasks becomes unavailable while learning on the current task data. CL\nis essentially a balancing act between being able to learn on the new task\n(i.e., plasticity) and maintaining the performance on the previously learned\nconcepts (i.e., stability). Intending to address the stability-plasticity\ntrade-off, we propose to perform weight-ensembling of the model parameters of\nthe previous and current tasks. This weighted-ensembled model, which we call\nContinual Model Averaging (or CoMA), attains high accuracy on the current task\nby leveraging plasticity, while not deviating too far from the previous weight\nconfiguration, ensuring stability. We also propose an improved variant of CoMA,\nnamed Continual Fisher-weighted Model Averaging (or CoFiMA), that selectively\nweighs each parameter in the weights ensemble by leveraging the Fisher\ninformation of the weights of the model. Both variants are conceptually simple,\neasy to implement, and effective in attaining state-of-the-art performance on\nseveral standard CL benchmarks. Code is available at:\nhttps://github.com/IemProg/CoFiMA.\n","authors":["Imad Eddine Marouf","Subhankar Roy","Enzo Tartaglione","Stéphane Lathuilière"],"pdf_url":"https://arxiv.org/pdf/2312.08977v4.pdf","comment":"Accepted for ECCV2024, Code: https://github.com/IemProg/CoFiMA"},{"id":"http://arxiv.org/abs/2412.08504v1","updated":"2024-12-11T16:15:14Z","published":"2024-12-11T16:15:14Z","title":"PointTalk: Audio-Driven Dynamic Lip Point Cloud for 3D Gaussian-based\n  Talking Head Synthesis","summary":"  Talking head synthesis with arbitrary speech audio is a crucial challenge in\nthe field of digital humans. Recently, methods based on radiance fields have\nreceived increasing attention due to their ability to synthesize high-fidelity\nand identity-consistent talking heads from just a few minutes of training\nvideo. However, due to the limited scale of the training data, these methods\noften exhibit poor performance in audio-lip synchronization and visual quality.\nIn this paper, we propose a novel 3D Gaussian-based method called PointTalk,\nwhich constructs a static 3D Gaussian field of the head and deforms it in sync\nwith the audio. It also incorporates an audio-driven dynamic lip point cloud as\na critical component of the conditional information, thereby facilitating the\neffective synthesis of talking heads. Specifically, the initial step involves\ngenerating the corresponding lip point cloud from the audio signal and\ncapturing its topological structure. The design of the dynamic difference\nencoder aims to capture the subtle nuances inherent in dynamic lip movements\nmore effectively. Furthermore, we integrate the audio-point enhancement module,\nwhich not only ensures the synchronization of the audio signal with the\ncorresponding lip point cloud within the feature space, but also facilitates a\ndeeper understanding of the interrelations among cross-modal conditional\nfeatures. Extensive experiments demonstrate that our method achieves superior\nhigh-fidelity and audio-lip synchronization in talking head synthesis compared\nto previous methods.\n","authors":["Yifan Xie","Tao Feng","Xin Zhang","Xiangyang Luo","Zixuan Guo","Weijiang Yu","Heng Chang","Fei Ma","Fei Richard Yu"],"pdf_url":"https://arxiv.org/pdf/2412.08504v1.pdf","comment":"9 pages, accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2410.15264v3","updated":"2024-12-11T16:11:07Z","published":"2024-10-20T03:33:25Z","title":"AI Can Enhance Creativity in Social Networks","summary":"  Can peer recommendation engines elevate people's creative performances in\nself-organizing social networks? Answering this question requires resolving\nchallenges in data collection (e.g., tracing inspiration links and\npsycho-social attributes of nodes) and intervention design (e.g., balancing\nidea stimulation and redundancy in evolving information environments). We\ntrained a model that predicts people's ideation performances using semantic and\nnetwork-structural features in an online platform. Using this model, we built\nSocialMuse, which maximizes people's predicted performances to generate peer\nrecommendations for them. We found treatment networks leveraging SocialMuse\noutperforming AI-agnostic control networks in several creativity measures. The\ntreatment networks were more decentralized than the control, as SocialMuse\nincreasingly emphasized network-structural features at large network sizes.\nThis decentralization spreads people's inspiration sources, helping inspired\nideas stand out better. Our study provides actionable insights into building\nintelligent systems for elevating creativity.\n","authors":["Raiyan Abdul Baten","Ali Sarosh Bangash","Krish Veera","Gourab Ghoshal","Ehsan Hoque"],"pdf_url":"https://arxiv.org/pdf/2410.15264v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.08728v2","updated":"2024-12-11T16:06:22Z","published":"2024-01-16T15:32:41Z","title":"AgentMixer: Multi-Agent Correlated Policy Factorization","summary":"  In multi-agent reinforcement learning, centralized training with\ndecentralized execution (CTDE) methods typically assume that agents make\ndecisions based on their local observations independently, which may not lead\nto a correlated joint policy with coordination. Coordination can be explicitly\nencouraged during training and individual policies can be trained to imitate\nthe correlated joint policy. However, this may lead to an \\textit{asymmetric\nlearning failure} due to the observation mismatch between the joint and\nindividual policies. Inspired by the concept of correlated equilibrium, we\nintroduce a \\textit{strategy modification} called AgentMixer that allows agents\nto correlate their policies. AgentMixer combines individual partially\nobservable policies into a joint fully observable policy non-linearly. To\nenable decentralized execution, we introduce\n\\textit{Individual-Global-Consistency} to guarantee mode consistency during\njoint training of the centralized and decentralized policies and prove that\nAgentMixer converges to an $\\epsilon$-approximate Correlated Equilibrium. In\nthe Multi-Agent MuJoCo, SMAC-v2, Matrix Game, and Predator-Prey benchmarks,\nAgentMixer outperforms or matches state-of-the-art methods.\n","authors":["Zhiyuan Li","Wenshuai Zhao","Lijun Wu","Joni Pajarinen"],"pdf_url":"https://arxiv.org/pdf/2401.08728v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07000v2","updated":"2024-12-11T15:58:46Z","published":"2024-12-09T21:10:22Z","title":"Extreme AutoML: Analysis of Classification, Regression, and NLP\n  Performance","summary":"  Utilizing machine learning techniques has always required choosing\nhyperparameters. This is true whether one uses a classical technique such as a\nKNN or very modern neural networks such as Deep Learning. Though in many\napplications, hyperparameters are chosen by hand, automated methods have become\nincreasingly more common. These automated methods have become collectively\nknown as automated machine learning, or AutoML. Several automated selection\nalgorithms have shown similar or improved performance over state-of-the-art\nmethods. This breakthrough has led to the development of cloud-based services\nlike Google AutoML, which is based on Deep Learning and is widely considered to\nbe the industry leader in AutoML services. Extreme Learning Machines (ELMs) use\na fundamentally different type of neural architecture, producing better results\nat a significantly discounted computational cost. We benchmark the Extreme\nAutoML technology against Google's AutoML using several popular classification\ndata sets from the University of California at Irvine's (UCI) repository, and\nseveral other data sets, observing significant advantages for Extreme AutoML in\naccuracy, Jaccard Indices, the variance of Jaccard Indices across classes (i.e.\nclass variance) and training times.\n","authors":["Edward Ratner","Elliot Farmer","Brandon Warner","Christopher Douglas","Amaury Lendasse"],"pdf_url":"https://arxiv.org/pdf/2412.07000v2.pdf","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2412.08490v1","updated":"2024-12-11T15:54:33Z","published":"2024-12-11T15:54:33Z","title":"SuperCode: Sustainability PER AI-driven CO-DEsign","summary":"  Currently, data-intensive scientific applications require vast amounts of\ncompute resources to deliver world-leading science. The climate emergency has\nmade it clear that unlimited use of resources (e.g., energy) for scientific\ndiscovery is no longer acceptable. Future computing hardware promises to be\nmuch more energy efficient, but without better optimized software this cannot\nreach its full potential. In this vision paper, we propose a generic AI-driven\nco-design methodology, using specialized Large Language Models (like ChatGPT),\nto effectively generate efficient code for emerging computing hardware. We\ndescribe how we will validate our methodology with two radio astronomy\napplications, with sustainability as the key performance indicator. This paper\nis a modified version of our accepted SuperCode project proposal. We present it\nhere in this form to introduce the vision behind this project and to\ndisseminate the work in the spirit of Open Science and transparency. An\nadditional aim is to collect feedback, invite potential collaboration partners\nand use-cases to join the project.\n","authors":["P. Chris Broekema","Rob V. van Nieuwpoort"],"pdf_url":"https://arxiv.org/pdf/2412.08490v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17196v3","updated":"2024-12-11T15:45:21Z","published":"2024-10-22T17:15:20Z","title":"VoiceBench: Benchmarking LLM-Based Voice Assistants","summary":"  Building on the success of large language models (LLMs), recent advancements\nsuch as GPT-4o have enabled real-time speech interactions through LLM-based\nvoice assistants, offering a significantly improved user experience compared to\ntraditional text-based interactions. However, the absence of benchmarks\ndesigned to evaluate these speech interaction capabilities has hindered\nprogress of LLM-based voice assistants development. Current evaluations focus\nprimarily on automatic speech recognition (ASR) or general knowledge evaluation\nwith clean speeches, neglecting the more intricate, real-world scenarios that\ninvolve diverse speaker characteristics, environmental and content factors. To\naddress this, we introduce VoiceBench, the first benchmark designed to provide\na multi-faceted evaluation of LLM-based voice assistants. VoiceBench also\nincludes both real and synthetic spoken instructions that incorporate the above\nthree key real-world variations. Extensive experiments reveal the limitations\nof current LLM-based voice assistant models and offer valuable insights for\nfuture research and development in this field.\n","authors":["Yiming Chen","Xianghu Yue","Chen Zhang","Xiaoxue Gao","Robby T. Tan","Haizhou Li"],"pdf_url":"https://arxiv.org/pdf/2410.17196v3.pdf","comment":"Work in progress. Data is available at\n  https://github.com/MatthewCYM/VoiceBench"},{"id":"http://arxiv.org/abs/2412.08477v1","updated":"2024-12-11T15:44:08Z","published":"2024-12-11T15:44:08Z","title":"Accurate Water Level Monitoring in AWD Rice Cultivation Using\n  Convolutional Neural Networks","summary":"  The Alternate Wetting and Drying (AWD) method is a rice-growing water\nmanagement technique promoted as a sustainable alternative to Continuous\nFlooding (CF). Climate change has placed the agricultural sector in a\nchallenging position, particularly as global water resources become\nincreasingly scarce, affecting rice production on irrigated lowlands. Rice, a\nstaple food for over half of the world's population, demands significantly more\nwater than other major crops. In Bangladesh, \\textit{Boro} rice, in particular,\nrequires considerable water inputs during its cultivation. Traditionally,\nfarmers manually measure water levels, a process that is both time-consuming\nand prone to errors. While ultrasonic sensors offer improvements in water\nheight measurement, they still face limitations, such as susceptibility to\nweather conditions and environmental factors. To address these issues, we\npropose a novel approach that automates water height measurement using computer\nvision, specifically through a convolutional neural network (CNN). Our\nattention-based architecture achieved an $R^2$ score of 0.9885 and a Mean\nSquared Error (MSE) of 0.2766, providing a more accurate and efficient solution\nfor managing AWD systems.\n","authors":["Ahmed Rafi Hasan","Niloy Kumar Kundu","Saad Hasan","Mohammad Rashedul Hoque","Swakkhar Shatabda"],"pdf_url":"https://arxiv.org/pdf/2412.08477v1.pdf","comment":"15 pages, 6 figures"},{"id":"http://arxiv.org/abs/2405.12910v2","updated":"2024-12-11T15:40:54Z","published":"2024-05-21T16:30:25Z","title":"Topic Classification of Case Law Using a Large Language Model and a New\n  Taxonomy for UK Law: AI Insights into Summary Judgment","summary":"  This paper addresses a critical gap in legal analytics by developing and\napplying a novel taxonomy for topic classification of summary judgment cases in\nthe United Kingdom. Using a curated dataset of summary judgment cases, we use\nthe Large Language Model Claude 3 Opus to explore functional topics and trends.\nWe find that Claude 3 Opus correctly classified the topic with an accuracy of\n87.13% and an F1 score of 0.87. The analysis reveals distinct patterns in the\napplication of summary judgments across various legal domains. As case law in\nthe United Kingdom is not originally labelled with keywords or a topic\nfiltering option, the findings not only refine our understanding of the\nthematic underpinnings of summary judgments but also illustrate the potential\nof combining traditional and AI-driven approaches in legal classification.\nTherefore, this paper provides a new and general taxonomy for UK law. The\nimplications of this work serve as a foundation for further research and policy\ndiscussions in the field of judicial administration and computational legal\nresearch methodologies.\n","authors":["Holli Sargeant","Ahmed Izzidien","Felix Steffek"],"pdf_url":"https://arxiv.org/pdf/2405.12910v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08467v1","updated":"2024-12-11T15:32:24Z","published":"2024-12-11T15:32:24Z","title":"Bootstrapping Language-Guided Navigation Learning with Self-Refining\n  Data Flywheel","summary":"  Creating high-quality data for training robust language-instructed agents is\na long-lasting challenge in embodied AI. In this paper, we introduce a\nSelf-Refining Data Flywheel (SRDF) that generates high-quality and large-scale\nnavigational instruction-trajectory pairs by iteratively refining the data pool\nthrough the collaboration between two models, the instruction generator and the\nnavigator, without any human-in-the-loop annotation. Specifically, SRDF starts\nwith using a base generator to create an initial data pool for training a base\nnavigator, followed by applying the trained navigator to filter the data pool.\nThis leads to higher-fidelity data to train a better generator, which can, in\nturn, produce higher-quality data for training the next-round navigator. Such a\nflywheel establishes a data self-refining process, yielding a continuously\nimproved and highly effective dataset for large-scale language-guided\nnavigation learning. Our experiments demonstrate that after several flywheel\nrounds, the navigator elevates the performance boundary from 70% to 78% SPL on\nthe classic R2R test set, surpassing human performance (76%) for the first\ntime. Meanwhile, this process results in a superior generator, evidenced by a\nSPICE increase from 23.5 to 26.2, better than all previous VLN instruction\ngeneration methods. Finally, we demonstrate the scalability of our method\nthrough increasing environment and instruction diversity, and the\ngeneralization ability of our pre-trained navigator across various downstream\nnavigation tasks, surpassing state-of-the-art methods by a large margin in all\ncases.\n","authors":["Zun Wang","Jialu Li","Yicong Hong","Songze Li","Kunchang Li","Shoubin Yu","Yi Wang","Yu Qiao","Yali Wang","Mohit Bansal","Limin Wang"],"pdf_url":"https://arxiv.org/pdf/2412.08467v1.pdf","comment":"28 pages, Code and data are available at\n  https://github.com/wz0919/VLN-SRDF"},{"id":"http://arxiv.org/abs/2412.08463v1","updated":"2024-12-11T15:28:04Z","published":"2024-12-11T15:28:04Z","title":"IRL for Restless Multi-Armed Bandits with Applications in Maternal and\n  Child Health","summary":"  Public health practitioners often have the goal of monitoring patients and\nmaximizing patients' time spent in \"favorable\" or healthy states while being\nconstrained to using limited resources. Restless multi-armed bandits (RMAB) are\nan effective model to solve this problem as they are helpful to allocate\nlimited resources among many agents under resource constraints, where patients\nbehave differently depending on whether they are intervened on or not. However,\nRMABs assume the reward function is known. This is unrealistic in many public\nhealth settings because patients face unique challenges and it is impossible\nfor a human to know who is most deserving of any intervention at such a large\nscale. To address this shortcoming, this paper is the first to present the use\nof inverse reinforcement learning (IRL) to learn desired rewards for RMABs, and\nwe demonstrate improved outcomes in a maternal and child health telehealth\nprogram. First we allow public health experts to specify their goals at an\naggregate or population level and propose an algorithm to design expert\ntrajectories at scale based on those goals. Second, our algorithm WHIRL uses\ngradient updates to optimize the objective, allowing for efficient and accurate\nlearning of RMAB rewards. Third, we compare with existing baselines and\noutperform those in terms of run-time and accuracy. Finally, we evaluate and\nshow the usefulness of WHIRL on thousands on beneficiaries from a real-world\nmaternal and child health setting in India. We publicly release our code here:\nhttps://github.com/Gjain234/WHIRL.\n","authors":["Gauri Jain","Pradeep Varakantham","Haifeng Xu","Aparna Taneja","Prashant Doshi","Milind Tambe"],"pdf_url":"https://arxiv.org/pdf/2412.08463v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08460v1","updated":"2024-12-11T15:25:38Z","published":"2024-12-11T15:25:38Z","title":"Federated Learning for Traffic Flow Prediction with Synthetic Data\n  Augmentation","summary":"  Deep-learning based traffic prediction models require vast amounts of data to\nlearn embedded spatial and temporal dependencies. The inherent privacy and\ncommercial sensitivity of such data has encouraged a shift towards\ndecentralised data-driven methods, such as Federated Learning (FL). Under a\ntraditional Machine Learning paradigm, traffic flow prediction models can\ncapture spatial and temporal relationships within centralised data. In reality,\ntraffic data is likely distributed across separate data silos owned by multiple\nstakeholders. In this work, a cross-silo FL setting is motivated to facilitate\nstakeholder collaboration for optimal traffic flow prediction applications.\nThis work introduces an FL framework, referred to as FedTPS, to generate\nsynthetic data to augment each client's local dataset by training a\ndiffusion-based trajectory generation model through FL. The proposed framework\nis evaluated on a large-scale real world ride-sharing dataset using various FL\nmethods and Traffic Flow Prediction models, including a novel prediction model\nwe introduce, which leverages Temporal and Graph Attention mechanisms to learn\nthe Spatio-Temporal dependencies embedded within regional traffic flow data.\nExperimental results show that FedTPS outperforms multiple other FL baselines\nwith respect to global model performance.\n","authors":["Fermin Orozco","Pedro Porto Buarque de Gusmão","Hongkai Wen","Johan Wahlström","Man Luo"],"pdf_url":"https://arxiv.org/pdf/2412.08460v1.pdf","comment":"11 pages, 7 figures, 6 tables, ACM format"},{"id":"http://arxiv.org/abs/2412.08457v1","updated":"2024-12-11T15:24:07Z","published":"2024-12-11T15:24:07Z","title":"Efficient Rectification of Neuro-Symbolic Reasoning Inconsistencies by\n  Abductive Reflection","summary":"  Neuro-Symbolic (NeSy) AI could be regarded as an analogy to human\ndual-process cognition, modeling the intuitive System 1 with neural networks\nand the algorithmic System 2 with symbolic reasoning. However, for complex\nlearning targets, NeSy systems often generate outputs inconsistent with domain\nknowledge and it is challenging to rectify them. Inspired by the human\nCognitive Reflection, which promptly detects errors in our intuitive response\nand revises them by invoking the System 2 reasoning, we propose to improve NeSy\nsystems by introducing Abductive Reflection (ABL-Refl) based on the Abductive\nLearning (ABL) framework. ABL-Refl leverages domain knowledge to abduce a\nreflection vector during training, which can then flag potential errors in the\nneural network outputs and invoke abduction to rectify them and generate\nconsistent outputs during inference. ABL-Refl is highly efficient in contrast\nto previous ABL implementations. Experiments show that ABL-Refl outperforms\nstate-of-the-art NeSy methods, achieving excellent accuracy with fewer training\nresources and enhanced efficiency.\n","authors":["Wen-Chao Hu","Wang-Zhou Dai","Yuan Jiang","Zhi-Hua Zhou"],"pdf_url":"https://arxiv.org/pdf/2412.08457v1.pdf","comment":"Accepted to AAAI 2025"},{"id":"http://arxiv.org/abs/2412.02730v2","updated":"2024-12-11T15:22:32Z","published":"2024-12-03T16:29:37Z","title":"Shaping AI's Impact on Billions of Lives","summary":"  Artificial Intelligence (AI), like any transformative technology, has the\npotential to be a double-edged sword, leading either toward significant\nadvancements or detrimental outcomes for society as a whole. As is often the\ncase when it comes to widely-used technologies in market economies (e.g., cars\nand semiconductor chips), commercial interest tends to be the predominant\nguiding factor. The AI community is at risk of becoming polarized to either\ntake a laissez-faire attitude toward AI development, or to call for government\noverregulation. Between these two poles we argue for the community of AI\npractitioners to consciously and proactively work for the common good. This\npaper offers a blueprint for a new type of innovation infrastructure including\n18 concrete milestones to guide AI research in that direction. Our view is that\nwe are still in the early days of practical AI, and focused efforts by\npractitioners, policymakers, and other stakeholders can still maximize the\nupsides of AI and minimize its downsides.\n  We talked to luminaries such as recent Nobelist John Jumper on science,\nPresident Barack Obama on governance, former UN Ambassador and former National\nSecurity Advisor Susan Rice on security, philanthropist Eric Schmidt on several\ntopics, and science fiction novelist Neal Stephenson on entertainment. This\nongoing dialogue and collaborative effort has produced a comprehensive,\nrealistic view of what the actual impact of AI could be, from a diverse\nassembly of thinkers with deep understanding of this technology and these\ndomains. From these exchanges, five recurring guidelines emerged, which form\nthe cornerstone of a framework for beginning to harness AI in service of the\npublic good. They not only guide our efforts in discovery but also shape our\napproach to deploying this transformative technology responsibly and ethically.\n","authors":["Mariano-Florentino Cuéllar","Jeff Dean","Finale Doshi-Velez","John Hennessy","Andy Konwinski","Sanmi Koyejo","Pelonomi Moiloa","Emma Pierson","David Patterson"],"pdf_url":"https://arxiv.org/pdf/2412.02730v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.16866v3","updated":"2024-12-11T15:14:05Z","published":"2024-04-18T09:37:54Z","title":"Annotation-guided Protein Design with Multi-Level Domain Alignment","summary":"  The core challenge of de novo protein design lies in creating proteins with\nspecific functions or properties, guided by certain conditions. Current models\nexplore to generate protein using structural and evolutionary guidance, which\nonly provide indirect conditions concerning functions and properties. However,\ntextual annotations of proteins, especially the annotations for protein\ndomains, which directly describe the protein's high-level functionalities,\nproperties, and their correlation with target amino acid sequences, remain\nunexplored in the context of protein design tasks. In this paper, we propose\nProtein-Annotation Alignment Generation, PAAG, a multi-modality protein design\nframework that integrates the textual annotations extracted from protein\ndatabase for controllable generation in sequence space. Specifically, within a\nmulti-level alignment module, PAAG can explicitly generate proteins containing\nspecific domains conditioned on the corresponding domain annotations, and can\neven design novel proteins with flexible combinations of different kinds of\nannotations. Our experimental results underscore the superiority of the aligned\nprotein representations from PAAG over 7 prediction tasks. Furthermore, PAAG\ndemonstrates a significant increase in generation success rate (24.7% vs 4.7%\nin zinc finger, and 54.3% vs 22.0% in the immunoglobulin domain) in comparison\nto the existing model. We anticipate that PAAG will broaden the horizons of\nprotein design by leveraging the knowledge from between textual annotation and\nproteins.\n","authors":["Chaohao Yuan","Songyou Li","Geyan Ye","Yikun Zhang","Long-Kai Huang","Wenbing Huang","Wei Liu","Jianhua Yao","Yu Rong"],"pdf_url":"https://arxiv.org/pdf/2404.16866v3.pdf","comment":"Accepted by KDD 2025"},{"id":"http://arxiv.org/abs/2412.06581v2","updated":"2024-12-11T15:13:39Z","published":"2024-12-09T15:36:37Z","title":"EmoSpeech: A Corpus of Emotionally Rich and Contextually Detailed Speech\n  Annotations","summary":"  Advances in text-to-speech (TTS) technology have significantly improved the\nquality of generated speech, closely matching the timbre and intonation of the\ntarget speaker. However, due to the inherent complexity of human emotional\nexpression, the development of TTS systems capable of controlling subtle\nemotional differences remains a formidable challenge. Existing emotional speech\ndatabases often suffer from overly simplistic labelling schemes that fail to\ncapture a wide range of emotional states, thus limiting the effectiveness of\nemotion synthesis in TTS applications. To this end, recent efforts have\nfocussed on building databases that use natural language annotations to\ndescribe speech emotions. However, these approaches are costly and require more\nemotional depth to train robust systems. In this paper, we propose a novel\nprocess aimed at building databases by systematically extracting emotion-rich\nspeech segments and annotating them with detailed natural language descriptions\nthrough a generative model. This approach enhances the emotional granularity of\nthe database and significantly reduces the reliance on costly manual\nannotations by automatically augmenting the data with high-level language\nmodels. The resulting rich database provides a scalable and economically viable\nsolution for developing a more nuanced and dynamic basis for developing\nemotionally controlled TTS systems.\n","authors":["Weizhen Bian","Yubo Zhou","Kaitai Zhang","Xiaohan Gu"],"pdf_url":"https://arxiv.org/pdf/2412.06581v2.pdf","comment":"We understand that this article is not currently allowed to be\n  published, and there are major errors in the data, so it needs to be\n  withdrawn and revised"},{"id":"http://arxiv.org/abs/2412.00777v2","updated":"2024-12-11T15:11:09Z","published":"2024-12-01T11:48:58Z","title":"Local vs. Global: Local Land-Use and Land-Cover Models Deliver Higher\n  Quality Maps","summary":"  In 2023, 58.0% of the African population experienced moderate to severe food\ninsecurity, with 21.6% facing severe food insecurity. Land-use and land-cover\nmaps provide crucial insights for addressing food insecurity by improving\nagricultural efforts, including mapping and monitoring crop types and\nestimating yield. The development of global land-cover maps has been\nfacilitated by the increasing availability of earth observation data and\nadvancements in geospatial machine learning. However, these global maps exhibit\nlower accuracy and inconsistencies in Africa, partly due to the lack of\nrepresentative training data. To address this issue, we propose a data-centric\nframework with a teacher-student model setup, which uses diverse data sources\nof satellite images and label examples to produce local land-cover maps. Our\nmethod trains a high-resolution teacher model on images with a resolution of\n0.331 m/pixel and a low-resolution student model on publicly available images\nwith a resolution of 10 m/pixel. The student model also utilizes the teacher\nmodel's output as its weak label examples through knowledge transfer. We\nevaluated our framework using Murang'a county in Kenya, renowned for its\nagricultural productivity, as a use case. Our local models achieved higher\nquality maps, with improvements of 0.14 in the F1 score and 0.21 in\nIntersection-over-Union, compared to the best global model. Our evaluation also\nrevealed inconsistencies in existing global maps, with a maximum agreement rate\nof 0.30 among themselves. Our work provides valuable guidance to\ndecision-makers for driving informed decisions to enhance food security.\n","authors":["Girmaw Abebe Tadesse","Caleb Robinson","Charles Mwangi","Esther Maina","Joshua Nyakundi","Luana Marotti","Gilles Quentin Hacheme","Hamed Alemohammad","Rahul Dodhia","Juan M. Lavista Ferres"],"pdf_url":"https://arxiv.org/pdf/2412.00777v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08445v1","updated":"2024-12-11T15:09:54Z","published":"2024-12-11T15:09:54Z","title":"TapeAgents: a Holistic Framework for Agent Development and Optimization","summary":"  We present TapeAgents, an agent framework built around a granular, structured\nlog tape of the agent session that also plays the role of the session's\nresumable state. In TapeAgents we leverage tapes to facilitate all stages of\nthe LLM Agent development lifecycle. The agent reasons by processing the tape\nand the LLM output to produce new thought and action steps and append them to\nthe tape. The environment then reacts to the agent's actions by likewise\nappending observation steps to the tape. By virtue of this tape-centred design,\nTapeAgents can provide AI practitioners with holistic end-to-end support. At\nthe development stage, tapes facilitate session persistence, agent auditing,\nand step-by-step debugging. Post-deployment, one can reuse tapes for\nevaluation, fine-tuning, and prompt-tuning; crucially, one can adapt tapes from\nother agents or use revised historical tapes. In this report, we explain the\nTapeAgents design in detail. We demonstrate possible applications of TapeAgents\nwith several concrete examples of building monolithic agents and multi-agent\nteams, of optimizing agent prompts and finetuning the agent's LLM. We present\ntooling prototypes and report a case study where we use TapeAgents to finetune\na Llama-3.1-8B form-filling assistant to perform as well as GPT-4o while being\norders of magnitude cheaper. Lastly, our comparative analysis shows that\nTapeAgents's advantages over prior frameworks stem from our novel design of the\nLLM agent as a resumable, modular state machine with a structured\nconfiguration, that generates granular, structured logs and that can transform\nthese logs into training text -- a unique combination of features absent in\nprevious work.\n","authors":["Dzmitry Bahdanau","Nicolas Gontier","Gabriel Huang","Ehsan Kamalloo","Rafael Pardinas","Alex Piché","Torsten Scholak","Oleh Shliazhko","Jordan Prince Tremblay","Karam Ghanem","Soham Parikh","Mitul Tiwari","Quaizar Vohra"],"pdf_url":"https://arxiv.org/pdf/2412.08445v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.00420v2","updated":"2024-12-11T15:03:08Z","published":"2024-03-01T10:16:46Z","title":"Robust Deep Reinforcement Learning Through Adversarial Attacks and\n  Training : A Survey","summary":"  Deep Reinforcement Learning (DRL) is a subfield of machine learning for\ntraining autonomous agents that take sequential actions across complex\nenvironments. Despite its significant performance in well-known environments,\nit remains susceptible to minor condition variations, raising concerns about\nits reliability in real-world applications. To improve usability, DRL must\ndemonstrate trustworthiness and robustness. A way to improve the robustness of\nDRL to unknown changes in the environmental conditions and possible\nperturbations is through Adversarial Training, by training the agent against\nwell-suited adversarial attacks on the observations and the dynamics of the\nenvironment. Addressing this critical issue, our work presents an in-depth\nanalysis of contemporary adversarial attack and training methodologies,\nsystematically categorizing them and comparing their objectives and operational\nmechanisms.\n","authors":["Lucas Schott","Josephine Delas","Hatem Hajri","Elies Gherbi","Reda Yaich","Nora Boulahia-Cuppens","Frederic Cuppens","Sylvain Lamprier"],"pdf_url":"https://arxiv.org/pdf/2403.00420v2.pdf","comment":"61 pages, 17 figues, 1 table"},{"id":"http://arxiv.org/abs/2409.08775v2","updated":"2024-12-11T14:58:53Z","published":"2024-09-13T12:34:14Z","title":"What Should We Engineer in Prompts? Training Humans in\n  Requirement-Driven LLM Use","summary":"  Prompting LLMs for complex tasks (e.g., building a trip advisor chatbot)\nneeds humans to clearly articulate customized requirements (e.g., \"start the\nresponse with a tl;dr\"). However, existing prompt engineering instructions\noften lack focused training on requirement articulation and instead tend to\nemphasize increasingly automatable strategies (e.g., tricks like adding\nrole-plays and \"think step-by-step\"). To address the gap, we introduce\nRequirement-Oriented Prompt Engineering (ROPE), a paradigm that focuses human\nattention on generating clear, complete requirements during prompting. We\nimplement ROPE through an assessment and training suite that provides\ndeliberate practice with LLM-generated feedback. In a randomized controlled\nexperiment with 30 novices, ROPE significantly outperforms conventional prompt\nengineering training (20% vs. 1% gains), a gap that automatic prompt\noptimization cannot close. Furthermore, we demonstrate a direct correlation\nbetween the quality of input requirements and LLM outputs. Our work paves the\nway to empower more end-users to build complex LLM applications.\n","authors":["Qianou Ma","Weirui Peng","Chenyang Yang","Hua Shen","Kenneth Koedinger","Tongshuang Wu"],"pdf_url":"https://arxiv.org/pdf/2409.08775v2.pdf","comment":"15 pages"},{"id":"http://arxiv.org/abs/2412.08435v1","updated":"2024-12-11T14:57:10Z","published":"2024-12-11T14:57:10Z","title":"Proactive Model Adaptation Against Concept Drift for Online Time Series\n  Forecasting","summary":"  Time series forecasting always faces the challenge of concept drift, where\ndata distributions evolve over time, leading to a decline in forecast model\nperformance. Existing solutions are based on online learning, which continually\norganize recent time series observations as new training samples and update\nmodel parameters according to the forecasting feedback on recent data. However,\nthey overlook a critical issue: obtaining ground-truth future values of each\nsample should be delayed until after the forecast horizon. This delay creates a\ntemporal gap between the training samples and the test sample. Our empirical\nanalysis reveals that the gap can introduce concept drift, causing forecast\nmodels to adapt to outdated concepts. In this paper, we present\n\\textsc{Proceed}, a novel proactive model adaptation framework for online time\nseries forecasting. \\textsc{Proceed} first operates by estimating the concept\ndrift between the recently used training samples and the current test sample.\nIt then employs an adaptation generator to efficiently translate the estimated\ndrift into parameter adjustments, proactively adapting the model to the test\nsample. To enhance the generalization capability of the framework,\n\\textsc{Proceed} is trained on synthetic diverse concept drifts. We conduct\nextensive experiments on five real-world datasets across various forecast\nmodels. The empirical study demonstrates that our proposed \\textsc{Proceed}\nbrings more performance improvements than the state-of-the-art online learning\nmethods, significantly facilitating forecast models' resilience against concept\ndrifts.\n","authors":["Lifan Zhao","Yanyan Shen"],"pdf_url":"https://arxiv.org/pdf/2412.08435v1.pdf","comment":"Accepted by KDD 2025. Preprint version"},{"id":"http://arxiv.org/abs/2412.08434v1","updated":"2024-12-11T14:55:48Z","published":"2024-12-11T14:55:48Z","title":"Mitigating Out-of-Entity Errors in Named Entity Recognition: A\n  Sentence-Level Strategy","summary":"  Many previous models of named entity recognition (NER) suffer from the\nproblem of Out-of-Entity (OOE), i.e., the tokens in the entity mentions of the\ntest samples have not appeared in the training samples, which hinders the\nachievement of satisfactory performance. To improve OOE-NER performance, in\nthis paper, we propose a new framework, namely S+NER, which fully leverages\nsentence-level information. Our S+NER achieves better OOE-NER performance\nmainly due to the following two particular designs. 1) It first exploits the\npre-trained language model's capability of understanding the target entity's\nsentence-level context with a template set. 2) Then, it refines the\nsentence-level representation based on the positive and negative templates,\nthrough a contrastive learning strategy and template pooling method, to obtain\nbetter NER results. Our extensive experiments on five benchmark datasets have\ndemonstrated that, our S+NER outperforms some state-of-the-art OOE-NER models.\n","authors":["Guochao Jiang","Ziqin Luo","Chengwei Hu","Zepeng Ding","Deqing Yang"],"pdf_url":"https://arxiv.org/pdf/2412.08434v1.pdf","comment":"Accepted by COLING 2025"},{"id":"http://arxiv.org/abs/2412.08428v1","updated":"2024-12-11T14:48:19Z","published":"2024-12-11T14:48:19Z","title":"SwarmGPT-Primitive: A Language-Driven Choreographer for Drone Swarms\n  Using Safe Motion Primitive Composition","summary":"  Catalyzed by advancements in hardware and software, drone performances are\nincreasingly making their mark in the entertainment industry. However,\ndesigning smooth and safe choreographies for drone swarms is complex and often\nrequires expert domain knowledge. In this work, we introduce\nSwarmGPT-Primitive, a language-based choreographer that integrates the\nreasoning capabilities of large language models (LLMs) with safe motion\nplanning to facilitate deployable drone swarm choreographies. The LLM composes\nchoreographies for a given piece of music by utilizing a library of motion\nprimitives; the language-based choreographer is augmented with an\noptimization-based safety filter, which certifies the choreography for\nreal-world deployment by making minimal adjustments when feasibility and safety\nconstraints are violated. The overall SwarmGPT-Primitive framework decouples\nchoreographic design from safe motion planning, which allows non-expert users\nto re-prompt and refine compositions without concerns about compliance with\nconstraints such as avoiding collisions or downwash effects or satisfying\nactuation limits. We demonstrate our approach through simulations and\nexperiments with swarms of up to 20 drones performing choreographies designed\nbased on various songs, highlighting the system's ability to generate effective\nand synchronized drone choreographies for real-world deployment.\n","authors":["Vedant Vyas","Martin Schuck","Dinushka O. Dahanaggamaarachchi","Siqi Zhou","Angela P. Schoellig"],"pdf_url":"https://arxiv.org/pdf/2412.08428v1.pdf","comment":"Submitted to ICRA 2025"},{"id":"http://arxiv.org/abs/2207.11759v2","updated":"2024-12-11T14:47:01Z","published":"2022-07-24T15:13:45Z","title":"Spatial-Temporal Federated Learning for Lifelong Person\n  Re-identification on Distributed Edges","summary":"  Data drift is a thorny challenge when deploying person re-identification\n(ReID) models into real-world devices, where the data distribution is\nsignificantly different from that of the training environment and keeps\nchanging. To tackle this issue, we propose a federated spatial-temporal\nincremental learning approach, named FedSTIL, which leverages both lifelong\nlearning and federated learning to continuously optimize models deployed on\nmany distributed edge clients. Unlike previous efforts, FedSTIL aims to mine\nspatial-temporal correlations among the knowledge learnt from different edge\nclients. Specifically, the edge clients first periodically extract general\nrepresentations of drifted data to optimize their local models. Then, the\nlearnt knowledge from edge clients will be aggregated by centralized parameter\nserver, where the knowledge will be selectively and attentively distilled from\nspatial- and temporal-dimension with carefully designed mechanisms. Finally,\nthe distilled informative spatial-temporal knowledge will be sent back to\ncorrelated edge clients to further improve the recognition accuracy of each\nedge client with a lifelong learning method. Extensive experiments on a mixture\nof five real-world datasets demonstrate that our method outperforms others by\nnearly 4% in Rank-1 accuracy, while reducing communication cost by 62%. All\nimplementation codes are publicly available on\nhttps://github.com/MSNLAB/Federated-Lifelong-Person-ReID\n","authors":["Lei Zhang","Guanyu Gao","Huaizheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2207.11759v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.14306v2","updated":"2024-12-11T14:36:10Z","published":"2023-12-21T21:36:43Z","title":"Social Recommendation through Heterogeneous Graph Modeling of the\n  Long-term and Short-term Preference Defined by Dynamic Time Spans","summary":"  Social recommendations have been widely adopted in substantial domains.\nRecently, graph neural networks (GNN) have been employed in recommender systems\ndue to their success in graph representation learning. However, dealing with\nthe dynamic property of social network data is a challenge. This research\npresents a novel method that provides social recommendations by incorporating\nthe dynamic property of social network data in a heterogeneous graph. The model\naims to capture user preference over time without going through the\ncomplexities of a dynamic graph by adding period nodes to define users'\nlong-term and short-term preferences and aggregating assigned edge weights. The\nmodel is applied to real-world data to argue its superior performance.\nPromising results demonstrate the effectiveness of this model.\n","authors":["Behafarid Mohammad Jafari","Xiao Luo","Ali Jafari"],"pdf_url":"https://arxiv.org/pdf/2312.14306v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06909v5","updated":"2024-12-11T14:08:57Z","published":"2023-06-12T07:27:31Z","title":"Graph Agent Network: Empowering Nodes with Inference Capabilities for\n  Adversarial Resilience","summary":"  End-to-end training with global optimization have popularized graph neural\nnetworks (GNNs) for node classification, yet inadvertently introduced\nvulnerabilities to adversarial edge-perturbing attacks. Adversaries can exploit\nthe inherent opened interfaces of GNNs' input and output, perturbing critical\nedges and thus manipulating the classification results. Current defenses, due\nto their persistent utilization of global-optimization-based end-to-end\ntraining schemes, inherently encapsulate the vulnerabilities of GNNs. This is\nspecifically evidenced in their inability to defend against targeted secondary\nattacks. In this paper, we propose the Graph Agent Network (GAgN) to address\nthe aforementioned vulnerabilities of GNNs. GAgN is a graph-structured agent\nnetwork in which each node is designed as an 1-hop-view agent. Through the\ndecentralized interactions between agents, they can learn to infer global\nperceptions to perform tasks including inferring embeddings, degrees and\nneighbor relationships for given nodes. This empowers nodes to filtering\nadversarial edges while carrying out classification tasks. Furthermore, agents'\nlimited view prevents malicious messages from propagating globally in GAgN,\nthereby resisting global-optimization-based secondary attacks. We prove that\nsingle-hidden-layer multilayer perceptrons (MLPs) are theoretically sufficient\nto achieve these functionalities. Experimental results show that GAgN\neffectively implements all its intended capabilities and, compared to\nstate-of-the-art defenses, achieves optimal classification accuracy on the\nperturbed datasets.\n","authors":["Ao Liu","Wenshan Li","Tao Li","Beibei Li","Guangquan Xu","Pan Zhou","Wengang Ma","Hanyuan Huang"],"pdf_url":"https://arxiv.org/pdf/2306.06909v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08392v1","updated":"2024-12-11T14:02:55Z","published":"2024-12-11T14:02:55Z","title":"The Roles of English in Evaluating Multilingual Language Models","summary":"  Multilingual natural language processing is getting increased attention, with\nnumerous models, benchmarks, and methods being released for many languages.\nEnglish is often used in multilingual evaluation to prompt language models\n(LMs), mainly to overcome the lack of instruction tuning data in other\nlanguages. In this position paper, we lay out two roles of English in\nmultilingual LM evaluations: as an interface and as a natural language. We\nargue that these roles have different goals: task performance versus language\nunderstanding. This discrepancy is highlighted with examples from datasets and\nevaluation setups. Numerous works explicitly use English as an interface to\nboost task performance. We recommend to move away from this imprecise method\nand instead focus on furthering language understanding.\n","authors":["Wessel Poelman","Miryam de Lhoneux"],"pdf_url":"https://arxiv.org/pdf/2412.08392v1.pdf","comment":"NoDaLiDa 2025"},{"id":"http://arxiv.org/abs/2405.17825v3","updated":"2024-12-11T13:58:19Z","published":"2024-05-28T04:47:54Z","title":"Diffusion Model Patching via Mixture-of-Prompts","summary":"  We present Diffusion Model Patching (DMP), a simple method to boost the\nperformance of pre-trained diffusion models that have already reached\nconvergence, with a negligible increase in parameters. DMP inserts a small,\nlearnable set of prompts into the model's input space while keeping the\noriginal model frozen. The effectiveness of DMP is not merely due to the\naddition of parameters but stems from its dynamic gating mechanism, which\nselects and combines a subset of learnable prompts at every timestep (i.e.,\nreverse denoising steps). This strategy, which we term \"mixture-of-prompts\",\nenables the model to draw on the distinct expertise of each prompt, essentially\n\"patching\" the model's functionality at every timestep with minimal yet\nspecialized parameters. Uniquely, DMP enhances the model by further training on\nthe original dataset already used for pre-training, even in a scenario where\nsignificant improvements are typically not expected due to model convergence.\nNotably, DMP significantly enhances the FID of converged DiT-L/2 by 10.38% on\nFFHQ, achieved with only a 1.43% parameter increase and 50K additional training\niterations.\n","authors":["Seokil Ham","Sangmin Woo","Jin-Young Kim","Hyojun Go","Byeongjun Park","Changick Kim"],"pdf_url":"https://arxiv.org/pdf/2405.17825v3.pdf","comment":"AAAI 2025; Project: https://sangminwoo.github.io/DMP/"},{"id":"http://arxiv.org/abs/2412.05587v2","updated":"2024-12-11T13:56:40Z","published":"2024-12-07T08:50:24Z","title":"GEE-OPs: An Operator Knowledge Base for Geospatial Code Generation on\n  the Google Earth Engine Platform Powered by Large Language Models","summary":"  As the scale and complexity of spatiotemporal data continue to grow rapidly,\nthe use of geospatial modeling on the Google Earth Engine (GEE) platform\npresents dual challenges: improving the coding efficiency of domain experts and\nenhancing the coding capabilities of interdisciplinary users. To address these\nchallenges and improve the performance of large language models (LLMs) in\ngeospatial code generation tasks, we propose a framework for building a\ngeospatial operator knowledge base tailored to the GEE JavaScript API. This\nframework consists of an operator syntax knowledge table, an operator\nrelationship frequency table, an operator frequent pattern knowledge table, and\nan operator relationship chain knowledge table. By leveraging Abstract Syntax\nTree (AST) techniques and frequent itemset mining, we systematically extract\noperator knowledge from 185,236 real GEE scripts and syntax documentation,\nforming a structured knowledge base. Experimental results demonstrate that the\nframework achieves over 90% accuracy, recall, and F1 score in operator\nknowledge extraction. When integrated with the Retrieval-Augmented Generation\n(RAG) strategy for LLM-based geospatial code generation tasks, the knowledge\nbase improves performance by 20-30%. Ablation studies further quantify the\nnecessity of each knowledge table in the knowledge base construction. This work\nprovides robust support for the advancement and application of geospatial code\nmodeling techniques, offering an innovative approach to constructing\ndomain-specific knowledge bases that enhance the code generation capabilities\nof LLMs, and fostering the deeper integration of generative AI technologies\nwithin the field of geoinformatics.\n","authors":["Shuyang Hou","Jianyuan Liang","Anqi Zhao","Huayi Wu"],"pdf_url":"https://arxiv.org/pdf/2412.05587v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08385v1","updated":"2024-12-11T13:50:17Z","published":"2024-12-11T13:50:17Z","title":"NyayaAnumana & INLegalLlama: The Largest Indian Legal Judgment\n  Prediction Dataset and Specialized Language Model for Enhanced Decision\n  Analysis","summary":"  The integration of artificial intelligence (AI) in legal judgment prediction\n(LJP) has the potential to transform the legal landscape, particularly in\njurisdictions like India, where a significant backlog of cases burdens the\nlegal system. This paper introduces NyayaAnumana, the largest and most diverse\ncorpus of Indian legal cases compiled for LJP, encompassing a total of 7,02,945\npreprocessed cases. NyayaAnumana, which combines the words \"Nyay\" (judgment)\nand \"Anuman\" (prediction or inference) respectively for most major Indian\nlanguages, includes a wide range of cases from the Supreme Court, High Courts,\nTribunal Courts, District Courts, and Daily Orders and, thus, provides\nunparalleled diversity and coverage. Our dataset surpasses existing datasets\nlike PredEx and ILDC, offering a comprehensive foundation for advanced AI\nresearch in the legal domain.\n  In addition to the dataset, we present INLegalLlama, a domain-specific\ngenerative large language model (LLM) tailored to the intricacies of the Indian\nlegal system. It is developed through a two-phase training approach over a base\nLLaMa model. First, Indian legal documents are injected using continual\npretraining. Second, task-specific supervised finetuning is done. This method\nallows the model to achieve a deeper understanding of legal contexts.\n  Our experiments demonstrate that incorporating diverse court data\nsignificantly boosts model accuracy, achieving approximately 90% F1-score in\nprediction tasks. INLegalLlama not only improves prediction accuracy but also\noffers comprehensible explanations, addressing the need for explainability in\nAI-assisted legal decisions.\n","authors":["Shubham Kumar Nigam","Balaramamahanthi Deepak Patnaik","Shivam Mishra","Noel Shallum","Kripabandhu Ghosh","Arnab Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2412.08385v1.pdf","comment":"Accepted on COLING 2025"},{"id":"http://arxiv.org/abs/2412.08378v1","updated":"2024-12-11T13:41:21Z","published":"2024-12-11T13:41:21Z","title":"HyViLM: Enhancing Fine-Grained Recognition with a Hybrid Encoder for\n  Vision-Language Models","summary":"  Recently, there has been growing interest in the capability of multimodal\nlarge language models (MLLMs) to process high-resolution images. A common\napproach currently involves dynamically cropping the original high-resolution\nimage into smaller sub-images, which are then fed into a vision encoder that\nwas pre-trained on lower-resolution images. However, this cropping approach\noften truncates objects and connected areas in the original image, causing\nsemantic breaks. To address this limitation, we introduce HyViLM, designed to\nprocess images of any resolution while retaining the overall context during\nencoding. Specifically, we: (i) Design a new visual encoder called Hybrid\nEncoder that not only encodes individual sub-images but also interacts with\ndetailed global visual features, significantly improving the model's ability to\nencode high-resolution images. (ii) Propose an optimal feature fusion strategy\nfor the dynamic cropping approach, effectively leveraging information from\ndifferent layers of the vision encoder. Compared with the state-of-the-art\nMLLMs under the same setting, our HyViLM outperforms existing MLLMs in nine out\nof ten tasks. Specifically, HyViLM achieves a 9.6% improvement in performance\non the TextVQA task and a 6.9% enhancement on the DocVQA task.\n","authors":["Shiding Zhu","Wenhui Dong","Jun Song","Yanan Guo","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2412.08378v1.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2412.04964v2","updated":"2024-12-11T13:27:00Z","published":"2024-12-06T11:29:32Z","title":"Flash Communication: Reducing Tensor Parallelization Bottleneck for Fast\n  Large Language Model Inference","summary":"  The ever-increasing sizes of large language models necessitate distributed\nsolutions for fast inference that exploit multi-dimensional parallelism, where\ncomputational loads are split across various accelerators such as GPU clusters.\nHowever, this approach often introduces significant communication overhead,\nespecially on devices with limited bandwidth. In this paper, we introduce Flash\nCommunication, a novel low-bit compression technique designed to alleviate the\ntensor-parallelism communication bottleneck during inference. Our method\nsubstantially boosts intra-node communication speed by more than 3x and reduces\nthe time-to-first-token by 2x, with nearly no sacrifice in model accuracy.\nExtensive experiments on various up-to-date LLMs demonstrate the effectiveness\nof our approach.\n","authors":["Qingyuan Li","Bo Zhang","Liang Ye","Yifan Zhang","Wei Wu","Yerui Sun","Lin Ma","Yuchen Xie"],"pdf_url":"https://arxiv.org/pdf/2412.04964v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.01468v2","updated":"2024-12-11T13:22:12Z","published":"2024-06-03T15:57:29Z","title":"Understanding Token Probability Encoding in Output Embeddings","summary":"  In this paper, we investigate the output token probability information in the\noutput embedding of language models. We find an approximate common log-linear\nencoding of output token probabilities within the output embedding vectors and\nempirically demonstrate that it is accurate and sparse. As a causality\nexamination, we steer the encoding in output embedding to modify the output\nprobability distribution accurately. Moreover, the sparsity we find in output\nprobability encoding suggests that a large number of dimensions in the output\nembedding do not contribute to causal language modeling. Therefore, we attempt\nto delete the output-unrelated dimensions and find more than 30% of the\ndimensions can be deleted without significant movement in output distribution\nand sequence generation. Additionally, in the pre-training dynamics of language\nmodels, we find that the output embeddings capture the corpus token frequency\ninformation in early steps, even before an obvious convergence of parameters\nstarts.\n","authors":["Hakaze Cho","Yoshihiro Sakai","Kenshiro Tanaka","Mariko Kato","Naoya Inoue"],"pdf_url":"https://arxiv.org/pdf/2406.01468v2.pdf","comment":"15 pages, 17 figures, 3 tables. COLING 2025 Accepted"},{"id":"http://arxiv.org/abs/2409.15092v3","updated":"2024-12-11T13:13:20Z","published":"2024-09-23T15:06:37Z","title":"M2OST: Many-to-one Regression for Predicting Spatial Transcriptomics\n  from Digital Pathology Images","summary":"  The advancement of Spatial Transcriptomics (ST) has facilitated the\nspatially-aware profiling of gene expressions based on histopathology images.\nAlthough ST data offers valuable insights into the micro-environment of tumors,\nits acquisition cost remains expensive. Therefore, directly predicting the ST\nexpressions from digital pathology images is desired. Current methods usually\nadopt existing regression backbones along with patch-sampling for this task,\nwhich ignores the inherent multi-scale information embedded in the pyramidal\ndata structure of digital pathology images, and wastes the inter-spot visual\ninformation crucial for accurate gene expression prediction. To address these\nlimitations, we propose M2OST, a many-to-one regression Transformer that can\naccommodate the hierarchical structure of the pathology images via a decoupled\nmulti-scale feature extractor. Unlike traditional models that are trained with\none-to-one image-label pairs, M2OST uses multiple images from different levels\nof the digital pathology image to jointly predict the gene expressions in their\ncommon corresponding spot. Built upon our many-to-one scheme, M2OST can be\neasily scaled to fit different numbers of inputs, and its network structure\ninherently incorporates nearby inter-spot features, enhancing regression\nperformance. We have tested M2OST on three public ST datasets and the\nexperimental results show that M2OST can achieve state-of-the-art performance\nwith fewer parameters and floating-point operations (FLOPs). The code is\navailable at: https://github.com/Dootmaan/M2OST.\n","authors":["Hongyi Wang","Xiuju Du","Jing Liu","Shuyi Ouyang","Yen-Wei Chen","Lanfen Lin"],"pdf_url":"https://arxiv.org/pdf/2409.15092v3.pdf","comment":"Accepted by AAAI 2025. arXiv admin note: substantial text overlap\n  with arXiv:2401.10608"},{"id":"http://arxiv.org/abs/2412.08360v1","updated":"2024-12-11T13:06:24Z","published":"2024-12-11T13:06:24Z","title":"Agency and Morality as part of Text Entry AI Assistant Personas","summary":"  This paper discusses the need to move away from an instrumental view of text\ncomposition AI assistants under direct control of the user, towards a more\nagentic approach that is based on a value rationale. Based on an analysis of\nmoral dimensions of AI assistance in computer mediated communication, the paper\nproposes basic guidelines for designing the agent's persona.\n","authors":["Andreas Komninos"],"pdf_url":"https://arxiv.org/pdf/2412.08360v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.05025v2","updated":"2024-12-11T13:03:47Z","published":"2024-03-08T04:03:54Z","title":"Debiased Multimodal Understanding for Human Language Sequences","summary":"  Multimodal intention understanding (MIU) is an indispensable component of\nhuman expression analysis (e.g., sentiment or humor) from heterogeneous\nmodalities, including visual postures, linguistic contents, and acoustic\nbehaviors. Existing works invariably focus on designing sophisticated\nstructures or fusion strategies to achieve impressive improvements.\nUnfortunately, they all suffer from the subject variation problem due to data\ndistribution discrepancies among subjects. Concretely, MIU models are easily\nmisled by distinct subjects with different expression customs and\ncharacteristics in the training data to learn subject-specific spurious\ncorrelations, significantly limiting performance and generalizability across\nuninitiated subjects.Motivated by this observation, we introduce a\nrecapitulative causal graph to formulate the MIU procedure and analyze the\nconfounding effect of subjects. Then, we propose SuCI, a simple yet effective\ncausal intervention module to disentangle the impact of subjects acting as\nunobserved confounders and achieve model training via true causal effects. As a\nplug-and-play component, SuCI can be widely applied to most methods that seek\nunbiased predictions. Comprehensive experiments on several MIU benchmarks\nclearly demonstrate the effectiveness of the proposed module.\n","authors":["Zhi Xu","Dingkang Yang","Mingcheng Li","Yuzheng Wang","Zhaoyu Chen","Jiawei Chen","Jinjie Wei","Lihua Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.05025v2.pdf","comment":"Accepted by AAAI2025"},{"id":"http://arxiv.org/abs/2404.18353v2","updated":"2024-12-11T13:02:30Z","published":"2024-04-29T01:24:14Z","title":"How secure is AI-generated Code: A Large-Scale Comparison of Large\n  Language Models","summary":"  This study compares state-of-the-art Large Language Models (LLMs) on their\ntendency to generate vulnerabilities when writing C programs using a neutral\nzero-shot prompt. Tihanyi et al. introduced the FormAI dataset at PROMISE'23,\nfeaturing 112,000 C programs generated by GPT-3.5-turbo, with over 51.24%\nidentified as vulnerable. We extended that research with a large-scale study\ninvolving 9 state-of-the-art models such as OpenAI's GPT-4o-mini, Google's\nGemini Pro 1.0, TII's 180 billion-parameter Falcon, Meta's 13 billion-parameter\nCode Llama, and several other compact models. Additionally, we introduce the\nFormAI-v2 dataset, which comprises 331 000 compilable C programs generated by\nthese LLMs. Each program in the dataset is labeled based on the vulnerabilities\ndetected in its source code through formal verification, using the Efficient\nSMT-based Context-Bounded Model Checker (ESBMC). This technique minimizes false\npositives by providing a counterexample for the specific vulnerability and\nreduces false negatives by thoroughly completing the verification process. Our\nstudy reveals that at least 62.07% of the generated programs are vulnerable.\nThe differences between the models are minor, as they all show similar coding\nerrors with slight variations. Our research highlights that while LLMs offer\npromising capabilities for code generation, deploying their output in a\nproduction environment requires proper risk assessment and validation.\n","authors":["Norbert Tihanyi","Tamas Bisztray","Mohamed Amine Ferrag","Ridhi Jain","Lucas C. Cordeiro"],"pdf_url":"https://arxiv.org/pdf/2404.18353v2.pdf","comment":"Accepted and will be shortly published at Empirical Software\n  Engineering (EMSE). Journal Impact Factor: 3.5 (2023)"},{"id":"http://arxiv.org/abs/2412.08347v1","updated":"2024-12-11T12:41:36Z","published":"2024-12-11T12:41:36Z","title":"SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better\n  Reasoning in SLMs","summary":"  We present SmolTulu-1.7b-Instruct, referenced in this report as\nSmolTulu-DPO-1130, an instruction-tuned language model that adapts AllenAI's\nTulu 3 post-training pipeline to enhance Huggingface's SmolLM2-1.7B base model.\nThrough comprehensive empirical analysis using a 135M parameter model, we\ndemonstrate that the relationship between learning rate and batch size\nsignificantly impacts model performance in a task-dependent manner. Our\nfindings reveal a clear split: reasoning tasks like ARC and GSM8K benefit from\nhigher learning rate to batch size ratios, while pattern recognition tasks such\nas HellaSwag and IFEval show optimal performance with lower ratios. These\ninsights informed the development of SmolTulu, which achieves state-of-the-art\nperformance among sub-2B parameter models on instruction following, scoring\n67.7% on IFEval ($\\Delta$11%), and mathematical reasoning with 51.6% on GSM8K\n($\\Delta$3.4%), with an alternate version achieving scoring 57.1% on ARC\n($\\Delta5.4%$). We release our model, training recipes, and ablation studies to\nfacilitate further research in efficient model alignment, demonstrating that\ncareful adaptation of optimization dynamics can help bridge the capability gap\nbetween small and large language models.\n","authors":["Sultan Alrashed"],"pdf_url":"https://arxiv.org/pdf/2412.08347v1.pdf","comment":"10 pages, 4 figures, and 13 tables. For the SmolTulu-1.7b-instruct\n  model, see: https://huggingface.co/SultanR/SmolTulu-1.7b-Instruct"},{"id":"http://arxiv.org/abs/2412.06843v2","updated":"2024-12-11T12:35:25Z","published":"2024-12-07T16:35:14Z","title":"Semantic Loss Guided Data Efficient Supervised Fine Tuning for Safe\n  Responses in LLMs","summary":"  Large Language Models (LLMs) generating unsafe responses to toxic prompts is\na significant issue in their applications. While various efforts aim to address\nthis safety concern, previous approaches often demand substantial human data\ncollection or rely on the less dependable option of using another LLM to\ngenerate corrective data. In this paper, we aim to take this problem and\novercome limitations of requiring significant high-quality human data. Our\nmethod requires only a small set of unsafe responses to toxic prompts, easily\nobtained from the unsafe LLM itself. By employing a semantic cost combined with\na negative Earth Mover Distance (EMD) loss, we guide the LLM away from\ngenerating unsafe responses. Additionally, we propose a novel lower bound for\nEMD loss, enabling more efficient optimization. Our results demonstrate\nsuperior performance and data efficiency compared to baselines, and we further\nexamine the nuanced effects of over-alignment and potential degradation of\nlanguage capabilities when using contrastive data.\n","authors":["Yuxiao Lu","Arunesh Sinha","Pradeep Varakantham"],"pdf_url":"https://arxiv.org/pdf/2412.06843v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.20356v2","updated":"2024-12-11T11:58:06Z","published":"2024-10-27T07:09:31Z","title":"Uncovering Capabilities of Model Pruning in Graph Contrastive Learning","summary":"  Graph contrastive learning has achieved great success in pre-training graph\nneural networks without ground-truth labels. Leading graph contrastive learning\nfollows the classical scheme of contrastive learning, forcing model to identify\nthe essential information from augmented views. However, general augmented\nviews are produced via random corruption or learning, which inevitably leads to\nsemantics alteration. Although domain knowledge guided augmentations alleviate\nthis issue, the generated views are domain specific and undermine the\ngeneralization. In this work, motivated by the firm representation ability of\nsparse model from pruning, we reformulate the problem of graph contrastive\nlearning via contrasting different model versions rather than augmented views.\nWe first theoretically reveal the superiority of model pruning in contrast to\ndata augmentations. In practice, we take original graph as input and\ndynamically generate a perturbed graph encoder to contrast with the original\nencoder by pruning its transformation weights. Furthermore, considering the\nintegrity of node embedding in our method, we are capable of developing a local\ncontrastive loss to tackle the hard negative samples that disturb the model\ntraining. We extensively validate our method on various benchmarks regarding\ngraph classification via unsupervised and transfer learning. Compared to the\nstate-of-the-art (SOTA) works, better performance can always be obtained by the\nproposed method.\n","authors":["Junran Wu","Xueyuan Chen","Shangzhe Li"],"pdf_url":"https://arxiv.org/pdf/2410.20356v2.pdf","comment":"MM' 24"},{"id":"http://arxiv.org/abs/2406.00380v3","updated":"2024-12-11T11:52:58Z","published":"2024-06-01T09:36:16Z","title":"HonestLLM: Toward an Honest and Helpful Large Language Model","summary":"  Large Language Models (LLMs) have achieved remarkable success across various\nindustries due to their exceptional generative capabilities. However, for safe\nand effective real-world deployments, ensuring honesty and helpfulness is\ncritical. This paper addresses the question: Can we prioritize the helpfulness\nof LLMs while preserving their honesty? To begin with, we establish exhaustive\nprinciples aimed at guaranteeing the honesty of LLM. Additionally, we introduce\na novel dataset, referred to as HoneSet, comprising 930 queries spanning six\ncategories meticulously crafted to assess an LLM's capacity for maintaining\nhonesty. Subsequently, we present two approaches to augmenting honesty and\nhelpfulness in LLMs: a training-free enhancement and a fine-tuning-based\nimprovement. The training-free approach, which is based on curiosity-driven\nprompting, empowers LLMs to articulate internal confusion and uncertainty\nregarding queries, thereby optimizing their responses. Conversely, the\nfine-tuning-based method employs a two-stage process inspired by curriculum\nlearning: initially instructing LLMs to discern between honest and dishonest\nresponses, then refining their training to enhance helpfulness. Experiments\nconducted on nine prominent LLMs demonstrate a significant improvement in\nalignment with honesty across all models through the implementation of our\nproposed enhancements. Particularly noteworthy is the 65.3% enhancement\nobserved in Llama3-8b and the remarkable 124.7% improvement in Mistral-7b, as\nmeasured by the H$^{2}$ (honest and helpful) assessment. We believe that our\nwork can pave the way for developing more trustworthy LLMs for real-world\napplications.\n","authors":["Chujie Gao","Siyuan Wu","Yue Huang","Dongping Chen","Qihui Zhang","Zhengyan Fu","Yao Wan","Lichao Sun","Xiangliang Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.00380v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02232v4","updated":"2024-12-11T11:18:54Z","published":"2024-08-05T04:53:01Z","title":"SpecRover: Code Intent Extraction via LLMs","summary":"  Autonomous program improvement typically involves automatically producing bug\nfixes and feature additions. Such program improvement can be accomplished by a\ncombination of large language model (LLM) and program analysis capabilities, in\nthe form of an LLM agent. Since program repair or program improvement typically\nrequires a specification of intended behavior - specification inference can be\nuseful for producing high quality program patches. In this work, we examine\nefficient and low-cost workflows for iterative specification inference within\nan LLM agent. Given a GitHub issue to be resolved in a software project, our\ngoal is to conduct iterative code search accompanied by specification inference\n- thereby inferring intent from both the project structure and behavior. The\nintent thus captured is examined by a reviewer agent with the goal of vetting\nthe patches as well as providing a measure of confidence in the vetted patches.\nOur approach SpecRover (AutoCodeRover-v2) is built on the open-source LLM agent\nAutoCodeRover. In an evaluation on the full SWE-Bench consisting of 2294 GitHub\nissues, it shows more than 50% improvement in efficacy over AutoCodeRover.\nCompared to the open-source agents available, our work shows modest cost ($0.65\nper issue) in resolving an average GitHub issue in SWE-Bench lite. The\nproduction of explanation by SpecRover allows for a better \"signal\" to be given\nto the developer, on when the suggested patches can be accepted with\nconfidence. SpecRover also seeks to demonstrate the continued importance of\nspecification inference in automated program repair, even as program repair\ntechnologies enter the LLM era.\n","authors":["Haifeng Ruan","Yuntong Zhang","Abhik Roychoudhury"],"pdf_url":"https://arxiv.org/pdf/2408.02232v4.pdf","comment":"Haifeng Ruan and Yuntong Zhang contributed equally to this work. To\n  appear in ICSE 2025"},{"id":"http://arxiv.org/abs/2411.06798v2","updated":"2024-12-11T11:10:22Z","published":"2024-11-11T08:51:18Z","title":"LA4SR: illuminating the dark proteome with generative AI","summary":"  AI language models (LMs) show promise for biological sequence analysis. We\nre-engineered open-source LMs (GPT-2, BLOOM, DistilRoBERTa, ELECTRA, and Mamba,\nranging from 70M to 12B parameters) for microbial sequence classification. The\nmodels achieved F1 scores up to 95 and operated 16,580x faster and at 2.9x the\nrecall of BLASTP. They effectively classified the algal dark proteome -\nuncharacterized proteins comprising about 65% of total proteins - validated on\nnew data including a new, complete Hi-C/Pacbio Chlamydomonas genome. Larger\n(>1B) LA4SR models reached high accuracy (F1 > 86) when trained on less than 2%\nof available data, rapidly achieving strong generalization capacity. High\naccuracy was achieved when training data had intact or scrambled terminal\ninformation, demonstrating robust generalization to incomplete sequences.\nFinally, we provide custom AI explainability software tools for attributing\namino acid patterns to AI generative processes and interpret their outputs in\nevolutionary and biophysical contexts.\n","authors":["David R. Nelson","Ashish Kumar Jaiswal","Noha Ismail","Alexandra Mystikou","Kourosh Salehi-Ashtiani"],"pdf_url":"https://arxiv.org/pdf/2411.06798v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08292v1","updated":"2024-12-11T11:08:09Z","published":"2024-12-11T11:08:09Z","title":"Self-Refining Diffusion Samplers: Enabling Parallelization via Parareal\n  Iterations","summary":"  In diffusion models, samples are generated through an iterative refinement\nprocess, requiring hundreds of sequential model evaluations. Several recent\nmethods have introduced approximations (fewer discretization steps or\ndistillation) to trade off speed at the cost of sample quality. In contrast, we\nintroduce Self-Refining Diffusion Samplers (SRDS) that retain sample quality\nand can improve latency at the cost of additional parallel compute. We take\ninspiration from the Parareal algorithm, a popular numerical method for\nparallel-in-time integration of differential equations. In SRDS, a quick but\nrough estimate of a sample is first created and then iteratively refined in\nparallel through Parareal iterations. SRDS is not only guaranteed to accurately\nsolve the ODE and converge to the serial solution but also benefits from\nparallelization across the diffusion trajectory, enabling batched inference and\npipelining. As we demonstrate for pre-trained diffusion models, the early\nconvergence of this refinement procedure drastically reduces the number of\nsteps required to produce a sample, speeding up generation for instance by up\nto 1.7x on a 25-step StableDiffusion-v2 benchmark and up to 4.3x on longer\ntrajectories.\n","authors":["Nikil Roashan Selvam","Amil Merchant","Stefano Ermon"],"pdf_url":"https://arxiv.org/pdf/2412.08292v1.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2412.08282v1","updated":"2024-12-11T10:57:16Z","published":"2024-12-11T10:57:16Z","title":"How Does the Smoothness Approximation Method Facilitate Generalization\n  for Federated Adversarial Learning?","summary":"  Federated Adversarial Learning (FAL) is a robust framework for resisting\nadversarial attacks on federated learning. Although some FAL studies have\ndeveloped efficient algorithms, they primarily focus on convergence performance\nand overlook generalization. Generalization is crucial for evaluating algorithm\nperformance on unseen data. However, generalization analysis is more\nchallenging due to non-smooth adversarial loss functions. A common approach to\naddressing this issue is to leverage smoothness approximation. In this paper,\nwe develop algorithm stability measures to evaluate the generalization\nperformance of two popular FAL algorithms: \\textit{Vanilla FAL (VFAL)} and {\\it\nSlack FAL (SFAL)}, using three different smooth approximation methods: 1)\n\\textit{Surrogate Smoothness Approximation (SSA)}, (2) \\textit{Randomized\nSmoothness Approximation (RSA)}, and (3) \\textit{Over-Parameterized Smoothness\nApproximation (OPSA)}. Based on our in-depth analysis, we answer the question\nof how to properly set the smoothness approximation method to mitigate\ngeneralization error in FAL. Moreover, we identify RSA as the most effective\nmethod for reducing generalization error. In highly data-heterogeneous\nscenarios, we also recommend employing SFAL to mitigate the deterioration of\ngeneralization performance caused by heterogeneity. Based on our theoretical\nresults, we provide insights to help develop more efficient FAL algorithms,\nsuch as designing new metrics and dynamic aggregation rules to mitigate\nheterogeneity.\n","authors":["Wenjun Ding","Ying An","Lixing Chen","Shichao Kan","Fan Wu","Zhe Qu"],"pdf_url":"https://arxiv.org/pdf/2412.08282v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08273v1","updated":"2024-12-11T10:44:47Z","published":"2024-12-11T10:44:47Z","title":"Can transformative AI shape a new age for our civilization?: Navigating\n  between speculation and reality","summary":"  Artificial Intelligence is widely regarded as a transformative force with the\npotential to redefine numerous sectors of human civilization. While Artificial\nIntelligence has evolved from speculative fiction to a pivotal element of\ntechnological progress, its role as a truly transformative agent, or\ntransformative Artificial Intelligence, remains a subject of debate. This work\nexplores the historical precedents of technological breakthroughs, examining\nwhether Artificial Intelligence can achieve a comparable impact, and it delves\ninto various ethical frameworks that shape the perception and development of\nArtificial Intelligence. Additionally, it considers the societal, technical,\nand regulatory challenges that must be addressed for Artificial Intelligence to\nbecome a catalyst for global change. We also examine not only the strategies\nand methodologies that could lead to transformative Artificial Intelligence but\nalso the barriers that could ultimately make these goals unattainable. We end\nwith a critical inquiry into whether reaching a transformative Artificial\nIntelligence might compel humanity to adopt an entirely new ethical approach,\ntailored to the complexities of advanced Artificial Intelligence. By addressing\nthe ethical, social, and scientific dimensions of Artificial Intelligence's\ndevelopment, this work contributes to the broader discourse on the long-term\nimplications of Artificial Intelligence and its capacity to drive civilization\ntoward a new era of progress or, conversely, exacerbate existing inequalities\nand risks.\n","authors":["Jesus L. Lobo","Javier Del Ser"],"pdf_url":"https://arxiv.org/pdf/2412.08273v1.pdf","comment":"100 pages, 6 Figures, 2 Tables"},{"id":"http://arxiv.org/abs/2412.08271v1","updated":"2024-12-11T10:43:11Z","published":"2024-12-11T10:43:11Z","title":"Position-aware Guided Point Cloud Completion with CLIP Model","summary":"  Point cloud completion aims to recover partial geometric and topological\nshapes caused by equipment defects or limited viewpoints. Current methods\neither solely rely on the 3D coordinates of the point cloud to complete it or\nincorporate additional images with well-calibrated intrinsic parameters to\nguide the geometric estimation of the missing parts. Although these methods\nhave achieved excellent performance by directly predicting the location of\ncomplete points, the extracted features lack fine-grained information regarding\nthe location of the missing area. To address this issue, we propose a rapid and\nefficient method to expand an unimodal framework into a multimodal framework.\nThis approach incorporates a position-aware module designed to enhance the\nspatial information of the missing parts through a weighted map learning\nmechanism. In addition, we establish a Point-Text-Image triplet corpus PCI-TI\nand MVP-TI based on the existing unimodal point cloud completion dataset and\nuse the pre-trained vision-language model CLIP to provide richer detail\ninformation for 3D shapes, thereby enhancing performance. Extensive\nquantitative and qualitative experiments demonstrate that our method\noutperforms state-of-the-art point cloud completion methods.\n","authors":["Feng Zhou","Qi Zhang","Ju Dai","Lei Li","Qing Fan","Junliang Xing"],"pdf_url":"https://arxiv.org/pdf/2412.08271v1.pdf","comment":"Accepted by AAAI25"},{"id":"http://arxiv.org/abs/2412.08261v1","updated":"2024-12-11T10:17:00Z","published":"2024-12-11T10:17:00Z","title":"FLIP: Flow-Centric Generative Planning for General-Purpose Manipulation\n  Tasks","summary":"  We aim to develop a model-based planning framework for world models that can\nbe scaled with increasing model and data budgets for general-purpose\nmanipulation tasks with only language and vision inputs. To this end, we\npresent FLow-centric generative Planning (FLIP), a model-based planning\nalgorithm on visual space that features three key modules: 1. a multi-modal\nflow generation model as the general-purpose action proposal module; 2. a\nflow-conditioned video generation model as the dynamics module; and 3. a\nvision-language representation learning model as the value module. Given an\ninitial image and language instruction as the goal, FLIP can progressively\nsearch for long-horizon flow and video plans that maximize the discounted\nreturn to accomplish the task. FLIP is able to synthesize long-horizon plans\nacross objects, robots, and tasks with image flows as the general action\nrepresentation, and the dense flow information also provides rich guidance for\nlong-horizon video generation. In addition, the synthesized flow and video\nplans can guide the training of low-level control policies for robot execution.\nExperiments on diverse benchmarks demonstrate that FLIP can improve both the\nsuccess rates and quality of long-horizon video plan synthesis and has the\ninteractive world model property, opening up wider applications for future\nworks.\n","authors":["Chongkai Gao","Haozhuo Zhang","Zhixuan Xu","Zhehao Cai","Lin Shao"],"pdf_url":"https://arxiv.org/pdf/2412.08261v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.05074v5","updated":"2024-12-11T10:14:32Z","published":"2024-08-09T14:02:24Z","title":"Improving Mortality Prediction After Radiotherapy with Large Language\n  Model Structuring of Large-Scale Unstructured Electronic Health Records","summary":"  Accurate survival prediction in radiotherapy (RT) is critical for optimizing\ntreatment decisions. This study developed and validated the RT-Surv framework,\nwhich integrates general-domain, open-source large language models (LLMs) to\nstructure unstructured electronic health records alongside structured clinical\ndata. Using data from 34,276 patients and an external cohort of 852, the\nframework successfully transformed unstructured clinical information into\nstructured formats. Incorporating LLM-structured clinical features improved the\nconcordance index from 0.779 to 0.842 during external validation, demonstrating\na significant performance enhancement. Key LLM-structured features, such as\ndisease extent, general condition, and RT purpose, showed high predictive\nimportance and aligned closely with statistically significant predictors\nidentified through conventional statistical analyses, thereby improving model\ninterpretability. Furthermore, the framework enhanced risk stratification,\nenabling more distinct differentiation among low-, intermediate-, and high-risk\ngroups (p < 0.001) using LLM-structured clinical features. These findings\nhighlight the potential of LLMs to convert unstructured data into actionable\ninsights, improving predictive modeling and patient outcomes in clinics.\n","authors":["Sangjoon Park","Chan Woo Wee","Seo Hee Choi","Kyung Hwan Kim","Jee Suk Chang","Hong In Yoon","Ik Jae Lee","Yong Bae Kim","Jaeho Cho","Ki Chang Keum","Chang Geol Lee","Hwa Kyung Byun","Woong Sub Koom"],"pdf_url":"https://arxiv.org/pdf/2408.05074v5.pdf","comment":"23 pages, 2 tables, 4 figures"},{"id":"http://arxiv.org/abs/2412.08258v1","updated":"2024-12-11T10:11:41Z","published":"2024-12-11T10:11:41Z","title":"Large Language Models for Scholarly Ontology Generation: An Extensive\n  Analysis in the Engineering Field","summary":"  Ontologies of research topics are crucial for structuring scientific\nknowledge, enabling scientists to navigate vast amounts of research, and\nforming the backbone of intelligent systems such as search engines and\nrecommendation systems. However, manual creation of these ontologies is\nexpensive, slow, and often results in outdated and overly general\nrepresentations. As a solution, researchers have been investigating ways to\nautomate or semi-automate the process of generating these ontologies. This\npaper offers a comprehensive analysis of the ability of large language models\n(LLMs) to identify semantic relationships between different research topics,\nwhich is a critical step in the development of such ontologies. To this end, we\ndeveloped a gold standard based on the IEEE Thesaurus to evaluate the task of\nidentifying four types of relationships between pairs of topics: broader,\nnarrower, same-as, and other. Our study evaluates the performance of seventeen\nLLMs, which differ in scale, accessibility (open vs. proprietary), and model\ntype (full vs. quantised), while also assessing four zero-shot reasoning\nstrategies. Several models have achieved outstanding results, including\nMixtral-8x7B, Dolphin-Mistral-7B, and Claude 3 Sonnet, with F1-scores of 0.847,\n0.920, and 0.967, respectively. Furthermore, our findings demonstrate that\nsmaller, quantised models, when optimised through prompt engineering, can\ndeliver performance comparable to much larger proprietary models, while\nrequiring significantly fewer computational resources.\n","authors":["Tanay Aggarwal","Angelo Salatino","Francesco Osborne","Enrico Motta"],"pdf_url":"https://arxiv.org/pdf/2412.08258v1.pdf","comment":"submitted to Information Processing & Management"},{"id":"http://arxiv.org/abs/2411.07941v2","updated":"2024-12-11T10:01:03Z","published":"2024-11-12T17:11:18Z","title":"DuoLift-GAN:Reconstructing CT from Single-view and Biplanar X-Rays with\n  Generative Adversarial Networks","summary":"  Computed tomography (CT) provides highly detailed three-dimensional (3D)\nmedical images but is costly, time-consuming, and often inaccessible in\nintraoperative settings (Organization et al. 2011). Recent advancements have\nexplored reconstructing 3D chest volumes from sparse 2D X-rays, such as\nsingle-view or orthogonal double-view images. However, current models tend to\nprocess 2D images in a planar manner, prioritizing visual realism over\nstructural accuracy. In this work, we introduce DuoLift Generative Adversarial\nNetworks (DuoLift-GAN), a novel architecture with dual branches that\nindependently elevate 2D images and their features into 3D representations.\nThese 3D outputs are merged into a unified 3D feature map and decoded into a\ncomplete 3D chest volume, enabling richer 3D information capture. We also\npresent a masked loss function that directs reconstruction towards critical\nanatomical regions, improving structural accuracy and visual quality. This\npaper demonstrates that DuoLift-GAN significantly enhances reconstruction\naccuracy while achieving superior visual realism compared to existing methods.\n","authors":["Zhaoxi Zhang","Yueliang Ying"],"pdf_url":"https://arxiv.org/pdf/2411.07941v2.pdf","comment":"9 pages, LaTeX; removed the superscript numbers associated with the\n  authors' names for clarity, typos corrected"},{"id":"http://arxiv.org/abs/2406.14035v3","updated":"2024-12-11T09:56:15Z","published":"2024-06-20T06:56:19Z","title":"Using Game Play to Investigate Multimodal and Conversational Grounding\n  in Large Multimodal Models","summary":"  While the situation has improved for text-only models, it again seems to be\nthe case currently that multimodal (text and image) models develop faster than\nways to evaluate them. In this paper, we bring a recently developed evaluation\nparadigm from text models to multimodal models, namely evaluation through the\ngoal-oriented game (self) play, complementing reference-based and\npreference-based evaluation. Specifically, we define games that challenge a\nmodel's capability to represent a situation from visual information and align\nsuch representations through dialogue. We find that the largest closed models\nperform rather well on the games that we define, while even the best\nopen-weight models struggle with them. On further analysis, we find that the\nexceptional deep captioning capabilities of the largest models drive some of\nthe performance. There is still room to grow for both kinds of models, ensuring\nthe continued relevance of the benchmark.\n","authors":["Sherzod Hakimov","Yerkezhan Abdullayeva","Kushal Koshti","Antonia Schmidt","Yan Weiser","Anne Beyer","David Schlangen"],"pdf_url":"https://arxiv.org/pdf/2406.14035v3.pdf","comment":"Accepted at COLING 2025"},{"id":"http://arxiv.org/abs/2409.04792v2","updated":"2024-12-11T09:40:27Z","published":"2024-09-07T11:08:20Z","title":"Improving Deep Reinforcement Learning by Reducing the Chain Effect of\n  Value and Policy Churn","summary":"  Deep neural networks provide Reinforcement Learning (RL) powerful function\napproximators to address large-scale decision-making problems. However, these\napproximators introduce challenges due to the non-stationary nature of RL\ntraining. One source of the challenges in RL is that output predictions can\nchurn, leading to uncontrolled changes after each batch update for states not\nincluded in the batch. Although such a churn phenomenon exists in each step of\nnetwork training, how churn occurs and impacts RL remains under-explored. In\nthis work, we start by characterizing churn in a view of Generalized Policy\nIteration with function approximation, and we discover a chain effect of churn\nthat leads to a cycle where the churns in value estimation and policy\nimprovement compound and bias the learning dynamics throughout the iteration.\nFurther, we concretize the study and focus on the learning issues caused by the\nchain effect in different settings, including greedy action deviation in\nvalue-based methods, trust region violation in proximal policy optimization,\nand dual bias of policy value in actor-critic methods. We then propose a method\nto reduce the chain effect across different settings, called Churn Approximated\nReductIoN (CHAIN), which can be easily plugged into most existing DRL\nalgorithms. Our experiments demonstrate the effectiveness of our method in both\nreducing churn and improving learning performance across online and offline,\nvalue-based and policy-based RL settings, as well as a scaling setting.\n","authors":["Hongyao Tang","Glen Berseth"],"pdf_url":"https://arxiv.org/pdf/2409.04792v2.pdf","comment":"Accepted to NeurIPS 2024. Project page:\n  https://bluecontra.github.io/CHAIN"},{"id":"http://arxiv.org/abs/2412.08231v1","updated":"2024-12-11T09:31:03Z","published":"2024-12-11T09:31:03Z","title":"Dynamic Modality-Camera Invariant Clustering for Unsupervised\n  Visible-Infrared Person Re-identification","summary":"  Unsupervised learning visible-infrared person re-identification (USL-VI-ReID)\noffers a more flexible and cost-effective alternative compared to supervised\nmethods. This field has gained increasing attention due to its promising\npotential. Existing methods simply cluster modality-specific samples and employ\nstrong association techniques to achieve instance-to-cluster or\ncluster-to-cluster cross-modality associations. However, they ignore\ncross-camera differences, leading to noticeable issues with excessive splitting\nof identities. Consequently, this undermines the accuracy and reliability of\ncross-modal associations. To address these issues, we propose a novel Dynamic\nModality-Camera Invariant Clustering (DMIC) framework for USL-VI-ReID.\nSpecifically, our DMIC naturally integrates Modality-Camera Invariant Expansion\n(MIE), Dynamic Neighborhood Clustering (DNC) and Hybrid Modality Contrastive\nLearning (HMCL) into a unified framework, which eliminates both the\ncross-modality and cross-camera discrepancies in clustering. MIE fuses\ninter-modal and inter-camera distance coding to bridge the gaps between\nmodalities and cameras at the clustering level. DNC employs two dynamic search\nstrategies to refine the network's optimization objective, transitioning from\nimproving discriminability to enhancing cross-modal and cross-camera\ngeneralizability. Moreover, HMCL is designed to optimize instance-level and\ncluster-level distributions. Memories for intra-modality and inter-modality\ntraining are updated using randomly selected samples, facilitating real-time\nexploration of modality-invariant representations. Extensive experiments have\ndemonstrated that our DMIC addresses the limitations present in current\nclustering approaches and achieve competitive performance, which significantly\nreduces the performance gap with supervised methods.\n","authors":["Yiming Yang","Weipeng Hu","Haifeng Hu"],"pdf_url":"https://arxiv.org/pdf/2412.08231v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.02965v2","updated":"2024-12-11T09:30:19Z","published":"2024-03-05T13:41:25Z","title":"ChatGPT and biometrics: an assessment of face recognition, gender\n  detection, and age estimation capabilities","summary":"  This paper explores the application of large language models (LLMs), like\nChatGPT, for biometric tasks. We specifically examine the capabilities of\nChatGPT in performing biometric-related tasks, with an emphasis on face\nrecognition, gender detection, and age estimation. Since biometrics are\nconsidered as sensitive information, ChatGPT avoids answering direct prompts,\nand thus we crafted a prompting strategy to bypass its safeguard and evaluate\nthe capabilities for biometrics tasks. Our study reveals that ChatGPT\nrecognizes facial identities and differentiates between two facial images with\nconsiderable accuracy. Additionally, experimental results demonstrate\nremarkable performance in gender detection and reasonable accuracy for the age\nestimation tasks. Our findings shed light on the promising potentials in the\napplication of LLMs and foundation models for biometrics.\n","authors":["Ahmad Hassanpour","Yasamin Kowsari","Hatef Otroshi Shahreza","Bian Yang","Sebastien Marcel"],"pdf_url":"https://arxiv.org/pdf/2403.02965v2.pdf","comment":"Published as a conference paper at IEEE International Conference on\n  Image Processing (ICIP) 2024"},{"id":"http://arxiv.org/abs/2412.08228v1","updated":"2024-12-11T09:28:30Z","published":"2024-12-11T09:28:30Z","title":"Hierarchical Classification for Automated Image Annotation of Coral Reef\n  Benthic Structures","summary":"  Automated benthic image annotation is crucial to efficiently monitor and\nprotect coral reefs against climate change. Current machine learning approaches\nfail to capture the hierarchical nature of benthic organisms covering reef\nsubstrata, i.e., coral taxonomic levels and health condition. To address this\nlimitation, we propose to annotate benthic images using hierarchical\nclassification. Experiments on a custom dataset from a Northeast Brazilian\ncoral reef show that our approach outperforms flat classifiers, improving both\nF1 and hierarchical F1 scores by approximately 2\\% across varying amounts of\ntraining data. In addition, this hierarchical method aligns more closely with\necological objectives.\n","authors":["Célia Blondin","Joris Guérin","Kelly Inagaki","Guilherme Longo","Laure Berti-Équille"],"pdf_url":"https://arxiv.org/pdf/2412.08228v1.pdf","comment":"Poster at Tackling Climate Change with Machine Learning: workshop at\n  NeurIPS 2024"},{"id":"http://arxiv.org/abs/2406.17462v2","updated":"2024-12-11T09:23:17Z","published":"2024-06-25T11:05:26Z","title":"EvolvED: Evolutionary Embeddings to Understand the Generation Process of\n  Diffusion Models","summary":"  Diffusion models, widely used in image generation, rely on iterative\nrefinement to generate images from noise. Understanding this data evolution is\nimportant for model development and interpretability, yet challenging due to\nits high-dimensional, iterative nature. Prior works often focus on static or\ninstance-level analyses, missing the iterative and holistic aspects of the\ngenerative path. While dimensionality reduction can visualize image evolution\nfor few instances, it does preserve the iterative structure. To address these\ngaps, we introduce EvolvED, a method that presents a holistic view of the\niterative generative process in diffusion models. EvolvED goes beyond instance\nexploration by leveraging predefined research questions to streamline\ngenerative space exploration. Tailored prompts aligned with these questions are\nused to extract intermediate images, preserving iterative context. Targeted\nfeature extractors trace the evolution of key image attribute evolution,\naddressing the complexity of high-dimensional outputs. Central to EvolvED is a\nnovel evolutionary embedding algorithm that encodes iterative steps while\nmaintaining semantic relations. It enhances the visualization of data evolution\nby clustering semantically similar elements within each iteration with t-SNE,\ngrouping elements by iteration, and aligning an instance's elements across\niterations. We present rectilinear and radial layouts to represent iterations\nand support exploration. We apply EvolvED to diffusion models like GLIDE and\nStable Diffusion, demonstrating its ability to provide valuable insights into\nthe generative process.\n","authors":["Vidya Prasad","Hans van Gorp","Christina Humer","Ruud J. G. van Sloun","Anna Vilanova","Nicola Pezzotti"],"pdf_url":"https://arxiv.org/pdf/2406.17462v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08221v1","updated":"2024-12-11T09:17:39Z","published":"2024-12-11T09:17:39Z","title":"Generate Any Scene: Evaluating and Improving Text-to-Vision Generation\n  with Scene Graph Programming","summary":"  DALL-E and Sora have gained attention by producing implausible images, such\nas \"astronauts riding a horse in space.\" Despite the proliferation of\ntext-to-vision models that have inundated the internet with synthetic visuals,\nfrom images to 3D assets, current benchmarks predominantly evaluate these\nmodels on real-world scenes paired with captions. We introduce Generate Any\nScene, a framework that systematically enumerates scene graphs representing a\nvast array of visual scenes, spanning realistic to imaginative compositions.\nGenerate Any Scene leverages 'scene graph programming', a method for\ndynamically constructing scene graphs of varying complexity from a structured\ntaxonomy of visual elements. This taxonomy includes numerous objects,\nattributes, and relations, enabling the synthesis of an almost infinite variety\nof scene graphs. Using these structured representations, Generate Any Scene\ntranslates each scene graph into a caption, enabling scalable evaluation of\ntext-to-vision models through standard metrics. We conduct extensive\nevaluations across multiple text-to-image, text-to-video, and text-to-3D\nmodels, presenting key findings on model performance. We find that DiT-backbone\ntext-to-image models align more closely with input captions than UNet-backbone\nmodels. Text-to-video models struggle with balancing dynamics and consistency,\nwhile both text-to-video and text-to-3D models show notable gaps in human\npreference alignment. We demonstrate the effectiveness of Generate Any Scene by\nconducting three practical applications leveraging captions generated by\nGenerate Any Scene: 1) a self-improving framework where models iteratively\nenhance their performance using generated data, 2) a distillation process to\ntransfer specific strengths from proprietary models to open-source\ncounterparts, and 3) improvements in content moderation by identifying and\ngenerating challenging synthetic data.\n","authors":["Ziqi Gao","Weikai Huang","Jieyu Zhang","Aniruddha Kembhavi","Ranjay Krishna"],"pdf_url":"https://arxiv.org/pdf/2412.08221v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.02819v3","updated":"2024-12-11T09:15:06Z","published":"2024-12-03T20:35:57Z","title":"CNNSum: Exploring Long-Context Summarization with Large Language Models\n  in Chinese Novels","summary":"  Large Language Models (LLMs) have been well-researched in many long-context\ntasks. However, due to high annotation costs, high-quality long-context summary\ndatasets for training or evaluation are scarce, limiting further research. In\nthis work, we introduce CNNSum, a new multi-scale Chinese long-context novel\nsummarization benchmark, including four subsets, length covering 16k to 128k,\n695 samples in total, the annotations are human-driven. We evaluate commercial\nand open-source models on CNNSum and conduct a detailed analysis. Based on the\nobservations, we further conduct fine-tuning exploration with short-context\nsummary data. In our study: (1) GPT-4o underperformed, due to excessive\nsubjective commentary. (2) Currently, long-context summarization mainly relies\non memory ability, small LLMs with stable longer context lengths are the most\ncost-effective. Using long data concatenated from short-context summaries makes\na significant improvement. (3) Prompt templates may cause a large performance\ngap but can be mitigated through fine-tuning. (4) Fine-tuned Chat or\nInstruction versions may harm the Base model and further fine-tuning cannot\nbridge performance gap. (5) while models with RoPE base scaling exhibit strong\nextrapolation potential, their performance may vary significantly when combined\nwith other interpolation methods and need careful selection. (6) CNNSum\nprovides more reliable and insightful evaluation results than other benchmarks.\nWe release CNNSum to advance research in this field\n(https://github.com/CxsGhost/CNNSum).\n","authors":["Lingxiao Wei","He Yan","Xiangju Lu","Junmin Zhu","Jun Wang","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.02819v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.05285v3","updated":"2024-12-11T09:05:22Z","published":"2024-07-07T07:06:49Z","title":"Mjolnir: Breaking the Shield of Perturbation-Protected Gradients via\n  Adaptive Diffusion","summary":"  Perturbation-based mechanisms, such as differential privacy, mitigate\ngradient leakage attacks by introducing noise into the gradients, thereby\npreventing attackers from reconstructing clients' private data from the leaked\ngradients. However, can gradient perturbation protection mechanisms truly\ndefend against all gradient leakage attacks? In this paper, we present the\nfirst attempt to break the shield of gradient perturbation protection in\nFederated Learning for the extraction of private information. We focus on\ncommon noise distributions, specifically Gaussian and Laplace, and apply our\napproach to DNN and CNN models. We introduce Mjolnir, a perturbation-resilient\ngradient leakage attack that is capable of removing perturbations from\ngradients without requiring additional access to the original model structure\nor external data. Specifically, we leverage the inherent diffusion properties\nof gradient perturbation protection to develop a novel diffusion-based gradient\ndenoising model for Mjolnir. By constructing a surrogate client model that\ncaptures the structure of perturbed gradients, we obtain crucial gradient data\nfor training the diffusion model. We further utilize the insight that\nmonitoring disturbance levels during the reverse diffusion process can enhance\ngradient denoising capabilities, allowing Mjolnir to generate gradients that\nclosely approximate the original, unperturbed versions through adaptive\nsampling steps. Extensive experiments demonstrate that Mjolnir effectively\nrecovers the protected gradients and exposes the Federated Learning process to\nthe threat of gradient leakage, achieving superior performance in gradient\ndenoising and private data recovery.\n","authors":["Xuan Liu","Siqi Cai","Qihua Zhou","Song Guo","Ruibin Li","Kaiwei Lin"],"pdf_url":"https://arxiv.org/pdf/2407.05285v3.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2404.11553v3","updated":"2024-12-11T09:04:18Z","published":"2024-04-17T16:53:16Z","title":"Language Ranker: A Metric for Quantifying LLM Performance Across High\n  and Low-Resource Languages","summary":"  The development of Large Language Models (LLMs) relies on extensive text\ncorpora, which are often unevenly distributed across languages. This imbalance\nresults in LLMs performing significantly better on high-resource languages like\nEnglish, German, and French, while their capabilities in low-resource languages\nremain inadequate. Currently, there is a lack of quantitative methods to\nevaluate the performance of LLMs in these low-resource languages. To address\nthis gap, we propose the Language Ranker, an intrinsic metric designed to\nbenchmark and rank languages based on LLM performance using internal\nrepresentations. By comparing the LLM's internal representation of various\nlanguages against a baseline derived from English, we can assess the model's\nmultilingual capabilities in a robust and language-agnostic manner. Our\nanalysis reveals that high-resource languages exhibit higher similarity scores\nwith English, demonstrating superior performance, while low-resource languages\nshow lower similarity scores, underscoring the effectiveness of our metric in\nassessing language-specific capabilities. Besides, the experiments show that\nthere is a strong correlation between the LLM's performance in different\nlanguages and the proportion of those languages in its pre-training corpus.\nThese insights underscore the efficacy of the Language Ranker as a tool for\nevaluating LLM performance across different languages, particularly those with\nlimited resources.\n","authors":["Zihao Li","Yucheng Shi","Zirui Liu","Fan Yang","Ali Payani","Ninghao Liu","Mengnan Du"],"pdf_url":"https://arxiv.org/pdf/2404.11553v3.pdf","comment":"Accepted by AAAI 2025 (Social Impact Track)"},{"id":"http://arxiv.org/abs/2412.04653v2","updated":"2024-12-11T08:42:20Z","published":"2024-12-05T22:50:42Z","title":"Hidden in the Noise: Two-Stage Robust Watermarking for Images","summary":"  As the quality of image generators continues to improve, deepfakes become a\ntopic of considerable societal debate. Image watermarking allows responsible\nmodel owners to detect and label their AI-generated content, which can mitigate\nthe harm. Yet, current state-of-the-art methods in image watermarking remain\nvulnerable to forgery and removal attacks. This vulnerability occurs in part\nbecause watermarks distort the distribution of generated images,\nunintentionally revealing information about the watermarking techniques.\n  In this work, we first demonstrate a distortion-free watermarking method for\nimages, based on a diffusion model's initial noise. However, detecting the\nwatermark requires comparing the initial noise reconstructed for an image to\nall previously used initial noises. To mitigate these issues, we propose a\ntwo-stage watermarking framework for efficient detection. During generation, we\naugment the initial noise with generated Fourier patterns to embed information\nabout the group of initial noises we used. For detection, we (i) retrieve the\nrelevant group of noises, and (ii) search within the given group for an initial\nnoise that might match our image. This watermarking approach achieves\nstate-of-the-art robustness to forgery and removal against a large battery of\nattacks.\n","authors":["Kasra Arabi","Benjamin Feuer","R. Teal Witter","Chinmay Hegde","Niv Cohen"],"pdf_url":"https://arxiv.org/pdf/2412.04653v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.15950v5","updated":"2024-12-11T08:40:48Z","published":"2023-10-24T15:51:13Z","title":"Representation Learning with Large Language Models for Recommendation","summary":"  Recommender systems have seen significant advancements with the influence of\ndeep learning and graph neural networks, particularly in capturing complex\nuser-item relationships. However, these graph-based recommenders heavily depend\non ID-based data, potentially disregarding valuable textual information\nassociated with users and items, resulting in less informative learned\nrepresentations. Moreover, the utilization of implicit feedback data introduces\npotential noise and bias, posing challenges for the effectiveness of user\npreference learning. While the integration of large language models (LLMs) into\ntraditional ID-based recommenders has gained attention, challenges such as\nscalability issues, limitations in text-only reliance, and prompt input\nconstraints need to be addressed for effective implementation in practical\nrecommender systems. To address these challenges, we propose a model-agnostic\nframework RLMRec that aims to enhance existing recommenders with LLM-empowered\nrepresentation learning. It proposes a recommendation paradigm that integrates\nrepresentation learning with LLMs to capture intricate semantic aspects of user\nbehaviors and preferences. RLMRec incorporates auxiliary textual signals,\ndevelops a user/item profiling paradigm empowered by LLMs, and aligns the\nsemantic space of LLMs with the representation space of collaborative\nrelational signals through a cross-view alignment framework. This work further\nestablish a theoretical foundation demonstrating that incorporating textual\nsignals through mutual information maximization enhances the quality of\nrepresentations. In our evaluation, we integrate RLMRec with state-of-the-art\nrecommender models, while also analyzing its efficiency and robustness to noise\ndata. Our implementation codes are available at\nhttps://github.com/HKUDS/RLMRec.\n","authors":["Xubin Ren","Wei Wei","Lianghao Xia","Lixin Su","Suqi Cheng","Junfeng Wang","Dawei Yin","Chao Huang"],"pdf_url":"https://arxiv.org/pdf/2310.15950v5.pdf","comment":"Published as a WWW'24 full paper"},{"id":"http://arxiv.org/abs/2412.08197v1","updated":"2024-12-11T08:40:37Z","published":"2024-12-11T08:40:37Z","title":"SAFIRE: Segment Any Forged Image Region","summary":"  Most techniques approach the problem of image forgery localization as a\nbinary segmentation task, training neural networks to label original areas as 0\nand forged areas as 1. In contrast, we tackle this issue from a more\nfundamental perspective by partitioning images according to their originating\nsources. To this end, we propose Segment Any Forged Image Region (SAFIRE),\nwhich solves forgery localization using point prompting. Each point on an image\nis used to segment the source region containing itself. This allows us to\npartition images into multiple source regions, a capability achieved for the\nfirst time. Additionally, rather than memorizing certain forgery traces, SAFIRE\nnaturally focuses on uniform characteristics within each source region. This\napproach leads to more stable and effective learning, achieving superior\nperformance in both the new task and the traditional binary forgery\nlocalization.\n","authors":["Myung-Joon Kwon","Wonjun Lee","Seung-Hun Nam","Minji Son","Changick Kim"],"pdf_url":"https://arxiv.org/pdf/2412.08197v1.pdf","comment":"Accepted at AAAI 2025. Code is available at:\n  https://github.com/mjkwon2021/SAFIRE"},{"id":"http://arxiv.org/abs/2412.08195v1","updated":"2024-12-11T08:36:36Z","published":"2024-12-11T08:36:36Z","title":"Semantic Scene Completion Based 3D Traversability Estimation for\n  Off-Road Terrains","summary":"  Off-road environments present significant challenges for autonomous ground\nvehicles due to the absence of structured roads and the presence of complex\nobstacles, such as uneven terrain, vegetation, and occlusions. Traditional\nperception algorithms, designed primarily for structured environments, often\nfail under these conditions, leading to inaccurate traversability estimations.\nIn this paper, ORDformer, a novel multimodal method that combines LiDAR point\nclouds with monocular images, is proposed to generate dense traversable\noccupancy predictions from a forward-facing perspective. By integrating\nmultimodal data, environmental feature extraction is enhanced, which is crucial\nfor accurate occupancy estimation in complex terrains. Furthermore, RELLIS-OCC,\na dataset with 3D traversable occupancy annotations, is introduced,\nincorporating geometric features such as step height, slope, and unevenness.\nThrough a comprehensive analysis of vehicle obstacle-crossing conditions and\nthe incorporation of vehicle body structure constraints, four traversability\ncost labels are generated: lethal, medium-cost, low-cost, and free.\nExperimental results demonstrate that ORDformer outperforms existing approaches\nin 3D traversable area recognition, particularly in off-road environments with\nirregular geometries and partial occlusions. Specifically, ORDformer achieves\nover a 20\\% improvement in scene completion IoU compared to other models. The\nproposed framework is scalable and adaptable to various vehicle platforms,\nallowing for adjustments to occupancy grid parameters and the integration of\nadvanced dynamic models for traversability cost estimation.\n","authors":["Zitong Chen","Chao Sun","Shida Nie","Chen Min","Changjiu Ning","Haoyu Li","Bo Wang"],"pdf_url":"https://arxiv.org/pdf/2412.08195v1.pdf","comment":"12 pages,14 figures"},{"id":"http://arxiv.org/abs/2412.01849v2","updated":"2024-12-11T08:28:37Z","published":"2024-11-28T06:09:12Z","title":"Towards Data-centric Machine Learning on Directed Graphs: a Survey","summary":"  In recent years, Graph Neural Networks (GNNs) have made significant advances\nin processing structured data. However, most of them primarily adopted a\nmodel-centric approach, which simplifies graphs by converting them into\nundirected formats and emphasizes model designs. This approach is inherently\nlimited in real-world applications due to the unavoidable information loss in\nsimple undirected graphs and the model optimization challenges that arise when\nexceeding the upper bounds of this sub-optimal data representational capacity.\nAs a result, there has been a shift toward data-centric methods that prioritize\nimproving graph quality and representation. Specifically, various types of\ngraphs can be derived from naturally structured data, including heterogeneous\ngraphs, hypergraphs, and directed graphs. Among these, directed graphs offer\ndistinct advantages in topological systems by modeling causal relationships,\nand directed GNNs have been extensively studied in recent years. However, a\ncomprehensive survey of this emerging topic is still lacking. Therefore, we aim\nto provide a comprehensive review of directed graph learning, with a particular\nfocus on a data-centric perspective. Specifically, we first introduce a novel\ntaxonomy for existing studies. Subsequently, we re-examine these methods from\nthe data-centric perspective, with an emphasis on understanding and improving\ndata representation. It demonstrates that a deep understanding of directed\ngraphs and their quality plays a crucial role in model performance.\nAdditionally, we explore the diverse applications of directed GNNs across 10+\ndomains, highlighting their broad applicability. Finally, we identify key\nopportunities and challenges within the field, offering insights that can guide\nfuture research and development in directed graph learning.\n","authors":["Henan Sun","Xunkai Li","Daohan Su","Junyi Han","Rong-Hua Li","Guoren Wang"],"pdf_url":"https://arxiv.org/pdf/2412.01849v2.pdf","comment":"In Progress"},{"id":"http://arxiv.org/abs/2412.08187v1","updated":"2024-12-11T08:27:25Z","published":"2024-12-11T08:27:25Z","title":"From communities to interpretable network and word embedding: an unified\n  approach","summary":"  Modelling information from complex systems such as humans social interaction\nor words co-occurrences in our languages can help to understand how these\nsystems are organized and function. Such systems can be modelled by networks,\nand network theory provides a useful set of methods to analyze them. Among\nthese methods, graph embedding is a powerful tool to summarize the interactions\nand topology of a network in a vectorized feature space. When used in input of\nmachine learning algorithms, embedding vectors help with common graph problems\nsuch as link prediction, graph matching, etc. Word embedding has the goal of\nrepresenting the sense of words, extracting it from large text corpora. Despite\ndifferences in the structure of information in input of embedding algorithms,\nmany graph embedding approaches are adapted and inspired from methods in NLP.\nLimits of these methods are observed in both domains. Most of these methods\nrequire long and resource greedy training. Another downside to most methods is\nthat they are black-box, from which understanding how the information is\nstructured is rather complex. Interpretability of a model allows understanding\nhow the vector space is structured without the need for external information,\nand thus can be audited more easily. With both these limitations in mind, we\npropose a novel framework to efficiently embed network vertices in an\ninterpretable vector space. Our Lower Dimension Bipartite Framework (LDBGF)\nleverages the bipartite projection of a network using cliques to reduce\ndimensionality. Along with LDBGF, we introduce two implementations of this\nframework that rely on communities instead of cliques: SINr-NR and SINr-MF. We\nshow that SINr-MF can perform well on classical graphs and SINr-NR can produce\nhigh-quality graph and word embeddings that are interpretable and stable across\nruns.\n","authors":["Thibault Prouteau","Nicolas Dugué","Simon Guillot"],"pdf_url":"https://arxiv.org/pdf/2412.08187v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08186v1","updated":"2024-12-11T08:24:38Z","published":"2024-12-11T08:24:38Z","title":"Towards Automated Algebraic Multigrid Preconditioner Design Using\n  Genetic Programming for Large-Scale Laser Beam Welding Simulations","summary":"  Multigrid methods are asymptotically optimal algorithms ideal for large-scale\nsimulations. But, they require making numerous algorithmic choices that\nsignificantly influence their efficiency. Unlike recent approaches that learn\noptimal multigrid components using machine learning techniques, we adopt a\ncomplementary strategy here, employing evolutionary algorithms to construct\nefficient multigrid cycles from available individual components. This\ntechnology is applied to finite element simulations of the laser beam welding\nprocess. The thermo-elastic behavior is described by a coupled system of\ntime-dependent thermo-elasticity equations, leading to nonlinear and\nill-conditioned systems. The nonlinearity is addressed using Newton's method,\nand iterative solvers are accelerated with an algebraic multigrid (AMG)\npreconditioner using hypre BoomerAMG interfaced via PETSc. This is applied as a\nmonolithic solver for the coupled equations. To further enhance solver\nefficiency, flexible AMG cycles are introduced, extending traditional cycle\ntypes with level-specific smoothing sequences and non-recursive cycling\npatterns. These are automatically generated using genetic programming, guided\nby a context-free grammar containing AMG rules. Numerical experiments\ndemonstrate the potential of these approaches to improve solver performance in\nlarge-scale laser beam welding simulations.\n","authors":["Dinesh Parthasarathy","Tommaso Bevilacqua","Martin Lanser","Axel Klawonn","Harald Köstler"],"pdf_url":"https://arxiv.org/pdf/2412.08186v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08179v1","updated":"2024-12-11T08:09:42Z","published":"2024-12-11T08:09:42Z","title":"Auto-Generating Earnings Report Analysis via a Financial-Augmented LLM","summary":"  Financial analysis heavily relies on the evaluation of earnings reports to\ngain insights into company performance. Traditional generation of these reports\nrequires extensive financial expertise and is time-consuming. With the\nimpressive progress in Large Language Models (LLMs), a wide variety of\nfinancially focused LLMs has emerged, addressing tasks like sentiment analysis\nand entity recognition in the financial domain. This paper presents a novel\nchallenge: developing an LLM specifically for automating the generation of\nearnings reports analysis. Our methodology involves an in-depth analysis of\nexisting earnings reports followed by a unique approach to fine-tune an LLM for\nthis purpose. This approach combines retrieval augmentation and the generation\nof instruction-based data, specifically tailored for the financial sector, to\nenhance the LLM's performance. With extensive financial documents, we construct\nfinancial instruction data, enabling the refined adaptation of our LLM to\nfinancial contexts. Preliminary results indicate that our augmented LLM\noutperforms general open-source models and rivals commercial counterparts like\nGPT-3.5 in financial applications. Our research paves the way for streamlined\nand insightful automation in financial report generation, marking a significant\nstride in the field of financial analysis.\n","authors":["Van-Duc Le"],"pdf_url":"https://arxiv.org/pdf/2412.08179v1.pdf","comment":"8 pages, 1 figure, 4 tables"},{"id":"http://arxiv.org/abs/2405.11464v3","updated":"2024-12-11T08:03:56Z","published":"2024-05-19T06:43:12Z","title":"Efficient Prompt Tuning by Multi-Space Projection and Prompt Fusion","summary":"  Prompt tuning is a promising method to fine-tune a pre-trained language model\nwithout retraining its large-scale parameters. Instead, it attaches a soft\nprompt to the input text, whereby downstream tasks can be well adapted by\nmerely learning the embeddings of prompt tokens. Nevertheless, existing methods\nstill suffer from two challenges: (i) they are hard to balance accuracy and\nefficiency. A longer (shorter) soft prompt generally leads to a better(worse)\naccuracy but at the cost of more (less) training time. (ii)The performance may\nnot be consistent when adapting to different downstream tasks. We attribute it\nto the same embedding space but responsible for different requirements of\ndownstream tasks. To address these issues, we propose an Efficient Prompt\nTuning method (EPT) by multi-space projection and prompt fusion. Specifically,\nit decomposes a given soft prompt into a shorter prompt and two low-rank\nmatrices, significantly reducing the training time. Accuracy is also enhanced\nby leveraging low-rank matrices and the short prompt as additional knowledge\nsources to enrich the semantics of the original short prompt. In addition, we\nproject the soft prompt into multiple subspaces to improve the performance\nconsistency, and then adaptively learn the combination weights of different\nspaces through a gating network. Experiments on 13 natural language processing\ndownstream tasks show that our method significantly and consistently\noutperforms 11 comparison methods with the relative percentage of improvements\nup to 12.9%, and training time decreased by 14%.\n","authors":["Pengxiang Lan","Enneng Yang","Yuting Liu","Guibing Guo","Jianzhe Zhao","Xingwei Wang"],"pdf_url":"https://arxiv.org/pdf/2405.11464v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08174v1","updated":"2024-12-11T08:03:35Z","published":"2024-12-11T08:03:35Z","title":"Can Graph Neural Networks Learn Language with Extremely Weak Text\n  Supervision?","summary":"  While great success has been achieved in building vision models with\nContrastive Language-Image Pre-training (CLIP) over Internet-scale image-text\npairs, building transferable Graph Neural Networks (GNNs) with CLIP pipeline is\nchallenging because of three fundamental issues: the scarcity of labeled data\nand text supervision, different levels of downstream tasks, and the conceptual\ngaps between domains. In this work, to address these issues, we leverage\nmulti-modal prompt learning to effectively adapt pre-trained GNN to downstream\ntasks and data, given only a few semantically labeled samples, each with\nextremely weak text supervision. Our new paradigm embeds the graphs directly in\nthe same space as the Large Language Models (LLMs) by learning both graph\nprompts and text prompts simultaneously. To accomplish this, we improve\nstate-of-the-art graph prompt method, and then propose the first graph-language\nmulti-modal prompt learning approach for exploiting the knowledge in\npre-trained models. Notably, due to the insufficient supervision for\nfine-tuning, in our paradigm, the pre-trained GNN and the LLM are kept frozen,\nso the learnable parameters are much fewer than fine-tuning any pre-trained\nmodel. Through extensive experiments on real-world datasets, we demonstrate the\nsuperior performance of our paradigm in few-shot, multi-task-level, and\ncross-domain settings. Moreover, we build the first CLIP-style zero-shot\nclassification prototype that can generalize GNNs to unseen classes with\nextremely weak text supervision.\n","authors":["Zihao Li","Lecheng Zheng","Bowen Jin","Dongqi Fu","Baoyu Jing","Yikun Ban","Jingrui He","Jiawei Han"],"pdf_url":"https://arxiv.org/pdf/2412.08174v1.pdf","comment":"Preprint, 26 pages"},{"id":"http://arxiv.org/abs/2210.04398v2","updated":"2024-12-11T07:58:21Z","published":"2022-10-10T02:07:32Z","title":"Scaling Up Probabilistic Circuits by Latent Variable Distillation","summary":"  Probabilistic Circuits (PCs) are a unified framework for tractable\nprobabilistic models that support efficient computation of various\nprobabilistic queries (e.g., marginal probabilities). One key challenge is to\nscale PCs to model large and high-dimensional real-world datasets: we observe\nthat as the number of parameters in PCs increases, their performance\nimmediately plateaus. This phenomenon suggests that the existing optimizers\nfail to exploit the full expressive power of large PCs. We propose to overcome\nsuch bottleneck by latent variable distillation: we leverage the less tractable\nbut more expressive deep generative models to provide extra supervision over\nthe latent variables of PCs. Specifically, we extract information from\nTransformer-based generative models to assign values to latent variables of\nPCs, providing guidance to PC optimizers. Experiments on both image and\nlanguage modeling benchmarks (e.g., ImageNet and WikiText-2) show that latent\nvariable distillation substantially boosts the performance of large PCs\ncompared to their counterparts without latent variable distillation. In\nparticular, on the image modeling benchmarks, PCs achieve competitive\nperformance against some of the widely-used deep generative models, including\nvariational autoencoders and flow-based models, opening up new avenues for\ntractable generative modeling. Our code can be found at\nhttps://github.com/UCLA-StarAI/LVD.\n","authors":["Anji Liu","Honghua Zhang","Guy Van den Broeck"],"pdf_url":"https://arxiv.org/pdf/2210.04398v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.19370v4","updated":"2024-12-11T07:53:57Z","published":"2024-06-27T17:50:05Z","title":"Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept\n  Space","summary":"  Modern generative models demonstrate impressive capabilities, likely stemming\nfrom an ability to identify and manipulate abstract concepts underlying their\ntraining data. However, fundamental questions remain: what determines the\nconcepts a model learns, the order in which it learns them, and its ability to\nmanipulate those concepts? To address these questions, we propose analyzing a\nmodel's learning dynamics via a framework we call the concept space, where each\naxis represents an independent concept underlying the data generating process.\nBy characterizing learning dynamics in this space, we identify how the speed at\nwhich a concept is learned, and hence the order of concept learning, is\ncontrolled by properties of the data we term concept signal. Further, we\nobserve moments of sudden turns in the direction of a model's learning dynamics\nin concept space. Surprisingly, these points precisely correspond to the\nemergence of hidden capabilities, i.e., where latent interventions show the\nmodel possesses the capability to manipulate a concept, but these capabilities\ncannot yet be elicited via naive input prompting. While our results focus on\nsynthetically defined toy datasets, we hypothesize a general claim on emergence\nof hidden capabilities may hold: generative models possess latent capabilities\nthat emerge suddenly and consistently during training, though a model might not\nexhibit these capabilities under naive input prompting.\n","authors":["Core Francisco Park","Maya Okawa","Andrew Lee","Hidenori Tanaka","Ekdeep Singh Lubana"],"pdf_url":"https://arxiv.org/pdf/2406.19370v4.pdf","comment":"NeurIPS 2024 (Spotlight)"},{"id":"http://arxiv.org/abs/2412.06394v2","updated":"2024-12-11T07:52:06Z","published":"2024-12-09T11:22:59Z","title":"GameArena: Evaluating LLM Reasoning through Live Computer Games","summary":"  Evaluating the reasoning abilities of large language models (LLMs) is\nchallenging. Existing benchmarks often depend on static datasets, which are\nvulnerable to data contamination and may get saturated over time, or on binary\nlive human feedback that conflates reasoning with other abilities. As the most\nprominent dynamic benchmark, Chatbot Arena evaluates open-ended questions in\nreal-world settings, but lacks the granularity in assessing specific reasoning\ncapabilities. We introduce GameArena, a dynamic benchmark designed to evaluate\nLLM reasoning capabilities through interactive gameplay with humans. GameArena\nconsists of three games designed to test specific reasoning capabilities (e.g.,\ndeductive and inductive reasoning), while keeping participants entertained and\nengaged. We analyze the gaming data retrospectively to uncover the underlying\nreasoning processes of LLMs and measure their fine-grained reasoning\ncapabilities. We collect over 2000 game sessions and provide detailed\nassessments of various reasoning capabilities for five state-of-the-art LLMs.\nOur user study with 100 participants suggests that GameArena improves user\nengagement compared to Chatbot Arena. For the first time, GameArena enables the\ncollection of step-by-step LLM reasoning data in the wild.\n","authors":["Lanxiang Hu","Qiyu Li","Anze Xie","Nan Jiang","Ion Stoica","Haojian Jin","Hao Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.06394v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13190v2","updated":"2024-12-11T07:25:40Z","published":"2024-10-17T03:36:18Z","title":"CohEx: A Generalized Framework for Cohort Explanation","summary":"  eXplainable Artificial Intelligence (XAI) has garnered significant attention\nfor enhancing transparency and trust in machine learning models. However, the\nscopes of most existing explanation techniques focus either on offering a\nholistic view of the explainee model (global explanation) or on individual\ninstances (local explanation), while the middle ground, i.e., cohort-based\nexplanation, is less explored. Cohort explanations offer insights into the\nexplainee's behavior on a specific group or cohort of instances, enabling a\ndeeper understanding of model decisions within a defined context. In this\npaper, we discuss the unique challenges and opportunities associated with\nmeasuring cohort explanations, define their desired properties, and create a\ngeneralized framework for generating cohort explanations based on supervised\nclustering.\n","authors":["Fanyu Meng","Xin Liu","Zhaodan Kong","Xin Chen"],"pdf_url":"https://arxiv.org/pdf/2410.13190v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08156v1","updated":"2024-12-11T07:22:51Z","published":"2024-12-11T07:22:51Z","title":"Antelope: Potent and Concealed Jailbreak Attack Strategy","summary":"  Due to the remarkable generative potential of diffusion-based models,\nnumerous researches have investigated jailbreak attacks targeting these\nframeworks. A particularly concerning threat within image models is the\ngeneration of Not-Safe-for-Work (NSFW) content. Despite the implementation of\nsecurity filters, numerous efforts continue to explore ways to circumvent these\nsafeguards. Current attack methodologies primarily encompass adversarial prompt\nengineering or concept obfuscation, yet they frequently suffer from slow search\nefficiency, conspicuous attack characteristics and poor alignment with targets.\nTo overcome these challenges, we propose Antelope, a more robust and covert\njailbreak attack strategy designed to expose security vulnerabilities inherent\nin generative models. Specifically, Antelope leverages the confusion of\nsensitive concepts with similar ones, facilitates searches in the semantically\nadjacent space of these related concepts and aligns them with the target\nimagery, thereby generating sensitive images that are consistent with the\ntarget and capable of evading detection. Besides, we successfully exploit the\ntransferability of model-based attacks to penetrate online black-box services.\nExperimental evaluations demonstrate that Antelope outperforms existing\nbaselines across multiple defensive mechanisms, underscoring its efficacy and\nversatility.\n","authors":["Xin Zhao","Xiaojun Chen","Haoyu Gao"],"pdf_url":"https://arxiv.org/pdf/2412.08156v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08148v1","updated":"2024-12-11T07:06:53Z","published":"2024-12-11T07:06:53Z","title":"A Review of Intelligent Device Fault Diagnosis Technologies Based on\n  Machine Vision","summary":"  This paper provides a comprehensive review of mechanical equipment fault\ndiagnosis methods, focusing on the advancements brought by Transformer-based\nmodels. It details the structure, working principles, and benefits of\nTransformers, particularly their self-attention mechanism and parallel\ncomputation capabilities, which have propelled their widespread application in\nnatural language processing and computer vision. The discussion highlights key\nTransformer model variants, such as Vision Transformers (ViT) and their\nextensions, which leverage self-attention to improve accuracy and efficiency in\nvisual tasks. Furthermore, the paper examines the application of\nTransformer-based approaches in intelligent fault diagnosis for mechanical\nsystems, showcasing their superior ability to extract and recognize patterns\nfrom complex sensor data for precise fault identification. Despite these\nadvancements, challenges remain, including the reliance on extensive labeled\ndatasets, significant computational demands, and difficulties in deploying\nmodels on resource-limited devices. To address these limitations, the paper\nproposes future research directions, such as developing lightweight Transformer\narchitectures, integrating multimodal data sources, and enhancing adaptability\nto diverse operational conditions. These efforts aim to further expand the\napplication of Transformer-based methods in mechanical fault diagnosis, making\nthem more robust, efficient, and suitable for real-world industrial\nenvironments.\n","authors":["Guiran Liu","Binrong Zhu"],"pdf_url":"https://arxiv.org/pdf/2412.08148v1.pdf","comment":"9 pages, This paper has been accepted for publication at RICAI 2024"},{"id":"http://arxiv.org/abs/2412.08147v1","updated":"2024-12-11T07:06:36Z","published":"2024-12-11T07:06:36Z","title":"How to Weight Multitask Finetuning? Fast Previews via Bayesian\n  Model-Merging","summary":"  When finetuning multiple tasks altogether, it is important to carefully weigh\nthem to get a good performance, but searching for good weights can be difficult\nand costly. Here, we propose to aid the search with fast previews to quickly\nget a rough idea of different reweighting options. We use model merging to\ncreate previews by simply reusing and averaging parameters of models trained on\neach task separately (no retraining required). To improve the quality of\npreviews, we propose a Bayesian approach to design new merging strategies by\nusing more flexible posteriors. We validate our findings on vision and\nnatural-language transformers. Our work shows the benefits of model merging via\nBayes to improve multitask finetuning.\n","authors":["Hugo Monzón Maldonado","Thomas Möllenhoff","Nico Daheim","Iryna Gurevych","Mohammad Emtiyaz Khan"],"pdf_url":"https://arxiv.org/pdf/2412.08147v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08145v1","updated":"2024-12-11T07:05:24Z","published":"2024-12-11T07:05:24Z","title":"A Survey on Private Transformer Inference","summary":"  Transformer models have revolutionized AI, enabling applications like content\ngeneration and sentiment analysis. However, their use in Machine Learning as a\nService (MLaaS) raises significant privacy concerns, as centralized servers\nprocess sensitive user data. Private Transformer Inference (PTI) addresses\nthese issues using cryptographic techniques such as Secure Multi-Party\nComputation (MPC) and Homomorphic Encryption (HE), enabling secure model\ninference without exposing inputs or models. This paper reviews recent\nadvancements in PTI, analyzing state-of-the-art solutions, their challenges,\nand potential improvements. We also propose evaluation guidelines to assess\nresource efficiency and privacy guarantees, aiming to bridge the gap between\nhigh-performance inference and data privacy.\n","authors":["Yang Li","Xinyu Zhou","Yitong Wang","Liangxin Qian","Jun Zhao"],"pdf_url":"https://arxiv.org/pdf/2412.08145v1.pdf","comment":"The manuscript is still being revised and will be continuously\n  updated in the future"},{"id":"http://arxiv.org/abs/2412.06853v2","updated":"2024-12-11T07:04:52Z","published":"2024-12-08T15:17:53Z","title":"Tube Loss: A Novel Approach for Prediction Interval Estimation and\n  probabilistic forecasting","summary":"  This paper proposes a novel loss function, called 'Tube Loss', for\nsimultaneous estimation of bounds of a Prediction Interval (PI) in the\nregression setup, and also for generating probabilistic forecasts from time\nseries data solving a single optimization problem. The PIs obtained by\nminimizing the empirical risk based on the Tube Loss are shown to be of better\nquality than the PIs obtained by the existing methods in the following sense.\nFirst, it yields intervals that attain the prespecified confidence level $t\n\\in(0,1)$ asymptotically. A theoretical proof of this fact is given. Secondly,\nthe user is allowed to move the interval up or down by controlling the value of\na parameter. This helps the user to choose a PI capturing denser regions of the\nprobability distribution of the response variable inside the interval, and\nthus, sharpening its width. This is shown to be especially useful when the\nconditional distribution of the response variable is skewed. Further, the Tube\nLoss based PI estimation method can trade-off between the coverage and the\naverage width by solving a single optimization problem. It enables further\nreduction of the average width of PI through re-calibration. Also, unlike a few\nexisting PI estimation methods the gradient descent (GD) method can be used for\nminimization of empirical risk. Finally, through extensive experimentation, we\nhave shown the efficacy of the Tube Loss based PI estimation in kernel\nmachines, neural networks and deep networks and also for probabilistic\nforecasting tasks. The codes of the experiments are available at\nhttps://github.com/ltpritamanand/Tube_loss\n","authors":["Pritam Anand","Tathagata Bandyopadhyay","Suresh Chandra"],"pdf_url":"https://arxiv.org/pdf/2412.06853v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08144v1","updated":"2024-12-11T07:04:35Z","published":"2024-12-11T07:04:35Z","title":"AGMixup: Adaptive Graph Mixup for Semi-supervised Node Classification","summary":"  Mixup is a data augmentation technique that enhances model generalization by\ninterpolating between data points using a mixing ratio $\\lambda$ in the image\ndomain. Recently, the concept of mixup has been adapted to the graph domain\nthrough node-centric interpolations. However, these approaches often fail to\naddress the complexity of interconnected relationships, potentially damaging\nthe graph's natural topology and undermining node interactions. Furthermore,\ncurrent graph mixup methods employ a one-size-fits-all strategy with a randomly\nsampled $\\lambda$ for all mixup pairs, ignoring the diverse needs of different\npairs. This paper proposes an Adaptive Graph Mixup (AGMixup) framework for\nsemi-supervised node classification. AGMixup introduces a subgraph-centric\napproach, which treats each subgraph similarly to how images are handled in\nEuclidean domains, thus facilitating a more natural integration of mixup into\ngraph-based learning. We also propose an adaptive mechanism to tune the mixing\nratio $\\lambda$ for diverse mixup pairs, guided by the contextual similarity\nand uncertainty of the involved subgraphs. Extensive experiments across seven\ndatasets on semi-supervised node classification benchmarks demonstrate\nAGMixup's superiority over state-of-the-art graph mixup methods. Source codes\nare available at \\url{https://github.com/WeigangLu/AGMixup}.\n","authors":["Weigang Lu","Ziyu Guan","Wei Zhao","Yaming Yang","Yibing Zhan","Yiheng Lu","Dapeng Tao"],"pdf_url":"https://arxiv.org/pdf/2412.08144v1.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2412.08139v1","updated":"2024-12-11T06:54:39Z","published":"2024-12-11T06:54:39Z","title":"Wasserstein Distance Rivals Kullback-Leibler Divergence for Knowledge\n  Distillation","summary":"  Since pioneering work of Hinton et al., knowledge distillation based on\nKullback-Leibler Divergence (KL-Div) has been predominant, and recently its\nvariants have achieved compelling performance. However, KL-Div only compares\nprobabilities of the corresponding category between the teacher and student\nwhile lacking a mechanism for cross-category comparison. Besides, KL-Div is\nproblematic when applied to intermediate layers, as it cannot handle\nnon-overlapping distributions and is unaware of geometry of the underlying\nmanifold. To address these downsides, we propose a methodology of Wasserstein\nDistance (WD) based knowledge distillation. Specifically, we propose a logit\ndistillation method called WKD-L based on discrete WD, which performs\ncross-category comparison of probabilities and thus can explicitly leverage\nrich interrelations among categories. Moreover, we introduce a feature\ndistillation method called WKD-F, which uses a parametric method for modeling\nfeature distributions and adopts continuous WD for transferring knowledge from\nintermediate layers. Comprehensive evaluations on image classification and\nobject detection have shown (1) for logit distillation WKD-L outperforms very\nstrong KL-Div variants; (2) for feature distillation WKD-F is superior to the\nKL-Div counterparts and state-of-the-art competitors. The source code is\navailable at https://peihuali.org/WKD\n","authors":["Jiaming Lv","Haoyuan Yang","Peihua Li"],"pdf_url":"https://arxiv.org/pdf/2412.08139v1.pdf","comment":"Accepted to NeurIPS 2024. Equal contribution from first two authors"},{"id":"http://arxiv.org/abs/2412.08138v1","updated":"2024-12-11T06:51:45Z","published":"2024-12-11T06:51:45Z","title":"Learn How to Query from Unlabeled Data Streams in Federated Learning","summary":"  Federated learning (FL) enables collaborative learning among decentralized\nclients while safeguarding the privacy of their local data. Existing studies on\nFL typically assume offline labeled data available at each client when the\ntraining starts. Nevertheless, the training data in practice often arrive at\nclients in a streaming fashion without ground-truth labels. Given the expensive\nannotation cost, it is critical to identify a subset of informative samples for\nlabeling on clients. However, selecting samples locally while accommodating the\nglobal training objective presents a challenge unique to FL. In this work, we\ntackle this conundrum by framing the data querying process in FL as a\ncollaborative decentralized decision-making problem and proposing an effective\nsolution named LeaDQ, which leverages multi-agent reinforcement learning\nalgorithms. In particular, under the implicit guidance from global information,\nLeaDQ effectively learns the local policies for distributed clients and steers\nthem towards selecting samples that can enhance the global model's accuracy.\nExtensive simulations on image and text tasks show that LeaDQ advances the\nmodel performance in various FL scenarios, outperforming the benchmarking\nalgorithms.\n","authors":["Yuchang Sun","Xinran Li","Tao Lin","Jun Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.08138v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08133v1","updated":"2024-12-11T06:41:51Z","published":"2024-12-11T06:41:51Z","title":"Intelligent Electric Power Steering: Artificial Intelligence Integration\n  Enhances Vehicle Safety and Performance","summary":"  Electric Power Steering (EPS) systems utilize electric motors to aid users in\nsteering their vehicles, which provide additional precise control and reduced\nenergy consumption compared to traditional hydraulic systems. EPS technology\nprovides safety,control and efficiency.. This paper explains the integration of\nArtificial Intelligence (AI) into Electric Power Steering (EPS) systems,\nfocusing on its role in enhancing the safety, and adaptability across diverse\ndriving conditions. We explore significant development in AI-driven EPS,\nincluding predictive control algorithms, adaptive torque management systems,\nand data-driven diagnostics. The paper presents case studies of AI applications\nin EPS, such as Lane centering control (LCC), Automated Parking Systems, and\nAutonomous Vehicle Steering, while considering the challenges, limitations, and\nfuture prospects of this technology. This article discusses current\ndevelopments in AI-driven EPS, emphasizing on the benefits of improved safety,\nadaptive control, and predictive maintenance. Challenges in integrating AI in\nEPS systems. This paper addresses cybersecurity risks, ethical concerns, and\ntechnical limitations,, along with next steps for research and implementation\nin autonomous, and connected vehicles.\n","authors":["Vikas Vyas","Sneha Sudhir Shetiya"],"pdf_url":"https://arxiv.org/pdf/2412.08133v1.pdf","comment":"IEEE Summit on Reliability, Availability and Serviceability, 2024"},{"id":"http://arxiv.org/abs/2412.08131v1","updated":"2024-12-11T06:36:55Z","published":"2024-12-11T06:36:55Z","title":"DiffRaman: A Conditional Latent Denoising Diffusion Probabilistic Model\n  for Bacterial Raman Spectroscopy Identification Under Limited Data Conditions","summary":"  Raman spectroscopy has attracted significant attention in various biochemical\ndetection fields, especially in the rapid identification of pathogenic\nbacteria. The integration of this technology with deep learning to facilitate\nautomated bacterial Raman spectroscopy diagnosis has emerged as a key focus in\nrecent research. However, the diagnostic performance of existing deep learning\nmethods largely depends on a sufficient dataset, and in scenarios where there\nis a limited availability of Raman spectroscopy data, it is inadequate to fully\noptimize the numerous parameters of deep neural networks. To address these\nchallenges, this paper proposes a data generation method utilizing deep\ngenerative models to expand the data volume and enhance the recognition\naccuracy of bacterial Raman spectra. Specifically, we introduce DiffRaman, a\nconditional latent denoising diffusion probability model for Raman spectra\ngeneration. Experimental results demonstrate that synthetic bacterial Raman\nspectra generated by DiffRaman can effectively emulate real experimental\nspectra, thereby enhancing the performance of diagnostic models, especially\nunder conditions of limited data. Furthermore, compared to existing generative\nmodels, the proposed DiffRaman offers improvements in both generation quality\nand computational efficiency. Our DiffRaman approach offers a well-suited\nsolution for automated bacteria Raman spectroscopy diagnosis in data-scarce\nscenarios, offering new insights into alleviating the labor of spectroscopic\nmeasurements and enhancing rare bacteria identification.\n","authors":["Haiming Yao","Wei Luo","Ang Gao","Tao Zhou","Xue Wang"],"pdf_url":"https://arxiv.org/pdf/2412.08131v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15658v2","updated":"2024-12-11T06:23:12Z","published":"2024-06-21T21:33:16Z","title":"TorchSpatial: A Location Encoding Framework and Benchmark for Spatial\n  Representation Learning","summary":"  Spatial representation learning (SRL) aims at learning general-purpose neural\nnetwork representations from various types of spatial data (e.g., points,\npolylines, polygons, networks, images, etc.) in their native formats. Learning\ngood spatial representations is a fundamental problem for various downstream\napplications such as species distribution modeling, weather forecasting,\ntrajectory generation, geographic question answering, etc. Even though SRL has\nbecome the foundation of almost all geospatial artificial intelligence (GeoAI)\nresearch, we have not yet seen significant efforts to develop an extensive deep\nlearning framework and benchmark to support SRL model development and\nevaluation. To fill this gap, we propose TorchSpatial, a learning framework and\nbenchmark for location (point) encoding, which is one of the most fundamental\ndata types of spatial representation learning. TorchSpatial contains three key\ncomponents: 1) a unified location encoding framework that consolidates 15\ncommonly recognized location encoders, ensuring scalability and reproducibility\nof the implementations; 2) the LocBench benchmark tasks encompassing 7\ngeo-aware image classification and 10 geo-aware image regression datasets; 3) a\ncomprehensive suite of evaluation metrics to quantify geo-aware models' overall\nperformance as well as their geographic bias, with a novel Geo-Bias Score\nmetric. Finally, we provide a detailed analysis and insights into the model\nperformance and geographic bias of different location encoders. We believe\nTorchSpatial will foster future advancement of spatial representation learning\nand spatial fairness in GeoAI research. The TorchSpatial model framework,\nLocBench, and Geo-Bias Score evaluation framework are available at\nhttps://github.com/seai-lab/TorchSpatial.\n","authors":["Nemin Wu","Qian Cao","Zhangyu Wang","Zeping Liu","Yanlin Qi","Jielu Zhang","Joshua Ni","Xiaobai Yao","Hongxu Ma","Lan Mu","Stefano Ermon","Tanuja Ganu","Akshay Nambi","Ni Lao","Gengchen Mai"],"pdf_url":"https://arxiv.org/pdf/2406.15658v2.pdf","comment":"10 pages, 2 figures. Accepted by NeurIPS 2024 Datasets and Benchmarks\n  Track"},{"id":"http://arxiv.org/abs/2412.08127v1","updated":"2024-12-11T06:22:44Z","published":"2024-12-11T06:22:44Z","title":"Evil twins are not that evil: Qualitative insights into\n  machine-generated prompts","summary":"  It has been widely observed that language models (LMs) respond in predictable\nways to algorithmically generated prompts that are seemingly unintelligible.\nThis is both a sign that we lack a full understanding of how LMs work, and a\npractical challenge, because opaqueness can be exploited for harmful uses of\nLMs, such as jailbreaking. We present the first thorough analysis of opaque\nmachine-generated prompts, or autoprompts, pertaining to 3 LMs of different\nsizes and families. We find that machine-generated prompts are characterized by\na last token that is often intelligible and strongly affects the generation. A\nsmall but consistent proportion of the previous tokens are fillers that\nprobably appear in the prompt as a by-product of the fact that the optimization\nprocess fixes the number of tokens. The remaining tokens tend to have at least\na loose semantic relation with the generation, although they do not engage in\nwell-formed syntactic relations with it. We find moreover that some of the\nablations we applied to machine-generated prompts can also be applied to\nnatural language sequences, leading to similar behavior, suggesting that\nautoprompts are a direct consequence of the way in which LMs process linguistic\ninputs in general.\n","authors":["Nathanaël Carraz Rakotonirina","Corentin Kervadec","Francesca Franzon","Marco Baroni"],"pdf_url":"https://arxiv.org/pdf/2412.08127v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.01039v2","updated":"2024-12-11T06:22:34Z","published":"2024-12-02T01:46:07Z","title":"Reducing Inference Energy Consumption Using Dual Complementary CNNs","summary":"  Energy efficiency of Convolutional Neural Networks (CNNs) has become an\nimportant area of research, with various strategies being developed to minimize\nthe power consumption of these models. Previous efforts, including techniques\nlike model pruning, quantization, and hardware optimization, have made\nsignificant strides in this direction. However, there remains a need for more\neffective on device AI solutions that balance energy efficiency with model\nperformance. In this paper, we propose a novel approach to reduce the energy\nrequirements of inference of CNNs. Our methodology employs two small\nComplementary CNNs that collaborate with each other by covering each other's\n\"weaknesses\" in predictions. If the confidence for a prediction of the first\nCNN is considered low, the second CNN is invoked with the aim of producing a\nhigher confidence prediction. This dual-CNN setup significantly reduces energy\nconsumption compared to using a single large deep CNN. Additionally, we propose\na memory component that retains previous classifications for identical inputs,\nbypassing the need to re-invoke the CNNs for the same input, further saving\nenergy. Our experiments on a Jetson Nano computer demonstrate an energy\nreduction of up to 85.8% achieved on modified datasets where each sample was\nduplicated once. These findings indicate that leveraging a complementary CNN\npair along with a memory component effectively reduces inference energy while\nmaintaining high accuracy.\n","authors":["Michail Kinnas","John Violos","Ioannis Kompatsiaris","Symeon Papadopoulos"],"pdf_url":"https://arxiv.org/pdf/2412.01039v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08120v1","updated":"2024-12-11T06:13:38Z","published":"2024-12-11T06:13:38Z","title":"Dense Depth from Event Focal Stack","summary":"  We propose a method for dense depth estimation from an event stream generated\nwhen sweeping the focal plane of the driving lens attached to an event camera.\nIn this method, a depth map is inferred from an ``event focal stack'' composed\nof the event stream using a convolutional neural network trained with\nsynthesized event focal stacks. The synthesized event stream is created from a\nfocal stack generated by Blender for any arbitrary 3D scene. This allows for\ntraining on scenes with diverse structures. Additionally, we explored methods\nto eliminate the domain gap between real event streams and synthetic event\nstreams. Our method demonstrates superior performance over a depth-from-defocus\nmethod in the image domain on synthetic and real datasets.\n","authors":["Kenta Horikawa","Mariko Isogawa","Hideo Saito","Shohei Mori"],"pdf_url":"https://arxiv.org/pdf/2412.08120v1.pdf","comment":"Accepted at WACV2025"},{"id":"http://arxiv.org/abs/2410.23748v2","updated":"2024-12-11T06:06:31Z","published":"2024-10-31T09:07:08Z","title":"Exploring Consistency in Graph Representations:from Graph Kernels to\n  Graph Neural Networks","summary":"  Graph Neural Networks (GNNs) have emerged as a dominant approach in graph\nrepresentation learning, yet they often struggle to capture consistent\nsimilarity relationships among graphs. While graph kernel methods such as the\nWeisfeiler-Lehman subtree (WL-subtree) and Weisfeiler-Lehman optimal assignment\n(WLOA) kernels are effective in capturing similarity relationships, they rely\nheavily on predefined kernels and lack sufficient non-linearity for more\ncomplex data patterns. Our work aims to bridge the gap between neural network\nmethods and kernel approaches by enabling GNNs to consistently capture\nrelational structures in their learned representations. Given the analogy\nbetween the message-passing process of GNNs and WL algorithms, we thoroughly\ncompare and analyze the properties of WL-subtree and WLOA kernels. We find that\nthe similarities captured by WLOA at different iterations are asymptotically\nconsistent, ensuring that similar graphs remain similar in subsequent\niterations, thereby leading to superior performance over the WL-subtree kernel.\nInspired by these findings, we conjecture that the consistency in the\nsimilarities of graph representations across GNN layers is crucial in capturing\nrelational structures and enhancing graph classification performance. Thus, we\npropose a loss to enforce the similarity of graph representations to be\nconsistent across different layers. Our empirical analysis verifies our\nconjecture and shows that our proposed consistency loss can significantly\nenhance graph classification performance across several GNN backbones on\nvarious datasets.\n","authors":["Xuyuan Liu","Yinghao Cai","Qihui Yang","Yujun Yan"],"pdf_url":"https://arxiv.org/pdf/2410.23748v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2407.00958v5","updated":"2024-12-11T06:01:38Z","published":"2024-07-01T04:29:35Z","title":"Dynamic Universal Approximation Theory: The Basic Theory for\n  Transformer-based Large Language Models","summary":"  Language models have emerged as a critical area of focus in artificial\nintelligence, particularly with the introduction of groundbreaking innovations\nlike ChatGPT. Large-scale Transformer networks have quickly become the leading\napproach for advancing natural language processing algorithms. Built on the\nTransformer architecture, these models enable interactions that closely mimic\nhuman communication and, equipped with extensive knowledge, can even assist in\nguiding human tasks. Despite their impressive capabilities and growing\ncomplexity, a key question remains-the theoretical foundations of large\nlanguage models (LLMs). What makes Transformer so effective for powering\nintelligent language applications, such as translation and coding? What\nunderlies LLMs' ability for In-Context Learning (ICL)? How does the LoRA scheme\nenhance the fine-tuning of LLMs? And what supports the practicality of pruning\nLLMs? To address these critical questions and explore the technological\nstrategies within LLMs, we leverage the Universal Approximation Theory (UAT) to\noffer a theoretical backdrop, shedding light on the mechanisms that underpin\nthese advancements.\n","authors":["Wei Wang","Qing Li"],"pdf_url":"https://arxiv.org/pdf/2407.00958v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08117v1","updated":"2024-12-11T05:55:06Z","published":"2024-12-11T05:55:06Z","title":"LatentSpeech: Latent Diffusion for Text-To-Speech Generation","summary":"  Diffusion-based Generative AI gains significant attention for its superior\nperformance over other generative techniques like Generative Adversarial\nNetworks and Variational Autoencoders. While it has achieved notable\nadvancements in fields such as computer vision and natural language processing,\ntheir application in speech generation remains under-explored. Mainstream\nText-to-Speech systems primarily map outputs to Mel-Spectrograms in the\nspectral space, leading to high computational loads due to the sparsity of\nMelSpecs. To address these limitations, we propose LatentSpeech, a novel TTS\ngeneration approach utilizing latent diffusion models. By using latent\nembeddings as the intermediate representation, LatentSpeech reduces the target\ndimension to 5% of what is required for MelSpecs, simplifying the processing\nfor the TTS encoder and vocoder and enabling efficient high-quality speech\ngeneration. This study marks the first integration of latent diffusion models\nin TTS, enhancing the accuracy and naturalness of generated speech.\nExperimental results on benchmark datasets demonstrate that LatentSpeech\nachieves a 25% improvement in Word Error Rate and a 24% improvement in Mel\nCepstral Distortion compared to existing models, with further improvements\nrising to 49.5% and 26%, respectively, with additional training data. These\nfindings highlight the potential of LatentSpeech to advance the\nstate-of-the-art in TTS technology\n","authors":["Haowei Lou","Helen Paik","Pari Delir Haghighi","Wen Hu","Lina Yao"],"pdf_url":"https://arxiv.org/pdf/2412.08117v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08112v1","updated":"2024-12-11T05:39:12Z","published":"2024-12-11T05:39:12Z","title":"Aligner-Guided Training Paradigm: Advancing Text-to-Speech Models with\n  Aligner Guided Duration","summary":"  Recent advancements in text-to-speech (TTS) systems, such as FastSpeech and\nStyleSpeech, have significantly improved speech generation quality. However,\nthese models often rely on duration generated by external tools like the\nMontreal Forced Aligner, which can be time-consuming and lack flexibility. The\nimportance of accurate duration is often underestimated, despite their crucial\nrole in achieving natural prosody and intelligibility. To address these\nlimitations, we propose a novel Aligner-Guided Training Paradigm that\nprioritizes accurate duration labelling by training an aligner before the TTS\nmodel. This approach reduces dependence on external tools and enhances\nalignment accuracy. We further explore the impact of different acoustic\nfeatures, including Mel-Spectrograms, MFCCs, and latent features, on TTS model\nperformance. Our experimental results show that aligner-guided duration\nlabelling can achieve up to a 16\\% improvement in word error rate and\nsignificantly enhance phoneme and tone alignment. These findings highlight the\neffectiveness of our approach in optimizing TTS systems for more natural and\nintelligible speech generation.\n","authors":["Haowei Lou","Helen Paik","Wen Hu","Lina Yao"],"pdf_url":"https://arxiv.org/pdf/2412.08112v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08109v1","updated":"2024-12-11T05:31:39Z","published":"2024-12-11T05:31:39Z","title":"Unseen Horizons: Unveiling the Real Capability of LLM Code Generation\n  Beyond the Familiar","summary":"  Recently, large language models (LLMs) have shown strong potential in code\ngeneration tasks. However, there are still gaps before they can be fully\napplied in actual software development processes. Accurately assessing the code\ngeneration capabilities of large language models has become an important basis\nfor evaluating and improving the models. Some existing works have constructed\ndatasets to evaluate the capabilities of these models. However, the current\nevaluation process may encounter the illusion of \"Specialist in Familiarity\",\nprimarily due to three gaps: the exposure of target code, case timeliness, and\ndependency availability. The fundamental reason for these gaps is that the code\nin current datasets may have been extensively exposed and exercised during the\ntraining phase, and due to the continuous training and development of LLM,\ntheir timeliness has been severely compromised. The key to solve the problem is\nto, as much as possible, evaluate the LLMs using code that they have not\nencountered before. Thus, the fundamental idea in this paper is to draw on the\nconcept of code obfuscation, changing code at different levels while ensuring\nthe functionality and output. To this end, we build a code-obfuscation based\nbenchmark OBFUSEVAL. We first collect 1,354 raw cases from five real-world\nprojects, including function description and code. Then we use three-level\nstrategy (symbol, structure and semantic) to obfuscate descriptions, code and\ncontext dependencies. We evaluate four LLMs on OBFU- SEVAL and compared the\neffectiveness of different obfuscation strategy. We use official test suites of\nthese projects to evaluate the generated code. The results show that after\nobfuscation, the average decrease ratio of test pass rate can up to 62.5%.\n","authors":["Yuanliang Zhang","Yifan Xie","Shanshan Li","Ke Liu","Chong Wang","Zhouyang Jia","Xiangbing Huang","Jie Song","Chaopeng Luo","Zhizheng Zheng","Rulin Xu","Yitong Liu","Si Zheng","Xiangke Liao"],"pdf_url":"https://arxiv.org/pdf/2412.08109v1.pdf","comment":"Large Language Model,Code Generation Capability,Code Dataset"},{"id":"http://arxiv.org/abs/2310.00385v2","updated":"2024-12-11T05:14:28Z","published":"2023-09-30T14:04:22Z","title":"Dynamic Demonstrations Controller for In-Context Learning","summary":"  In-context learning (ICL) is a new paradigm for natural language processing\n(NLP), where a large language model (LLM) observes a small number of\ndemonstrations and a test instance as its input, and directly makes predictions\nwithout updating model parameters. Previous studies have revealed that ICL is\nsensitive to the selection and the ordering of demonstrations. However, there\nare few studies regarding the impact of the demonstration number on the ICL\nperformance within a limited input length of LLM, because it is commonly\nbelieved that the number of demonstrations is positively correlated with model\nperformance. In this paper, we found this conclusion does not always hold true.\nThrough pilot experiments, we discover that increasing the number of\ndemonstrations does not necessarily lead to improved performance. Building upon\nthis insight, we propose a Dynamic Demonstrations Controller (D$^2$Controller),\nwhich can improve the ICL performance by adjusting the number of demonstrations\ndynamically. The experimental results show that D$^2$Controller yields a 4.6%\nrelative improvement on ten different sizes of LLMs across ten datasets.\nMoreover, we also extend our method to previous ICL models and achieve\ncompetitive results.\n","authors":["Fei Zhao","Taotian Pang","Zhen Wu","Zheng Ma","Shujian Huang","Xinyu Dai"],"pdf_url":"https://arxiv.org/pdf/2310.00385v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08099v1","updated":"2024-12-11T04:53:15Z","published":"2024-12-11T04:53:15Z","title":"Adversarial Vulnerabilities in Large Language Models for Time Series\n  Forecasting","summary":"  Large Language Models (LLMs) have recently demonstrated significant potential\nin the field of time series forecasting, offering impressive capabilities in\nhandling complex temporal data. However, their robustness and reliability in\nreal-world applications remain under-explored, particularly concerning their\nsusceptibility to adversarial attacks. In this paper, we introduce a targeted\nadversarial attack framework for LLM-based time series forecasting. By\nemploying both gradient-free and black-box optimization methods, we generate\nminimal yet highly effective perturbations that significantly degrade the\nforecasting accuracy across multiple datasets and LLM architectures. Our\nexperiments, which include models like TimeGPT and LLM-Time with GPT-3.5,\nGPT-4, LLaMa, and Mistral, show that adversarial attacks lead to much more\nsevere performance degradation than random noise, and demonstrate the broad\neffectiveness of our attacks across different LLMs. The results underscore the\ncritical vulnerabilities of LLMs in time series forecasting, highlighting the\nneed for robust defense mechanisms to ensure their reliable deployment in\npractical applications.\n","authors":["Fuqiang Liu","Sicong Jiang","Luis Miranda-Moreno","Seongjin Choi","Lijun Sun"],"pdf_url":"https://arxiv.org/pdf/2412.08099v1.pdf","comment":"11 pages, 5 figures"},{"id":"http://arxiv.org/abs/2412.08098v1","updated":"2024-12-11T04:52:41Z","published":"2024-12-11T04:52:41Z","title":"What You See Is Not Always What You Get: An Empirical Study of Code\n  Comprehension by Large Language Models","summary":"  Recent studies have demonstrated outstanding capabilities of large language\nmodels (LLMs) in software engineering domain, covering numerous tasks such as\ncode generation and comprehension. While the benefit of LLMs for coding task is\nwell noted, it is perceived that LLMs are vulnerable to adversarial attacks. In\nthis paper, we study the specific LLM vulnerability to imperceptible character\nattacks, a type of prompt-injection attack that uses special characters to\nbefuddle an LLM whilst keeping the attack hidden to human eyes. We devise four\ncategories of attacks and investigate their effects on the performance outcomes\nof tasks relating to code analysis and code comprehension. Two generations of\nChatGPT are included to evaluate the impact of advancements made to\ncontemporary models. Our experimental design consisted of comparing perturbed\nand unperturbed code snippets and evaluating two performance outcomes, which\nare model confidence using log probabilities of response, and correctness of\nresponse. We conclude that earlier version of ChatGPT exhibits a strong\nnegative linear correlation between the amount of perturbation and the\nperformance outcomes, while the recent ChatGPT presents a strong negative\ncorrelation between the presence of perturbation and performance outcomes, but\nno valid correlational relationship between perturbation budget and performance\noutcomes. We anticipate this work contributes to an in-depth understanding of\nleveraging LLMs for coding tasks. It is suggested future research should delve\ninto how to create LLMs that can return a correct response even if the prompt\nexhibits perturbations.\n","authors":["Bangshuo Zhu","Jiawen Wen","Huaming Chen"],"pdf_url":"https://arxiv.org/pdf/2412.08098v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.22870v2","updated":"2024-12-11T04:51:58Z","published":"2024-10-30T10:08:03Z","title":"Conditioned quantum-assisted deep generative surrogate for\n  particle-calorimeter interactions","summary":"  Particle collisions at accelerators such as the Large Hadron Collider,\nrecorded and analyzed by experiments such as ATLAS and CMS, enable exquisite\nmeasurements of the Standard Model and searches for new phenomena. Simulations\nof collision events at these detectors have played a pivotal role in shaping\nthe design of future experiments and analyzing ongoing ones. However, the quest\nfor accuracy in Large Hadron Collider (LHC) collisions comes at an imposing\ncomputational cost, with projections estimating the need for millions of\nCPU-years annually during the High Luminosity LHC (HL-LHC) run\n\\cite{collaboration2022atlas}. Simulating a single LHC event with\n\\textsc{Geant4} currently devours around 1000 CPU seconds, with simulations of\nthe calorimeter subdetectors in particular imposing substantial computational\ndemands \\cite{rousseau2023experimental}. To address this challenge, we propose\na conditioned quantum-assisted deep generative model. Our model integrates a\nconditioned variational autoencoder (VAE) on the exterior with a conditioned\nRestricted Boltzmann Machine (RBM) in the latent space, providing enhanced\nexpressiveness compared to conventional VAEs. The RBM nodes and connections are\nmeticulously engineered to enable the use of qubits and couplers on D-Wave's\nPegasus-structured \\textit{Advantage} quantum annealer (QA) for sampling. We\nintroduce a novel method for conditioning the quantum-assisted RBM using\n\\textit{flux biases}. We further propose a novel adaptive mapping to estimate\nthe effective inverse temperature in quantum annealers. The effectiveness of\nour framework is illustrated using Dataset 2 of the CaloChallenge\n\\cite{calochallenge}.\n","authors":["J. Quetzalcoatl Toledo-Marin","Sebastian Gonzalez","Hao Jia","Ian Lu","Deniz Sogutlu","Abhishek Abhishek","Colin Gay","Eric Paquet","Roger Melko","Geoffrey C. Fox","Maximilian Swiatlowski","Wojciech Fedorko"],"pdf_url":"https://arxiv.org/pdf/2410.22870v2.pdf","comment":"27 pages, 10 figures, 8 appendices"},{"id":"http://arxiv.org/abs/2409.13566v2","updated":"2024-12-11T04:40:00Z","published":"2024-09-20T15:07:14Z","title":"Deep Learning and Machine Learning, Advancing Big Data Analytics and\n  Management: Tensorflow Pretrained Models","summary":"  The application of TensorFlow pre-trained models in deep learning is\nexplored, with an emphasis on practical guidance for tasks such as image\nclassification and object detection. The study covers modern architectures,\nincluding ResNet, MobileNet, and EfficientNet, and demonstrates the\neffectiveness of transfer learning through real-world examples and experiments.\nA comparison of linear probing and model fine-tuning is presented, supplemented\nby visualizations using techniques like PCA, t-SNE, and UMAP, allowing for an\nintuitive understanding of the impact of these approaches. The work provides\ncomplete example code and step-by-step instructions, offering valuable insights\nfor both beginners and advanced users. By integrating theoretical concepts with\nhands-on practice, the paper equips readers with the tools necessary to address\ndeep learning challenges efficiently.\n","authors":["Keyu Chen","Ziqian Bi","Qian Niu","Junyu Liu","Benji Peng","Sen Zhang","Ming Liu","Ming Li","Xuanhe Pan","Jiawei Xu","Jinlang Wang","Pohsun Feng"],"pdf_url":"https://arxiv.org/pdf/2409.13566v2.pdf","comment":"This book contains 148 pages and 7 figures"},{"id":"http://arxiv.org/abs/2406.17840v2","updated":"2024-12-11T04:37:15Z","published":"2024-06-25T17:46:28Z","title":"Human-Object Interaction from Human-Level Instructions","summary":"  Intelligent agents must autonomously interact with the environments to\nperform daily tasks based on human-level instructions. They need a foundational\nunderstanding of the world to accurately interpret these instructions, along\nwith precise low-level movement and interaction skills to execute the derived\nactions. In this work, we propose the first complete system for synthesizing\nphysically plausible, long-horizon human-object interactions for object\nmanipulation in contextual environments, driven by human-level instructions. We\nleverage large language models (LLMs) to interpret the input instructions into\ndetailed execution plans. Unlike prior work, our system is capable of\ngenerating detailed finger-object interactions, in seamless coordination with\nfull-body movements. We also train a policy to track generated motions in\nphysics simulation via reinforcement learning (RL) to ensure physical\nplausibility of the motion. Our experiments demonstrate the effectiveness of\nour system in synthesizing realistic interactions with diverse objects in\ncomplex environments, highlighting its potential for real-world applications.\n","authors":["Zhen Wu","Jiaman Li","Pei Xu","C. Karen Liu"],"pdf_url":"https://arxiv.org/pdf/2406.17840v2.pdf","comment":"project page: https://hoifhli.github.io/"},{"id":"http://arxiv.org/abs/2412.08090v1","updated":"2024-12-11T04:16:39Z","published":"2024-12-11T04:16:39Z","title":"Multilingual LLMs Inherently Reward In-Language Time-Sensitive Semantic\n  Alignment for Low-Resource Languages","summary":"  The unwavering disparity in labeled resources between resource-rich languages\nand those considered low-resource remains a significant impediment for Large\nLanguage Models (LLMs). Recent strides in cross-lingual in-context learning\n(X-ICL), mainly through semantically aligned examples retrieved from\nmultilingual pre-trained transformers, have shown promise in mitigating this\nissue. However, our investigation reveals that LLMs intrinsically reward\nin-language semantically aligned cross-lingual instances over direct\ncross-lingual semantic alignments, with a pronounced disparity in handling\ntime-sensitive queries in the X-ICL setup. Such queries demand sound temporal\nreasoning ability from LLMs, yet the advancements have predominantly focused on\nEnglish. This study aims to bridge this gap by improving temporal reasoning\ncapabilities in low-resource languages. To this end, we introduce mTEMPREASON a\ntemporal reasoning dataset aimed at the varied degrees of low-resource\nlanguages and propose Cross-Lingual Time-Sensitive Semantic Alignment\n(CLiTSSA), a novel method to improve temporal reasoning in these contexts. To\nfacilitate this, we construct an extension of mTEMPREASON comprising pairs of\nparallel cross-language temporal queries along with their anticipated\nin-language semantic similarity scores. Our empirical evidence underscores the\nsuperior performance of CLiTSSA compared to established baselines across three\nlanguages - Romanian, German, and French, encompassing three temporal tasks and\nincluding a diverse set of four contemporaneous LLMs. This marks a significant\nstep forward in addressing resource disparity in the context of temporal\nreasoning across languages.\n","authors":["Ashutosh Bajpai","Tanmoy Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2412.08090v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.02387v6","updated":"2024-12-11T04:12:39Z","published":"2024-09-04T02:30:12Z","title":"Large Language Models and Cognitive Science: A Comprehensive Review of\n  Similarities, Differences, and Challenges","summary":"  This comprehensive review explores the intersection of Large Language Models\n(LLMs) and cognitive science, examining similarities and differences between\nLLMs and human cognitive processes. We analyze methods for evaluating LLMs\ncognitive abilities and discuss their potential as cognitive models. The review\ncovers applications of LLMs in various cognitive fields, highlighting insights\ngained for cognitive science research. We assess cognitive biases and\nlimitations of LLMs, along with proposed methods for improving their\nperformance. The integration of LLMs with cognitive architectures is examined,\nrevealing promising avenues for enhancing artificial intelligence (AI)\ncapabilities. Key challenges and future research directions are identified,\nemphasizing the need for continued refinement of LLMs to better align with\nhuman cognition. This review provides a balanced perspective on the current\nstate and future potential of LLMs in advancing our understanding of both\nartificial and human intelligence.\n","authors":["Qian Niu","Junyu Liu","Ziqian Bi","Pohsun Feng","Benji Peng","Keyu Chen","Ming Li","Lawrence KQ Yan","Yichao Zhang","Caitlyn Heqi Yin","Cheng Fei","Tianyang Wang","Yunze Wang","Silin Chen","Ming Liu"],"pdf_url":"https://arxiv.org/pdf/2409.02387v6.pdf","comment":"10 pages, 1 figure"},{"id":"http://arxiv.org/abs/2412.08085v1","updated":"2024-12-11T04:05:29Z","published":"2024-12-11T04:05:29Z","title":"Non-Myopic Multi-Objective Bayesian Optimization","summary":"  We consider the problem of finite-horizon sequential experimental design to\nsolve multi-objective optimization (MOO) of expensive black-box objective\nfunctions. This problem arises in many real-world applications, including\nmaterials design, where we have a small resource budget to make and evaluate\ncandidate materials in the lab. We solve this problem using the framework of\nBayesian optimization (BO) and propose the first set of non-myopic methods for\nMOO problems. Prior work on non-myopic BO for single-objective problems relies\non the Bellman optimality principle to handle the lookahead reasoning process.\nHowever, this principle does not hold for most MOO problems because the reward\nfunction needs to satisfy some conditions: scalar variable, monotonicity, and\nadditivity. We address this challenge by using hypervolume improvement (HVI) as\nour scalarization approach, which allows us to use a lower-bound on the Bellman\nequation to approximate the finite-horizon using a batch expected hypervolume\nimprovement (EHVI) acquisition function (AF) for MOO. Our formulation naturally\nallows us to use other improvement-based scalarizations and compare their\nefficacy to HVI. We derive three non-myopic AFs for MOBO: 1) the Nested AF,\nwhich is based on the exact computation of the lower bound, 2) the Joint AF,\nwhich is a lower bound on the nested AF, and 3) the BINOM AF, which is a fast\nand approximate variant based on batch multi-objective acquisition functions.\nOur experiments on multiple diverse real-world MO problems demonstrate that our\nnon-myopic AFs substantially improve performance over the existing myopic AFs\nfor MOBO.\n","authors":["Syrine Belakaria","Alaleh Ahmadianshalchi","Barbara Engelhardt","Stefano Ermon","Janardhan Rao Doppa"],"pdf_url":"https://arxiv.org/pdf/2412.08085v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08081v1","updated":"2024-12-11T03:59:05Z","published":"2024-12-11T03:59:05Z","title":"How to select slices for annotation to train best-performing deep\n  learning segmentation models for cross-sectional medical images?","summary":"  Automated segmentation of medical images highly depends on the availability\nof accurate manual image annotations. Such annotations are very time-consuming\nand costly to generate, and often require specialized expertise, particularly\nfor cross-sectional images which contain many slices for each patient. It is\ncrucial to ensure the best use of annotation resources. In this paper, we\nsystematically answer the question of how to select slices of cross-sectional\nmedical images in order to maximize performance of the resulting deep learning\nsegmentation models. We conducted experiments on 4 medical imaging segmentation\ntasks with varying annotation budgets, numbers of annotated cases, numbers of\nannotated slices per volume, slice selection techniques, and mask\ninterpolations. We found that:\n  1) It is almost always preferable to annotate fewer slices per volume and\nmore volumes given an annotation budget. 2) Selecting slices for annotation by\nunsupervised active learning (UAL) is not superior to selecting slices randomly\nor at fixed intervals, provided that each volume is allocated the same number\nof annotated slices. 3) Interpolating masks between annotated slices rarely\nenhances model performance, with exceptions of some specific configuration for\n3D models.\n","authors":["Yixin Zhang","Kevin Kramer","Maciej A. Mazurowski"],"pdf_url":"https://arxiv.org/pdf/2412.08081v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.02021v4","updated":"2024-12-11T03:37:28Z","published":"2023-12-04T16:46:38Z","title":"Strong but simple: A Baseline for Domain Generalized Dense Perception by\n  CLIP-based Transfer Learning","summary":"  Domain generalization (DG) remains a significant challenge for perception\nbased on deep neural networks (DNNs), where domain shifts occur due to\nsynthetic data, lighting, weather, or location changes. Vision-language models\n(VLMs) marked a large step for the generalization capabilities and have been\nalready applied to various tasks. Very recently, first approaches utilized VLMs\nfor domain generalized segmentation and object detection and obtained strong\ngeneralization. However, all these approaches rely on complex modules, feature\naugmentation frameworks or additional models. Surprisingly and in contrast to\nthat, we found that simple fine-tuning of vision-language pre-trained models\nyields competitive or even stronger generalization results while being\nextremely simple to apply. Moreover, we found that vision-language pre-training\nconsistently provides better generalization than the previous standard of\nvision-only pre-training. This challenges the standard of using ImageNet-based\ntransfer learning for domain generalization. Fully fine-tuning a\nvision-language pre-trained model is capable of reaching the domain\ngeneralization SOTA when training on the synthetic GTA5 dataset. Moreover, we\nconfirm this observation for object detection on a novel synthetic-to-real\nbenchmark. We further obtain superior generalization capabilities by reaching\n77.9% mIoU on the popular Cityscapes-to-ACDC benchmark. We also found improved\nin-domain generalization, leading to an improved SOTA of 86.4% mIoU on the\nCityscapes test set marking the first place on the leaderboard.\n","authors":["Christoph Hümmer","Manuel Schwonberg","Liangwei Zhou","Hu Cao","Alois Knoll","Hanno Gottschalk"],"pdf_url":"https://arxiv.org/pdf/2312.02021v4.pdf","comment":"Accepted to ACCV 2024; Project Page: https://vltseg.github.io/"},{"id":"http://arxiv.org/abs/2412.08072v1","updated":"2024-12-11T03:35:38Z","published":"2024-12-11T03:35:38Z","title":"Using Large Language Models for Parametric Shape Optimization","summary":"  Recent advanced large language models (LLMs) have showcased their emergent\ncapability of in-context learning, facilitating intelligent decision-making\nthrough natural language prompts without retraining. This new machine learning\nparadigm has shown promise in various fields, including general control and\noptimization problems. Inspired by these advancements, we explore the potential\nof LLMs for a specific and essential engineering task: parametric shape\noptimization (PSO). We develop an optimization framework, LLM-PSO, that\nleverages an LLM to determine the optimal shape of parameterized engineering\ndesigns in the spirit of evolutionary strategies. Utilizing the ``Claude 3.5\nSonnet'' LLM, we evaluate LLM-PSO on two benchmark flow optimization problems,\nspecifically aiming to identify drag-minimizing profiles for 1) a\ntwo-dimensional airfoil in laminar flow, and 2) a three-dimensional\naxisymmetric body in Stokes flow. In both cases, LLM-PSO successfully\nidentifies optimal shapes in agreement with benchmark solutions. Besides, it\ngenerally converges faster than other classical optimization algorithms. Our\npreliminary exploration may inspire further investigations into harnessing LLMs\nfor shape optimization and engineering design more broadly.\n","authors":["Xinxin Zhang","Zhuoqun Xu","Guangpu Zhu","Chien Ming Jonathan Tay","Yongdong Cui","Boo Cheong Khoo","Lailai Zhu"],"pdf_url":"https://arxiv.org/pdf/2412.08072v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08069v1","updated":"2024-12-11T03:31:36Z","published":"2024-12-11T03:31:36Z","title":"DialogAgent: An Auto-engagement Agent for Code Question Answering Data\n  Production","summary":"  Large Language Models (LLMs) have become increasingly integral to enhancing\ndeveloper productivity, particularly in code generation, comprehension, and\nrepair tasks. However, fine-tuning these models with high-quality, real-world\ndata is challenging due to privacy concerns and the lack of accessible, labeled\ndatasets. In this paper, we present DialogAgent, an automated tool for\ngenerating synthetic training data that closely mimics real developer\ninteractions within Integrated Development Environments (IDEs). DialogAgent\nenables the production of diverse, high-fidelity query-response pairs by\nsimulating multi-turn dialogues and contextual behaviors observed in real-world\nprogramming scenarios. The tool significantly reduces the reliance on manual\ndata generation, increasing efficiency by 4.8 times compared to traditional\nmethods. Our experiments and online deployment demonstrate substantial\nimprovements in model performance for code-related question-answering tasks:\nthe acceptance rate of responses generated by our in-house model is improved by\n33%, after training on synthesized data generated by DialogAgent.\n","authors":["Xiaoyun Liang","Jingyi Ren","Jiayi Qi","Chao Peng","Bo Jiang"],"pdf_url":"https://arxiv.org/pdf/2412.08069v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08068v1","updated":"2024-12-11T03:29:56Z","published":"2024-12-11T03:29:56Z","title":"Repository-Level Graph Representation Learning for Enhanced Security\n  Patch Detection","summary":"  Software vendors often silently release security patches without providing\nsufficient advisories (e.g., Common Vulnerabilities and Exposures) or delayed\nupdates via resources (e.g., National Vulnerability Database). Therefore, it\nhas become crucial to detect these security patches to ensure secure software\nmaintenance. However, existing methods face the following challenges: (1) They\nprimarily focus on the information within the patches themselves, overlooking\nthe complex dependencies in the repository. (2) Security patches typically\ninvolve multiple functions and files, increasing the difficulty in well\nlearning the representations. To alleviate the above challenges, this paper\nproposes a Repository-level Security Patch Detection framework named RepoSPD,\nwhich comprises three key components: 1) a repository-level graph construction,\nRepoCPG, which represents software patches by merging pre-patch and post-patch\nsource code at the repository level; 2) a structure-aware patch representation,\nwhich fuses the graph and sequence branch and aims at comprehending the\nrelationship among multiple code changes; 3) progressive learning, which\nfacilitates the model in balancing semantic and structural information. To\nevaluate RepoSPD, we employ two widely-used datasets in security patch\ndetection: SPI-DB and PatchDB. We further extend these datasets to the\nrepository level, incorporating a total of 20,238 and 28,781 versions of\nrepository in C/C++ programming languages, respectively, denoted as SPI-DB* and\nPatchDB*. We compare RepoSPD with six existing security patch detection methods\nand five static tools. Our experimental results demonstrate that RepoSPD\noutperforms the state-of-the-art baseline, with improvements of 11.90%, and\n3.10% in terms of accuracy on the two datasets, respectively.\n","authors":["Xin-Cheng Wen","Zirui Lin","Cuiyun Gao","Hongyu Zhang","Yong Wang","Qing Liao"],"pdf_url":"https://arxiv.org/pdf/2412.08068v1.pdf","comment":"13 pages. This paper is accepted by ICSE 2025"},{"id":"http://arxiv.org/abs/2412.08063v1","updated":"2024-12-11T03:15:49Z","published":"2024-12-11T03:15:49Z","title":"ContextModule: Improving Code Completion via Repository-level Contextual\n  Information","summary":"  Large Language Models (LLMs) have demonstrated impressive capabilities in\ncode completion tasks, where they assist developers by predicting and\ngenerating new code in real-time. However, existing LLM-based code completion\nsystems primarily rely on the immediate context of the file being edited, often\nmissing valuable repository-level information, user behaviour and edit history\nthat could improve suggestion accuracy. Additionally, challenges such as\nefficiently retrieving relevant code snippets from large repositories,\nincorporating user behavior, and balancing accuracy with low-latency\nrequirements in production environments remain unresolved. In this paper, we\npropose ContextModule, a framework designed to enhance LLM-based code\ncompletion by retrieving and integrating three types of contextual information\nfrom the repository: user behavior-based code, similar code snippets, and\ncritical symbol definitions. By capturing user interactions across files and\nleveraging repository-wide static analysis, ContextModule improves the\nrelevance and precision of generated code. We implement performance\noptimizations, such as index caching, to ensure the system meets the latency\nconstraints of real-world coding environments. Experimental results and\nindustrial practise demonstrate that ContextModule significantly improves code\ncompletion accuracy and user acceptance rates.\n","authors":["Zhanming Guan","Junlin Liu","Jierui Liu","Chao Peng","Dexin Liu","Ningyuan Sun","Bo Jiang","Wenchao Li","Jie Liu","Hang Zhu"],"pdf_url":"https://arxiv.org/pdf/2412.08063v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08061v1","updated":"2024-12-11T03:07:56Z","published":"2024-12-11T03:07:56Z","title":"Go-Oracle: Automated Test Oracle for Go Concurrency Bugs","summary":"  The Go programming language has gained significant traction for developing\nsoftware, especially in various infrastructure systems. Nonetheless,\nconcurrency bugs have become a prevalent issue within Go, presenting a unique\nchallenge due to the language's dual concurrency mechanisms-communicating\nsequential processes and shared memory. Detecting concurrency bugs and\naccurately classifying program executions as pass or fail presents an immense\nchallenge, even for domain experts. We conducted a survey with expert\ndevelopers at Bytedance that confirmed this challenge. Our work seeks to\naddress the test oracle problem for Go programs, to automatically classify test\nexecutions as pass or fail. This problem has not been investigated in the\nliterature for Go programs owing to its distinctive programming model.\n  Our approach involves collecting both passing and failing execution traces\nfrom various subject Go programs. We capture a comprehensive array of execution\nevents using the native Go execution tracer. Subsequently, we preprocess and\nencode these traces before training a transformer-based neural network to\neffectively classify the traces as either passing or failing. The evaluation of\nour approach encompasses 8 subject programs sourced from the GoBench\nrepository. These subject programs are routinely used as benchmarks in an\nindustry setting. Encouragingly, our test oracle, Go-Oracle, demonstrates high\naccuracies even when operating with a limited dataset, showcasing the efficacy\nand potential of our methodology. Developers at Bytedance strongly agreed that\nthey would use the Go-Oracle tool over the current practice of manual\ninspections to classify tests for Go programs as pass or fail.\n","authors":["Foivos Tsimpourlas","Chao Peng","Carlos Rosuero","Ping Yang","Ajitha Rajan"],"pdf_url":"https://arxiv.org/pdf/2412.08061v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08054v1","updated":"2024-12-11T03:00:24Z","published":"2024-12-11T03:00:24Z","title":"Federated In-Context LLM Agent Learning","summary":"  Large Language Models (LLMs) have revolutionized intelligent services by\nenabling logical reasoning, tool use, and interaction with external systems as\nagents. The advancement of LLMs is frequently hindered by the scarcity of\nhigh-quality data, much of which is inherently sensitive. Federated learning\n(FL) offers a potential solution by facilitating the collaborative training of\ndistributed LLMs while safeguarding private data. However, FL frameworks face\nsignificant bandwidth and computational demands, along with challenges from\nheterogeneous data distributions. The emerging in-context learning capability\nof LLMs offers a promising approach by aggregating natural language rather than\nbulky model parameters. Yet, this method risks privacy leakage, as it\nnecessitates the collection and presentation of data samples from various\nclients during aggregation. In this paper, we propose a novel\nprivacy-preserving Federated In-Context LLM Agent Learning (FICAL) algorithm,\nwhich to our best knowledge for the first work unleashes the power of\nin-context learning to train diverse LLM agents through FL. In our design,\nknowledge compendiums generated by a novel LLM-enhanced Knowledge Compendiums\nGeneration (KCG) module are transmitted between clients and the server instead\nof model parameters in previous FL methods. Apart from that, an incredible\nRetrieval Augmented Generation (RAG) based Tool Learning and Utilizing (TLU)\nmodule is designed and we incorporate the aggregated global knowledge\ncompendium as a teacher to teach LLM agents the usage of tools. We conducted\nextensive experiments and the results show that FICAL has competitive\nperformance compared to other SOTA baselines with a significant communication\ncost decrease of $\\mathbf{3.33\\times10^5}$ times.\n","authors":["Panlong Wu","Kangshuo Li","Junbao Nan","Fangxin Wang"],"pdf_url":"https://arxiv.org/pdf/2412.08054v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08053v1","updated":"2024-12-11T03:00:15Z","published":"2024-12-11T03:00:15Z","title":"DynamicPAE: Generating Scene-Aware Physical Adversarial Examples in\n  Real-Time","summary":"  Physical adversarial examples (PAEs) are regarded as \"whistle-blowers\" of\nreal-world risks in deep-learning applications. However, current PAE generation\nstudies show limited adaptive attacking ability to diverse and varying scenes.\nThe key challenges in generating dynamic PAEs are exploring their patterns\nunder noisy gradient feedback and adapting the attack to agnostic scenario\nnatures. To address the problems, we present DynamicPAE, the first generative\nframework that enables scene-aware real-time physical attacks beyond static\nattacks. Specifically, to train the dynamic PAE generator under noisy gradient\nfeedback, we introduce the residual-driven sample trajectory guidance\ntechnique, which redefines the training task to break the limited feedback\ninformation restriction that leads to the degeneracy problem. Intuitively, it\nallows the gradient feedback to be passed to the generator through a low-noise\nauxiliary task, thereby guiding the optimization away from degenerate solutions\nand facilitating a more comprehensive and stable exploration of feasible PAEs.\nTo adapt the generator to agnostic scenario natures, we introduce the\ncontext-aligned scene expectation simulation process, consisting of the\nconditional-uncertainty-aligned data module and the skewness-aligned objective\nre-weighting module. The former enhances robustness in the context of\nincomplete observation by employing a conditional probabilistic model for\ndomain randomization, while the latter facilitates consistent stealth control\nacross different attack targets by automatically reweighting losses based on\nthe skewness indicator. Extensive digital and physical evaluations demonstrate\nthe superior attack performance of DynamicPAE, attaining a 1.95 $\\times$ boost\n(65.55% average AP drop under attack) on representative object detectors (e.g.,\nYolo-v8) over state-of-the-art static PAE generating methods.\n","authors":["Jin Hu","Xianglong Liu","Jiakai Wang","Junkai Zhang","Xianqi Yang","Haotong Qin","Yuqing Ma","Ke Xu"],"pdf_url":"https://arxiv.org/pdf/2412.08053v1.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2310.16045v2","updated":"2024-12-11T02:46:29Z","published":"2023-10-24T17:58:07Z","title":"Woodpecker: Hallucination Correction for Multimodal Large Language\n  Models","summary":"  Hallucination is a big shadow hanging over the rapidly evolving Multimodal\nLarge Language Models (MLLMs), referring to the phenomenon that the generated\ntext is inconsistent with the image content. In order to mitigate\nhallucinations, existing studies mainly resort to an instruction-tuning manner\nthat requires retraining the models with specific data. In this paper, we pave\na different way, introducing a training-free method named Woodpecker. Like a\nwoodpecker heals trees, it picks out and corrects hallucinations from the\ngenerated text. Concretely, Woodpecker consists of five stages: key concept\nextraction, question formulation, visual knowledge validation, visual claim\ngeneration, and hallucination correction. Implemented in a post-remedy manner,\nWoodpecker can easily serve different MLLMs, while being interpretable by\naccessing intermediate outputs of the five stages. We evaluate Woodpecker both\nquantitatively and qualitatively and show the huge potential of this new\nparadigm. On the POPE benchmark, our method obtains a 30.66%/24.33% improvement\nin accuracy over the baseline MiniGPT-4/mPLUG-Owl. The source code is released\nat https://github.com/BradyFU/Woodpecker.\n","authors":["Shukang Yin","Chaoyou Fu","Sirui Zhao","Tong Xu","Hao Wang","Dianbo Sui","Yunhang Shen","Ke Li","Xing Sun","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2310.16045v2.pdf","comment":"Accepted by Science China Information Sciences (SCIS)"},{"id":"http://arxiv.org/abs/2412.07289v2","updated":"2024-12-11T02:31:45Z","published":"2024-12-10T08:18:29Z","title":"Enhancing Relation Extraction via Supervised Rationale Verification and\n  Feedback","summary":"  Despite the rapid progress that existing automated feedback methods have made\nin correcting the output of large language models (LLMs), these methods cannot\nbe well applied to the relation extraction (RE) task due to their designated\nfeedback objectives and correction manner. To address this problem, we propose\na novel automated feedback framework for RE, which presents a rationale\nsupervisor to verify the rationale and provides re-selected demonstrations as\nfeedback to correct the initial prediction. Specifically, we first design a\ncausal intervention and observation method to collect biased/unbiased\nrationales for contrastive training the rationale supervisor. Then, we present\na verification-feedback-correction procedure to iteratively enhance LLMs'\ncapability of handling the RE task. Extensive experiments prove that our\nproposed framework significantly outperforms existing methods.\n","authors":["Yongqi Li","Xin Miao","Shen Zhou","Mayi Xu","Yuyang Ren","Tieyun Qian"],"pdf_url":"https://arxiv.org/pdf/2412.07289v2.pdf","comment":"Accepted to AAAI 2025, camera ready version"},{"id":"http://arxiv.org/abs/2412.05280v2","updated":"2024-12-11T02:27:18Z","published":"2024-12-06T18:59:56Z","title":"Stag-1: Towards Realistic 4D Driving Simulation with Video Generation\n  Model","summary":"  4D driving simulation is essential for developing realistic autonomous\ndriving simulators. Despite advancements in existing methods for generating\ndriving scenes, significant challenges remain in view transformation and\nspatial-temporal dynamic modeling. To address these limitations, we propose a\nSpatial-Temporal simulAtion for drivinG (Stag-1) model to reconstruct\nreal-world scenes and design a controllable generative network to achieve 4D\nsimulation. Stag-1 constructs continuous 4D point cloud scenes using\nsurround-view data from autonomous vehicles. It decouples spatial-temporal\nrelationships and produces coherent keyframe videos. Additionally, Stag-1\nleverages video generation models to obtain photo-realistic and controllable 4D\ndriving simulation videos from any perspective. To expand the range of view\ngeneration, we train vehicle motion videos based on decomposed camera poses,\nenhancing modeling capabilities for distant scenes. Furthermore, we reconstruct\nvehicle camera trajectories to integrate 3D points across consecutive views,\nenabling comprehensive scene understanding along the temporal dimension.\nFollowing extensive multi-level scene training, Stag-1 can simulate from any\ndesired viewpoint and achieve a deep understanding of scene evolution under\nstatic spatial-temporal conditions. Compared to existing methods, our approach\nshows promising performance in multi-view scene consistency, background\ncoherence, and accuracy, and contributes to the ongoing advancements in\nrealistic autonomous driving simulation. Code: https://github.com/wzzheng/Stag.\n","authors":["Lening Wang","Wenzhao Zheng","Dalong Du","Yunpeng Zhang","Yilong Ren","Han Jiang","Zhiyong Cui","Haiyang Yu","Jie Zhou","Jiwen Lu","Shanghang Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.05280v2.pdf","comment":"Code is available at: https://github.com/wzzheng/Stag"},{"id":"http://arxiv.org/abs/2412.08029v1","updated":"2024-12-11T02:17:33Z","published":"2024-12-11T02:17:33Z","title":"NeRF-NQA: No-Reference Quality Assessment for Scenes Generated by NeRF\n  and Neural View Synthesis Methods","summary":"  Neural View Synthesis (NVS) has demonstrated efficacy in generating\nhigh-fidelity dense viewpoint videos using a image set with sparse views.\nHowever, existing quality assessment methods like PSNR, SSIM, and LPIPS are not\ntailored for the scenes with dense viewpoints synthesized by NVS and NeRF\nvariants, thus, they often fall short in capturing the perceptual quality,\nincluding spatial and angular aspects of NVS-synthesized scenes. Furthermore,\nthe lack of dense ground truth views makes the full reference quality\nassessment on NVS-synthesized scenes challenging. For instance, datasets such\nas LLFF provide only sparse images, insufficient for complete full-reference\nassessments. To address the issues above, we propose NeRF-NQA, the first\nno-reference quality assessment method for densely-observed scenes synthesized\nfrom the NVS and NeRF variants. NeRF-NQA employs a joint quality assessment\nstrategy, integrating both viewwise and pointwise approaches, to evaluate the\nquality of NVS-generated scenes. The viewwise approach assesses the spatial\nquality of each individual synthesized view and the overall inter-views\nconsistency, while the pointwise approach focuses on the angular qualities of\nscene surface points and their compound inter-point quality. Extensive\nevaluations are conducted to compare NeRF-NQA with 23 mainstream visual quality\nassessment methods (from fields of image, video, and light-field assessment).\nThe results demonstrate NeRF-NQA outperforms the existing assessment methods\nsignificantly and it shows substantial superiority on assessing NVS-synthesized\nscenes without references. An implementation of this paper are available at\nhttps://github.com/VincentQQu/NeRF-NQA.\n","authors":["Qiang Qu","Hanxue Liang","Xiaoming Chen","Yuk Ying Chung","Yiran Shen"],"pdf_url":"https://arxiv.org/pdf/2412.08029v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08021v1","updated":"2024-12-11T02:00:39Z","published":"2024-12-11T02:00:39Z","title":"Can a MISL Fly? Analysis and Ingredients for Mutual Information Skill\n  Learning","summary":"  Self-supervised learning has the potential of lifting several of the key\nchallenges in reinforcement learning today, such as exploration, representation\nlearning, and reward design. Recent work (METRA) has effectively argued that\nmoving away from mutual information and instead optimizing a certain\nWasserstein distance is important for good performance. In this paper, we argue\nthat the benefits seen in that paper can largely be explained within the\nexisting framework of mutual information skill learning (MISL). Our analysis\nsuggests a new MISL method (contrastive successor features) that retains the\nexcellent performance of METRA with fewer moving parts, and highlights\nconnections between skill learning, contrastive representation learning, and\nsuccessor features. Finally, through careful ablation studies, we provide\nfurther insight into some of the key ingredients for both our method and METRA.\n","authors":["Chongyi Zheng","Jens Tuyls","Joanne Peng","Benjamin Eysenbach"],"pdf_url":"https://arxiv.org/pdf/2412.08021v1.pdf","comment":"Code and videos are available on the website:\n  https://princeton-rl.github.io/contrastive-successor-features/"},{"id":"http://arxiv.org/abs/2412.08020v1","updated":"2024-12-11T02:00:25Z","published":"2024-12-11T02:00:25Z","title":"Intelligent Control of Robotic X-ray Devices using a Language-promptable\n  Digital Twin","summary":"  Natural language offers a convenient, flexible interface for controlling\nrobotic C-arm X-ray systems, making advanced functionality and controls\naccessible. However, enabling language interfaces requires specialized AI\nmodels that interpret X-ray images to create a semantic representation for\nreasoning. The fixed outputs of such AI models limit the functionality of\nlanguage controls. Incorporating flexible, language-aligned AI models prompted\nthrough language enables more versatile interfaces for diverse tasks and\nprocedures. Using a language-aligned foundation model for X-ray image\nsegmentation, our system continually updates a patient digital twin based on\nsparse reconstructions of desired anatomical structures. This supports\nautonomous capabilities such as visualization, patient-specific viewfinding,\nand automatic collimation from novel viewpoints, enabling commands 'Focus in on\nthe lower lumbar vertebrae.' In a cadaver study, users visualized, localized,\nand collimated structures across the torso using verbal commands, achieving 84%\nend-to-end success. Post hoc analysis of randomly oriented images showed our\npatient digital twin could localize 35 commonly requested structures to within\n51.68 mm, enabling localization and isolation from arbitrary orientations. Our\nresults demonstrate how intelligent robotic X-ray systems can incorporate\nphysicians' expressed intent directly. While existing foundation models for\nintra-operative X-ray analysis exhibit failure modes, as they improve, they can\nfacilitate highly flexible, intelligent robotic C-arms.\n","authors":["Benjamin D. Killeen","Anushri Suresh","Catalina Gomez","Blanca Inigo","Christopher Bailey","Mathias Unberath"],"pdf_url":"https://arxiv.org/pdf/2412.08020v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08014v1","updated":"2024-12-11T01:41:19Z","published":"2024-12-11T01:41:19Z","title":"MAGIC: Mastering Physical Adversarial Generation in Context through\n  Collaborative LLM Agents","summary":"  Physical adversarial attacks in driving scenarios can expose critical\nvulnerabilities in visual perception models. However, developing such attacks\nremains challenging due to diverse real-world backgrounds and the requirement\nfor maintaining visual naturality. Building upon this challenge, we reformulate\nphysical adversarial attacks as a one-shot patch-generation problem. Our\napproach generates adversarial patches through a deep generative model that\nconsiders the specific scene context, enabling direct physical deployment in\nmatching environments. The primary challenge lies in simultaneously achieving\ntwo objectives: generating adversarial patches that effectively mislead object\ndetection systems while determining contextually appropriate placement within\nthe scene. We propose MAGIC (Mastering Physical Adversarial Generation In\nContext), a novel framework powered by multi-modal LLM agents to address these\nchallenges. MAGIC automatically understands scene context and orchestrates\nadversarial patch generation through the synergistic interaction of language\nand vision capabilities. MAGIC orchestrates three specialized LLM agents: The\nadv-patch generation agent (GAgent) masters the creation of deceptive patches\nthrough strategic prompt engineering for text-to-image models. The adv-patch\ndeployment agent (DAgent) ensures contextual coherence by determining optimal\nplacement strategies based on scene understanding. The self-examination agent\n(EAgent) completes this trilogy by providing critical oversight and iterative\nrefinement of both processes. We validate our method on both digital and\nphysical level, \\ie, nuImage and manually captured real scenes, where both\nstatistical and visual results prove that our MAGIC is powerful and effectively\nfor attacking wide-used object detection systems.\n","authors":["Yun Xing","Nhat Chung","Jie Zhang","Yue Cao","Ivor Tsang","Yang Liu","Lei Ma","Qing Guo"],"pdf_url":"https://arxiv.org/pdf/2412.08014v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.11694v2","updated":"2024-12-11T01:32:08Z","published":"2024-11-18T16:15:17Z","title":"Technical Report: Enhancing LLM Reasoning with Reward-guided Tree Search","summary":"  Recently, test-time scaling has garnered significant attention from the\nresearch community, largely due to the substantial advancements of the o1 model\nreleased by OpenAI. By allocating more computational resources during the\ninference phase, large language models~(LLMs) can extensively explore the\nsolution space by generating more thought tokens or diverse solutions, thereby\nproducing more accurate responses. However, developing an o1-like reasoning\napproach is challenging, and researchers have been making various attempts to\nadvance this open area of research. In this paper, we present a preliminary\nexploration into enhancing the reasoning abilities of LLMs through\nreward-guided tree search algorithms. This framework is implemented by\nintegrating the policy model, reward model, and search algorithm. It is\nprimarily constructed around a tree search algorithm, where the policy model\nnavigates a dynamically expanding tree guided by a specially trained reward\nmodel. We thoroughly explore various design considerations necessary for\nimplementing this framework and provide a detailed report of the technical\naspects. To assess the effectiveness of our approach, we focus on mathematical\nreasoning tasks and conduct extensive evaluations on four challenging datasets,\nsignificantly enhancing the reasoning abilities of LLMs.\n","authors":["Jinhao Jiang","Zhipeng Chen","Yingqian Min","Jie Chen","Xiaoxue Cheng","Jiapeng Wang","Yiru Tang","Haoxiang Sun","Jia Deng","Wayne Xin Zhao","Zheng Liu","Dong Yan","Jian Xie","Zhongyuan Wang","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2411.11694v2.pdf","comment":"Technical Report on Slow Thinking with LLMs: I"},{"id":"http://arxiv.org/abs/2406.11872v3","updated":"2024-12-11T01:21:13Z","published":"2024-05-31T05:13:02Z","title":"The EarlyBird Gets the WORM: Heuristically Accelerating EarlyBird\n  Convergence","summary":"  The Lottery Ticket hypothesis proposes that ideal, sparse subnetworks, called\nlottery tickets, exist in untrained dense neural networks. The Early Bird\nhypothesis proposes an efficient algorithm to find these winning lottery\ntickets in convolutional neural networks, using the novel concept of distance\nbetween subnetworks to detect convergence in the subnetworks of a model.\nHowever, this approach overlooks unchanging groups of unimportant neurons near\nthe search's end. We proposes WORM, a method that exploits these static groups\nby truncating their gradients, forcing the model to rely on other neurons.\nExperiments show WORM achieves faster ticket identification during training on\nconvolutional neural networks, despite the additional computational overhead,\nwhen compared to EarlyBird search. Additionally, WORM-pruned models lose less\naccuracy during pruning and recover accuracy faster, improving the robustness\nof a given model. Furthermore, WORM is also able to generalize the Early Bird\nhypothesis reasonably well to larger models, such as transformers, displaying\nits flexibility to adapt to more complex architectures.\n","authors":["Adithya Vasudev"],"pdf_url":"https://arxiv.org/pdf/2406.11872v3.pdf","comment":"Accepted to the Efficient Natural Language and Speech Processing\n  Workshop at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2404.05959v2","updated":"2024-12-11T01:17:34Z","published":"2024-04-09T02:45:39Z","title":"Map Optical Properties to Subwavelength Structures Directly via a\n  Diffusion Model","summary":"  Subwavelength photonic structures and metamaterials provide revolutionary\napproaches for controlling light. The inverse design methods proposed for these\nsubwavelength structures are vital to the development of new photonic devices.\nHowever, most of the existing inverse design methods cannot realize direct\nmapping from optical properties to photonic structures but instead rely on\nforward simulation methods to perform iterative optimization. In this work, we\nexploit the powerful generative abilities of artificial intelligence (AI) and\npropose a practical inverse design method based on latent diffusion models. Our\nmethod maps directly the optical properties to structures without the\nrequirement of forward simulation and iterative optimization. Here, the given\noptical properties can work as \"prompts\" and guide the constructed model to\ncorrectly \"draw\" the required photonic structures. Experiments show that our\ndirect mapping-based inverse design method can generate subwavelength photonic\nstructures at high fidelity while following the given optical properties. This\nmay change the method used for optical design and greatly accelerate the\nresearch on new photonic devices.\n","authors":["Shijie Rao","Kaiyu Cui","Yidong Huang","Jiawei Yang","Yali Li","Shengjin Wang","Xue Feng","Fang Liu","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2404.05959v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17740v2","updated":"2024-12-11T00:59:09Z","published":"2024-06-25T17:26:05Z","title":"Structured Unrestricted-Rank Matrices for Parameter Efficient\n  Fine-tuning","summary":"  Recent efforts to scale Transformer models have demonstrated rapid progress\nacross a wide range of tasks (Wei et al., 2022). However, fine-tuning these\nmodels for downstream tasks is expensive due to their large parameter counts.\nParameter-efficient fine-tuning (PEFT) approaches have emerged as a viable\nalternative by allowing us to fine-tune models by updating only a small number\nof parameters. In this work, we propose a general framework for parameter\nefficient fine-tuning (PEFT), based on structured unrestricted-rank matrices\n(SURM) which can serve as a drop-in replacement for popular approaches such as\nAdapters and LoRA. Unlike other methods like LoRA, SURMs provides more\nflexibility in finding the right balance between compactness and\nexpressiveness. This is achieved by using low displacement rank matrices\n(LDRMs), which hasn't been used in this context before. SURMs remain\ncompetitive with baselines, often providing significant quality improvements\nwhile using a smaller parameter budget. SURMs achieve 5-7% accuracy gains on\nvarious image classification tasks while replacing low-rank matrices in LoRA.\nIt also results in up to 12x reduction of the number of parameters in adapters\n(with virtually no loss in quality) on the GLUE benchmark.\n","authors":["Arijit Sehanobish","Avinava Dubey","Krzysztof Choromanski","Somnath Basu Roy Chowdhury","Deepali Jain","Vikas Sindhwani","Snigdha Chaturvedi"],"pdf_url":"https://arxiv.org/pdf/2406.17740v2.pdf","comment":"Accepted at NeurIPS 2024. Updated draft at:\n  https://openreview.net/pdf?id=MXOzgjlWDF"},{"id":"http://arxiv.org/abs/2411.05282v3","updated":"2024-12-11T00:42:02Z","published":"2024-11-08T02:25:45Z","title":"MicroScopiQ: Accelerating Foundational Models through Outlier-Aware\n  Microscaling Quantization","summary":"  Quantization of foundational models (FMs) is significantly more challenging\nthan traditional DNNs due to the emergence of large magnitude features called\noutliers. Existing outlier-aware algorithm/architecture co-design techniques\neither use mixed-precision, retaining outliers at high precision but compromise\nhardware efficiency, or quantize inliers and outliers at the same precision,\nimproving hardware efficiency at the cost of accuracy. To address this mutual\nexclusivity, in this paper, we propose MicroScopiQ, a novel co-design technique\nthat leverages pruning to complement outlier-aware quantization. MicroScopiQ\nretains outliers at higher precision while pruning a certain fraction of least\nimportant weights to distribute the additional outlier bits; ensuring high\naccuracy, aligned memory and hardware efficiency. We design a high-throughput,\nlow overhead accelerator architecture composed of simple multi-precision INT\nprocessing elements and a novel network-on-chip called ReCoN that efficiently\nabstracts the complexity of supporting high-precision outliers. Additionally,\nunlike existing alternatives, MicroScopiQ does not assume any locality of\noutlier weights, enabling applicability to a broad range of FMs. Extensive\nexperiments across various quantization settings show that MicroScopiQ achieves\nSoTA quantization performance while simultaneously improving inference\nperformance by 3x and reducing energy by 2x over existing alternatives.\n","authors":["Akshat Ramachandran","Souvik Kundu","Tushar Krishna"],"pdf_url":"https://arxiv.org/pdf/2411.05282v3.pdf","comment":"Preprint under review"},{"id":"http://arxiv.org/abs/2412.07990v1","updated":"2024-12-11T00:02:48Z","published":"2024-12-11T00:02:48Z","title":"Adaptive Querying for Reward Learning from Human Feedback","summary":"  Learning from human feedback is a popular approach to train robots to adapt\nto user preferences and improve safety. Existing approaches typically consider\na single querying (interaction) format when seeking human feedback and do not\nleverage multiple modes of user interaction with a robot. We examine how to\nlearn a penalty function associated with unsafe behaviors, such as side\neffects, using multiple forms of human feedback, by optimizing the query state\nand feedback format. Our framework for adaptive feedback selection enables\nquerying for feedback in critical states in the most informative format, while\naccounting for the cost and probability of receiving feedback in a certain\nformat. We employ an iterative, two-phase approach which first selects critical\nstates for querying, and then uses information gain to select a feedback format\nfor querying across the sampled critical states. Our evaluation in simulation\ndemonstrates the sample efficiency of our approach.\n","authors":["Yashwanthi Anand","Sandhya Saisubramanian"],"pdf_url":"https://arxiv.org/pdf/2412.07990v1.pdf","comment":null}]},"2024-12-13T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2412.10369v1","updated":"2024-12-13T18:58:48Z","published":"2024-12-13T18:58:48Z","title":"A Grounded Typology of Word Classes","summary":"  We propose a grounded approach to meaning in language typology. We treat data\nfrom perceptual modalities, such as images, as a language-agnostic\nrepresentation of meaning. Hence, we can quantify the function--form\nrelationship between images and captions across languages. Inspired by\ninformation theory, we define \"groundedness\", an empirical measure of\ncontextual semantic contentfulness (formulated as a difference in surprisal)\nwhich can be computed with multilingual multimodal language models. As a proof\nof concept, we apply this measure to the typology of word classes. Our measure\ncaptures the contentfulness asymmetry between functional (grammatical) and\nlexical (content) classes across languages, but contradicts the view that\nfunctional classes do not convey content. Moreover, we find universal trends in\nthe hierarchy of groundedness (e.g., nouns > adjectives > verbs), and show that\nour measure partly correlates with psycholinguistic concreteness norms in\nEnglish. We release a dataset of groundedness scores for 30 languages. Our\nresults suggest that the grounded typology approach can provide quantitative\nevidence about semantic function in language.\n","authors":["Coleman Haley","Sharon Goldwater","Edoardo Ponti"],"pdf_url":"https://arxiv.org/pdf/2412.10369v1.pdf","comment":"19 pages, 5 figures"},{"id":"http://arxiv.org/abs/2412.10321v1","updated":"2024-12-13T18:00:57Z","published":"2024-12-13T18:00:57Z","title":"AdvPrefix: An Objective for Nuanced LLM Jailbreaks","summary":"  Many jailbreak attacks on large language models (LLMs) rely on a common\nobjective: making the model respond with the prefix \"Sure, here is (harmful\nrequest)\". While straightforward, this objective has two limitations: limited\ncontrol over model behaviors, often resulting in incomplete or unrealistic\nresponses, and a rigid format that hinders optimization. To address these\nlimitations, we introduce AdvPrefix, a new prefix-forcing objective that\nenables more nuanced control over model behavior while being easy to optimize.\nOur objective leverages model-dependent prefixes, automatically selected based\non two criteria: high prefilling attack success rates and low negative\nlog-likelihood. It can further simplify optimization by using multiple prefixes\nfor a single user request. AdvPrefix can integrate seamlessly into existing\njailbreak attacks to improve their performance for free. For example, simply\nreplacing GCG attack's target prefixes with ours on Llama-3 improves nuanced\nattack success rates from 14% to 80%, suggesting that current alignment\nstruggles to generalize to unseen prefixes. Our work demonstrates the\nimportance of jailbreak objectives in achieving nuanced jailbreaks.\n","authors":["Sicheng Zhu","Brandon Amos","Yuandong Tian","Chuan Guo","Ivan Evtimov"],"pdf_url":"https://arxiv.org/pdf/2412.10321v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10319v1","updated":"2024-12-13T17:59:52Z","published":"2024-12-13T17:59:52Z","title":"SCBench: A KV Cache-Centric Analysis of Long-Context Methods","summary":"  Long-context LLMs have enabled numerous downstream applications but also\nintroduced significant challenges related to computational and memory\nefficiency. To address these challenges, optimizations for long-context\ninference have been developed, centered around the KV cache. However, existing\nbenchmarks often evaluate in single-request, neglecting the full lifecycle of\nthe KV cache in real-world use. This oversight is particularly critical, as KV\ncache reuse has become widely adopted in LLMs inference frameworks, such as\nvLLM and SGLang, as well as by LLM providers, including OpenAI, Microsoft,\nGoogle, and Anthropic. To address this gap, we introduce\nSCBench(SharedContextBench), a comprehensive benchmark for evaluating\nlong-context methods from a KV cachecentric perspective: 1) KV cache\ngeneration, 2) KV cache compression, 3) KV cache retrieval, 4) KV cache\nloading. Specifically, SCBench uses test examples with shared context, ranging\n12 tasks with two shared context modes, covering four categories of\nlong-context capabilities: string retrieval, semantic retrieval, global\ninformation, and multi-task. With it, we provide an extensive KV cache-centric\nanalysis of eight categories long-context solutions, including Gated Linear\nRNNs, Mamba-Attention hybrids, and efficient methods such as sparse attention,\nKV cache dropping, quantization, retrieval, loading, and prompt compression.\nThe evaluation is conducted on 8 long-context LLMs. Our findings show that\nsub-O(n) memory methods suffer in multi-turn scenarios, while sparse encoding\nwith O(n) memory and sub-O(n^2) pre-filling computation perform robustly.\nDynamic sparsity yields more expressive KV caches than static patterns, and\nlayer-level sparsity in hybrid architectures reduces memory usage with strong\nperformance. Additionally, we identify attention distribution shift issues in\nlong-generation scenarios. https://aka.ms/SCBench.\n","authors":["Yucheng Li","Huiqiang Jiang","Qianhui Wu","Xufang Luo","Surin Ahn","Chengruidong Zhang","Amir H. Abdi","Dongsheng Li","Jianfeng Gao","Yuqing Yang","Lili Qiu"],"pdf_url":"https://arxiv.org/pdf/2412.10319v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02820v2","updated":"2024-12-13T17:53:25Z","published":"2024-11-05T05:41:41Z","title":"DroidSpeak: KV Cache Sharing for Efficient Multi-LLM Serving","summary":"  Large Language Models (LLMs) are increasingly employed in complex workflows,\nwhere different LLMs and fine-tuned variants collaboratively address complex\ntasks. However, these systems face significant inefficiencies due to redundant\ncontext processing of the shared context. We propose DroidSpeak, a framework\nthat optimizes context sharing between fine-tuned LLMs derived from the same\nfoundational model. DroidSpeak identifies critical layers in the KV cache and\nselectively recomputes them, enabling effective reuse of intermediate data\nwhile maintaining high accuracy.\n  Our approach balances computational efficiency and task fidelity,\nsignificantly reducing inference latency and throughput bottlenecks.\nExperiments on diverse datasets and model pairs demonstrate that DroidSpeak\nachieves up to 3x higher throughputs and 2.6x faster prefill times with\nnegligible accuracy loss compared to full recomputation.\n","authors":["Yuhan Liu","Yuyang Huang","Jiayi Yao","Zhuohan Gu","Kuntai Du","Hanchen Li","Yihua Cheng","Junchen Jiang","Shan Lu","Madan Musuvathi","Esha Choukse"],"pdf_url":"https://arxiv.org/pdf/2411.02820v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10312v1","updated":"2024-12-13T17:52:48Z","published":"2024-12-13T17:52:48Z","title":"Interlocking-free Selective Rationalization Through Genetic-based\n  Learning","summary":"  A popular end-to-end architecture for selective rationalization is the\nselect-then-predict pipeline, comprising a generator to extract highlights fed\nto a predictor. Such a cooperative system suffers from suboptimal equilibrium\nminima due to the dominance of one of the two modules, a phenomenon known as\ninterlocking. While several contributions aimed at addressing interlocking,\nthey only mitigate its effect, often by introducing feature-based heuristics,\nsampling, and ad-hoc regularizations. We present GenSPP, the first\ninterlocking-free architecture for selective rationalization that does not\nrequire any learning overhead, as the above-mentioned. GenSPP avoids\ninterlocking by performing disjoint training of the generator and predictor via\ngenetic global search. Experiments on a synthetic and a real-world benchmark\nshow that our model outperforms several state-of-the-art competitors.\n","authors":["Federico Ruggeri","Gaetano Signorelli"],"pdf_url":"https://arxiv.org/pdf/2412.10312v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10302v1","updated":"2024-12-13T17:37:48Z","published":"2024-12-13T17:37:48Z","title":"DeepSeek-VL2: Mixture-of-Experts Vision-Language Models for Advanced\n  Multimodal Understanding","summary":"  We present DeepSeek-VL2, an advanced series of large Mixture-of-Experts (MoE)\nVision-Language Models that significantly improves upon its predecessor,\nDeepSeek-VL, through two key major upgrades. For the vision component, we\nincorporate a dynamic tiling vision encoding strategy designed for processing\nhigh-resolution images with different aspect ratios. For the language\ncomponent, we leverage DeepSeekMoE models with the Multi-head Latent Attention\nmechanism, which compresses Key-Value cache into latent vectors, to enable\nefficient inference and high throughput. Trained on an improved vision-language\ndataset, DeepSeek-VL2 demonstrates superior capabilities across various tasks,\nincluding but not limited to visual question answering, optical character\nrecognition, document/table/chart understanding, and visual grounding. Our\nmodel series is composed of three variants: DeepSeek-VL2-Tiny,\nDeepSeek-VL2-Small and DeepSeek-VL2, with 1.0B, 2.8B and 4.5B activated\nparameters respectively. DeepSeek-VL2 achieves competitive or state-of-the-art\nperformance with similar or fewer activated parameters compared to existing\nopen-source dense and MoE-based models. Codes and pre-trained models are\npublicly accessible at https://github.com/deepseek-ai/DeepSeek-VL2.\n","authors":["Zhiyu Wu","Xiaokang Chen","Zizheng Pan","Xingchao Liu","Wen Liu","Damai Dai","Huazuo Gao","Yiyang Ma","Chengyue Wu","Bingxuan Wang","Zhenda Xie","Yu Wu","Kai Hu","Jiawei Wang","Yaofeng Sun","Yukun Li","Yishi Piao","Kang Guan","Aixin Liu","Xin Xie","Yuxiang You","Kai Dong","Xingkai Yu","Haowei Zhang","Liang Zhao","Yisong Wang","Chong Ruan"],"pdf_url":"https://arxiv.org/pdf/2412.10302v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.06223v3","updated":"2024-12-13T17:29:55Z","published":"2024-09-10T05:26:53Z","title":"Enhancing Temporal Understanding in Audio Question Answering for Large\n  Audio Language Models","summary":"  The Audio Question Answering (AQA) task includes audio event classification,\naudio captioning, and open-ended reasoning. Recently, AQA has garnered\nattention due to the advent of Large Audio Language Models (LALMs). Current\nliterature focuses on constructing LALMs by integrating audio encoders with\ntext-only Large Language Models (LLMs) through a projection module. While LALMs\nexcel in general audio understanding, they are limited in temporal reasoning,\nwhich may hinder their commercial applications and on-device deployment. This\npaper addresses these challenges and limitations in audio temporal reasoning.\nFirst, we introduce a data augmentation technique for generating reliable audio\ntemporal questions and answers using an LLM. Second, we perform a further\nfine-tuning of an existing baseline using curriculum learning strategy to\nspecialize in temporal reasoning without compromising performance on fine-tuned\ntasks. We demonstrate the performance of our model using state-of-the-art LALMs\non public audio benchmark datasets. Third, we implement our AQA model on-device\nlocally and investigate its CPU inference for edge applications.\n","authors":["Arvind Krishna Sridhar","Yinyi Guo","Erik Visser"],"pdf_url":"https://arxiv.org/pdf/2409.06223v3.pdf","comment":"9 pages, 6 figures"},{"id":"http://arxiv.org/abs/2412.10291v1","updated":"2024-12-13T17:21:29Z","published":"2024-12-13T17:21:29Z","title":"Still \"Talking About Large Language Models\": Some Clarifications","summary":"  My paper \"Talking About Large Language Models\" has more than once been\ninterpreted as advocating a reductionist stance towards large language models.\nBut the paper was not intended that way, and I do not endorse such positions.\nThis short note situates the paper in the context of a larger philosophical\nproject that is concerned with the (mis)use of words rather than metaphysics,\nin the spirit of Wittgenstein's later writing.\n","authors":["Murray Shanahan"],"pdf_url":"https://arxiv.org/pdf/2412.10291v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10281v1","updated":"2024-12-13T17:03:56Z","published":"2024-12-13T17:03:56Z","title":"One world, one opinion? The superstar effect in LLM responses","summary":"  As large language models (LLMs) are shaping the way information is shared and\naccessed online, their opinions have the potential to influence a wide\naudience. This study examines who the LLMs view as the most prominent figures\nacross various fields, using prompts in ten different languages to explore the\ninfluence of linguistic diversity. Our findings reveal low diversity in\nresponses, with a small number of figures dominating recognition across\nlanguages (also known as the \"superstar effect\"). These results highlight the\nrisk of narrowing global knowledge representation when LLMs retrieve subjective\ninformation.\n","authors":["Sofie Goethals","Lauren Rhue"],"pdf_url":"https://arxiv.org/pdf/2412.10281v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.04482v2","updated":"2024-12-13T16:56:21Z","published":"2024-11-20T15:44:58Z","title":"NLP Cluster Analysis of Common Core State Standards and NAEP Item\n  Specifications","summary":"  Camilli (2024) proposed a methodology using natural language processing (NLP)\nto map the relationship of a set of content standards to item specifications.\nThis study provided evidence that NLP can be used to improve the mapping\nprocess. As part of this investigation, the nominal classifications of\nstandards and items specifications were used to examine construct equivalence.\nIn the current paper, we determine the strength of empirical support for the\nsemantic distinctiveness of these classifications, which are known as \"domains\"\nfor Common Core standards, and \"strands\" for National Assessment of Educational\nProgress (NAEP) item specifications. This is accomplished by separate k-means\nclustering for standards and specifications of their corresponding embedding\nvectors. We then briefly illustrate an application of these findings.\n","authors":["Gregory Camilli","Larry Suter"],"pdf_url":"https://arxiv.org/pdf/2412.04482v2.pdf","comment":"10 pages, 5 tables"},{"id":"http://arxiv.org/abs/2412.10271v1","updated":"2024-12-13T16:46:03Z","published":"2024-12-13T16:46:03Z","title":"Benchmarking Linguistic Diversity of Large Language Models","summary":"  The development and evaluation of Large Language Models (LLMs) has primarily\nfocused on their task-solving capabilities, with recent models even surpassing\nhuman performance in some areas. However, this focus often neglects whether\nmachine-generated language matches the human level of diversity, in terms of\nvocabulary choice, syntactic construction, and expression of meaning, raising\nquestions about whether the fundamentals of language generation have been fully\naddressed. This paper emphasizes the importance of examining the preservation\nof human linguistic richness by language models, given the concerning surge in\nonline content produced or aided by LLMs. We propose a comprehensive framework\nfor evaluating LLMs from various linguistic diversity perspectives including\nlexical, syntactic, and semantic dimensions. Using this framework, we benchmark\nseveral state-of-the-art LLMs across all diversity dimensions, and conduct an\nin-depth case study for syntactic diversity. Finally, we analyze how different\ndevelopment and deployment choices impact the linguistic diversity of LLM\noutputs.\n","authors":["Yanzhu Guo","Guokan Shang","Chloé Clavel"],"pdf_url":"https://arxiv.org/pdf/2412.10271v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10266v1","updated":"2024-12-13T16:34:39Z","published":"2024-12-13T16:34:39Z","title":"Reasoner Outperforms: Generative Stance Detection with Rationalization\n  for Social Media","summary":"  Stance detection is crucial for fostering a human-centric Web by analyzing\nuser-generated content to identify biases and harmful narratives that undermine\ntrust. With the development of Large Language Models (LLMs), existing\napproaches treat stance detection as a classification problem, providing robust\nmethodologies for modeling complex group interactions and advancing\ncapabilities in natural language tasks. However, these methods often lack\ninterpretability, limiting their ability to offer transparent and\nunderstandable justifications for predictions. This study adopts a generative\napproach, where stance predictions include explicit, interpretable rationales,\nand integrates them into smaller language models through single-task and\nmultitask learning. We find that incorporating reasoning into stance detection\nenables the smaller model (FlanT5) to outperform GPT-3.5's zero-shot\nperformance, achieving an improvement of up to 9.57%. Moreover, our results\nshow that reasoning capabilities enhance multitask learning performance but may\nreduce effectiveness in single-task settings. Crucially, we demonstrate that\nfaithful rationales improve rationale distillation into SLMs, advancing efforts\nto build interpretable, trustworthy systems for addressing discrimination,\nfostering trust, and promoting equitable engagement on social media.\n","authors":["Jiaqing Yuan","Ruijie Xi","Munindar P. Singh"],"pdf_url":"https://arxiv.org/pdf/2412.10266v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10257v1","updated":"2024-12-13T16:26:34Z","published":"2024-12-13T16:26:34Z","title":"Targeted Angular Reversal of Weights (TARS) for Knowledge Removal in\n  Large Language Models","summary":"  The sheer scale of data required to train modern large language models (LLMs)\nposes significant risks, as models are likely to gain knowledge of sensitive\ntopics such as bio-security, as well the ability to replicate copyrighted\nworks. Methods designed to remove such knowledge must do so from all prompt\ndirections, in a multi-lingual capacity and without degrading general model\nperformance. To this end, we introduce the targeted angular reversal (TARS)\nmethod of knowledge removal from LLMs. The TARS method firstly leverages the\nLLM in combination with a detailed prompt to aggregate information about a\nselected concept in the internal representation space of the LLM. It then\nrefines this approximate concept vector to trigger the concept token with high\nprobability, by perturbing the approximate concept vector with noise and\ntransforming it into token scores with the language model head. The feedforward\nweight vectors in the LLM which operate directly on the internal representation\nspace, and have the highest cosine similarity with this targeting vector, are\nthen replaced by a reversed targeting vector, thus limiting the ability of the\nconcept to propagate through the model. The modularity of the TARS method\nallows for a sequential removal of concepts from Llama 3.1 8B, such as the\nfamous literary detective Sherlock Holmes, and the planet Saturn. It is\ndemonstrated that the probability of triggering target concepts can be reduced\nto 0.00 with as few as 1 TARS edit, whilst simultaneously removing the\nknowledge bi-directionally. Moreover, knowledge is shown to be removed across\nall languages despite only being targeted in English. Importantly, TARS has\nminimal impact on the general model capabilities, as after removing 5 diverse\nconcepts in a modular fashion, there is minimal KL divergence in the next token\nprobabilities of the LLM on large corpora of Wikipedia text (median of 0.002).\n","authors":["Harry J. Davies","Giorgos Iacovides","Danilo P. Mandic"],"pdf_url":"https://arxiv.org/pdf/2412.10257v1.pdf","comment":"14 pages, 5 figures, 1 table"},{"id":"http://arxiv.org/abs/2412.10244v1","updated":"2024-12-13T16:13:35Z","published":"2024-12-13T16:13:35Z","title":"Efficient Continual Pre-training of LLMs for Low-resource Languages","summary":"  Open-source Large Language models (OsLLMs) propel the democratization of\nnatural language research by giving the flexibility to augment or update model\nparameters for performance improvement. Nevertheless, like proprietary LLMs,\nOs-LLMs offer poorer performance on low-resource languages (LRLs) than\nhigh-resource languages (HRLs), owing to smaller amounts of training data and\nunderrepresented vocabulary. On the other hand, continual pre-training (CPT)\nwith large amounts of language-specific data is a costly proposition in terms\nof data acquisition and computational resources. Our goal is to drastically\nreduce CPT cost. To that end, we first develop a new algorithm to select a\nsubset of texts from a larger corpus. We show the effectiveness of our\ntechnique using very little CPT data. In search of further improvement, we\ndesign a new algorithm to select tokens to include in the LLM vocabulary. We\nexperiment with the recent Llama-3 model and nine Indian languages with diverse\nscripts and extent of resource availability. For evaluation, we use\nIndicGenBench, a generation task benchmark dataset for Indic languages. We\nexperiment with various CPT corpora and augmented vocabulary size and offer\ninsights across language families.\n","authors":["Arijit Nag","Soumen Chakrabarti","Animesh Mukherjee","Niloy Ganguly"],"pdf_url":"https://arxiv.org/pdf/2412.10244v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12691v4","updated":"2024-12-13T15:56:43Z","published":"2024-10-16T15:51:18Z","title":"Building Better: Avoiding Pitfalls in Developing Language Resources when\n  Data is Scarce","summary":"  Language is a symbolic capital that affects people's lives in many ways\n(Bourdieu, 1977, 1991). It is a powerful tool that accounts for identities,\ncultures, traditions, and societies in general. Hence, data in a given language\nshould be viewed as more than a collection of tokens. Good data collection and\nlabeling practices are key to building more human-centered and socially aware\ntechnologies. While there has been a rising interest in mid- to low-resource\nlanguages within the NLP community, work in this space has to overcome unique\nchallenges such as data scarcity and access to suitable annotators. In this\npaper, we collect feedback from those directly involved in and impacted by NLP\nartefacts for mid- to low-resource languages. We conduct a quantitative and\nqualitative analysis of the responses and highlight the main issues related to\n(1) data quality such as linguistic and cultural data suitability; and (2) the\nethics of common annotation practices such as the misuse of online community\nservices. Based on these findings, we make several recommendations for the\ncreation of high-quality language artefacts that reflect the cultural milieu of\nits speakers, while simultaneously respecting the dignity and labor of data\nworkers.\n","authors":["Nedjma Ousidhoum","Meriem Beloucif","Saif M. Mohammad"],"pdf_url":"https://arxiv.org/pdf/2410.12691v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.12435v2","updated":"2024-12-13T15:50:26Z","published":"2024-09-19T03:29:40Z","title":"Linguistic Minimal Pairs Elicit Linguistic Similarity in Large Language\n  Models","summary":"  We introduce a novel analysis that leverages linguistic minimal pairs to\nprobe the internal linguistic representations of Large Language Models (LLMs).\nBy measuring the similarity between LLM activation differences across minimal\npairs, we quantify the and gain insight into the linguistic knowledge captured\nby LLMs. Our large-scale experiments, spanning 100+ LLMs and 150k minimal pairs\nin three languages, reveal properties of linguistic similarity from four key\naspects: consistency across LLMs, relation to theoretical categorizations,\ndependency to semantic context, and cross-lingual alignment of relevant\nphenomena. Our findings suggest that 1) linguistic similarity is significantly\ninfluenced by training data exposure, leading to higher cross-LLM agreement in\nhigher-resource languages. 2) Linguistic similarity strongly aligns with\nfine-grained theoretical linguistic categories but weakly with broader ones. 3)\nLinguistic similarity shows a weak correlation with semantic similarity,\nshowing its context-dependent nature. 4) LLMs exhibit limited cross-lingual\nalignment in their understanding of relevant linguistic phenomena. This work\ndemonstrates the potential of minimal pairs as a window into the neural\nrepresentations of language in LLMs, shedding light on the relationship between\nLLMs and linguistic theory. Codes and data are available at\nhttps://github.com/ChenDelong1999/Linguistic-Similarity\n","authors":["Xinyu Zhou","Delong Chen","Samuel Cahyawijaya","Xufeng Duan","Zhenguang G. Cai"],"pdf_url":"https://arxiv.org/pdf/2409.12435v2.pdf","comment":"COLING 2025"},{"id":"http://arxiv.org/abs/2412.10220v1","updated":"2024-12-13T15:45:45Z","published":"2024-12-13T15:45:45Z","title":"How good is my story? Towards quantitative metrics for evaluating\n  LLM-generated XAI narratives","summary":"  A rapidly developing application of LLMs in XAI is to convert quantitative\nexplanations such as SHAP into user-friendly narratives to explain the\ndecisions made by smaller prediction models. Evaluating the narratives without\nrelying on human preference studies or surveys is becoming increasingly\nimportant in this field. In this work we propose a framework and explore\nseveral automated metrics to evaluate LLM-generated narratives for explanations\nof tabular classification tasks. We apply our approach to compare several\nstate-of-the-art LLMs across different datasets and prompt types. As a\ndemonstration of their utility, these metrics allow us to identify new\nchallenges related to LLM hallucinations for XAI narratives.\n","authors":["Timour Ichmoukhamedov","James Hinns","David Martens"],"pdf_url":"https://arxiv.org/pdf/2412.10220v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.12741v3","updated":"2024-12-13T15:37:01Z","published":"2024-09-19T13:03:24Z","title":"Fine Tuning Large Language Models for Medicine: The Role and Importance\n  of Direct Preference Optimization","summary":"  Large Language Model (LLM) fine tuning is underutilized in the field of\nmedicine. Two of the most common methods of fine tuning are Supervised Fine\nTuning (SFT) and Direct Preference Optimization (DPO), but there is little\nguidance informing users when to use either technique. In this investigation,\nwe compare the performance of SFT and DPO for five common natural language\ntasks in medicine: Classification with text data, Classification with numeric\ndata, Clinical Reasoning, Summarization, and Clinical Triage. We find that SFT\nalone is sufficient for Classification with text data, whereas DPO improves\nperformance for the more complex tasks of Clinical Reasoning, Summarization and\nClinical Triage. Our results establish the role and importance of DPO fine\ntuning within medicine, and consequently call attention to current software\ngaps that prevent widespread deployment of this technique.\n","authors":["Thomas Savage","Stephen Ma","Abdessalem Boukil","Vishwesh Patel","Ekanath Rangan","Ivan Lopez","Jonathan H Chen"],"pdf_url":"https://arxiv.org/pdf/2409.12741v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10207v1","updated":"2024-12-13T15:30:20Z","published":"2024-12-13T15:30:20Z","title":"Retrieval-Augmented Semantic Parsing: Using Large Language Models to\n  Improve Generalization","summary":"  Open-domain semantic parsing remains a challenging task, as models often rely\non heuristics and struggle to handle unseen concepts. In this paper, we\ninvestigate the potential of large language models (LLMs) for this task and\nintroduce Retrieval-Augmented Semantic Parsing (RASP), a simple yet effective\napproach that integrates external lexical knowledge into the parsing process.\nOur experiments not only show that LLMs outperform previous encoder-decoder\nbaselines for semantic parsing, but that RASP further enhances their ability to\npredict unseen concepts, nearly doubling the performance of previous models on\nout-of-distribution concepts. These findings highlight the promise of\nleveraging large language models and retrieval mechanisms for robust and\nopen-domain semantic parsing.\n","authors":["Xiao Zhang","Qianru Meng","Johan Bos"],"pdf_url":"https://arxiv.org/pdf/2412.10207v1.pdf","comment":"Submitted to ARR"},{"id":"http://arxiv.org/abs/2406.18916v2","updated":"2024-12-13T15:15:46Z","published":"2024-06-27T06:13:05Z","title":"TrustUQA: A Trustful Framework for Unified Structured Data Question\n  Answering","summary":"  Natural language question answering (QA) over structured data sources such as\ntables and knowledge graphs have been widely investigated, especially with\nLarge Language Models (LLMs) in recent years. The main solutions include\nquestion to formal query parsing and retrieval-based answer generation.\nHowever, current methods of the former often suffer from weak generalization,\nfailing to dealing with multi-types of sources, while the later is limited in\ntrustfulness. In this paper, we propose TrustUQA, a trustful QA framework that\ncan simultaneously support multiple types of structured data in a unified way.\nTo this end, it adopts an LLM-friendly and unified knowledge representation\nmethod called Condition Graph(CG), and uses an LLM and demonstration-based\ntwo-level method for CG querying. For enhancement, it is also equipped with\ndynamic demonstration retrieval. We have evaluated TrustUQA with 5 benchmarks\ncovering 3 types of structured data. It outperforms 2 existing unified\nstructured data QA methods. In comparison with the baselines that are specific\nto one data type, it achieves state-of-the-art on 2 of the datasets. Further\nmore, we have demonstrated the potential of our method for more general QA\ntasks, QA over mixed structured data and QA across structured data. The code is\navailable at https://github.com/zjukg/TrustUQA.\n","authors":["Wen Zhang","Long Jin","Yushan Zhu","Jiaoyan Chen","Zhiwei Huang","Junjie Wang","Yin Hua","Lei Liang","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2406.18916v2.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2407.11242v3","updated":"2024-12-13T14:59:58Z","published":"2024-07-15T21:10:40Z","title":"Bridging Sequence-Structure Alignment in RNA Foundation Models","summary":"  The alignment between RNA sequences and structures in foundation models (FMs)\nhas yet to be thoroughly investigated. Existing FMs have struggled to establish\nsequence-structure alignment, hindering the free flow of genomic information\nbetween RNA sequences and structures. In this study, we introduce OmniGenome,\nan RNA FM trained to align RNA sequences with respect to secondary structures\nbased on structure-contextualised modelling. The alignment enables free and\nbidirectional mappings between sequences and structures by utilising the\nflexible RNA modelling paradigm that supports versatile input and output\nmodalities, i.e., sequence and/or structure as input/output. We implement RNA\ndesign and zero-shot secondary structure prediction as case studies to evaluate\nthe Seq2Str and Str2Seq mapping capacity of OmniGenome. Results on the EternaV2\nbenchmark show that OmniGenome solved 74% of puzzles, whereas existing FMs only\nsolved up to 3% of the puzzles due to the oversight of sequence-structure\nalignment. We leverage four comprehensive in-silico genome modelling benchmarks\nto evaluate performance across a diverse set of genome downstream tasks, where\nthe results show that OmniGenome achieves state-of-the-art performance on RNA\nand DNA benchmarks, even without any training on DNA genomes.\n","authors":["Heng Yang","Renzhi Chen","Ke Li"],"pdf_url":"https://arxiv.org/pdf/2407.11242v3.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2412.10151v1","updated":"2024-12-13T14:11:26Z","published":"2024-12-13T14:11:26Z","title":"VLR-Bench: Multilingual Benchmark Dataset for Vision-Language Retrieval\n  Augmented Generation","summary":"  We propose the VLR-Bench, a visual question answering (VQA) benchmark for\nevaluating vision language models (VLMs) based on retrieval augmented\ngeneration (RAG). Unlike existing evaluation datasets for external\nknowledge-based VQA, the proposed VLR-Bench includes five input passages. This\nallows testing of the ability to determine which passage is useful for\nanswering a given query, a capability lacking in previous research. In this\ncontext, we constructed a dataset of 32,000 automatically generated\ninstruction-following examples, which we denote as VLR-IF. This dataset is\nspecifically designed to enhance the RAG capabilities of VLMs by enabling them\nto learn how to generate appropriate answers based on input passages. We\nevaluated the validity of the proposed benchmark and training data and verified\nits performance using the state-of-the-art Llama3-based VLM, the Llava-Llama-3\nmodel. The proposed VLR-Bench and VLR-IF datasets are publicly available\nonline.\n","authors":["Hyeonseok Lim","Dongjae Shin","Seohyun Song","Inho Won","Minjun Kim","Junghun Yuk","Haneol Jang","KyungTae Lim"],"pdf_url":"https://arxiv.org/pdf/2412.10151v1.pdf","comment":"The 31st International Conference on Computational Linguistics\n  (COLING 2025), 19 pages"},{"id":"http://arxiv.org/abs/2412.10139v1","updated":"2024-12-13T13:41:24Z","published":"2024-12-13T13:41:24Z","title":"TACOMORE: Leveraging the Potential of LLMs in Corpus-based Discourse\n  Analysis with Prompt Engineering","summary":"  The capacity of LLMs to carry out automated qualitative analysis has been\nquestioned by corpus linguists, and it has been argued that corpus-based\ndiscourse analysis incorporating LLMs is hindered by issues of unsatisfying\nperformance, hallucination, and irreproducibility. Our proposed method,\nTACOMORE, aims to address these concerns by serving as an effective prompting\nframework in this domain. The framework consists of four principles, i.e.,\nTask, Context, Model and Reproducibility, and specifies five fundamental\nelements of a good prompt, i.e., Role Description, Task Definition, Task\nProcedures, Contextual Information and Output Format. We conduct experiments on\nthree LLMs, i.e., GPT-4o, Gemini-1.5-Pro and Gemini-1.5.Flash, and find that\nTACOMORE helps improve LLM performance in three representative discourse\nanalysis tasks, i.e., the analysis of keywords, collocates and concordances,\nbased on an open corpus of COVID-19 research articles. Our findings show the\nefficacy of the proposed prompting framework TACOMORE in corpus-based discourse\nanalysis in terms of Accuracy, Ethicality, Reasoning, and Reproducibility, and\nprovide novel insights into the application and evaluation of LLMs in automated\nqualitative studies.\n","authors":["Bingru Li","Han Wang"],"pdf_url":"https://arxiv.org/pdf/2412.10139v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10138v1","updated":"2024-12-13T13:41:18Z","published":"2024-12-13T13:41:18Z","title":"ROUTE: Robust Multitask Tuning and Collaboration for Text-to-SQL","summary":"  Despite the significant advancements in Text-to-SQL (Text2SQL) facilitated by\nlarge language models (LLMs), the latest state-of-the-art techniques are still\ntrapped in the in-context learning of closed-source LLMs (e.g., GPT-4), which\nlimits their applicability in open scenarios. To address this challenge, we\npropose a novel RObust mUltitask Tuning and collaboration mEthod (ROUTE) to\nimprove the comprehensive capabilities of open-source LLMs for Text2SQL,\nthereby providing a more practical solution. Our approach begins with\nmulti-task supervised fine-tuning (SFT) using various synthetic training data\nrelated to SQL generation. Unlike existing SFT-based Text2SQL methods, we\nintroduced several additional SFT tasks, including schema linking, noise\ncorrection, and continuation writing. Engaging in a variety of SQL generation\ntasks enhances the model's understanding of SQL syntax and improves its ability\nto generate high-quality SQL queries. Additionally, inspired by the\ncollaborative modes of LLM agents, we introduce a Multitask Collaboration\nPrompting (MCP) strategy. This strategy leverages collaboration across several\nSQL-related tasks to reduce hallucinations during SQL generation, thereby\nmaximizing the potential of enhancing Text2SQL performance through explicit\nmultitask capabilities. Extensive experiments and in-depth analyses have been\nperformed on eight open-source LLMs and five widely-used benchmarks. The\nresults demonstrate that our proposal outperforms the latest Text2SQL methods\nand yields leading performance.\n","authors":["Yang Qin","Chao Chen","Zhihang Fu","Ze Chen","Dezhong Peng","Peng Hu","Jieping Ye"],"pdf_url":"https://arxiv.org/pdf/2412.10138v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10136v1","updated":"2024-12-13T13:32:59Z","published":"2024-12-13T13:32:59Z","title":"Can LLMs Convert Graphs to Text-Attributed Graphs?","summary":"  Graphs are ubiquitous data structures found in numerous real-world\napplications, such as drug discovery, recommender systems, and social network\nanalysis. Graph neural networks (GNNs) have become a popular tool to learn node\nembeddings through message passing on these structures. However, a significant\nchallenge arises when applying GNNs to multiple graphs with different feature\nspaces, as existing GNN architectures are not designed for cross-graph feature\nalignment. To address this, recent approaches introduce text-attributed graphs,\nwhere each node is associated with a textual description, enabling the use of a\nshared textual encoder to project nodes from different graphs into a unified\nfeature space. While promising, this method relies heavily on the availability\nof text-attributed data, which can be difficult to obtain in practice. To\nbridge this gap, we propose a novel method named Topology-Aware Node\ndescription Synthesis (TANS), which leverages large language models (LLMs) to\nautomatically convert existing graphs into text-attributed graphs. The key idea\nis to integrate topological information with each node's properties, enhancing\nthe LLMs' ability to explain how graph topology influences node semantics. We\nevaluate our TANS on text-rich, text-limited, and text-free graphs,\ndemonstrating that it enables a single GNN to operate across diverse graphs.\nNotably, on text-free graphs, our method significantly outperforms existing\napproaches that manually design node features, showcasing the potential of LLMs\nfor preprocessing graph-structured data, even in the absence of textual\ninformation. The code and data are available at\nhttps://github.com/Zehong-Wang/TANS.\n","authors":["Zehong Wang","Sidney Liu","Zheyuan Zhang","Tianyi Ma","Chuxu Zhang","Yanfang Ye"],"pdf_url":"https://arxiv.org/pdf/2412.10136v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10135v1","updated":"2024-12-13T13:32:13Z","published":"2024-12-13T13:32:13Z","title":"ASLoRA: Adaptive Sharing Low-Rank Adaptation Across Layers","summary":"  As large language models (LLMs) grow in size, traditional full fine-tuning\nbecomes increasingly impractical due to its high computational and storage\ncosts. Although popular parameter-efficient fine-tuning methods, such as LoRA,\nhave significantly reduced the number of tunable parameters, there is still\nroom for further optimization. In this work, we propose ASLoRA, a cross-layer\nparameter-sharing strategy combining global sharing with partial adaptive\nsharing. Specifically, we share the low-rank matrix A across all layers and\nadaptively merge matrix B during training. This sharing mechanism not only\nmitigates overfitting effectively but also captures inter-layer dependencies,\nsignificantly enhancing the model's representational capability. We conduct\nextensive experiments on various NLP tasks, showing that ASLoRA outperforms\nLoRA while using less than 25% of the parameters, highlighting its flexibility\nand superior parameter efficiency. Furthermore, in-depth analyses of the\nadaptive sharing strategy confirm its significant advantages in enhancing both\nmodel flexibility and task adaptability.\n","authors":["Junyan Hu","Xue Xiao","Mengqi Zhang","Xiao Chen","Zhaochun Ren","Zhumin Chen","Pengjie Ren"],"pdf_url":"https://arxiv.org/pdf/2412.10135v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10121v1","updated":"2024-12-13T13:06:58Z","published":"2024-12-13T13:06:58Z","title":"Familiarity: Better Evaluation of Zero-Shot Named Entity Recognition by\n  Quantifying Label Shifts in Synthetic Training Data","summary":"  Zero-shot named entity recognition (NER) is the task of detecting named\nentities of specific types (such as 'Person' or 'Medicine') without any\ntraining examples. Current research increasingly relies on large synthetic\ndatasets, automatically generated to cover tens of thousands of distinct entity\ntypes, to train zero-shot NER models. However, in this paper, we find that\nthese synthetic datasets often contain entity types that are semantically\nhighly similar to (or even the same as) those in standard evaluation\nbenchmarks. Because of this overlap, we argue that reported F1 scores for\nzero-shot NER overestimate the true capabilities of these approaches. Further,\nwe argue that current evaluation setups provide an incomplete picture of\nzero-shot abilities since they do not quantify the label shift (i.e., the\nsimilarity of labels) between training and evaluation datasets. To address\nthese issues, we propose Familiarity, a novel metric that captures both the\nsemantic similarity between entity types in training and evaluation, as well as\ntheir frequency in the training data, to provide an estimate of label shift. It\nallows researchers to contextualize reported zero-shot NER scores when using\ncustom synthetic training datasets. Further, it enables researchers to generate\nevaluation setups of various transfer difficulties for fine-grained analysis of\nzero-shot NER.\n","authors":["Jonas Golde","Patrick Haller","Max Ploner","Fabio Barth","Nicolaas Jedema","Alan Akbik"],"pdf_url":"https://arxiv.org/pdf/2412.10121v1.pdf","comment":"8 pages, 4 figures, 5 tables"},{"id":"http://arxiv.org/abs/2412.10110v1","updated":"2024-12-13T12:51:50Z","published":"2024-12-13T12:51:50Z","title":"Label-template based Few-Shot Text Classification with Contrastive\n  Learning","summary":"  As an algorithmic framework for learning to learn, meta-learning provides a\npromising solution for few-shot text classification. However, most existing\nresearch fail to give enough attention to class labels. Traditional basic\nframework building meta-learner based on prototype networks heavily relies on\ninter-class variance, and it is easily influenced by noise. To address these\nlimitations, we proposes a simple and effective few-shot text classification\nframework. In particular, the corresponding label templates are embed into\ninput sentences to fully utilize the potential value of class labels, guiding\nthe pre-trained model to generate more discriminative text representations\nthrough the semantic information conveyed by labels. With the continuous\ninfluence of label semantics, supervised contrastive learning is utilized to\nmodel the interaction information between support samples and query samples.\nFurthermore, the averaging mechanism is replaced with an attention mechanism to\nhighlight vital semantic information. To verify the proposed scheme, four\ntypical datasets are employed to assess the performance of different methods.\nExperimental results demonstrate that our method achieves substantial\nperformance enhancements and outperforms existing state-of-the-art models on\nfew-shot text classification tasks.\n","authors":["Guanghua Hou","Shuhui Cao","Deqiang Ouyang","Ning Wang"],"pdf_url":"https://arxiv.org/pdf/2412.10110v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.12046v2","updated":"2024-12-13T12:50:18Z","published":"2024-02-19T10:59:29Z","title":"Citation Amnesia: On The Recency Bias of NLP and Other Academic Fields","summary":"  This study examines the tendency to cite older work across 20 fields of study\nover 43 years (1980--2023). We put NLP's propensity to cite older work in the\ncontext of these 20 other fields to analyze whether NLP shows similar temporal\ncitation patterns to these other fields over time or whether differences can be\nobserved. Our analysis, based on a dataset of approximately 240 million papers,\nreveals a broader scientific trend: many fields have markedly declined in\nciting older works (e.g., psychology, computer science). We term this decline a\n'citation age recession', analogous to how economists define periods of reduced\neconomic activity. The trend is strongest in NLP and ML research (-12.8% and\n-5.5% in citation age from previous peaks). Our results suggest that citing\nmore recent works is not directly driven by the growth in publication rates\n(-3.4% across fields; -5.2% in humanities; -5.5% in formal sciences) -- even\nwhen controlling for an increase in the volume of papers. Our findings raise\nquestions about the scientific community's engagement with past literature,\nparticularly for NLP, and the potential consequences of neglecting older but\nrelevant research. The data and a demo showcasing our results are publicly\navailable.\n","authors":["Jan Philip Wahle","Terry Ruas","Mohamed Abdalla","Bela Gipp","Saif M. Mohammad"],"pdf_url":"https://arxiv.org/pdf/2402.12046v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10105v1","updated":"2024-12-13T12:46:33Z","published":"2024-12-13T12:46:33Z","title":"MALAMUTE: A Multilingual, Highly-granular, Template-free,\n  Education-based Probing Dataset","summary":"  Language models (LMs) have excelled in various broad domains. However, to\nensure their safe and effective integration into real-world educational\nsettings, they must demonstrate proficiency in specific, granular areas of\nknowledge. Existing cloze-style benchmarks, commonly used to evaluate LMs'\nknowledge, have three major limitations. They: 1) do not cover the educational\ndomain; 2) typically focus on low-complexity, generic knowledge or broad\ndomains, which do not adequately assess the models' knowledge in specific\nsubjects; and 3) often rely on templates that can bias model predictions. Here,\nwe introduce MALAMUTE, a multilingual, template-free, and highly granular\nprobing dataset comprising expert-written, peer-reviewed probes from 71\nuniversity-level textbooks across three languages (English, Spanish, and\nPolish). MALAMUTE is the first education-based cloze-style dataset. It covers\neight domains, each with up to 14 subdomains, further broken down into concepts\nand concept-based prompts, totaling 33,361 university curriculum concepts and\n116,887 prompts. MALAMUTE's fine granularity, educational focus, and inclusion\nof both sentence-level and paragraph-level prompts make it an ideal tool for\nevaluating LMs' course-related knowledge. Our evaluation of masked and causal\nLMs on MALAMUTE shows that despite overall proficiency, they have significant\ngaps in knowledge when examined closely on specific subjects, hindering their\nsafe use in classrooms and underscoring the need for further development.\n","authors":["Sagi Shaier","George Arthur Baker","Chiranthan Sridhar","Lawrence E Hunter","Katharina von der Wense"],"pdf_url":"https://arxiv.org/pdf/2412.10105v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10104v1","updated":"2024-12-13T12:45:14Z","published":"2024-12-13T12:45:14Z","title":"RETQA: A Large-Scale Open-Domain Tabular Question Answering Dataset for\n  Real Estate Sector","summary":"  The real estate market relies heavily on structured data, such as property\ndetails, market trends, and price fluctuations. However, the lack of\nspecialized Tabular Question Answering datasets in this domain limits the\ndevelopment of automated question-answering systems. To fill this gap, we\nintroduce RETQA, the first large-scale open-domain Chinese Tabular Question\nAnswering dataset for Real Estate. RETQA comprises 4,932 tables and 20,762\nquestion-answer pairs across 16 sub-fields within three major domains: property\ninformation, real estate company finance information and land auction\ninformation. Compared with existing tabular question answering datasets, RETQA\nposes greater challenges due to three key factors: long-table structures,\nopen-domain retrieval, and multi-domain queries. To tackle these challenges, we\npropose the SLUTQA framework, which integrates large language models with\nspoken language understanding tasks to enhance retrieval and answering\naccuracy. Extensive experiments demonstrate that SLUTQA significantly improves\nthe performance of large language models on RETQA by in-context learning. RETQA\nand SLUTQA provide essential resources for advancing tabular question answering\nresearch in the real estate domain, addressing critical challenges in\nopen-domain and long-table question-answering. The dataset and code are\npublicly available at \\url{https://github.com/jensen-w/RETQA}.\n","authors":["Zhensheng Wang","Wenmian Yang","Kun Zhou","Yiquan Zhang","Weijia Jia"],"pdf_url":"https://arxiv.org/pdf/2412.10104v1.pdf","comment":"This paper is accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2412.10103v1","updated":"2024-12-13T12:42:51Z","published":"2024-12-13T12:42:51Z","title":"AMuSeD: An Attentive Deep Neural Network for Multimodal Sarcasm\n  Detection Incorporating Bi-modal Data Augmentation","summary":"  Detecting sarcasm effectively requires a nuanced understanding of context,\nincluding vocal tones and facial expressions. The progression towards\nmultimodal computational methods in sarcasm detection, however, faces\nchallenges due to the scarcity of data. To address this, we present AMuSeD\n(Attentive deep neural network for MUltimodal Sarcasm dEtection incorporating\nbi-modal Data augmentation). This approach utilizes the Multimodal Sarcasm\nDetection Dataset (MUStARD) and introduces a two-phase bimodal data\naugmentation strategy. The first phase involves generating varied text samples\nthrough Back Translation from several secondary languages. The second phase\ninvolves the refinement of a FastSpeech 2-based speech synthesis system,\ntailored specifically for sarcasm to retain sarcastic intonations. Alongside a\ncloud-based Text-to-Speech (TTS) service, this Fine-tuned FastSpeech 2 system\nproduces corresponding audio for the text augmentations. We also investigate\nvarious attention mechanisms for effectively merging text and audio data,\nfinding self-attention to be the most efficient for bimodal integration. Our\nexperiments reveal that this combined augmentation and attention approach\nachieves a significant F1-score of 81.0% in text-audio modalities, surpassing\neven models that use three modalities from the MUStARD dataset.\n","authors":["Xiyuan Gao","Shubhi Bansal","Kushaan Gowda","Zhu Li","Shekhar Nayak","Nagendra Kumar","Matt Coler"],"pdf_url":"https://arxiv.org/pdf/2412.10103v1.pdf","comment":"This is a preprint version of the paper, submitted and under review\n  at the IEEE Transactions on Affective Computing"},{"id":"http://arxiv.org/abs/2412.07646v3","updated":"2024-12-13T12:35:21Z","published":"2024-12-10T16:32:19Z","title":"Searching for Structure: Investigating Emergent Communication with Large\n  Language Models","summary":"  Human languages have evolved to be structured through repeated language\nlearning and use. These processes introduce biases that operate during language\nacquisition and shape linguistic systems toward communicative efficiency. In\nthis paper, we investigate whether the same happens if artificial languages are\noptimised for implicit biases of Large Language Models (LLMs). To this end, we\nsimulate a classical referential game in which LLMs learn and use artificial\nlanguages. Our results show that initially unstructured holistic languages are\nindeed shaped to have some structural properties that allow two LLM agents to\ncommunicate successfully. Similar to observations in human experiments,\ngenerational transmission increases the learnability of languages, but can at\nthe same time result in non-humanlike degenerate vocabularies. Taken together,\nthis work extends experimental findings, shows that LLMs can be used as tools\nin simulations of language evolution, and opens possibilities for future\nhuman-machine experiments in this field.\n","authors":["Tom Kouwenhoven","Max Peeperkorn","Tessa Verhoef"],"pdf_url":"https://arxiv.org/pdf/2412.07646v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10095v1","updated":"2024-12-13T12:31:06Z","published":"2024-12-13T12:31:06Z","title":"HiTZ at VarDial 2025 NorSID: Overcoming Data Scarcity with Language\n  Transfer and Automatic Data Annotation","summary":"  In this paper we present our submission for the NorSID Shared Task as part of\nthe 2025 VarDial Workshop (Scherrer et al., 2025), consisting of three tasks:\nIntent Detection, Slot Filling and Dialect Identification, evaluated using data\nin different dialects of the Norwegian language. For Intent Detection and Slot\nFilling, we have fine-tuned a multitask model in a cross-lingual setting, to\nleverage the xSID dataset available in 17 languages. In the case of Dialect\nIdentification, our final submission consists of a model fine-tuned on the\nprovided development set, which has obtained the highest scores within our\nexperiments. Our final results on the test set show that our models do not drop\nin performance compared to the development set, likely due to the\ndomain-specificity of the dataset and the similar distribution of both subsets.\nFinally, we also report an in-depth analysis of the provided datasets and their\nartifacts, as well as other sets of experiments that have been carried out but\ndid not yield the best results. Additionally, we present an analysis on the\nreasons why some methods have been more successful than others; mainly the\nimpact of the combination of languages and domain-specificity of the training\ndata on the results.\n","authors":["Jaione Bengoetxea","Mikel Zubillaga","Ekhi Azurmendi","Maite Heredia","Julen Etxaniz","Markel Ferro","Jeremy Barnes"],"pdf_url":"https://arxiv.org/pdf/2412.10095v1.pdf","comment":"Vardial 2025 NorSID Shared Task"},{"id":"http://arxiv.org/abs/2412.09612v2","updated":"2024-12-13T12:27:52Z","published":"2024-12-12T18:59:40Z","title":"Olympus: A Universal Task Router for Computer Vision Tasks","summary":"  We introduce Olympus, a new approach that transforms Multimodal Large\nLanguage Models (MLLMs) into a unified framework capable of handling a wide\narray of computer vision tasks. Utilizing a controller MLLM, Olympus delegates\nover 20 specialized tasks across images, videos, and 3D objects to dedicated\nmodules. This instruction-based routing enables complex workflows through\nchained actions without the need for training heavy generative models. Olympus\neasily integrates with existing MLLMs, expanding their capabilities with\ncomparable performance. Experimental results demonstrate that Olympus achieves\nan average routing accuracy of 94.75% across 20 tasks and precision of 91.82%\nin chained action scenarios, showcasing its effectiveness as a universal task\nrouter that can solve a diverse range of computer vision tasks. Project page:\nhttp://yuanze-lin.me/Olympus_page/\n","authors":["Yuanze Lin","Yunsheng Li","Dongdong Chen","Weijian Xu","Ronald Clark","Philip H. S. Torr"],"pdf_url":"https://arxiv.org/pdf/2412.09612v2.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2410.21013v2","updated":"2024-12-13T12:27:37Z","published":"2024-10-28T13:36:46Z","title":"Frequency matters: Modeling irregular morphological patterns in Spanish\n  with Transformers","summary":"  The present paper evaluates the learning behaviour of a transformer-based\nneural network with regard to an irregular inflectional paradigm. We apply the\nparadigm cell filling problem to irregular patterns. We approach this problem\nusing the morphological reinflection task and model it as a character\nsequence-to-sequence learning problem. The test case under investigation are\nirregular verbs in Spanish. Besides many regular verbs in Spanish L-shaped\nverbs the first person singular indicative stem irregularly matches the\nsubjunctive paradigm, while other indicative forms remain unaltered. We examine\nthe role of frequency during learning and compare models under differing input\nfrequency conditions. We train the model on a corpus of Spanish with a\nrealistic distribution of regular and irregular verbs to compare it with models\ntrained on input with augmented distributions of (ir)regular words. We explore\nhow the neural models learn this L-shaped pattern using post-hoc analyses. Our\nexperiments show that, across frequency conditions, the models are surprisingly\ncapable of learning the irregular pattern. Furthermore, our post-hoc analyses\nreveal the possible sources of errors. All code and data are available at\n\\url{https://anonymous.4open.science/r/modeling_spanish_acl-7567/} under MIT\nlicense.\n","authors":["Akhilesh Kakolu Ramarao","Kevin Tang","Dinah Baer-Henney"],"pdf_url":"https://arxiv.org/pdf/2410.21013v2.pdf","comment":"Typos and grammatical corrections"},{"id":"http://arxiv.org/abs/2412.10079v1","updated":"2024-12-13T12:13:19Z","published":"2024-12-13T12:13:19Z","title":"Lost in the Middle, and In-Between: Enhancing Language Models' Ability\n  to Reason Over Long Contexts in Multi-Hop QA","summary":"  Previous work finds that recent long-context language models fail to make\nequal use of information in the middle of their inputs, preferring pieces of\ninformation located at the tail ends which creates an undue bias in situations\nwhere we would like models to be equally capable of using different parts of\nthe input. Thus far, the problem has mainly only been considered in settings\nwith single pieces of critical information, leading us to question what happens\nwhen multiple necessary pieces of information are spread out over the inputs.\nHere, we demonstrate the effects of the \"lost in the middle\" problem in the\nmulti-hop question answering setting -- in which multiple reasoning \"hops\" over\ndisconnected documents are required -- and show that performance degrades not\nonly with respect to the distance of information from the edges of the context,\nbut also between pieces of information. Additionally, we experiment with means\nof alleviating the problem by reducing superfluous document contents through\nknowledge graph triple extraction and summarization, and prompting models to\nreason more thoroughly using chain-of-thought prompting.\n","authors":["George Arthur Baker","Ankush Raut","Sagi Shaier","Lawrence E Hunter","Katharina von der Wense"],"pdf_url":"https://arxiv.org/pdf/2412.10079v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09383v2","updated":"2024-12-13T12:08:28Z","published":"2024-12-12T15:50:55Z","title":"Neural Text Normalization for Luxembourgish using Real-Life Variation\n  Data","summary":"  Orthographic variation is very common in Luxembourgish texts due to the\nabsence of a fully-fledged standard variety. Additionally, developing NLP tools\nfor Luxembourgish is a difficult task given the lack of annotated and parallel\ndata, which is exacerbated by ongoing standardization. In this paper, we\npropose the first sequence-to-sequence normalization models using the ByT5 and\nmT5 architectures with training data obtained from word-level real-life\nvariation data. We perform a fine-grained, linguistically-motivated evaluation\nto test byte-based, word-based and pipeline-based models for their strengths\nand weaknesses in text normalization. We show that our sequence model using\nreal-life variation data is an effective approach for tailor-made normalization\nin Luxembourgish.\n","authors":["Anne-Marie Lutgen","Alistair Plum","Christoph Purschke","Barbara Plank"],"pdf_url":"https://arxiv.org/pdf/2412.09383v2.pdf","comment":"Accepted at VarDial 2025"},{"id":"http://arxiv.org/abs/2412.01408v3","updated":"2024-12-13T11:59:06Z","published":"2024-12-02T11:51:19Z","title":"Towards Cross-Lingual Audio Abuse Detection in Low-Resource Settings\n  with Few-Shot Learning","summary":"  Online abusive content detection, particularly in low-resource settings and\nwithin the audio modality, remains underexplored. We investigate the potential\nof pre-trained audio representations for detecting abusive language in\nlow-resource languages, in this case, in Indian languages using Few Shot\nLearning (FSL). Leveraging powerful representations from models such as Wav2Vec\nand Whisper, we explore cross-lingual abuse detection using the ADIMA dataset\nwith FSL. Our approach integrates these representations within the\nModel-Agnostic Meta-Learning (MAML) framework to classify abusive language in\n10 languages. We experiment with various shot sizes (50-200) evaluating the\nimpact of limited data on performance. Additionally, a feature visualization\nstudy was conducted to better understand model behaviour. This study highlights\nthe generalization ability of pre-trained models in low-resource scenarios and\noffers valuable insights into detecting abusive language in multilingual\ncontexts.\n","authors":["Aditya Narayan Sankaran","Reza Farahbakhsh","Noel Crespi"],"pdf_url":"https://arxiv.org/pdf/2412.01408v3.pdf","comment":"Accepted as part of the proceedings of COLING 2025"},{"id":"http://arxiv.org/abs/2409.16667v3","updated":"2024-12-13T11:50:50Z","published":"2024-09-25T06:54:29Z","title":"A Character-Centric Creative Story Generation via Imagination","summary":"  Creative story generation has long been a goal of NLP research. While\nexisting methodologies have aimed to generate long and coherent stories, they\nfall significantly short of human capabilities in terms of diversity and\ncharacter depth. To address this, we introduce a novel story generation\nframework called CCI (Character-centric Creative story generation via\nImagination). CCI features two modules for creative story generation: IG\n(Image-Guided Imagination) and MW (Multi-Writer model). In the IG module, we\nutilize a text-to-image model to create visual representations of key story\nelements, such as characters, backgrounds, and main plots, in a more novel and\nconcrete manner than text-only approaches. The MW module uses these story\nelements to generate multiple persona-description candidates and selects the\nbest one to insert into the story, thereby enhancing the richness and depth of\nthe narrative. We compared the stories generated by CCI and baseline models\nthrough statistical analysis, as well as human and LLM evaluations. The results\nshowed that the IG and MW modules significantly improve various aspects of the\nstories' creativity. Furthermore, our framework enables interactive multi-modal\nstory generation with users, opening up new possibilities for human-LLM\nintegration in cultural development. Project page : https://www.2024cci.p-e.kr/\n","authors":["Kyeongman Park","Minbeom Kim","Kyomin Jung"],"pdf_url":"https://arxiv.org/pdf/2409.16667v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10056v1","updated":"2024-12-13T11:38:10Z","published":"2024-12-13T11:38:10Z","title":"GAOKAO-Eval: Does high scores truly reflect strong capabilities in LLMs?","summary":"  Large Language Models (LLMs) are commonly evaluated using human-crafted\nbenchmarks, under the premise that higher scores implicitly reflect stronger\nhuman-like performance. However, there is growing concern that LLMs may ``game\"\nthese benchmarks due to data leakage, achieving high scores while struggling\nwith tasks simple for humans. To substantively address the problem, we create\nGAOKAO-Eval, a comprehensive benchmark based on China's National College\nEntrance Examination (Gaokao), and conduct ``closed-book\" evaluations for\nrepresentative models released prior to Gaokao. Contrary to prevailing\nconsensus, even after addressing data leakage and comprehensiveness,\nGAOKAO-Eval reveals that high scores still fail to truly reflect human-aligned\ncapabilities. To better understand this mismatch, We introduce the Rasch model\nfrom cognitive psychology to analyze LLM scoring patterns and identify two key\ndiscrepancies: 1) anomalous consistent performance across various question\ndifficulties, and 2) high variance in performance on questions of similar\ndifficulty. In addition, We identified inconsistent grading of LLM-generated\nanswers among teachers and recurring mistake patterns. we find that the\nphenomenons are well-grounded in the motivations behind OpenAI o1, and o1's\nreasoning-as-difficulties can mitigate the mismatch. These results show that\nGAOKAO-Eval can reveal limitations in LLM capabilities not captured by current\nbenchmarks and highlight the need for more LLM-aligned difficulty analysis.\n","authors":["Zhikai Lei","Tianyi Liang","Hanglei Hu","Jin Zhang","Yunhua Zhou","Yunfan Shao","Linyang Li","Chenchui Li","Changbo Wang","Hang Yan","Qipeng Guo"],"pdf_url":"https://arxiv.org/pdf/2412.10056v1.pdf","comment":"10 pages, 13 figures"},{"id":"http://arxiv.org/abs/2412.10054v1","updated":"2024-12-13T11:35:00Z","published":"2024-12-13T11:35:00Z","title":"Unsupervised Named Entity Disambiguation for Low Resource Domains","summary":"  In the ever-evolving landscape of natural language processing and information\nretrieval, the need for robust and domain-specific entity linking algorithms\nhas become increasingly apparent. It is crucial in a considerable number of\nfields such as humanities, technical writing and biomedical sciences to enrich\ntexts with semantics and discover more knowledge. The use of Named Entity\nDisambiguation (NED) in such domains requires handling noisy texts, low\nresource settings and domain-specific KBs. Existing approaches are mostly\ninappropriate for such scenarios, as they either depend on training data or are\nnot flexible enough to work with domain-specific KBs. Thus in this work, we\npresent an unsupervised approach leveraging the concept of Group Steiner Trees\n(GST), which can identify the most relevant candidates for entity\ndisambiguation using the contextual similarities across candidate entities for\nall the mentions present in a document. We outperform the state-of-the-art\nunsupervised methods by more than 40\\% (in avg.) in terms of Precision@1 across\nvarious domain-specific datasets.\n","authors":["Debarghya Datta","Soumajit Pramanik"],"pdf_url":"https://arxiv.org/pdf/2412.10054v1.pdf","comment":"Accepted in EMNLP-2024"},{"id":"http://arxiv.org/abs/2410.15633v2","updated":"2024-12-13T11:16:57Z","published":"2024-10-21T04:30:53Z","title":"GATEAU: Selecting Influential Sample for Long Context Alignment","summary":"  Aligning large language models to handle instructions with extremely long\ncontexts has yet to be fully investigated. Previous studies attempt to scale up\nthe available data volume by synthesizing long instruction-following samples,\nas constructing such a dataset tends to be challenging for annotators. However,\na lack of a well-defined strategy for ensuring data quality may introduce\nlow-quality samples and restrict the model performance. Thus, we propose\nGATEAU, a novel framework to address the unique challenge of long context\nalignment by identifying the influential samples enriched with long-range\ndependency relations. Specifically, GATEAU measures the long-range dependencies\nfrom two essential aspects: the difficulty of generating target responses due\nto the long-range dependencies, and the difficulty of understanding long inputs\ndue to such dependencies. Comprehensive experiments indicate that GATEAU\neffectively identifies influential samples and the model trained on these\nselected samples exhibits better instruction-following and long-context\nunderstanding capabilities.\n","authors":["Shuzheng Si","Haozhe Zhao","Gang Chen","Yunshui Li","Kangyang Luo","Chuancheng Lv","Kaikai An","Fanchao Qi","Baobao Chang","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2410.15633v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.03536v3","updated":"2024-12-13T10:55:37Z","published":"2024-07-03T22:45:36Z","title":"Social Bias in Large Language Models For Bangla: An Empirical Study on\n  Gender and Religious Bias","summary":"  The rapid growth of Large Language Models (LLMs) has put forward the study of\nbiases as a crucial field. It is important to assess the influence of different\ntypes of biases embedded in LLMs to ensure fair use in sensitive fields.\nAlthough there have been extensive works on bias assessment in English, such\nefforts are rare and scarce for a major language like Bangla. In this work, we\nexamine two types of social biases in LLM generated outputs for Bangla\nlanguage. Our main contributions in this work are: (1) bias studies on two\ndifferent social biases for Bangla, (2) a curated dataset for bias measurement\nbenchmarking and (3) testing two different probing techniques for bias\ndetection in the context of Bangla. This is the first work of such kind\ninvolving bias assessment of LLMs for Bangla to the best of our knowledge. All\nour code and resources are publicly available for the progress of bias related\nresearch in Bangla NLP.\n","authors":["Jayanta Sadhu","Maneesha Rani Saha","Rifat Shahriyar"],"pdf_url":"https://arxiv.org/pdf/2407.03536v3.pdf","comment":"Accepted at The First Workshop on Language Models for Low-Resource\n  Languages (LoResLM) at COLING 2025"},{"id":"http://arxiv.org/abs/2402.13125v2","updated":"2024-12-13T10:48:13Z","published":"2024-02-20T16:38:33Z","title":"TreeEval: Benchmark-Free Evaluation of Large Language Models through\n  Tree Planning","summary":"  Recently, numerous new benchmarks have been established to evaluate the\nperformance of large language models (LLMs) via either computing a holistic\nscore or employing another LLM as a judge. However, these approaches suffer\nfrom data leakage due to the open access of the benchmark and inflexible\nevaluation process. To address this issue, we introduce $\\textbf{TreeEval}$, a\nbenchmark-free evaluation method for LLMs that let a high-performance LLM host\nan irreproducible evaluation session and essentially avoids the data leakage.\nMoreover, this LLM performs as an examiner to raise up a series of questions\nunder a topic with a tree planing strategy, which considers the current\nevaluation status to decide the next question generation and ensures the\ncompleteness and efficiency of the evaluation process. We evaluate $6$ models\nof different parameter sizes, including $7$B, $13$B, and $33$B, and ultimately\nachieved the highest correlation coefficient with AlpacaEval2.0 using only\naround $45$ questions. We also conduct more analysis to show the robustness and\nreliability of TreeEval. Our code can be accessed via the provided\nhttps://github.com/Ashura5/TreeEval.\n","authors":["Xiang Li","Yunshi Lan","Chao Yang"],"pdf_url":"https://arxiv.org/pdf/2402.13125v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06175v2","updated":"2024-12-13T10:11:31Z","published":"2024-11-09T13:17:39Z","title":"Clustering Algorithms and RAG Enhancing Semi-Supervised Text\n  Classification with Large LLMs","summary":"  This paper introduces a novel semi-supervised learning framework specifically\ndesigned for text classification tasks, effectively addressing the challenge of\nvast datasets with limited labeled examples. By integrating multi-level\nsimilarity based data augmentation techniques from Retrieval-Augmented\nGeneration (RAG) to Large Language Model (LLM) rewriting and traditional word\nsubstitution-we constructed an intelligent augmentation pipeline. This\nframework innovatively employs the selection of representative landmarks\nthrough clustering, which serve as intermediaries in the retrieval and\nrewriting processes, ensuring that the augmented data maintains a distribution\nsimilar to the original dataset. Empirical results show that even in complex\ntext document classification scenarios with over 100 categories, our method\nachieves state-of-the-art accuracies of 95.41% and 82.43% on the Reuters and\nWeb of Science datasets, respectively. These findings highlight the\neffectiveness and broad applicability of our semi-supervised learning approach\nfor text classification tasks.\n","authors":["Shan Zhong","Jiahao Zeng","Yongxin Yu","Bohong Lin"],"pdf_url":"https://arxiv.org/pdf/2411.06175v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.11112v2","updated":"2024-12-13T10:01:19Z","published":"2024-09-17T12:06:05Z","title":"Strategic Insights in Human and Large Language Model Tactics at Word\n  Guessing Games","summary":"  At the beginning of 2022, a simplistic word-guessing game took the world by\nstorm and was further adapted to many languages beyond the original English\nversion. In this paper, we examine the strategies of daily word-guessing game\nplayers that have evolved during a period of over two years. A survey gathered\nfrom 25% of frequent players reveals their strategies and motivations for\ncontinuing the daily journey. We also explore the capability of several popular\nopen-access large language model systems and open-source models at\ncomprehending and playing the game in two different languages. Results\nhighlight the struggles of certain models to maintain correct guess length and\ngenerate repetitions, as well as hallucinations of non-existent words and\ninflections.\n","authors":["Matīss Rikters","Sanita Reinsone"],"pdf_url":"https://arxiv.org/pdf/2409.11112v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10008v1","updated":"2024-12-13T09:47:26Z","published":"2024-12-13T09:47:26Z","title":"Automated Collection of Evaluation Dataset for Semantic Search in\n  Low-Resource Domain Language","summary":"  Domain-specific languages that use a lot of specific terminology often fall\ninto the category of low-resource languages. Collecting test datasets in a\nnarrow domain is time-consuming and requires skilled human resources with\ndomain knowledge and training for the annotation task. This study addresses the\nchallenge of automated collecting test datasets to evaluate semantic search in\nlow-resource domain-specific German language of the process industry. Our\napproach proposes an end-to-end annotation pipeline for automated query\ngeneration to the score reassessment of query-document pairs. To overcome the\nlack of text encoders trained in the German chemistry domain, we explore a\nprinciple of an ensemble of \"weak\" text encoders trained on common knowledge\ndatasets. We combine individual relevance scores from diverse models to\nretrieve document candidates and relevance scores generated by an LLM, aiming\nto achieve consensus on query-document alignment. Evaluation results\ndemonstrate that the ensemble method significantly improves alignment with\nhuman-assigned relevance scores, outperforming individual models in both\ninter-coder agreement and accuracy metrics. These findings suggest that\nensemble learning can effectively adapt semantic search systems for\nspecialized, low-resource languages, offering a practical solution to resource\nlimitations in domain-specific contexts.\n","authors":["Anastasia Zhukova","Christian E. Matt","Bela Gipp"],"pdf_url":"https://arxiv.org/pdf/2412.10008v1.pdf","comment":"accepted in the First Workshop on Language Models for Low-Resource\n  Languages (LoResLM) co-located with the 31st International Conference on\n  Computational Linguistics (COLING 2025)"},{"id":"http://arxiv.org/abs/2412.10006v1","updated":"2024-12-13T09:45:30Z","published":"2024-12-13T09:45:30Z","title":"The role of inhibitory control in garden-path sentence processing: A\n  Chinese-English bilingual perspective","summary":"  In reading garden-path sentences, people must resolve competing\ninterpretations, though initial misinterpretations can linger despite\nreanalysis. This study examines the role of inhibitory control (IC) in managing\nthese misinterpretations among Chinese-English bilinguals. Using self-paced\nreading tasks, we investigated how IC influences recovery from garden-path\nsentences in Chinese (L1) and its interaction with language proficiency during\nEnglish (L2) processing. Results indicate that IC does not affect garden-path\nrecovery in Chinese, suggesting reliance on semantic context may reduce the\nneed for IC. In contrast, findings for English L2 learners reveal a complex\nrelationship between language proficiency and IC: Participants with low L2\nproficiency but high IC showed lingering misinterpretations, while those with\nhigh proficiency exhibited none. These results support and extend the Model of\nCognitive Control (Ness et al., 2023). Moreover, our comparison of three Stroop\ntask versions identifies L1 colour-word Stroop task as the preferred measure of\nIC in bilingual research.\n","authors":["Xiaohui Rao","Haoze Li","Xiaofang Lin","Lijuan Liang"],"pdf_url":"https://arxiv.org/pdf/2412.10006v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09318v2","updated":"2024-12-13T09:30:36Z","published":"2024-12-12T14:43:03Z","title":"Benchmarking LLMs for Mimicking Child-Caregiver Language in Interaction","summary":"  LLMs can generate human-like dialogues, yet their ability to simulate early\nchild-adult interactions remains largely unexplored. In this paper, we examined\nhow effectively LLMs can capture the distinctive features of child-caregiver\nlanguage in interaction, using both static and interactive benchmarking\nmethods. We found that state-of-the-art LLMs like Llama 3 and GPT-4o can\napproximate child-caregiver dialogues at the word and utterance level, but they\nstruggle to reproduce the child and caregiver's discursive patterns, exaggerate\nalignment, and fail to reach the level of diversity shown by humans. The\nbroader goal of this work is to initiate the development of a comprehensive\nbenchmark for LLMs in child-oriented applications.\n","authors":["Jing Liu","Abdellah Fourtassi"],"pdf_url":"https://arxiv.org/pdf/2412.09318v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09993v1","updated":"2024-12-13T09:29:27Z","published":"2024-12-13T09:29:27Z","title":"A Comparative Study of LLMs, NMT Models, and Their Combination in\n  Persian-English Idiom Translation","summary":"  Large language models (LLMs) have shown superior capabilities in translating\nfigurative language compared to neural machine translation (NMT) systems.\nHowever, the impact of different prompting methods and LLM-NMT combinations on\nidiom translation has yet to be thoroughly investigated. This paper introduces\ntwo parallel datasets of sentences containing idiomatic expressions for\nPersian$\\rightarrow$English and English$\\rightarrow$Persian translations, with\nPersian idioms sampled from our PersianIdioms resource, a collection of 2,200\nidioms and their meanings. Using these datasets, we evaluate various open- and\nclosed-source LLMs, NMT models, and their combinations. Translation quality is\nassessed through idiom translation accuracy and fluency. We also find that\nautomatic evaluation methods like LLM-as-a-judge, BLEU and BERTScore are\neffective for comparing different aspects of model performance. Our experiments\nreveal that Claude-3.5-Sonnet delivers outstanding results in both translation\ndirections. For English$\\rightarrow$Persian, combining weaker LLMs with Google\nTranslate improves results, while Persian$\\rightarrow$English translations\nbenefit from single prompts for simpler models and complex prompts for advanced\nones.\n","authors":["Sara Rezaeimanesh","Faezeh Hosseini","Yadollah Yaghoobzadeh"],"pdf_url":"https://arxiv.org/pdf/2412.09993v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09990v1","updated":"2024-12-13T09:23:58Z","published":"2024-12-13T09:23:58Z","title":"Small Language Model as Data Prospector for Large Language Model","summary":"  The quality of instruction data directly affects the performance of\nfine-tuned Large Language Models (LLMs). Previously, \\cite{li2023one} proposed\n\\texttt{NUGGETS}, which identifies and selects high-quality quality data from a\nlarge dataset by identifying those individual instruction examples that can\nsignificantly improve the performance of different tasks after being learnt as\none-shot instances. In this work, we propose \\texttt{SuperNUGGETS}, an improved\nvariant of \\texttt{NUGGETS} optimised for efficiency and performance. Our\n\\texttt{SuperNUGGETS} uses a small language model (SLM) instead of a large\nlanguage model (LLM) to filter the data for outstanding one-shot instances and\nrefines the predefined set of tests. The experimental results show that the\nperformance of \\texttt{SuperNUGGETS} only decreases by 1-2% compared to\n\\texttt{NUGGETS}, but the efficiency can be increased by a factor of 58.\nCompared to the original \\texttt{NUGGETS}, our \\texttt{SuperNUGGETS} has a\nhigher utility value due to the significantly lower resource consumption.\n","authors":["Shiwen Ni","Haihong Wu","Di Yang","Qiang Qu","Hamid Alinejad-Rokny","Min Yang"],"pdf_url":"https://arxiv.org/pdf/2412.09990v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04680v2","updated":"2024-12-13T08:44:55Z","published":"2024-08-08T04:49:21Z","title":"Dynamic Fog Computing for Enhanced LLM Execution in Medical Applications","summary":"  The ability of large language models (LLMs) to transform, interpret, and\ncomprehend vast quantities of heterogeneous data presents a significant\nopportunity to enhance data-driven care delivery. However, the sensitive nature\nof protected health information (PHI) raises valid concerns about data privacy\nand trust in remote LLM platforms. In addition, the cost associated with\ncloud-based artificial intelligence (AI) services continues to impede\nwidespread adoption. To address these challenges, we propose a shift in the LLM\nexecution environment from opaque, centralized cloud providers to a\ndecentralized and dynamic fog computing architecture. By executing open-weight\nLLMs in more trusted environments, such as the user's edge device or a fog\nlayer within a local network, we aim to mitigate the privacy, trust, and\nfinancial challenges associated with cloud-based LLMs. We further present\nSpeziLLM, an open-source framework designed to facilitate rapid and seamless\nleveraging of different LLM execution layers and lowering barriers to LLM\nintegration in digital health applications. We demonstrate SpeziLLM's broad\napplicability across six digital health applications, showcasing its\nversatility in various healthcare settings.\n","authors":["Philipp Zagar","Vishnu Ravi","Lauren Aalami","Stephan Krusche","Oliver Aalami","Paul Schmiedmayer"],"pdf_url":"https://arxiv.org/pdf/2408.04680v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09957v1","updated":"2024-12-13T08:33:26Z","published":"2024-12-13T08:33:26Z","title":"Romanized to Native Malayalam Script Transliteration Using an\n  Encoder-Decoder Framework","summary":"  In this work, we present the development of a reverse transliteration model\nto convert romanized Malayalam to native script using an encoder-decoder\nframework built with attention-based bidirectional Long Short Term Memory\n(Bi-LSTM) architecture. To train the model, we have used curated and combined\ncollection of 4.3 million transliteration pairs derived from publicly available\nIndic language translitertion datasets, Dakshina and Aksharantar. We evaluated\nthe model on two different test dataset provided by IndoNLP-2025-Shared-Task\nthat contain, (1) General typing patterns and (2) Adhoc typing patterns,\nrespectively. On the Test Set-1, we obtained a character error rate (CER) of\n7.4%. However upon Test Set-2, with adhoc typing patterns, where most vowel\nindicators are missing, our model gave a CER of 22.7%.\n","authors":["Bajiyo Baiju","Kavya Manohar","Leena G Pillai","Elizabeth Sherly"],"pdf_url":"https://arxiv.org/pdf/2412.09957v1.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2404.19252v2","updated":"2024-12-13T08:12:22Z","published":"2024-04-30T04:16:55Z","title":"ViTHSD: Exploiting Hatred by Targets for Hate Speech Detection on\n  Vietnamese Social Media Texts","summary":"  The growth of social networks makes toxic content spread rapidly. Hate speech\ndetection is a task to help decrease the number of harmful comments. With the\ndiversity in the hate speech created by users, it is necessary to interpret the\nhate speech besides detecting it. Hence, we propose a methodology to construct\na system for targeted hate speech detection from online streaming texts from\nsocial media. We first introduce the ViTHSD - a targeted hate speech detection\ndataset for Vietnamese Social Media Texts. The dataset contains 10K comments,\neach comment is labeled to specific targets with three levels: clean,\noffensive, and hate. There are 5 targets in the dataset, and each target is\nlabeled with the corresponding level manually by humans with strict annotation\nguidelines. The inter-annotator agreement obtained from the dataset is 0.45 by\nCohen's Kappa index, which is indicated as a moderate level. Then, we construct\na baseline for this task by combining the Bi-GRU-LSTM-CNN with the pre-trained\nlanguage model to leverage the power of text representation of BERTology.\nFinally, we suggest a methodology to integrate the baseline model for targeted\nhate speech detection into the online streaming system for practical\napplication in preventing hateful and offensive content on social media.\n","authors":["Cuong Nhat Vo","Khanh Bao Huynh","Son T. Luu","Trong-Hop Do"],"pdf_url":"https://arxiv.org/pdf/2404.19252v2.pdf","comment":"Accepted for publication at Journal of Computational Social Science"},{"id":"http://arxiv.org/abs/2412.09946v1","updated":"2024-12-13T08:10:56Z","published":"2024-12-13T08:10:56Z","title":"Enhancing Nursing and Elderly Care with Large Language Models: An\n  AI-Driven Framework","summary":"  This paper explores the application of large language models (LLMs) in\nnursing and elderly care, focusing on AI-driven patient monitoring and\ninteraction. We introduce a novel Chinese nursing dataset and implement\nincremental pre-training (IPT) and supervised fine-tuning (SFT) techniques to\nenhance LLM performance in specialized tasks. Using LangChain, we develop a\ndynamic nursing assistant capable of real-time care and personalized\ninterventions. Experimental results demonstrate significant improvements,\npaving the way for AI-driven solutions to meet the growing demands of\nhealthcare in aging populations.\n","authors":["Qiao Sun","Jiexin Xie","Nanyang Ye","Qinying Gu","Shijie Guo"],"pdf_url":"https://arxiv.org/pdf/2412.09946v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04617v2","updated":"2024-12-13T08:05:53Z","published":"2024-10-06T20:34:03Z","title":"Evaluation of Code LLMs on Geospatial Code Generation","summary":"  Software development support tools have been studied for a long time, with\nrecent approaches using Large Language Models (LLMs) for code generation. These\nmodels can generate Python code for data science and machine learning\napplications. LLMs are helpful for software engineers because they increase\nproductivity in daily work. An LLM can also serve as a \"mentor\" for\ninexperienced software developers, and be a viable learning support.\nHigh-quality code generation with LLMs can also be beneficial in geospatial\ndata science. However, this domain poses different challenges, and code\ngeneration LLMs are typically not evaluated on geospatial tasks. Here, we show\nhow we constructed an evaluation benchmark for code generation models, based on\na selection of geospatial tasks. We categorised geospatial tasks based on their\ncomplexity and required tools. Then, we created a dataset with tasks that test\nmodel capabilities in spatial reasoning, spatial data processing, and\ngeospatial tools usage. The dataset consists of specific coding problems that\nwere manually created for high quality. For every problem, we proposed a set of\ntest scenarios that make it possible to automatically check the generated code\nfor correctness. In addition, we tested a selection of existing code generation\nLLMs for code generation in the geospatial domain. We share our dataset and\nreproducible evaluation code on a public GitHub repository, arguing that this\ncan serve as an evaluation benchmark for new LLMs in the future. Our dataset\nwill hopefully contribute to the development new models capable of solving\ngeospatial coding tasks with high accuracy. These models will enable the\ncreation of coding assistants tailored for geospatial applications.\n","authors":["Piotr Gramacki","Bruno Martins","Piotr Szymański"],"pdf_url":"https://arxiv.org/pdf/2410.04617v2.pdf","comment":"7th ACM SIGSPATIAL International Workshop on AI for Geographic\n  Knowledge Discovery (GeoAI'24)"},{"id":"http://arxiv.org/abs/2305.11626v2","updated":"2024-12-13T07:32:04Z","published":"2023-05-19T12:09:49Z","title":"CCT-Code: Cross-Consistency Training for Multilingual Clone Detection\n  and Code Search","summary":"  We consider the well-known and important tasks of clone detection and\ninformation retrieval for source code. The most standard setup is to search\nclones inside the same language code snippets. But it is also useful to find\ncode snippets with identical behaviour in different programming languages.\nNevertheless multi- and cross-lingual clone detection has been little studied\nin literature. We present a novel training procedure, cross-consistency\ntraining (CCT) leveraging cross-lingual similarity, that we apply to train\nlanguage models on source code in various programming languages. We show that\nthis training is effective both for encoder- and decoder-based models. The\ntrained encoder-based CCT-LM model achieves a new state of the art on POJ-104\n(monolingual C++ clone detection benchmark) with 96.73\\% MAP and AdvTest\n(monolingual Python code search benchmark) with 47.18\\% MRR. The decoder-based\nCCT-LM model shows comparable performance in these tasks. In addition, we\nformulate the multi- and cross-lingual clone detection problem and present XCD,\na new benchmark dataset produced from CodeForces submissions.\n","authors":["Anton Tikhonov","Nikita Sorokin","Dmitry Abulkhanov","Irina Piontkovskaya","Sergey Nikolenko","Valentin Malykh"],"pdf_url":"https://arxiv.org/pdf/2305.11626v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09925v1","updated":"2024-12-13T07:27:42Z","published":"2024-12-13T07:27:42Z","title":"Simulating Hard Attention Using Soft Attention","summary":"  We study conditions under which transformers using soft attention can\nsimulate hard attention, that is, effectively focus all attention on a subset\nof positions. First, we examine several variants of linear temporal logic,\nwhose formulas have been previously been shown to be computable using hard\nattention transformers. We demonstrate how soft attention transformers can\ncompute formulas of these logics using unbounded positional embeddings or\ntemperature scaling. Second, we demonstrate how temperature scaling allows\nsoftmax transformers to simulate a large subclass of average-hard attention\ntransformers, those that have what we call the uniform-tieless property.\n","authors":["Andy Yang","Lena Strobl","David Chiang","Dana Angluin"],"pdf_url":"https://arxiv.org/pdf/2412.09925v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09922v1","updated":"2024-12-13T07:22:13Z","published":"2024-12-13T07:22:13Z","title":"Low-Resource Fast Text Classification Based on Intra-Class and\n  Inter-Class Distance Calculation","summary":"  In recent years, text classification methods based on neural networks and\npre-trained models have gained increasing attention and demonstrated excellent\nperformance. However, these methods still have some limitations in practical\napplications: (1) They typically focus only on the matching similarity between\nsentences. However, there exists implicit high-value information both within\nsentences of the same class and across different classes, which is very crucial\nfor classification tasks. (2) Existing methods such as pre-trained language\nmodels and graph-based approaches often consume substantial memory for training\nand text-graph construction. (3) Although some low-resource methods can achieve\ngood performance, they often suffer from excessively long processing times. To\naddress these challenges, we propose a low-resource and fast text\nclassification model called LFTC. Our approach begins by constructing a\ncompressor list for each class to fully mine the regularity information within\nintra-class data. We then remove redundant information irrelevant to the target\nclassification to reduce processing time. Finally, we compute the similarity\ndistance between text pairs for classification. We evaluate LFTC on 9 publicly\navailable benchmark datasets, and the results demonstrate significant\nimprovements in performance and processing time, especially under limited\ncomputational and data resources, highlighting its superior advantages.\n","authors":["Yanxu Mao","Peipei Liu","Tiehan Cui","Congying Liu","Datao You"],"pdf_url":"https://arxiv.org/pdf/2412.09922v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.13748v2","updated":"2024-12-13T06:55:46Z","published":"2024-06-19T18:01:08Z","title":"Learn and Unlearn in Multilingual LLMs","summary":"  This paper investigates the propagation of harmful information in\nmultilingual large language models (LLMs) and evaluates the efficacy of various\nunlearning methods. We demonstrate that fake information, regardless of the\nlanguage it is in, once introduced into these models through training data, can\nspread across different languages, compromising the integrity and reliability\nof the generated content. Our findings reveal that standard unlearning\ntechniques, which typically focus on English data, are insufficient in\nmitigating the spread of harmful content in multilingual contexts and could\ninadvertently reinforce harmful content across languages. We show that only by\naddressing harmful responses in both English and the original language of the\nharmful data can we effectively eliminate generations for all languages. This\nunderscores the critical need for comprehensive unlearning strategies that\nconsider the multilingual nature of modern LLMs to enhance their safety and\nreliability across diverse linguistic landscapes.\n","authors":["Taiming Lu","Philipp Koehn"],"pdf_url":"https://arxiv.org/pdf/2406.13748v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09906v1","updated":"2024-12-13T06:45:26Z","published":"2024-12-13T06:45:26Z","title":"Enhancing the Reasoning Capabilities of Small Language Models via\n  Solution Guidance Fine-Tuning","summary":"  Large language models (LLMs) have demonstrated remarkable performance across\na wide range of tasks. Advances in prompt engineering and fine-tuning\ntechniques have further enhanced their ability to address complex reasoning\nchallenges. However, these advanced capabilities are often exclusive to models\nexceeding 100 billion parameters. Although Chain-of-Thought (CoT) fine-tuning\nmethods have been explored for smaller models (under 10 billion parameters),\nthey typically depend on extensive CoT training data, which can introduce\ninconsistencies and limit effectiveness in low-data settings. To overcome these\nlimitations, this paper introduce a new reasoning strategy Solution Guidance\n(SG) and a plug-and-play training paradigm Solution-Guidance Fine-Tuning (SGFT)\nfor enhancing the reasoning capabilities of small language models. SG focuses\non problem understanding and decomposition at the semantic and logical levels,\nrather than specific computations, which can effectively improve the SLMs'\ngeneralization and reasoning abilities. With only a small amount of SG training\ndata, SGFT can fine-tune a SLM to produce accurate problem-solving guidances,\nwhich can then be flexibly fed to any SLM as prompts, enabling it to generate\ncorrect answers directly. Experimental results demonstrate that our method\nsignificantly improves the performance of SLMs on various reasoning tasks,\nenhancing both their practicality and efficiency within resource-constrained\nenvironments.\n","authors":["Jing Bi","Yuting Wu","Weiwei Xing","Zhenjie Wei"],"pdf_url":"https://arxiv.org/pdf/2412.09906v1.pdf","comment":"11 pages, 4 figures, to be published in The 31st International\n  Conference on Computational Linguistics (COLING 2025)"},{"id":"http://arxiv.org/abs/2412.08038v2","updated":"2024-12-13T06:39:00Z","published":"2024-12-11T02:37:32Z","title":"Bootstrapping Heterogeneous Graph Representation Learning via Large\n  Language Models: A Generalized Approach","summary":"  Graph representation learning methods are highly effective in handling\ncomplex non-Euclidean data by capturing intricate relationships and features\nwithin graph structures. However, traditional methods face challenges when\ndealing with heterogeneous graphs that contain various types of nodes and edges\ndue to the diverse sources and complex nature of the data. Existing\nHeterogeneous Graph Neural Networks (HGNNs) have shown promising results but\nrequire prior knowledge of node and edge types and unified node feature\nformats, which limits their applicability. Recent advancements in graph\nrepresentation learning using Large Language Models (LLMs) offer new solutions\nby integrating LLMs' data processing capabilities, enabling the alignment of\nvarious graph representations. Nevertheless, these methods often overlook\nheterogeneous graph data and require extensive preprocessing. To address these\nlimitations, we propose a novel method that leverages the strengths of both LLM\nand GNN, allowing for the processing of graph data with any format and type of\nnodes and edges without the need for type information or special preprocessing.\nOur method employs LLM to automatically summarize and classify different data\nformats and types, aligns node features, and uses a specialized GNN for\ntargeted learning, thus obtaining effective graph representations for\ndownstream tasks. Theoretical analysis and experimental validation have\ndemonstrated the effectiveness of our method.\n","authors":["Hang Gao","Chenhao Zhang","Fengge Wu","Junsuo Zhao","Changwen Zheng","Huaping Liu"],"pdf_url":"https://arxiv.org/pdf/2412.08038v2.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2412.09900v1","updated":"2024-12-13T06:35:55Z","published":"2024-12-13T06:35:55Z","title":"Analyzing Fairness of Computer Vision and Natural Language Processing\n  Models","summary":"  Machine learning (ML) algorithms play a crucial role in decision making\nacross diverse fields such as healthcare, finance, education, and law\nenforcement. Despite their widespread adoption, these systems raise ethical and\nsocial concerns due to potential biases and fairness issues. This study focuses\non evaluating and improving the fairness of Computer Vision and Natural\nLanguage Processing (NLP) models applied to unstructured datasets, emphasizing\nhow biased predictions can reinforce existing systemic inequalities. A publicly\navailable dataset from Kaggle was utilized to simulate a practical scenario for\nexamining fairness in ML workflows. To address and mitigate biases, the study\nemployed two leading fairness libraries: Fairlearn by Microsoft, and AIF360 by\nIBM. These tools offer comprehensive frameworks for fairness analysis,\nincluding metrics evaluation, result visualization, and bias mitigation\ntechniques. The research aims to measure bias levels in ML models, compare the\neffectiveness of these fairness libraries, and provide actionable\nrecommendations for practitioners. The results demonstrate that each library\npossesses distinct strengths and limitations in evaluating and mitigating\nfairness. By systematically analyzing these tools, the study contributes\nvaluable insights to the growing field of ML fairness, offering practical\nguidance for integrating fairness solutions into real world applications. This\nresearch underscores the importance of building more equitable and responsible\nmachine learning systems.\n","authors":["Ahmed Rashed","Abdelkrim Kallich","Mohamed Eltayeb"],"pdf_url":"https://arxiv.org/pdf/2412.09900v1.pdf","comment":"16 pages, 1 table, 4 figures"},{"id":"http://arxiv.org/abs/2412.09263v2","updated":"2024-12-13T06:28:11Z","published":"2024-12-12T13:21:09Z","title":"First Train to Generate, then Generate to Train: UnitedSynT5 for\n  Few-Shot NLI","summary":"  Natural Language Inference (NLI) tasks require identifying the relationship\nbetween sentence pairs, typically classified as entailment, contradiction, or\nneutrality. While the current state-of-the-art (SOTA) model, Entailment\nFew-Shot Learning (EFL), achieves a 93.1% accuracy on the Stanford Natural\nLanguage Inference (SNLI) dataset, further advancements are constrained by the\ndataset's limitations. To address this, we propose a novel approach leveraging\nsynthetic data augmentation to enhance dataset diversity and complexity. We\npresent UnitedSynT5, an advanced extension of EFL that leverages a T5-based\ngenerator to synthesize additional premise-hypothesis pairs, which are\nrigorously cleaned and integrated into the training data. These augmented\nexamples are processed within the EFL framework, embedding labels directly into\nhypotheses for consistency. We train a GTR-T5-XL model on this expanded\ndataset, achieving a new benchmark of 94.7% accuracy on the SNLI dataset, 94.0%\naccuracy on the E-SNLI dataset, and 92.6% accuracy on the MultiNLI dataset,\nsurpassing the previous SOTA models. This research demonstrates the potential\nof synthetic data augmentation in improving NLI models, offering a path forward\nfor further advancements in natural language understanding tasks.\n","authors":["Sourav Banerjee","Anush Mahajan","Ayushi Agarwal","Eishkaran Singh"],"pdf_url":"https://arxiv.org/pdf/2412.09263v2.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2406.00627v4","updated":"2024-12-13T06:13:08Z","published":"2024-06-02T06:09:56Z","title":"Role-playing Prompt Framework: Generation and Evaluation","summary":"  Large language models (LLMs) exhibit impressive proficiency in natural\nlanguage generation, understanding user instructions, and emulating human-like\nlanguage use, which has led to significant interest in their application to\nrole-playing scenarios. However, the manual collection of role-specific script\ndata and the evaluation of model performance are resource-intensive processes.\nThis paper introduces a prompt-based framework designed to leverage GPT's\ncapabilities for the generation of role-playing dialogue datasets and the\nevaluation of role-playing performance. To validate the effectiveness of the\nGPT-based generation and evaluation, we further incorporate the recall-oriented\nRouge-L metric, providing an additional quantitative measure of performance.\n","authors":["Xun Liu","Zhengwei Ni"],"pdf_url":"https://arxiv.org/pdf/2406.00627v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09884v1","updated":"2024-12-13T05:52:37Z","published":"2024-12-13T05:52:37Z","title":"Benchmarking Table Comprehension In The Wild","summary":"  Large Language Models (LLMs), while being increasingly dominant on a myriad\nof knowledge-intensive activities, have only had limited success understanding\nlengthy table-text mixtures, such as academic papers and financial reports.\nRecent advances of long-context LLMs have opened up new possibilities for this\nfield. Nonetheless, we identify two roadblocks: (1) Prior benchmarks of table\nquestion answering (TableQA) have focused on isolated tables without context,\nmaking it hard to evaluate models in real-world scenarios. (2) Prior benchmarks\nhave focused on some narrow skill sets of table comprehension such as table\nrecognition, data manipulation/calculation, table summarization etc., while a\nskilled human employs those skills collectively. In this work, we introduce\nTableQuest, a new benchmark designed to evaluate the holistic table\ncomprehension capabilities of LLMs in the natural table-rich context of\nfinancial reports. We employ a rigorous data processing and filtering procedure\nto ensure that the question-answer pairs are logical, reasonable, and diverse.\nWe experiment with 7 state-of-the-art models, and find that despite reasonable\naccuracy in locating facts, they often falter when required to execute more\nsophisticated reasoning or multi-step calculations. We conclude with a\nqualitative study of the failure modes and discuss the challenges of\nconstructing a challenging benchmark. We make the evaluation data, judging\nprocedure and results of this study publicly available to facilitate research\nin this field.\n","authors":["Yikang Pan","Yi Zhu","Rand Xie","Yizhi Liu"],"pdf_url":"https://arxiv.org/pdf/2412.09884v1.pdf","comment":"Accepted at TRL Workshop@Neurips 2024. Link to data\n  https://github.com/boson-ai/Table_eval_public"},{"id":"http://arxiv.org/abs/2412.09879v1","updated":"2024-12-13T05:50:22Z","published":"2024-12-13T05:50:22Z","title":"On the Limit of Language Models as Planning Formalizers","summary":"  Large Language Models have been shown to fail to create executable and\nverifiable plans in grounded environments. An emerging line of work shows\nsuccess in using LLM as a formalizer to generate a formal representation (e.g.,\nPDDL) of the planning domain, which can be deterministically solved to find a\nplan. We systematically evaluate this methodology while bridging some major\ngaps. While previous work only generates a partial PDDL representation given\ntemplated and thus unrealistic environment descriptions, we generate the\ncomplete representation given descriptions of various naturalness levels. Among\nan array of observations critical to improve LLMs' formal planning ability, we\nnote that large enough models can effectively formalize descriptions as PDDL,\noutperforming those directly generating plans, while being robust to lexical\nperturbation. As the descriptions become more natural-sounding, we observe a\ndecrease in performance and provide detailed error analysis.\n","authors":["Cassie Huang","Li Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.09879v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09871v1","updated":"2024-12-13T05:33:32Z","published":"2024-12-13T05:33:32Z","title":"Byte Latent Transformer: Patches Scale Better Than Tokens","summary":"  We introduce the Byte Latent Transformer (BLT), a new byte-level LLM\narchitecture that, for the first time, matches tokenization-based LLM\nperformance at scale with significant improvements in inference efficiency and\nrobustness. BLT encodes bytes into dynamically sized patches, which serve as\nthe primary units of computation. Patches are segmented based on the entropy of\nthe next byte, allocating more compute and model capacity where increased data\ncomplexity demands it. We present the first FLOP controlled scaling study of\nbyte-level models up to 8B parameters and 4T training bytes. Our results\ndemonstrate the feasibility of scaling models trained on raw bytes without a\nfixed vocabulary. Both training and inference efficiency improve due to\ndynamically selecting long patches when data is predictable, along with\nqualitative improvements on reasoning and long tail generalization. Overall,\nfor fixed inference costs, BLT shows significantly better scaling than\ntokenization-based models, by simultaneously growing both patch and model size.\n","authors":["Artidoro Pagnoni","Ram Pasunuru","Pedro Rodriguez","John Nguyen","Benjamin Muller","Margaret Li","Chunting Zhou","Lili Yu","Jason Weston","Luke Zettlemoyer","Gargi Ghosh","Mike Lewis","Ari Holtzman","Srinivasan Iyer"],"pdf_url":"https://arxiv.org/pdf/2412.09871v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09867v1","updated":"2024-12-13T05:19:49Z","published":"2024-12-13T05:19:49Z","title":"Human-Like Embodied AI Interviewer: Employing Android ERICA in Real\n  International Conference","summary":"  This paper introduces the human-like embodied AI interviewer which integrates\nandroid robots equipped with advanced conversational capabilities, including\nattentive listening, conversational repairs, and user fluency adaptation.\nMoreover, it can analyze and present results post-interview. We conducted a\nreal-world case study at SIGDIAL 2024 with 42 participants, of whom 69%\nreported positive experiences. This study demonstrated the system's\neffectiveness in conducting interviews just like a human and marked the first\nemployment of such a system at an international conference. The demonstration\nvideo is available at https://youtu.be/jCuw9g99KuE.\n","authors":["Zi Haur Pang","Yahui Fu","Divesh Lala","Mikey Elmers","Koji Inoue","Tatsuya Kawahara"],"pdf_url":"https://arxiv.org/pdf/2412.09867v1.pdf","comment":"This paper has been accepted for demonstration presentation at\n  International Conference on Computational Linguistics (COLING 2025)"},{"id":"http://arxiv.org/abs/2401.07977v3","updated":"2024-12-13T05:19:47Z","published":"2024-01-15T21:43:46Z","title":"Towards Efficient Methods in Medical Question Answering using Knowledge\n  Graph Embeddings","summary":"  In Natural Language Processing (NLP), Machine Reading Comprehension (MRC) is\nthe task of answering a question based on a given context. To handle questions\nin the medical domain, modern language models such as BioBERT, SciBERT and even\nChatGPT are trained on vast amounts of in-domain medical corpora. However,\nin-domain pre-training is expensive in terms of time and resources. In this\npaper, we propose a resource-efficient approach for injecting domain knowledge\ninto a model without relying on such domain-specific pre-training.\n  Knowledge graphs are powerful resources for accessing medical information.\nBuilding on existing work, we introduce a method using Multi-Layer Perceptrons\n(MLPs) for aligning and integrating embeddings extracted from medical knowledge\ngraphs with the embedding spaces of pre-trained language models (LMs). The\naligned embeddings are fused with open-domain LMs BERT and RoBERTa that are\nfine-tuned for two MRC tasks, span detection (COVID-QA) and multiple-choice\nquestions (PubMedQA). We compare our method to prior techniques that rely on a\nvocabulary overlap for embedding alignment and show how our method circumvents\nthis requirement to deliver better performance. On both datasets, our method\nallows BERT/RoBERTa to either perform on par (occasionally exceeding) with\nstronger domain-specific models or show improvements in general over prior\ntechniques. With the proposed approach, we signal an alternative method to\nin-domain pre-training to achieve domain proficiency. Our code is available\nhere.\n","authors":["Saptarshi Sengupta","Connor Heaton","Suhan Cui","Soumalya Sarkar","Prasenjit Mitra"],"pdf_url":"https://arxiv.org/pdf/2401.07977v3.pdf","comment":"Accepted to the MABM workshop at IEEE BIBM 2024"},{"id":"http://arxiv.org/abs/2412.09859v1","updated":"2024-12-13T04:59:50Z","published":"2024-12-13T04:59:50Z","title":"Financial Sentiment Analysis: Leveraging Actual and Synthetic Data for\n  Supervised Fine-tuning","summary":"  The Efficient Market Hypothesis (EMH) highlights the essence of financial\nnews in stock price movement. Financial news comes in the form of corporate\nannouncements, news titles, and other forms of digital text. The generation of\ninsights from financial news can be done with sentiment analysis.\nGeneral-purpose language models are too general for sentiment analysis in\nfinance. Curated labeled data for fine-tuning general-purpose language models\nare scare, and existing fine-tuned models for sentiment analysis in finance do\nnot capture the maximum context width. We hypothesize that using actual and\nsynthetic data can improve performance. We introduce BertNSP-finance to\nconcatenate shorter financial sentences into longer financial sentences, and\nfinbert-lc to determine sentiment from digital text. The results show improved\nperformance on the accuracy and the f1 score for the financial phrasebank data\nwith $50\\%$ and $100\\%$ agreement levels.\n","authors":["Abraham Atsiwo"],"pdf_url":"https://arxiv.org/pdf/2412.09859v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.08966v3","updated":"2024-12-13T04:59:10Z","published":"2024-02-14T06:20:48Z","title":"Pretraining Vision-Language Model for Difference Visual Question\n  Answering in Longitudinal Chest X-rays","summary":"  Difference visual question answering (diff-VQA) is a challenging task that\nrequires answering complex questions based on differences between a pair of\nimages. This task is particularly important in reading chest X-ray images\nbecause radiologists often compare multiple images of the same patient taken at\ndifferent times to track disease progression and changes in its severity in\ntheir clinical practice. However, previous works focused on designing specific\nnetwork architectures for the diff-VQA task, missing opportunities to enhance\nthe model's performance using a pretrained vision-language model (VLM). Here,\nwe introduce a novel VLM called PLURAL, which is pretrained on natural and\nlongitudinal chest X-ray data for the diff-VQA task. The model is developed\nusing a step-by-step approach, starting with being pretrained on natural images\nand texts, followed by being trained using longitudinal chest X-ray data. The\nlongitudinal data consist of pairs of X-ray images, along with question-answer\nsets and radiologist's reports that describe the changes in lung abnormalities\nand diseases over time. Our experimental results show that the PLURAL model\noutperforms state-of-the-art methods not only in diff-VQA for longitudinal\nX-rays but also in conventional VQA for a single X-ray image. Through extensive\nexperiments, we demonstrate the effectiveness of the proposed VLM architecture\nand pretraining method in improving the model's performance.\n","authors":["Yeongjae Cho","Taehee Kim","Heejun Shin","Sungzoon Cho","Dongmyung Shin"],"pdf_url":"https://arxiv.org/pdf/2402.08966v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.08967v3","updated":"2024-12-13T04:44:11Z","published":"2024-01-17T04:43:21Z","title":"ReFT: Reasoning with Reinforced Fine-Tuning","summary":"  One way to enhance the reasoning capability of Large Language Models (LLMs)\nis to conduct Supervised Fine-Tuning (SFT) using Chain-of-Thought (CoT)\nannotations. This approach does not show sufficiently strong generalization\nability, however, because the training only relies on the given CoT data. In\nmath problem-solving, for example, there is usually only one annotated\nreasoning path for each question in the training data. Intuitively, it would be\nbetter for the algorithm to learn from multiple annotated reasoning paths given\na question. To address this issue, we propose a simple yet effective approach\ncalled Reinforced Fine-Tuning (ReFT) to enhance the generalizability of\nlearning LLMs for reasoning, with math problem-solving as an example. ReFT\nfirst warmups the model with SFT, and then employs on-line reinforcement\nlearning, specifically the PPO algorithm in this paper, to further fine-tune\nthe model, where an abundance of reasoning paths are automatically sampled\ngiven the question and the rewards are naturally derived from the ground-truth\nanswers. Extensive experiments on GSM8K, MathQA, and SVAMP datasets show that\nReFT significantly outperforms SFT, and the performance can be potentially\nfurther boosted by combining inference-time strategies such as majority voting\nand re-ranking. Note that ReFT obtains the improvement by learning from the\nsame training questions as SFT, without relying on extra or augmented training\nquestions. This indicates a superior generalization ability for ReFT.\n","authors":["Trung Quoc Luong","Xinbo Zhang","Zhanming Jie","Peng Sun","Xiaoran Jin","Hang Li"],"pdf_url":"https://arxiv.org/pdf/2401.08967v3.pdf","comment":"ACL 2024 main conference; adjust with reviewer comments; 13 pages"},{"id":"http://arxiv.org/abs/2412.07144v2","updated":"2024-12-13T04:05:05Z","published":"2024-12-10T03:06:28Z","title":"Political Actor Agent: Simulating Legislative System for Roll Call Votes\n  Prediction with Large Language Models","summary":"  Predicting roll call votes through modeling political actors has emerged as a\nfocus in quantitative political science and computer science. Widely used\nembedding-based methods generate vectors for legislators from diverse data sets\nto predict legislative behaviors. However, these methods often contend with\nchallenges such as the need for manually predefined features, reliance on\nextensive training data, and a lack of interpretability. Achieving more\ninterpretable predictions under flexible conditions remains an unresolved\nissue. This paper introduces the Political Actor Agent (PAA), a novel\nagent-based framework that utilizes Large Language Models to overcome these\nlimitations. By employing role-playing architectures and simulating legislative\nsystem, PAA provides a scalable and interpretable paradigm for predicting\nroll-call votes. Our approach not only enhances the accuracy of predictions but\nalso offers multi-view, human-understandable decision reasoning, providing new\ninsights into political actor behaviors. We conducted comprehensive experiments\nusing voting records from the 117-118th U.S. House of Representatives,\nvalidating the superior performance and interpretability of PAA. This study not\nonly demonstrates PAA's effectiveness but also its potential in political\nscience research.\n","authors":["Hao Li","Ruoyuan Gong","Hao Jiang"],"pdf_url":"https://arxiv.org/pdf/2412.07144v2.pdf","comment":"Accepted at AAAI 2025"},{"id":"http://arxiv.org/abs/2408.12325v3","updated":"2024-12-13T04:03:07Z","published":"2024-08-22T12:00:31Z","title":"Improving Factuality in Large Language Models via Decoding-Time\n  Hallucinatory and Truthful Comparators","summary":"  Despite their remarkable capabilities, Large Language Models (LLMs) are prone\nto generate responses that contradict verifiable facts, i.e., unfaithful\nhallucination content. Existing efforts generally focus on optimizing model\nparameters or editing semantic representations, which compromise the internal\nfactual knowledge of target LLMs. In addition, hallucinations typically exhibit\nmultifaceted patterns in downstream tasks, limiting the model's holistic\nperformance across tasks. In this paper, we propose a Comparator-driven\nDecoding-Time (CDT) framework to alleviate the response hallucination. Firstly,\nwe construct hallucinatory and truthful comparators with multi-task fine-tuning\nsamples. In this case, we present an instruction prototype-guided mixture of\nexperts strategy to enhance the ability of the corresponding comparators to\ncapture different hallucination or truthfulness patterns in distinct task\ninstructions. CDT constrains next-token predictions to factuality-robust\ndistributions by contrasting the logit differences between the target LLMs and\nthese comparators. Systematic experiments on multiple downstream tasks show\nthat our framework can significantly improve the model performance and response\nfactuality.\n","authors":["Dingkang Yang","Dongling Xiao","Jinjie Wei","Mingcheng Li","Zhaoyu Chen","Ke Li","Lihua Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.12325v3.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2412.06724v2","updated":"2024-12-13T03:43:35Z","published":"2024-12-09T18:13:27Z","title":"AutoDCWorkflow: LLM-based Data Cleaning Workflow Auto-Generation and\n  Benchmark","summary":"  We investigate the reasoning capabilities of large language models (LLMs) for\nautomatically generating data-cleaning workflows. To evaluate LLMs' ability to\ncomplete data-cleaning tasks, we implemented a pipeline for LLM-based Auto Data\nCleaning Workflow (AutoDCWorkflow), prompting LLMs on data cleaning operations\nto repair three types of data quality issues: duplicates, missing values, and\ninconsistent data formats. Given a dirty table and a purpose (expressed as a\nquery), this pipeline generates a minimal, clean table sufficient to address\nthe purpose and the data cleaning workflow used to produce the table. The\nplanning process involves three main LLM-driven components: (1) Select Target\nColumns: Identifies a set of target columns related to the purpose. (2) Inspect\nColumn Quality: Assesses the data quality for each target column and generates\na Data Quality Report as operation objectives. (3) Generate Operation &\nArguments: Predicts the next operation and arguments based on the data quality\nreport results. Additionally, we propose a data cleaning benchmark to evaluate\nthe capability of LLM agents to automatically generate workflows that address\ndata cleaning purposes of varying difficulty levels. The benchmark comprises\nthe annotated datasets as a collection of purpose, raw table, clean table, data\ncleaning workflow, and answer set. In our experiments, we evaluated three LLMs\nthat auto-generate purpose-driven data cleaning workflows. The results indicate\nthat LLMs perform well in planning and generating data-cleaning workflows\nwithout the need for fine-tuning.\n","authors":["Lan Li","Liri Fang","Vetle I. Torvik"],"pdf_url":"https://arxiv.org/pdf/2412.06724v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09827v1","updated":"2024-12-13T03:38:49Z","published":"2024-12-13T03:38:49Z","title":"Low-Rank Adaptation with Task-Relevant Feature Enhancement for\n  Fine-tuning Language Models","summary":"  Fine-tuning pre-trained large language models in a parameter-efficient manner\nis widely studied for its effectiveness and efficiency. LoRA is one of the most\nwidely used methods, which assumes that the optimization process is essentially\nlow dimensional. Although LoRA has demonstrated commendable performance, there\nremains a significant performance gap between LoRA and full fine-tuning when\nlearning new tasks. In this work, we propose Low-Rank Adaptation with\nTask-Relevant Feature Enhancement(LoRATRF) for enhancing task-relevant features\nfrom the perspective of editing neural network representations. To prioritize\ntask-relevant features, a task-aware filter that selectively extracts valuable\nknowledge from hidden representations for the target or current task is\ndesigned. As the experiments on a vareity of datasets including NLU,\ncommonsense reasoning and mathematical reasoning tasks demonstrates, our method\nreduces 33.71% parameters and achieves better performance on a variety of\ndatasets in comparison with SOTA low-rank methods.\n","authors":["Changqun Li","Chaofan Ding","Kexin Luan","Xinhan Di"],"pdf_url":"https://arxiv.org/pdf/2412.09827v1.pdf","comment":"6 Pages, 3 figures accepted by AAAI 2025 CoLoRAI - Connecting\n  Low-Rank Representations in AI Workshop"},{"id":"http://arxiv.org/abs/2407.00416v2","updated":"2024-12-13T03:15:51Z","published":"2024-06-29T11:50:16Z","title":"Too Late to Train, Too Early To Use? A Study on Necessity and Viability\n  of Low-Resource Bengali LLMs","summary":"  Each new generation of English-oriented Large Language Models (LLMs) exhibits\nenhanced cross-lingual transfer capabilities and significantly outperforms\nolder LLMs on low-resource languages. This prompts the question: Is there a\nneed for LLMs dedicated to a particular low-resource language? We aim to\nexplore this question for Bengali, a low-to-moderate resource Indo-Aryan\nlanguage native to the Bengal region of South Asia.\n  We compare the performance of open-weight and closed-source LLMs such as\nLLaMA-3 and GPT-4 against fine-tuned encoder-decoder models across a diverse\nset of Bengali downstream tasks, including translation, summarization,\nparaphrasing, question-answering, and natural language inference. Our findings\nreveal that while LLMs generally excel in reasoning tasks, their performance in\ntasks requiring Bengali script generation is inconsistent. Key challenges\ninclude inefficient tokenization of Bengali script by existing LLMs, leading to\nincreased computational costs and potential performance degradation.\nAdditionally, we highlight biases in machine-translated datasets commonly used\nfor Bengali NLP tasks. We conclude that there is a significant need for a\nBengali-oriented LLM, but the field currently lacks the high-quality\npretraining and instruction-tuning datasets necessary to develop a highly\neffective model.\n","authors":["Tamzeed Mahfuz","Satak Kumar Dey","Ruwad Naswan","Hasnaen Adil","Khondker Salman Sayeed","Haz Sameen Shahgir"],"pdf_url":"https://arxiv.org/pdf/2407.00416v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09818v1","updated":"2024-12-13T03:15:05Z","published":"2024-12-13T03:15:05Z","title":"MERaLiON-AudioLLM: Technical Report","summary":"  We introduce MERaLiON-AudioLLM (Multimodal Empathetic Reasoning and Learning\nin One Network), the first speech-text model tailored for Singapore's\nmultilingual and multicultural landscape. Developed under the National Large\nLanguage Models Funding Initiative, Singapore, MERaLiON-AudioLLM integrates\nadvanced speech and text processing to address the diverse linguistic nuances\nof local accents and dialects, enhancing accessibility and usability in\ncomplex, multilingual environments. Our results demonstrate improvements in\nboth speech recognition and task-specific understanding, positioning\nMERaLiON-AudioLLM as a pioneering solution for region specific AI applications.\nWe envision this release to set a precedent for future models designed to\naddress localised linguistic and cultural contexts in a global framework.\n","authors":["Yingxu He","Zhuohan Liu","Shuo Sun","Bin Wang","Wenyu Zhang","Xunlong Zou","Nancy F. Chen","Ai Ti Aw"],"pdf_url":"https://arxiv.org/pdf/2412.09818v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09817v1","updated":"2024-12-13T03:13:44Z","published":"2024-12-13T03:13:44Z","title":"Enhancing Multimodal Large Language Models Complex Reason via Similarity\n  Computation","summary":"  Multimodal large language models have experienced rapid growth, and numerous\ndifferent models have emerged. The interpretability of LVLMs remains an\nunder-explored area. Especially when faced with more complex tasks such as\nchain-of-thought reasoning, its internal mechanisms still resemble a black box\nthat is difficult to decipher. By studying the interaction and information flow\nbetween images and text, we noticed that in models such as LLaVA1.5, image\ntokens that are semantically related to text are more likely to have\ninformation flow convergence in the LLM decoding layer, and these image tokens\nreceive higher attention scores. However, those image tokens that are less\nrelevant to the text do not have information flow convergence, and they only\nget very small attention scores. To efficiently utilize the image information,\nwe propose a new image token reduction method, Simignore, which aims to improve\nthe complex reasoning ability of LVLMs by computing the similarity between\nimage and text embeddings and ignoring image tokens that are irrelevant and\nunimportant to the text. Through extensive experiments, we demonstrate the\neffectiveness of our method for complex reasoning tasks. The paper's source\ncode can be accessed from \\url{https://github.com/FanshuoZeng/Simignore}.\n","authors":["Xiaofeng Zhang","Fanshuo Zeng","Yihao Quan","Zheng Hui","Jiawei Yao"],"pdf_url":"https://arxiv.org/pdf/2412.09817v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09812v1","updated":"2024-12-13T03:00:48Z","published":"2024-12-13T03:00:48Z","title":"ScaleOT: Privacy-utility-scalable Offsite-tuning with Dynamic\n  LayerReplace and Selective Rank Compression","summary":"  Offsite-tuning is a privacy-preserving method for tuning large language\nmodels (LLMs) by sharing a lossy compressed emulator from the LLM owners with\ndata owners for downstream task tuning. This approach protects the privacy of\nboth the model and data owners. However, current offsite tuning methods often\nsuffer from adaptation degradation, high computational costs, and limited\nprotection strength due to uniformly dropping LLM layers or relying on\nexpensive knowledge distillation. To address these issues, we propose ScaleOT,\na novel privacy-utility-scalable offsite-tuning framework that effectively\nbalances privacy and utility. ScaleOT introduces a novel layerwise lossy\ncompression algorithm that uses reinforcement learning to obtain the importance\nof each layer. It employs lightweight networks, termed harmonizers, to replace\nthe raw LLM layers. By combining important original LLM layers and harmonizers\nin different ratios, ScaleOT generates emulators tailored for optimal\nperformance with various model scales for enhanced privacy protection.\nAdditionally, we present a rank reduction method to further compress the\noriginal LLM layers, significantly enhancing privacy with negligible impact on\nutility. Comprehensive experiments show that ScaleOT can achieve nearly\nlossless offsite tuning performance compared with full fine-tuning while\nobtaining better model privacy.\n","authors":["Kai Yao","Zhaorui Tan","Tiandi Ye","Lichun Li","Yuan Zhao","Wenyan Liu","Wei Wang","Jianke Zhu"],"pdf_url":"https://arxiv.org/pdf/2412.09812v1.pdf","comment":"accepted by AAAI2025"},{"id":"http://arxiv.org/abs/2408.09688v2","updated":"2024-12-13T02:48:44Z","published":"2024-08-19T03:53:48Z","title":"Recording for Eyes, Not Echoing to Ears: Contextualized\n  Spoken-to-Written Conversion of ASR Transcripts","summary":"  Automatic Speech Recognition (ASR) transcripts exhibit recognition errors and\nvarious spoken language phenomena such as disfluencies, ungrammatical\nsentences, and incomplete sentences, hence suffering from poor readability. To\nimprove readability, we propose a Contextualized Spoken-to-Written conversion\n(CoS2W) task to address ASR and grammar errors and also transfer the informal\ntext into the formal style with content preserved, utilizing contexts and\nauxiliary information. This task naturally matches the in-context learning\ncapabilities of Large Language Models (LLMs). To facilitate comprehensive\ncomparisons of various LLMs, we construct a document-level Spoken-to-Written\nconversion of ASR Transcripts Benchmark (SWAB) dataset. Using SWAB, we study\nthe impact of different granularity levels on the CoS2W performance, and\npropose methods to exploit contexts and auxiliary information to enhance the\noutputs. Experimental results reveal that LLMs have the potential to excel in\nthe CoS2W task, particularly in grammaticality and formality, our methods\nachieve effective understanding of contexts and auxiliary information by LLMs.\nWe further investigate the effectiveness of using LLMs as evaluators and find\nthat LLM evaluators show strong correlations with human evaluations on rankings\nof faithfulness and formality, which validates the reliability of LLM\nevaluators for the CoS2W task.\n","authors":["Jiaqing Liu","Chong Deng","Qinglin Zhang","Shilin Zhou","Qian Chen","Hai Yu","Wen Wang"],"pdf_url":"https://arxiv.org/pdf/2408.09688v2.pdf","comment":"7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2412.09807v1","updated":"2024-12-13T02:48:36Z","published":"2024-12-13T02:48:36Z","title":"LLM Distillation for Efficient Few-Shot Multiple Choice Question\n  Answering","summary":"  Multiple Choice Question Answering (MCQA) is an important problem with\nnumerous real-world applications, such as medicine, law, and education. The\nhigh cost of building MCQA datasets makes few-shot learning pivotal in this\ndomain. While Large Language Models (LLMs) can enable few-shot learning, their\ndirect application in real-world scenarios is often hindered by their high\ncomputational cost. To address this challenge, we propose a simple yet\neffective approach that uses LLMs for data generation and scoring. Our approach\nutilizes LLMs to create MCQA data which contains questions and choices, and to\nassign probability scores to the generated choices. We then use the generated\ndata and LLM-assigned scores to finetune a smaller and more efficient\nencoder-only model, DeBERTa-v3-base by leveraging distillation loss. Extensive\nexperiments on the Massive Multitask Language Understanding (MMLU) benchmark\ndemonstrate that our method improves accuracy from 28.9% to 39.3%, representing\na gain of over 10% compared to a baseline finetuned directly on 5-shot\nexamples. This shows the effectiveness of LLM-driven data generation and\nknowledge distillation for few-shot MCQA.\n","authors":["Patrick Sutanto","Joan Santoso"],"pdf_url":"https://arxiv.org/pdf/2412.09807v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.03514v2","updated":"2024-12-13T02:45:14Z","published":"2024-04-04T15:21:22Z","title":"Embedding-Informed Adaptive Retrieval-Augmented Generation of Large\n  Language Models","summary":"  Retrieval-augmented large language models (LLMs) have been remarkably\ncompetent in various NLP tasks. However, it was observed by previous works that\nretrieval is not always helpful, especially when the LLM is already\nknowledgeable on the query to answer. Motivated by this, Adaptive\nRetrieval-Augmented Generation (ARAG) studies retrieving only when the\nknowledge asked by the query is absent in the LLM. Previous works of ARAG\neither require accessing the pre-training corpus or prompting with additional\nmodel inferences. Aiming to avoid such drawbacks, we propose to determine\nwhether the model is knowledgeable on a query via inspecting the\n(contextualized) pre-trained token embeddings of LLMs. We hypothesize that such\nembeddings capture rich information on the model's intrinsic knowledge base,\nwhich enables an efficient way of judging the necessity to retrieve from an\nexternal corpus. Extensive experiments demonstrate our ARAG approach's superior\nperformance across various benchmarks.\n","authors":["Chengkai Huang","Yu Xia","Rui Wang","Kaige Xie","Tong Yu","Julian McAuley","Lina Yao"],"pdf_url":"https://arxiv.org/pdf/2404.03514v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.09025v6","updated":"2024-12-13T02:44:34Z","published":"2024-02-14T09:01:13Z","title":"SLEB: Streamlining LLMs through Redundancy Verification and Elimination\n  of Transformer Blocks","summary":"  Large language models (LLMs) have proven to be highly effective across\nvarious natural language processing tasks. However, their large number of\nparameters poses significant challenges for practical deployment. Pruning, a\ntechnique aimed at reducing the size and complexity of LLMs, offers a potential\nsolution by removing redundant components from the network. Despite the promise\nof pruning, existing methods often struggle to achieve substantial end-to-end\nLLM inference speedup. In this paper, we introduce SLEB, a novel approach\ndesigned to streamline LLMs by eliminating redundant transformer blocks. We\nchoose the transformer block as the fundamental unit for pruning, because LLMs\nexhibit block-level redundancy with high similarity between the outputs of\nneighboring blocks. This choice allows us to effectively enhance the processing\nspeed of LLMs. Our experimental results demonstrate that SLEB outperforms\nprevious LLM pruning methods in accelerating LLM inference while also\nmaintaining superior perplexity and accuracy, making SLEB as a promising\ntechnique for enhancing the efficiency of LLMs. The code is available at:\nhttps://github.com/jiwonsong-dev/SLEB.\n","authors":["Jiwon Song","Kyungseok Oh","Taesu Kim","Hyungjun Kim","Yulhwa Kim","Jae-Joon Kim"],"pdf_url":"https://arxiv.org/pdf/2402.09025v6.pdf","comment":"ICML 2024"},{"id":"http://arxiv.org/abs/2412.09014v2","updated":"2024-12-13T02:34:05Z","published":"2024-12-12T07:24:16Z","title":"Improvement in Sign Language Translation Using Text CTC Alignment","summary":"  Current sign language translation (SLT) approaches often rely on gloss-based\nsupervision with Connectionist Temporal Classification (CTC), limiting their\nability to handle non-monotonic alignments between sign language video and\nspoken text. In this work, we propose a novel method combining joint\nCTC/Attention and transfer learning. The joint CTC/Attention introduces\nhierarchical encoding and integrates CTC with the attention mechanism during\ndecoding, effectively managing both monotonic and non-monotonic alignments.\nMeanwhile, transfer learning helps bridge the modality gap between vision and\nlanguage in SLT. Experimental results on two widely adopted benchmarks,\nRWTH-PHOENIX-Weather 2014 T and CSL-Daily, show that our method achieves\nresults comparable to state-of-the-art and outperforms the pure-attention\nbaseline. Additionally, this work opens a new door for future research into\ngloss-free SLT using text-based CTC alignment.\n","authors":["Sihan Tan","Taro Miyazaki","Nabeela Khan","Kazuhiro Nakadai"],"pdf_url":"https://arxiv.org/pdf/2412.09014v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.10188v6","updated":"2024-12-13T02:32:06Z","published":"2024-08-19T17:48:08Z","title":"LongVILA: Scaling Long-Context Visual Language Models for Long Videos","summary":"  Long-context capability is critical for multi-modal foundation models,\nespecially for long video understanding. We introduce LongVILA, a full-stack\nsolution for long-context visual-language models by co-designing the algorithm\nand system. For model training, we upgrade existing VLMs to support long video\nunderstanding by incorporating two additional stages, i.e., long context\nextension and long video supervised fine-tuning. However, training on long\nvideo is computationally and memory intensive. We introduce the long-context\nMulti-Modal Sequence Parallelism (MM-SP) system that efficiently parallelizes\nlong video training and inference, enabling 2M context length training on 256\nGPUs without any gradient checkpointing. LongVILA efficiently extends the\nnumber of video frames of VILA from 8 to 2048, achieving 99.8% accuracy in\n6,000-frame (more than 1 million tokens) video needle-in-a-haystack.\nLongVILA-7B demonstrates strong accuracy on 9 popular video benchmarks, e.g.\n65.1% VideoMME with subtitle. Besides, MM-SP is 2.1x - 5.7x faster than ring\nstyle sequence parallelism and 1.1x - 1.4x faster than Megatron with a hybrid\ncontext and tensor parallelism. Moreover, it seamlessly integrates with Hugging\nFace Transformers.\n","authors":["Yukang Chen","Fuzhao Xue","Dacheng Li","Qinghao Hu","Ligeng Zhu","Xiuyu Li","Yunhao Fang","Haotian Tang","Shang Yang","Zhijian Liu","Ethan He","Hongxu Yin","Pavlo Molchanov","Jan Kautz","Linxi Fan","Yuke Zhu","Yao Lu","Song Han"],"pdf_url":"https://arxiv.org/pdf/2408.10188v6.pdf","comment":"Code and models are available at\n  https://github.com/NVlabs/VILA/tree/main/longvila"},{"id":"http://arxiv.org/abs/2412.09796v1","updated":"2024-12-13T02:27:34Z","published":"2024-12-13T02:27:34Z","title":"AutoPatent: A Multi-Agent Framework for Automatic Patent Generation","summary":"  As the capabilities of Large Language Models (LLMs) continue to advance, the\nfield of patent processing has garnered increased attention within the natural\nlanguage processing community. However, the majority of research has been\nconcentrated on classification tasks, such as patent categorization and\nexamination, or on short text generation tasks like patent summarization and\npatent quizzes. In this paper, we introduce a novel and practical task known as\nDraft2Patent, along with its corresponding D2P benchmark, which challenges LLMs\nto generate full-length patents averaging 17K tokens based on initial drafts.\nPatents present a significant challenge to LLMs due to their specialized\nnature, standardized terminology, and extensive length. We propose a\nmulti-agent framework called AutoPatent which leverages the LLM-based planner\nagent, writer agents, and examiner agent with PGTree and RRAG to generate\nlengthy, intricate, and high-quality complete patent documents. The\nexperimental results demonstrate that our AutoPatent framework significantly\nenhances the ability to generate comprehensive patents across various LLMs.\nFurthermore, we have discovered that patents generated solely with the\nAutoPatent framework based on the Qwen2.5-7B model outperform those produced by\nlarger and more powerful LLMs, such as GPT-4o, Qwen2.5-72B, and LLAMA3.1-70B,\nin both objective metrics and human evaluations. We will make the data and code\navailable upon acceptance at \\url{https://github.com/QiYao-Wang/AutoPatent}.\n","authors":["Qiyao Wang","Shiwen Ni","Huaren Liu","Shule Lu","Guhong Chen","Xi Feng","Chi Wei","Qiang Qu","Hamid Alinejad-Rokny","Yuan Lin","Min Yang"],"pdf_url":"https://arxiv.org/pdf/2412.09796v1.pdf","comment":"19 pages, 7 figures"},{"id":"http://arxiv.org/abs/2412.09784v1","updated":"2024-12-13T01:48:07Z","published":"2024-12-13T01:48:07Z","title":"Semi-IIN: Semi-supervised Intra-inter modal Interaction Learning Network\n  for Multimodal Sentiment Analysis","summary":"  Despite multimodal sentiment analysis being a fertile research ground that\nmerits further investigation, current approaches take up high annotation cost\nand suffer from label ambiguity, non-amicable to high-quality labeled data\nacquisition. Furthermore, choosing the right interactions is essential because\nthe significance of intra- or inter-modal interactions can differ among various\nsamples. To this end, we propose Semi-IIN, a Semi-supervised Intra-inter modal\nInteraction learning Network for multimodal sentiment analysis. Semi-IIN\nintegrates masked attention and gating mechanisms, enabling effective dynamic\nselection after independently capturing intra- and inter-modal interactive\ninformation. Combined with the self-training approach, Semi-IIN fully utilizes\nthe knowledge learned from unlabeled data. Experimental results on two public\ndatasets, MOSI and MOSEI, demonstrate the effectiveness of Semi-IIN,\nestablishing a new state-of-the-art on several metrics. Code is available at\nhttps://github.com/flow-ljh/Semi-IIN.\n","authors":["Jinhao Lin","Yifei Wang","Yanwu Xu","Qi Liu"],"pdf_url":"https://arxiv.org/pdf/2412.09784v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2412.10313v1","updated":"2024-12-13T17:53:29Z","published":"2024-12-13T17:53:29Z","title":"MST-R: Multi-Stage Tuning for Retrieval Systems and Metric Evaluation","summary":"  Regulatory documents are rich in nuanced terminology and specialized\nsemantics. FRAG systems: Frozen retrieval-augmented generators utilizing\npre-trained (or, frozen) components face consequent challenges with both\nretriever and answering performance. We present a system that adapts the\nretriever performance to the target domain using a multi-stage tuning (MST)\nstrategy. Our retrieval approach, called MST-R (a) first fine-tunes encoders\nused in vector stores using hard negative mining, (b) then uses a hybrid\nretriever, combining sparse and dense retrievers using reciprocal rank fusion,\nand then (c) adapts the cross-attention encoder by fine-tuning only the top-k\nretrieved results. We benchmark the system performance on the dataset released\nfor the RIRAG challenge (as part of the RegNLP workshop at COLING 2025). We\nachieve significant performance gains obtaining a top rank on the RegNLP\nchallenge leaderboard. We also show that a trivial answering approach games the\nRePASs metric outscoring all baselines and a pre-trained Llama model. Analyzing\nthis anomaly, we present important takeaways for future research.\n","authors":["Yash Malviya","Karan Dhingra","Maneesh Singh"],"pdf_url":"https://arxiv.org/pdf/2412.10313v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09983v1","updated":"2024-12-13T09:09:20Z","published":"2024-12-13T09:09:20Z","title":"Static Pruning in Dense Retrieval using Matrix Decomposition","summary":"  In the era of dense retrieval, document indexing and retrieval is largely\nbased on encoding models that transform text documents into embeddings. The\nefficiency of retrieval is directly proportional to the number of documents and\nthe size of the embeddings. Recent studies have shown that it is possible to\nreduce embedding size without sacrificing - and in some cases improving - the\nretrieval effectiveness. However, the methods introduced by these studies are\nquery-dependent, so they can't be applied offline and require additional\ncomputations during query processing, thus negatively impacting the retrieval\nefficiency. In this paper, we present a novel static pruning method for\nreducing the dimensionality of embeddings using Principal Components Analysis.\nThis approach is query-independent and can be executed offline, leading to a\nsignificant boost in dense retrieval efficiency with a negligible impact on the\nsystem effectiveness. Our experiments show that our proposed method reduces the\ndimensionality of document representations by over 50% with up to a 5%\nreduction in NDCG@10, for different dense retrieval models.\n","authors":["Federico Siciliano","Francesca Pezzuti","Nicola Tonellotto","Fabrizio Silvestri"],"pdf_url":"https://arxiv.org/pdf/2412.09983v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09950v1","updated":"2024-12-13T08:14:10Z","published":"2024-12-13T08:14:10Z","title":"Hesitation and Tolerance in Recommender Systems","summary":"  User interactions in recommender systems are inherently complex, often\ninvolving behaviors that go beyond simple acceptance or rejection. One\nparticularly common behavior is hesitation, where users deliberate over\nrecommended items, signaling uncertainty. Our large-scale surveys, with 6,644\nand 3,864 responses respectively, confirm that hesitation is not only\nwidespread but also has a profound impact on user experiences. When users spend\nadditional time engaging with content they are ultimately uninterested in, this\ncan lead to negative emotions, a phenomenon we term as tolerance. The surveys\nreveal that such tolerance behaviors often arise after hesitation and can erode\ntrust, satisfaction, and long-term loyalty to the platform. For instance, a\nclick might reflect a need for more information rather than genuine interest,\nand prolonged exposure to unsuitable content amplifies frustration. This\nmisalignment between user intent and system interpretation introduces noise\ninto recommendation training, resulting in suggestions that increase\nuncertainty and disengagement. To address these issues, we identified signals\nindicative of tolerance behavior and analyzed datasets from both e-commerce and\nshort-video platforms. The analysis shows a strong correlation between\nincreased tolerance behavior and decreased user activity. We integrated these\ninsights into the training process of a recommender system for a major\nshort-video platform. Results from four independent online A/B experiments\ndemonstrated significant improvements in user retention, achieved with minimal\nadditional computational costs. These findings underscore the importance of\nrecognizing hesitation as a ubiquitous user behavior and addressing tolerance\nto enhance satisfaction, build trust, and sustain long-term engagement in\nrecommender systems.\n","authors":["Kuan Zou","Aixin Sun","Xuemeng Jiang","Yitong Ji","Hao Zhang","Jing Wang","Ruijie Guo"],"pdf_url":"https://arxiv.org/pdf/2412.09950v1.pdf","comment":"30 pages, 6 figures, 6 tables"},{"id":"http://arxiv.org/abs/2406.00004v3","updated":"2024-12-13T06:41:02Z","published":"2024-05-12T04:15:05Z","title":"Navigating the Future of Federated Recommendation Systems with\n  Foundation Models","summary":"  In recent years, the integration of federated learning (FL) and\nrecommendation systems (RS), known as Federated Recommendation Systems (FRS),\nhas attracted attention for preserving user privacy by keeping private data on\nclient devices. However, FRS faces inherent limitations such as data\nheterogeneity and scarcity, due to the privacy requirements of FL and the\ntypical data sparsity issues of RSs. Models like ChatGPT are empowered by the\nconcept of transfer learning and self-supervised learning, so they can be\neasily applied to the downstream tasks after fine-tuning or prompting. These\nmodels, so-called Foundation Models (FM), fouce on understanding the human's\nintent and perform following their designed roles in the specific tasks, which\nare widely recognized for producing high-quality content in the image and\nlanguage domains. Thus, the achievements of FMs inspire the design of FRS and\nsuggest a promising research direction: integrating foundation models to\naddress the above limitations. In this study, we conduct a comprehensive review\nof FRSs with FMs. Specifically, we: 1) summarise the common approaches of\ncurrent FRSs and FMs; 2) review the challenges posed by FRSs and FMs; 3)\ndiscuss potential future research directions; and 4) introduce some common\nbenchmarks and evaluation metrics in the FRS field. We hope that this position\npaper provides the necessary background and guidance to explore this\ninteresting and emerging topic.\n","authors":["Zhiwei Li","Guodong Long","Chunxu Zhang","Honglei Zhang","Jing Jiang","Chengqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.00004v3.pdf","comment":"20 pages, position paper, survey"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2412.10373v1","updated":"2024-12-13T18:59:54Z","published":"2024-12-13T18:59:54Z","title":"GaussianWorld: Gaussian World Model for Streaming 3D Occupancy\n  Prediction","summary":"  3D occupancy prediction is important for autonomous driving due to its\ncomprehensive perception of the surroundings. To incorporate sequential inputs,\nmost existing methods fuse representations from previous frames to infer the\ncurrent 3D occupancy. However, they fail to consider the continuity of driving\nscenarios and ignore the strong prior provided by the evolution of 3D scenes\n(e.g., only dynamic objects move). In this paper, we propose a\nworld-model-based framework to exploit the scene evolution for perception. We\nreformulate 3D occupancy prediction as a 4D occupancy forecasting problem\nconditioned on the current sensor input. We decompose the scene evolution into\nthree factors: 1) ego motion alignment of static scenes; 2) local movements of\ndynamic objects; and 3) completion of newly-observed scenes. We then employ a\nGaussian world model (GaussianWorld) to explicitly exploit these priors and\ninfer the scene evolution in the 3D Gaussian space considering the current RGB\nobservation. We evaluate the effectiveness of our framework on the widely used\nnuScenes dataset. Our GaussianWorld improves the performance of the\nsingle-frame counterpart by over 2% in mIoU without introducing additional\ncomputations. Code: https://github.com/zuosc19/GaussianWorld.\n","authors":["Sicheng Zuo","Wenzhao Zheng","Yuanhui Huang","Jie Zhou","Jiwen Lu"],"pdf_url":"https://arxiv.org/pdf/2412.10373v1.pdf","comment":"Code is available at: https://github.com/zuosc19/GaussianWorld"},{"id":"http://arxiv.org/abs/2412.10371v1","updated":"2024-12-13T18:59:30Z","published":"2024-12-13T18:59:30Z","title":"GaussianAD: Gaussian-Centric End-to-End Autonomous Driving","summary":"  Vision-based autonomous driving shows great potential due to its satisfactory\nperformance and low costs. Most existing methods adopt dense representations\n(e.g., bird's eye view) or sparse representations (e.g., instance boxes) for\ndecision-making, which suffer from the trade-off between comprehensiveness and\nefficiency. This paper explores a Gaussian-centric end-to-end autonomous\ndriving (GaussianAD) framework and exploits 3D semantic Gaussians to\nextensively yet sparsely describe the scene. We initialize the scene with\nuniform 3D Gaussians and use surrounding-view images to progressively refine\nthem to obtain the 3D Gaussian scene representation. We then use sparse\nconvolutions to efficiently perform 3D perception (e.g., 3D detection, semantic\nmap construction). We predict 3D flows for the Gaussians with dynamic semantics\nand plan the ego trajectory accordingly with an objective of future scene\nforecasting. Our GaussianAD can be trained in an end-to-end manner with\noptional perception labels when available. Extensive experiments on the widely\nused nuScenes dataset verify the effectiveness of our end-to-end GaussianAD on\nvarious tasks including motion planning, 3D occupancy prediction, and 4D\noccupancy forecasting. Code: https://github.com/wzzheng/GaussianAD.\n","authors":["Wenzhao Zheng","Junjie Wu","Yao Zheng","Sicheng Zuo","Zixun Xie","Longchao Yang","Yong Pan","Zhihui Hao","Peng Jia","Xianpeng Lang","Shanghang Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.10371v1.pdf","comment":"Code is available at: https://github.com/wzzheng/GaussianAD"},{"id":"http://arxiv.org/abs/2402.01886v2","updated":"2024-12-13T18:59:14Z","published":"2024-02-02T20:21:09Z","title":"Inverse Reinforcement Learning by Estimating Expertise of Demonstrators","summary":"  In Imitation Learning (IL), utilizing suboptimal and heterogeneous\ndemonstrations presents a substantial challenge due to the varied nature of\nreal-world data. However, standard IL algorithms consider these datasets as\nhomogeneous, thereby inheriting the deficiencies of suboptimal demonstrators.\nPrevious approaches to this issue rely on impractical assumptions like\nhigh-quality data subsets, confidence rankings, or explicit environmental\nknowledge. This paper introduces IRLEED, Inverse Reinforcement Learning by\nEstimating Expertise of Demonstrators, a novel framework that overcomes these\nhurdles without prior knowledge of demonstrator expertise. IRLEED enhances\nexisting Inverse Reinforcement Learning (IRL) algorithms by combining a general\nmodel for demonstrator suboptimality to address reward bias and action\nvariance, with a Maximum Entropy IRL framework to efficiently derive the\noptimal policy from diverse, suboptimal demonstrations. Experiments in both\nonline and offline IL settings, with simulated and human-generated data,\ndemonstrate IRLEED's adaptability and effectiveness, making it a versatile\nsolution for learning from suboptimal demonstrations.\n","authors":["Mark Beliaev","Ramtin Pedarsani"],"pdf_url":"https://arxiv.org/pdf/2402.01886v2.pdf","comment":"11 pages, 4 figures, extended version of AAAI publication"},{"id":"http://arxiv.org/abs/2412.10362v1","updated":"2024-12-13T18:55:19Z","published":"2024-12-13T18:55:19Z","title":"OP-LoRA: The Blessing of Dimensionality","summary":"  Low-rank adapters enable fine-tuning of large models with only a small number\nof parameters, thus reducing storage costs and minimizing the risk of\ncatastrophic forgetting. However, they often pose optimization challenges, with\npoor convergence. To overcome these challenges, we introduce an\nover-parameterized approach that accelerates training without increasing\ninference costs. This method reparameterizes low-rank adaptation by employing a\nseparate MLP and learned embedding for each layer. The learned embedding is\ninput to the MLP, which generates the adapter parameters. Such\noverparamaterization has been shown to implicitly function as an adaptive\nlearning rate and momentum, accelerating optimization. At inference time, the\nMLP can be discarded, leaving behind a standard low-rank adapter. To study the\neffect of MLP overparameterization on a small yet difficult proxy task, we\nimplement it for matrix factorization, and find it achieves faster convergence\nand lower final loss. Extending this approach to larger-scale tasks, we observe\nconsistent performance gains across domains. We achieve improvements in\nvision-language tasks and especially notable increases in image generation,\nwith CMMD scores improving by up to 15 points.\n","authors":["Piotr Teterwak","Kate Saenko","Bryan A. Plummer","Ser-Nam Lim"],"pdf_url":"https://arxiv.org/pdf/2412.10362v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10357v1","updated":"2024-12-13T18:51:33Z","published":"2024-12-13T18:51:33Z","title":"The Correlated Gaussian Sparse Histogram Mechanism","summary":"  We consider the problem of releasing a sparse histogram under $(\\varepsilon,\n\\delta)$-differential privacy. The stability histogram independently adds noise\nfrom a Laplace or Gaussian distribution to the non-zero entries and removes\nthose noisy counts below a threshold.\n  Thereby, the introduction of new non-zero values between neighboring\nhistograms is only revealed with probability at most $\\delta$, and typically,\nthe value of the threshold dominates the error of the mechanism. We consider\nthe variant of the stability histogram with Gaussian noise.\n  Recent works ([Joseph and Yu, COLT '24] and [Lebeda, SOSA '25]) reduced the\nerror for private histograms using correlated Gaussian noise. However, these\ntechniques can not be directly applied in the very sparse setting. Instead, we\nadopt Lebeda's technique and show that adding correlated noise to the non-zero\ncounts only allows us to reduce the magnitude of noise when we have a sparsity\nbound. This, in turn, allows us to use a lower threshold by up to a factor of\n$1/2$ compared to the non-correlated noise mechanism. We then extend our\nmechanism to a setting without a known bound on sparsity. Additionally, we show\nthat correlated noise can give a similar improvement for the more practical\ndiscrete Gaussian mechanism.\n","authors":["Christian Janos Lebeda","Lukas Retschmeier"],"pdf_url":"https://arxiv.org/pdf/2412.10357v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10354v1","updated":"2024-12-13T18:49:37Z","published":"2024-12-13T18:49:37Z","title":"A Library for Learning Neural Operators","summary":"  We present NeuralOperator, an open-source Python library for operator\nlearning. Neural operators generalize neural networks to maps between function\nspaces instead of finite-dimensional Euclidean spaces. They can be trained and\ninferenced on input and output functions given at various discretizations,\nsatisfying a discretization convergence properties. Built on top of PyTorch,\nNeuralOperator provides all the tools for training and deploying neural\noperator models, as well as developing new ones, in a high-quality, tested,\nopen-source package. It combines cutting-edge models and customizability with a\ngentle learning curve and simple user interface for newcomers.\n","authors":["Jean Kossaifi","Nikola Kovachki","Zongyi Li","Davit Pitt","Miguel Liu-Schiaffini","Robert Joseph George","Boris Bonev","Kamyar Azizzadenesheli","Julius Berner","Anima Anandkumar"],"pdf_url":"https://arxiv.org/pdf/2412.10354v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10353v1","updated":"2024-12-13T18:49:25Z","published":"2024-12-13T18:49:25Z","title":"Robust image classification with multi-modal large language models","summary":"  Deep Neural Networks are vulnerable to adversarial examples, i.e., carefully\ncrafted input samples that can cause models to make incorrect predictions with\nhigh confidence. To mitigate these vulnerabilities, adversarial training and\ndetection-based defenses have been proposed to strengthen models in advance.\nHowever, most of these approaches focus on a single data modality, overlooking\nthe relationships between visual patterns and textual descriptions of the\ninput. In this paper, we propose a novel defense, Multi-Shield, designed to\ncombine and complement these defenses with multi-modal information to further\nenhance their robustness. Multi-Shield leverages multi-modal large language\nmodels to detect adversarial examples and abstain from uncertain\nclassifications when there is no alignment between textual and visual\nrepresentations of the input. Extensive evaluations on CIFAR-10 and ImageNet\ndatasets, using robust and non-robust image classification models, demonstrate\nthat Multi-Shield can be easily integrated to detect and reject adversarial\nexamples, outperforming the original defenses.\n","authors":["Francesco Villani","Igor Maljkovic","Dario Lazzaro","Angelo Sotgiu","Antonio Emanuele Cinà","Fabio Roli"],"pdf_url":"https://arxiv.org/pdf/2412.10353v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10347v1","updated":"2024-12-13T18:42:00Z","published":"2024-12-13T18:42:00Z","title":"COMET: Benchmark for Comprehensive Biological Multi-omics Evaluation\n  Tasks and Language Models","summary":"  As key elements within the central dogma, DNA, RNA, and proteins play crucial\nroles in maintaining life by guaranteeing accurate genetic expression and\nimplementation. Although research on these molecules has profoundly impacted\nfields like medicine, agriculture, and industry, the diversity of machine\nlearning approaches-from traditional statistical methods to deep learning\nmodels and large language models-poses challenges for researchers in choosing\nthe most suitable models for specific tasks, especially for cross-omics and\nmulti-omics tasks due to the lack of comprehensive benchmarks. To address this,\nwe introduce the first comprehensive multi-omics benchmark COMET (Benchmark for\nBiological COmprehensive Multi-omics Evaluation Tasks and Language Models),\ndesigned to evaluate models across single-omics, cross-omics, and multi-omics\ntasks. First, we curate and develop a diverse collection of downstream tasks\nand datasets covering key structural and functional aspects in DNA, RNA, and\nproteins, including tasks that span multiple omics levels. Then, we evaluate\nexisting foundational language models for DNA, RNA, and proteins, as well as\nthe newly proposed multi-omics method, offering valuable insights into their\nperformance in integrating and analyzing data from different biological\nmodalities. This benchmark aims to define critical issues in multi-omics\nresearch and guide future directions, ultimately promoting advancements in\nunderstanding biological processes through integrated and different omics data\nanalysis.\n","authors":["Yuchen Ren","Wenwei Han","Qianyuan Zhang","Yining Tang","Weiqiang Bai","Yuchen Cai","Lifeng Qiao","Hao Jiang","Dong Yuan","Tao Chen","Siqi Sun","Pan Tan","Wanli Ouyang","Nanqing Dong","Xinzhu Ma","Peng Ye"],"pdf_url":"https://arxiv.org/pdf/2412.10347v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10341v1","updated":"2024-12-13T18:38:47Z","published":"2024-12-13T18:38:47Z","title":"Shape error prediction in 5-axis machining using graph neural networks","summary":"  This paper presents an innovative method for predicting shape errors in\n5-axis machining using graph neural networks. The graph structure is defined\nwith nodes representing workpiece surface points and edges denoting the\nneighboring relationships. The dataset encompasses data from a material removal\nsimulation, process data, and post-machining quality information. Experimental\nresults show that the presented approach can generalize the shape error\nprediction for the investigated workpiece geometry. Moreover, by modelling\nspatial and temporal connections within the workpiece, the approach handles a\nlow number of labels compared to non-graphical methods such as Support Vector\nMachines.\n","authors":["Julia Huuk","Abheek Dhingra","Eirini Ntoutsi","Bernd Denkena"],"pdf_url":"https://arxiv.org/pdf/2412.10341v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10337v1","updated":"2024-12-13T18:32:21Z","published":"2024-12-13T18:32:21Z","title":"Generative AI in Medicine","summary":"  The increased capabilities of generative AI have dramatically expanded its\npossible use cases in medicine. We provide a comprehensive overview of\ngenerative AI use cases for clinicians, patients, clinical trial organizers,\nresearchers, and trainees. We then discuss the many challenges -- including\nmaintaining privacy and security, improving transparency and interpretability,\nupholding equity, and rigorously evaluating models -- which must be overcome to\nrealize this potential, and the open research directions they give rise to.\n","authors":["Divya Shanmugam","Monica Agrawal","Rajiv Movva","Irene Y. Chen","Marzyeh Ghassemi","Emma Pierson"],"pdf_url":"https://arxiv.org/pdf/2412.10337v1.pdf","comment":"To appear in the Annual Review of Biomedical Data Science, August\n  2025"},{"id":"http://arxiv.org/abs/2406.06290v2","updated":"2024-12-13T18:12:02Z","published":"2024-06-10T14:12:33Z","title":"Geometric sparsification in recurrent neural networks","summary":"  A common technique for ameliorating the computational costs of running large\nneural models is sparsification, or the pruning of neural connections during\ntraining. Sparse models are capable of maintaining the high accuracy of state\nof the art models, while functioning at the cost of more parsimonious models.\nThe structures which underlie sparse architectures are, however, poorly\nunderstood and not consistent between differently trained models and\nsparsification schemes. In this paper, we propose a new technique for\nsparsification of recurrent neural nets (RNNs), called moduli regularization,\nin combination with magnitude pruning. Moduli regularization leverages the\ndynamical system induced by the recurrent structure to induce a geometric\nrelationship between neurons in the hidden state of the RNN. By making our\nregularizing term explicitly geometric, we provide the first, to our knowledge,\na priori description of the desired sparse architecture of our neural net, as\nwell as explicit end-to-end learning of RNN geometry. We verify the\neffectiveness of our scheme under diverse conditions, testing in navigation,\nnatural language processing, and addition RNNs. Navigation is a structurally\ngeometric task, for which there are known moduli spaces, and we show that\nregularization can be used to reach 90% sparsity while maintaining model\nperformance only when coefficients are chosen in accordance with a suitable\nmoduli space. Natural language processing and addition, however, have no known\nmoduli space in which computations are performed. Nevertheless, we show that\nmoduli regularization induces more stable recurrent neural nets, and achieves\nhigh fidelity models above 90% sparsity.\n","authors":["Wyatt Mackey","Ioannis Schizas","Jared Deighton","David L. Boothe, Jr.","Vasileios Maroulas"],"pdf_url":"https://arxiv.org/pdf/2406.06290v2.pdf","comment":"25 pages, 4 figures"},{"id":"http://arxiv.org/abs/2412.10321v1","updated":"2024-12-13T18:00:57Z","published":"2024-12-13T18:00:57Z","title":"AdvPrefix: An Objective for Nuanced LLM Jailbreaks","summary":"  Many jailbreak attacks on large language models (LLMs) rely on a common\nobjective: making the model respond with the prefix \"Sure, here is (harmful\nrequest)\". While straightforward, this objective has two limitations: limited\ncontrol over model behaviors, often resulting in incomplete or unrealistic\nresponses, and a rigid format that hinders optimization. To address these\nlimitations, we introduce AdvPrefix, a new prefix-forcing objective that\nenables more nuanced control over model behavior while being easy to optimize.\nOur objective leverages model-dependent prefixes, automatically selected based\non two criteria: high prefilling attack success rates and low negative\nlog-likelihood. It can further simplify optimization by using multiple prefixes\nfor a single user request. AdvPrefix can integrate seamlessly into existing\njailbreak attacks to improve their performance for free. For example, simply\nreplacing GCG attack's target prefixes with ours on Llama-3 improves nuanced\nattack success rates from 14% to 80%, suggesting that current alignment\nstruggles to generalize to unseen prefixes. Our work demonstrates the\nimportance of jailbreak objectives in achieving nuanced jailbreaks.\n","authors":["Sicheng Zhu","Brandon Amos","Yuandong Tian","Chuan Guo","Ivan Evtimov"],"pdf_url":"https://arxiv.org/pdf/2412.10321v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10319v1","updated":"2024-12-13T17:59:52Z","published":"2024-12-13T17:59:52Z","title":"SCBench: A KV Cache-Centric Analysis of Long-Context Methods","summary":"  Long-context LLMs have enabled numerous downstream applications but also\nintroduced significant challenges related to computational and memory\nefficiency. To address these challenges, optimizations for long-context\ninference have been developed, centered around the KV cache. However, existing\nbenchmarks often evaluate in single-request, neglecting the full lifecycle of\nthe KV cache in real-world use. This oversight is particularly critical, as KV\ncache reuse has become widely adopted in LLMs inference frameworks, such as\nvLLM and SGLang, as well as by LLM providers, including OpenAI, Microsoft,\nGoogle, and Anthropic. To address this gap, we introduce\nSCBench(SharedContextBench), a comprehensive benchmark for evaluating\nlong-context methods from a KV cachecentric perspective: 1) KV cache\ngeneration, 2) KV cache compression, 3) KV cache retrieval, 4) KV cache\nloading. Specifically, SCBench uses test examples with shared context, ranging\n12 tasks with two shared context modes, covering four categories of\nlong-context capabilities: string retrieval, semantic retrieval, global\ninformation, and multi-task. With it, we provide an extensive KV cache-centric\nanalysis of eight categories long-context solutions, including Gated Linear\nRNNs, Mamba-Attention hybrids, and efficient methods such as sparse attention,\nKV cache dropping, quantization, retrieval, loading, and prompt compression.\nThe evaluation is conducted on 8 long-context LLMs. Our findings show that\nsub-O(n) memory methods suffer in multi-turn scenarios, while sparse encoding\nwith O(n) memory and sub-O(n^2) pre-filling computation perform robustly.\nDynamic sparsity yields more expressive KV caches than static patterns, and\nlayer-level sparsity in hybrid architectures reduces memory usage with strong\nperformance. Additionally, we identify attention distribution shift issues in\nlong-generation scenarios. https://aka.ms/SCBench.\n","authors":["Yucheng Li","Huiqiang Jiang","Qianhui Wu","Xufang Luo","Surin Ahn","Chengruidong Zhang","Amir H. Abdi","Dongsheng Li","Jianfeng Gao","Yuqing Yang","Lili Qiu"],"pdf_url":"https://arxiv.org/pdf/2412.10319v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10313v1","updated":"2024-12-13T17:53:29Z","published":"2024-12-13T17:53:29Z","title":"MST-R: Multi-Stage Tuning for Retrieval Systems and Metric Evaluation","summary":"  Regulatory documents are rich in nuanced terminology and specialized\nsemantics. FRAG systems: Frozen retrieval-augmented generators utilizing\npre-trained (or, frozen) components face consequent challenges with both\nretriever and answering performance. We present a system that adapts the\nretriever performance to the target domain using a multi-stage tuning (MST)\nstrategy. Our retrieval approach, called MST-R (a) first fine-tunes encoders\nused in vector stores using hard negative mining, (b) then uses a hybrid\nretriever, combining sparse and dense retrievers using reciprocal rank fusion,\nand then (c) adapts the cross-attention encoder by fine-tuning only the top-k\nretrieved results. We benchmark the system performance on the dataset released\nfor the RIRAG challenge (as part of the RegNLP workshop at COLING 2025). We\nachieve significant performance gains obtaining a top rank on the RegNLP\nchallenge leaderboard. We also show that a trivial answering approach games the\nRePASs metric outscoring all baselines and a pre-trained Llama model. Analyzing\nthis anomaly, we present important takeaways for future research.\n","authors":["Yash Malviya","Karan Dhingra","Maneesh Singh"],"pdf_url":"https://arxiv.org/pdf/2412.10313v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02820v2","updated":"2024-12-13T17:53:25Z","published":"2024-11-05T05:41:41Z","title":"DroidSpeak: KV Cache Sharing for Efficient Multi-LLM Serving","summary":"  Large Language Models (LLMs) are increasingly employed in complex workflows,\nwhere different LLMs and fine-tuned variants collaboratively address complex\ntasks. However, these systems face significant inefficiencies due to redundant\ncontext processing of the shared context. We propose DroidSpeak, a framework\nthat optimizes context sharing between fine-tuned LLMs derived from the same\nfoundational model. DroidSpeak identifies critical layers in the KV cache and\nselectively recomputes them, enabling effective reuse of intermediate data\nwhile maintaining high accuracy.\n  Our approach balances computational efficiency and task fidelity,\nsignificantly reducing inference latency and throughput bottlenecks.\nExperiments on diverse datasets and model pairs demonstrate that DroidSpeak\nachieves up to 3x higher throughputs and 2.6x faster prefill times with\nnegligible accuracy loss compared to full recomputation.\n","authors":["Yuhan Liu","Yuyang Huang","Jiayi Yao","Zhuohan Gu","Kuntai Du","Hanchen Li","Yihua Cheng","Junchen Jiang","Shan Lu","Madan Musuvathi","Esha Choukse"],"pdf_url":"https://arxiv.org/pdf/2411.02820v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10312v1","updated":"2024-12-13T17:52:48Z","published":"2024-12-13T17:52:48Z","title":"Interlocking-free Selective Rationalization Through Genetic-based\n  Learning","summary":"  A popular end-to-end architecture for selective rationalization is the\nselect-then-predict pipeline, comprising a generator to extract highlights fed\nto a predictor. Such a cooperative system suffers from suboptimal equilibrium\nminima due to the dominance of one of the two modules, a phenomenon known as\ninterlocking. While several contributions aimed at addressing interlocking,\nthey only mitigate its effect, often by introducing feature-based heuristics,\nsampling, and ad-hoc regularizations. We present GenSPP, the first\ninterlocking-free architecture for selective rationalization that does not\nrequire any learning overhead, as the above-mentioned. GenSPP avoids\ninterlocking by performing disjoint training of the generator and predictor via\ngenetic global search. Experiments on a synthetic and a real-world benchmark\nshow that our model outperforms several state-of-the-art competitors.\n","authors":["Federico Ruggeri","Gaetano Signorelli"],"pdf_url":"https://arxiv.org/pdf/2412.10312v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10298v1","updated":"2024-12-13T17:34:18Z","published":"2024-12-13T17:34:18Z","title":"Buzz to Broadcast: Predicting Sports Viewership Using Social Media\n  Engagement","summary":"  Accurately predicting sports viewership is crucial for optimizing ad sales\nand revenue forecasting. Social media platforms, such as Reddit, provide a\nwealth of user-generated content that reflects audience engagement and\ninterest. In this study, we propose a regression-based approach to predict\nsports viewership using social media metrics, including post counts, comments,\nscores, and sentiment analysis from TextBlob and VADER. Through iterative\nimprovements, such as focusing on major sports subreddits, incorporating\ncategorical features, and handling outliers by sport, the model achieved an\n$R^2$ of 0.99, a Mean Absolute Error (MAE) of 1.27 million viewers, and a Root\nMean Squared Error (RMSE) of 2.33 million viewers on the full dataset. These\nresults demonstrate the model's ability to accurately capture patterns in\naudience behavior, offering significant potential for pre-event revenue\nforecasting and targeted advertising strategies.\n","authors":["Anakin Trotter"],"pdf_url":"https://arxiv.org/pdf/2412.10298v1.pdf","comment":"17 pages, 4 figures, 2 tables"},{"id":"http://arxiv.org/abs/2412.10291v1","updated":"2024-12-13T17:21:29Z","published":"2024-12-13T17:21:29Z","title":"Still \"Talking About Large Language Models\": Some Clarifications","summary":"  My paper \"Talking About Large Language Models\" has more than once been\ninterpreted as advocating a reductionist stance towards large language models.\nBut the paper was not intended that way, and I do not endorse such positions.\nThis short note situates the paper in the context of a larger philosophical\nproject that is concerned with the (mis)use of words rather than metaphysics,\nin the spirit of Wittgenstein's later writing.\n","authors":["Murray Shanahan"],"pdf_url":"https://arxiv.org/pdf/2412.10291v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10288v1","updated":"2024-12-13T17:11:47Z","published":"2024-12-13T17:11:47Z","title":"Performance evaluation of predictive AI models to support medical\n  decisions: Overview and guidance","summary":"  A myriad of measures to illustrate performance of predictive artificial\nintelligence (AI) models have been proposed in the literature. Selecting\nappropriate performance measures is essential for predictive AI models that are\ndeveloped to be used in medical practice, because poorly performing models may\nharm patients and lead to increased costs. We aim to assess the merits of\nclassic and contemporary performance measures when validating predictive AI\nmodels for use in medical practice. We focus on models with a binary outcome.\nWe discuss 32 performance measures covering five performance domains\n(discrimination, calibration, overall, classification, and clinical utility)\nalong with accompanying graphical assessments. The first four domains cover\nstatistical performance, the fifth domain covers decision-analytic performance.\nWe explain why two key characteristics are important when selecting which\nperformance measures to assess: (1) whether the measure's expected value is\noptimized when it is calculated using the correct probabilities (i.e., a\n\"proper\" measure), and (2) whether they reflect either purely statistical\nperformance or decision-analytic performance by properly considering\nmisclassification costs. Seventeen measures exhibit both characteristics,\nfourteen measures exhibited one characteristic, and one measure possessed\nneither characteristic (the F1 measure). All classification measures (such as\nclassification accuracy and F1) are improper for clinically relevant decision\nthresholds other than 0.5 or the prevalence. We recommend the following\nmeasures and plots as essential to report: AUROC, calibration plot, a clinical\nutility measure such as net benefit with decision curve analysis, and a plot\nwith probability distributions per outcome category.\n","authors":["Ben Van Calster","Gary S. Collins","Andrew J. Vickers","Laure Wynants","Kathleen F. Kerr","Lasai Barreñada","Gael Varoquaux","Karandeep Singh","Karel G. M. Moons","Tina Hernandez-boussard","Dirk Timmerman","David J. Mclernon","Maarten Van Smeden","Ewout W. Steyerberg"],"pdf_url":"https://arxiv.org/pdf/2412.10288v1.pdf","comment":"60 pages, 8 tables, 11 figures, two supplementary appendices"},{"id":"http://arxiv.org/abs/2410.01697v3","updated":"2024-12-13T16:55:33Z","published":"2024-10-02T16:05:03Z","title":"MOREL: Enhancing Adversarial Robustness through Multi-Objective\n  Representation Learning","summary":"  Extensive research has shown that deep neural networks (DNNs) are vulnerable\nto slight adversarial perturbations$-$small changes to the input data that\nappear insignificant but cause the model to produce drastically different\noutputs. In addition to augmenting training data with adversarial examples\ngenerated from a specific attack method, most of the current defense strategies\nnecessitate modifying the original model architecture components to improve\nrobustness or performing test-time data purification to handle adversarial\nattacks. In this work, we demonstrate that strong feature representation\nlearning during training can significantly enhance the original model's\nrobustness. We propose MOREL, a multi-objective feature representation learning\napproach, encouraging classification models to produce similar features for\ninputs within the same class, despite perturbations. Our training method\ninvolves an embedding space where cosine similarity loss and multi-positive\ncontrastive loss are used to align natural and adversarial features from the\nmodel encoder and ensure tight clustering. Concurrently, the classifier is\nmotivated to achieve accurate predictions. Through extensive experiments, we\ndemonstrate that our approach significantly enhances the robustness of DNNs\nagainst white-box and black-box adversarial attacks, outperforming other\nmethods that similarly require no architectural changes or test-time data\npurification. Our code is available at https://github.com/salomonhotegni/MOREL\n","authors":["Sedjro Salomon Hotegni","Sebastian Peitz"],"pdf_url":"https://arxiv.org/pdf/2410.01697v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10273v1","updated":"2024-12-13T16:46:46Z","published":"2024-12-13T16:46:46Z","title":"Probabilistic Inverse Cameras: Image to 3D via Multiview Geometry","summary":"  We introduce a hierarchical probabilistic approach to go from a 2D image to\nmultiview 3D: a diffusion \"prior\" models the unseen 3D geometry, which then\nconditions a diffusion \"decoder\" to generate novel views of the subject. We use\na pointmap-based geometric representation in a multiview image format to\ncoordinate the generation of multiple target views simultaneously. We\nfacilitate correspondence between views by assuming fixed target camera poses\nrelative to the source camera, and constructing a predictable distribution of\ngeometric features per target. Our modular, geometry-driven approach to\nnovel-view synthesis (called \"unPIC\") beats SoTA baselines such as CAT3D and\nOne-2-3-45 on held-out objects from ObjaverseXL, as well as real-world objects\nranging from Google Scanned Objects, Amazon Berkeley Objects, to the Digital\nTwin Catalog.\n","authors":["Rishabh Kabra","Drew A. Hudson","Sjoerd van Steenkiste","Joao Carreira","Niloy J. Mitra"],"pdf_url":"https://arxiv.org/pdf/2412.10273v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.02702v4","updated":"2024-12-13T16:34:56Z","published":"2023-10-04T10:15:57Z","title":"On the Power of Adaptive Weighted Aggregation in Heterogeneous Federated\n  Learning and Beyond","summary":"  Federated averaging (FedAvg) is the most fundamental algorithm in Federated\nlearning (FL). Previous theoretical results assert that FedAvg convergence and\ngeneralization degenerate under heterogeneous clients. However, recent\nempirical results show that FedAvg can perform well in many real-world\nheterogeneous tasks. These results reveal an inconsistency between FL theory\nand practice that is not fully explained. In this paper, we show that common\nheterogeneity measures contribute to this inconsistency based on rigorous\nconvergence analysis. Furthermore, we introduce a new measure \\textit{client\nconsensus dynamics} and prove that \\textit{FedAvg can effectively handle client\nheterogeneity when an appropriate aggregation strategy is used}. Building on\nthis theoretical insight, we present a simple and effective FedAvg variant\ntermed FedAWARE. Extensive experiments on three datasets and two modern neural\nnetwork architectures demonstrate that FedAWARE ensures faster convergence and\nbetter generalization in heterogeneous client settings. Moreover, our results\nshow that FedAWARE can significantly enhance the generalization performance of\nadvanced FL algorithms when used as a plug-in module.\n","authors":["Dun Zeng","Zenglin Xu","Shiyu Liu","Yu Pan","Qifan Wang","Xiaoying Tang"],"pdf_url":"https://arxiv.org/pdf/2310.02702v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10265v1","updated":"2024-12-13T16:33:36Z","published":"2024-12-13T16:33:36Z","title":"Adversarial Robustness of Bottleneck Injected Deep Neural Networks for\n  Task-Oriented Communication","summary":"  This paper investigates the adversarial robustness of Deep Neural Networks\n(DNNs) using Information Bottleneck (IB) objectives for task-oriented\ncommunication systems. We empirically demonstrate that while IB-based\napproaches provide baseline resilience against attacks targeting downstream\ntasks, the reliance on generative models for task-oriented communication\nintroduces new vulnerabilities. Through extensive experiments on several\ndatasets, we analyze how bottleneck depth and task complexity influence\nadversarial robustness. Our key findings show that Shallow Variational\nBottleneck Injection (SVBI) provides less adversarial robustness compared to\nDeep Variational Information Bottleneck (DVIB) approaches, with the gap\nwidening for more complex tasks. Additionally, we reveal that IB-based\nobjectives exhibit stronger robustness against attacks focusing on salient\npixels with high intensity compared to those perturbing many pixels with lower\nintensity. Lastly, we demonstrate that task-oriented communication systems that\nrely on generative models to extract and recover salient information have an\nincreased attack surface. The results highlight important security\nconsiderations for next-generation communication systems that leverage neural\nnetworks for goal-oriented compression.\n","authors":["Alireza Furutanpey","Pantelis A. Frangoudis","Patrik Szabo","Schahram Dustdar"],"pdf_url":"https://arxiv.org/pdf/2412.10265v1.pdf","comment":"Submission to ICMLCN, 6 pages, 9 figures, 3 tables"},{"id":"http://arxiv.org/abs/2412.10251v1","updated":"2024-12-13T16:21:56Z","published":"2024-12-13T16:21:56Z","title":"Controlling dynamical systems into unseen target states using machine\n  learning","summary":"  We present a novel, model-free, and data-driven methodology for controlling\ncomplex dynamical systems into previously unseen target states, including those\nwith significantly different and complex dynamics. Leveraging a parameter-aware\nrealization of next-generation reservoir computing, our approach accurately\npredicts system behavior in unobserved parameter regimes, enabling control over\ntransitions to arbitrary target states. Crucially, this includes states with\ndynamics that differ fundamentally from known regimes, such as shifts from\nperiodic to intermittent or chaotic behavior. The method's parameter-awareness\nfacilitates non-stationary control, ensuring smooth transitions between states.\nBy extending the applicability of machine learning-based control mechanisms to\npreviously inaccessible target dynamics, this methodology opens the door to\ntransformative new applications while maintaining exceptional efficiency. Our\nresults highlight reservoir computing as a powerful alternative to traditional\nmethods for dynamic system control.\n","authors":["Daniel Köglmayr","Alexander Haluszczynski","Christoph Räth"],"pdf_url":"https://arxiv.org/pdf/2412.10251v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10246v1","updated":"2024-12-13T16:14:49Z","published":"2024-12-13T16:14:49Z","title":"Detecting LLM Hallucination Through Layer-wise Information Deficiency:\n  Analysis of Unanswerable Questions and Ambiguous Prompts","summary":"  Large language models (LLMs) frequently generate confident yet inaccurate\nresponses, introducing significant risks for deployment in safety-critical\ndomains. We present a novel approach to detecting model hallucination through\nsystematic analysis of information flow across model layers when processing\ninputs with insufficient or ambiguous context. Our investigation reveals that\nhallucination manifests as usable information deficiencies in inter-layer\ntransmissions. While existing approaches primarily focus on final-layer output\nanalysis, we demonstrate that tracking cross-layer information dynamics\n($\\mathcal{L}$I) provides robust indicators of model reliability, accounting\nfor both information gain and loss during computation. $\\mathcal{L}$I improves\nmodel reliability by immediately integrating with universal LLMs without\nadditional training or architectural modifications.\n","authors":["Hazel Kim","Adel Bibi","Philip Torr","Yarin Gal"],"pdf_url":"https://arxiv.org/pdf/2412.10246v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10244v1","updated":"2024-12-13T16:13:35Z","published":"2024-12-13T16:13:35Z","title":"Efficient Continual Pre-training of LLMs for Low-resource Languages","summary":"  Open-source Large Language models (OsLLMs) propel the democratization of\nnatural language research by giving the flexibility to augment or update model\nparameters for performance improvement. Nevertheless, like proprietary LLMs,\nOs-LLMs offer poorer performance on low-resource languages (LRLs) than\nhigh-resource languages (HRLs), owing to smaller amounts of training data and\nunderrepresented vocabulary. On the other hand, continual pre-training (CPT)\nwith large amounts of language-specific data is a costly proposition in terms\nof data acquisition and computational resources. Our goal is to drastically\nreduce CPT cost. To that end, we first develop a new algorithm to select a\nsubset of texts from a larger corpus. We show the effectiveness of our\ntechnique using very little CPT data. In search of further improvement, we\ndesign a new algorithm to select tokens to include in the LLM vocabulary. We\nexperiment with the recent Llama-3 model and nine Indian languages with diverse\nscripts and extent of resource availability. For evaluation, we use\nIndicGenBench, a generation task benchmark dataset for Indic languages. We\nexperiment with various CPT corpora and augmented vocabulary size and offer\ninsights across language families.\n","authors":["Arijit Nag","Soumen Chakrabarti","Animesh Mukherjee","Niloy Ganguly"],"pdf_url":"https://arxiv.org/pdf/2412.10244v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15312v2","updated":"2024-12-13T15:48:04Z","published":"2024-05-24T07:53:27Z","title":"Multi-Feature Fusion and Compressed Bi-LSTM for Memory-Efficient\n  Heartbeat Classification on Wearable Devices","summary":"  In this article, we present a resource-efficient approach for\nelectrocardiogram (ECG) based heartbeat classification using multi-feature\nfusion and bidirectional long short-term memory (Bi-LSTM). The dataset\ncomprises five original classes from the MIT-BIH Arrhythmia Database: Normal\n(N), Left Bundle Branch Block (LBBB), Right Bundle Branch Block (RBBB),\nPremature Ventricular Contraction (PVC), and Paced Beat (PB). Preprocessing\nmethods including the discrete wavelet transform and dual moving average\nwindows are used to reduce noise and artifacts in the raw ECG signal, and\nextract the main points (PQRST) of the ECG waveform. Multi-feature fusion is\nachieved by utilizing time intervals and the proposed under-the-curve areas,\nwhich are inherently robust against noise, as input features. Simulations\ndemonstrated that incorporating under-the-curve area features improved the\nclassification accuracy for the challenging RBBB and LBBB classes from 31.4\\%\nto 84.3\\% for RBBB, and from 69.6\\% to 87.0\\% for LBBB. Using a Bi-LSTM\nnetwork, rather than a conventional LSTM network, resulted in higher accuracy\n(33.8\\% vs 21.8\\%) with a 28\\% reduction in required network parameters for the\nRBBB class. Multiple neural network models with varying parameter sizes,\nincluding tiny (84k), small (150k), medium (478k), and large (1.25M) models,\nare developed to achieve high accuracy \\textit{across all classes}, a more\ncrucial and challenging goal than overall classification accuracy.\n","authors":["Reza Nikandish","Jiayu He","Benyamin Haghi"],"pdf_url":"https://arxiv.org/pdf/2405.15312v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02541v2","updated":"2024-12-13T15:45:48Z","published":"2024-10-03T14:45:23Z","title":"Fair Decentralized Learning","summary":"  Decentralized learning (DL) is an emerging approach that enables nodes to\ncollaboratively train a machine learning model without sharing raw data. In\nmany application domains, such as healthcare, this approach faces challenges\ndue to the high level of heterogeneity in the training data's feature space.\nSuch feature heterogeneity lowers model utility and negatively impacts\nfairness, particularly for nodes with under-represented training data. In this\npaper, we introduce \\textsc{Facade}, a clustering-based DL algorithm\nspecifically designed for fair model training when the training data exhibits\nseveral distinct features. The challenge of \\textsc{Facade} is to assign nodes\nto clusters, one for each feature, based on the similarity in the features of\ntheir local data, without requiring individual nodes to know apriori which\ncluster they belong to. \\textsc{Facade} (1) dynamically assigns nodes to their\nappropriate clusters over time, and (2) enables nodes to collaboratively train\na specialized model for each cluster in a fully decentralized manner. We\ntheoretically prove the convergence of \\textsc{Facade}, implement our\nalgorithm, and compare it against three state-of-the-art baselines. Our\nexperimental results on three datasets demonstrate the superiority of our\napproach in terms of model accuracy and fairness compared to all three\ncompetitors. Compared to the best-performing baseline, \\textsc{Facade} on the\nCIFAR-10 dataset also reduces communication costs by 32.3\\% to reach a target\naccuracy when cluster sizes are imbalanced.\n","authors":["Sayan Biswas","Anne-Marie Kermarrec","Rishi Sharma","Thibaud Trinca","Martijn de Vos"],"pdf_url":"https://arxiv.org/pdf/2410.02541v2.pdf","comment":"To appear in the proceedings of \"3rd IEEE Conference on Secure and\n  Trustworthy Machine Learning\" (SatML'25)"},{"id":"http://arxiv.org/abs/2412.10208v1","updated":"2024-12-13T15:31:17Z","published":"2024-12-13T15:31:17Z","title":"Efficient Generative Modeling with Residual Vector Quantization-Based\n  Tokens","summary":"  We explore the use of Residual Vector Quantization (RVQ) for high-fidelity\ngeneration in vector-quantized generative models. This quantization technique\nmaintains higher data fidelity by employing more in-depth tokens. However,\nincreasing the token number in generative models leads to slower inference\nspeeds. To this end, we introduce ResGen, an efficient RVQ-based discrete\ndiffusion model that generates high-fidelity samples without compromising\nsampling speed. Our key idea is a direct prediction of vector embedding of\ncollective tokens rather than individual ones. Moreover, we demonstrate that\nour proposed token masking and multi-token prediction method can be formulated\nwithin a principled probabilistic framework using a discrete diffusion process\nand variational inference. We validate the efficacy and generalizability of the\nproposed method on two challenging tasks across different modalities:\nconditional image generation} on ImageNet 256x256 and zero-shot text-to-speech\nsynthesis. Experimental results demonstrate that ResGen outperforms\nautoregressive counterparts in both tasks, delivering superior performance\nwithout compromising sampling speed. Furthermore, as we scale the depth of RVQ,\nour generative models exhibit enhanced generation fidelity or faster sampling\nspeeds compared to similarly sized baseline models. The project page can be\nfound at https://resgen-genai.github.io\n","authors":["Jaehyeon Kim","Taehong Moon","Keon Lee","Jaewoong Cho"],"pdf_url":"https://arxiv.org/pdf/2412.10208v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.05349v2","updated":"2024-12-13T15:17:28Z","published":"2023-05-09T11:20:11Z","title":"Towards the Characterization of Representations Learned via\n  Capsule-based Network Architectures","summary":"  Capsule Networks (CapsNets) have been re-introduced as a more compact and\ninterpretable alternative to standard deep neural networks. While recent\nefforts have proved their compression capabilities, to date, their\ninterpretability properties have not been fully assessed. Here, we conduct a\nsystematic and principled study towards assessing the interpretability of these\ntypes of networks. Moreover, we pay special attention towards analyzing the\nlevel to which part-whole relationships are indeed encoded within the learned\nrepresentation. Our analysis in the MNIST, SVHN, PASCAL-part and CelebA\ndatasets suggest that the representations encoded in CapsNets might not be as\ndisentangled nor strictly related to parts-whole relationships as is commonly\nstated in the literature.\n","authors":["Saja Tawalbeh","José Oramas"],"pdf_url":"https://arxiv.org/pdf/2305.05349v2.pdf","comment":"This paper consist of 32 pages including 19 figures. This paper\n  concern about interpretation of capsule networks"},{"id":"http://arxiv.org/abs/2412.10199v1","updated":"2024-12-13T15:17:23Z","published":"2024-12-13T15:17:23Z","title":"Integrative Analysis of Financial Market Sentiment Using CNN and GRU for\n  Risk Prediction and Alert Systems","summary":"  This document presents an in-depth examination of stock market sentiment\nthrough the integration of Convolutional Neural Networks (CNN) and Gated\nRecurrent Units (GRU), enabling precise risk alerts. The robust feature\nextraction capability of CNN is utilized to preprocess and analyze extensive\nnetwork text data, identifying local features and patterns. The extracted\nfeature sequences are then input into the GRU model to understand the\nprogression of emotional states over time and their potential impact on future\nmarket sentiment and risk. This approach addresses the order dependence and\nlong-term dependencies inherent in time series data, resulting in a detailed\nanalysis of stock market sentiment and effective early warnings of future\nrisks.\n","authors":["You Wu","Mengfang Sun","Hongye Zheng","Jinxin Hu","Yingbin Liang","Zhenghao Lin"],"pdf_url":"https://arxiv.org/pdf/2412.10199v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.17461v2","updated":"2024-12-13T15:08:32Z","published":"2024-11-26T14:28:25Z","title":"SoK: Decentralized AI (DeAI)","summary":"  The centralization of Artificial Intelligence (AI) poses significant\nchallenges, including single points of failure, inherent biases, data privacy\nconcerns, and scalability issues. These problems are especially prevalent in\nclosed-source large language models (LLMs), where user data is collected and\nused without transparency. To mitigate these issues, blockchain-based\ndecentralized AI (DeAI) has emerged as a promising solution. DeAI combines the\nstrengths of both blockchain and AI technologies to enhance the transparency,\nsecurity, decentralization, and trustworthiness of AI systems. However, a\ncomprehensive understanding of state-of-the-art DeAI development, particularly\nfor active industry solutions, is still lacking. In this work, we present a\nSystematization of Knowledge (SoK) for blockchain-based DeAI solutions. We\npropose a taxonomy to classify existing DeAI protocols based on the model\nlifecycle. Based on this taxonomy, we provide a structured way to clarify the\nlandscape of DeAI protocols and identify their similarities and differences. We\nanalyze the functionalities of blockchain in DeAI, investigating how blockchain\nfeatures contribute to enhancing the security, transparency, and\ntrustworthiness of AI processes, while also ensuring fair incentives for AI\ndata and model contributors. In addition, we identify key insights and research\ngaps in developing DeAI protocols, highlighting several critical avenues for\nfuture research.\n","authors":["Zhipeng Wang","Rui Sun","Elizabeth Lui","Vatsal Shah","Xihan Xiong","Jiahao Sun","Davide Crapis","William Knottenbelt"],"pdf_url":"https://arxiv.org/pdf/2411.17461v2.pdf","comment":"This is a Systematization of Knowledge (SoK) for the rapidly evolving\n  field of Decentralized AI (DeAI). We welcome valuable comments, suggestions,\n  and collaboration to further refine and enhance this work. We hope our\n  contribution will help accelerate the advancement of DeAI"},{"id":"http://arxiv.org/abs/2412.10193v1","updated":"2024-12-13T15:08:30Z","published":"2024-12-13T15:08:30Z","title":"Simple Guidance Mechanisms for Discrete Diffusion Models","summary":"  Diffusion models for continuous data gained widespread adoption owing to\ntheir high quality generation and control mechanisms. However, controllable\ndiffusion on discrete data faces challenges given that continuous guidance\nmethods do not directly apply to discrete diffusion. Here, we provide a\nstraightforward derivation of classifier-free and classifier-based guidance for\ndiscrete diffusion, as well as a new class of diffusion models that leverage\nuniform noise and that are more guidable because they can continuously edit\ntheir outputs. We improve the quality of these models with a novel\ncontinuous-time variational lower bound that yields state-of-the-art\nperformance, especially in settings involving guidance or fast generation.\nEmpirically, we demonstrate that our guidance mechanisms combined with uniform\nnoise diffusion improve controllable generation relative to autoregressive and\ndiffusion baselines on several discrete data domains, including genomic\nsequences, small molecule design, and discretized image generation.\n","authors":["Yair Schiff","Subham Sekhar Sahoo","Hao Phung","Guanghan Wang","Sam Boshar","Hugo Dalla-torre","Bernardo P. de Almeida","Alexander Rush","Thomas Pierrot","Volodymyr Kuleshov"],"pdf_url":"https://arxiv.org/pdf/2412.10193v1.pdf","comment":"Code to reproduce our experiments is available here:\n  https://github.com/kuleshov-group/discrete-diffusion-guidance"},{"id":"http://arxiv.org/abs/2409.15161v2","updated":"2024-12-13T15:04:30Z","published":"2024-09-23T16:11:43Z","title":"A Gated Residual Kolmogorov-Arnold Networks for Mixtures of Experts","summary":"  This paper introduces KAMoE, a novel Mixture of Experts (MoE) framework based\non Gated Residual Kolmogorov-Arnold Networks (GRKAN). We propose GRKAN as an\nalternative to the traditional gating function, aiming to enhance efficiency\nand interpretability in MoE modeling. Through extensive experiments on digital\nasset markets and real estate valuation, we demonstrate that KAMoE consistently\noutperforms traditional MoE architectures across various tasks and model types.\nOur results show that GRKAN exhibits superior performance compared to standard\nGating Residual Networks, particularly in LSTM-based models for sequential\ntasks. We also provide insights into the trade-offs between model complexity\nand performance gains in MoE and KAMoE architectures.\n","authors":["Hugo Inzirillo","Remi Genet"],"pdf_url":"https://arxiv.org/pdf/2409.15161v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10186v1","updated":"2024-12-13T14:56:39Z","published":"2024-12-13T14:56:39Z","title":"BiCert: A Bilinear Mixed Integer Programming Formulation for Precise\n  Certified Bounds Against Data Poisoning Attacks","summary":"  Data poisoning attacks pose one of the biggest threats to modern AI systems,\nnecessitating robust defenses. While extensive efforts have been made to\ndevelop empirical defenses, attackers continue to evolve, creating\nsophisticated methods to circumvent these measures. To address this, we must\nmove beyond empirical defenses and establish provable certification methods\nthat guarantee robustness. This paper introduces a novel certification\napproach, BiCert, using Bilinear Mixed Integer Programming (BMIP) to compute\nsound deterministic bounds that provide such provable robustness. Using BMIP,\nwe compute the reachable set of parameters that could result from training with\npotentially manipulated data. A key element to make this computation feasible\nis to relax the reachable parameter set to a convex set between training\niterations. At test time, this parameter set allows us to predict all possible\noutcomes, guaranteeing robustness. BiCert is more precise than previous\nmethods, which rely solely on interval and polyhedral bounds. Crucially, our\napproach overcomes the fundamental limitation of prior approaches where\nparameter bounds could only grow, often uncontrollably. We show that BiCert's\ntighter bounds eliminate a key source of divergence issues, resulting in more\nstable training and higher certified accuracy.\n","authors":["Tobias Lorenz","Marta Kwiatkowska","Mario Fritz"],"pdf_url":"https://arxiv.org/pdf/2412.10186v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10185v1","updated":"2024-12-13T14:55:48Z","published":"2024-12-13T14:55:48Z","title":"Solving Robust Markov Decision Processes: Generic, Reliable, Efficient","summary":"  Markov decision processes (MDP) are a well-established model for sequential\ndecision-making in the presence of probabilities. In robust MDP (RMDP), every\naction is associated with an uncertainty set of probability distributions,\nmodelling that transition probabilities are not known precisely. Based on the\nknown theoretical connection to stochastic games, we provide a framework for\nsolving RMDPs that is generic, reliable, and efficient. It is *generic* both\nwith respect to the model, allowing for a wide range of uncertainty sets,\nincluding but not limited to intervals, $L^1$- or $L^2$-balls, and polytopes;\nand with respect to the objective, including long-run average reward,\nundiscounted total reward, and stochastic shortest path. It is *reliable*, as\nour approach not only converges in the limit, but provides precision guarantees\nat any time during the computation. It is *efficient* because -- in contrast to\nstate-of-the-art approaches -- it avoids explicitly constructing the underlying\nstochastic game. Consequently, our prototype implementation outperforms\nexisting tools by several orders of magnitude and can solve RMDPs with a\nmillion states in under a minute.\n","authors":["Tobias Meggendorfer","Maximilian Weininger","Patrick Wienhöft"],"pdf_url":"https://arxiv.org/pdf/2412.10185v1.pdf","comment":"Accepted for publication at AAAI'25. Extended version with full\n  appendix, 26 pages"},{"id":"http://arxiv.org/abs/2412.10184v1","updated":"2024-12-13T14:55:24Z","published":"2024-12-13T14:55:24Z","title":"Sims: An Interactive Tool for Geospatial Matching and Clustering","summary":"  Acquiring, processing, and visualizing geospatial data requires significant\ncomputing resources, especially for large spatio-temporal domains. This\nchallenge hinders the rapid discovery of predictive features, which is\nessential for advancing geospatial modeling. To address this, we developed\nSimilarity Search (Sims), a no-code web tool that allows users to visualize,\ncompare, cluster, and perform similarity search over defined regions of\ninterest using Google Earth Engine as a backend. Sims is designed to complement\nexisting modeling tools by focusing on feature exploration rather than model\ncreation. We demonstrate the utility of Sims through a case study analyzing\nsimulated maize yield data in Rwanda, where we evaluate how different\ncombinations of soil, weather, and agronomic features affect the clustering of\nyield response zones. Sims is open source and available at\nhttps://github.com/microsoft/Sims\n","authors":["Akram Zaytar","Girmaw Abebe Tadesse","Caleb Robinson","Eduardo G. Bendito","Medha Devare","Meklit Chernet","Gilles Q. Hacheme","Rahul Dodhia","Juan M. Lavista Ferres"],"pdf_url":"https://arxiv.org/pdf/2412.10184v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10182v1","updated":"2024-12-13T14:53:47Z","published":"2024-12-13T14:53:47Z","title":"Multi-Head Encoding for Extreme Label Classification","summary":"  The number of categories of instances in the real world is normally huge, and\neach instance may contain multiple labels. To distinguish these massive labels\nutilizing machine learning, eXtreme Label Classification (XLC) has been\nestablished. However, as the number of categories increases, the number of\nparameters and nonlinear operations in the classifier also rises. This results\nin a Classifier Computational Overload Problem (CCOP). To address this, we\npropose a Multi-Head Encoding (MHE) mechanism, which replaces the vanilla\nclassifier with a multi-head classifier. During the training process, MHE\ndecomposes extreme labels into the product of multiple short local labels, with\neach head trained on these local labels. During testing, the predicted labels\ncan be directly calculated from the local predictions of each head. This\nreduces the computational load geometrically. Then, according to the\ncharacteristics of different XLC tasks, e.g., single-label, multi-label, and\nmodel pretraining tasks, three MHE-based implementations, i.e., Multi-Head\nProduct, Multi-Head Cascade, and Multi-Head Sampling, are proposed to more\neffectively cope with CCOP. Moreover, we theoretically demonstrate that MHE can\nachieve performance approximately equivalent to that of the vanilla classifier\nby generalizing the low-rank approximation problem from Frobenius-norm to\nCross-Entropy. Experimental results show that the proposed methods achieve\nstate-of-the-art performance while significantly streamlining the training and\ninference processes of XLC tasks. The source code has been made public at\nhttps://github.com/Anoise/MHE.\n","authors":["Daojun Liang","Haixia Zhang","Dongfeng Yuan","Minggao Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.10182v1.pdf","comment":"20 pages, 12 figs, Published in TPAMI"},{"id":"http://arxiv.org/abs/2412.10168v1","updated":"2024-12-13T14:33:50Z","published":"2024-12-13T14:33:50Z","title":"Learning payoffs while routing in skill-based queues","summary":"  Motivated by applications in service systems, we consider queueing systems\nwhere each customer must be handled by a server with the right skill set. We\nfocus on optimizing the routing of customers to servers in order to maximize\nthe total payoff of customer--server matches. In addition, customer--server\ndependent payoff parameters are assumed to be unknown a priori. We construct a\nmachine learning algorithm that adaptively learns the payoff parameters while\nmaximizing the total payoff and prove that it achieves polylogarithmic regret.\nMoreover, we show that the algorithm is asymptotically optimal up to\nlogarithmic terms by deriving a regret lower bound. The algorithm leverages the\nbasic feasible solutions of a static linear program as the action space. The\nregret analysis overcomes the complex interplay between queueing and learning\nby analyzing the convergence of the queue length process to its stationary\nbehavior. We also demonstrate the performance of the algorithm numerically, and\nhave included an experiment with time-varying parameters highlighting the\npotential of the algorithm in non-static environments.\n","authors":["Sanne van Kempen","Jaron Sanders","Fiona Sloothaak","Maarten G. Wolf"],"pdf_url":"https://arxiv.org/pdf/2412.10168v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10163v1","updated":"2024-12-13T14:25:27Z","published":"2024-12-13T14:25:27Z","title":"Scaling Combinatorial Optimization Neural Improvement Heuristics with\n  Online Search and Adaptation","summary":"  We introduce Limited Rollout Beam Search (LRBS), a beam search strategy for\ndeep reinforcement learning (DRL) based combinatorial optimization improvement\nheuristics. Utilizing pre-trained models on the Euclidean Traveling Salesperson\nProblem, LRBS significantly enhances both in-distribution performance and\ngeneralization to larger problem instances, achieving optimality gaps that\noutperform existing improvement heuristics and narrowing the gap with\nstate-of-the-art constructive methods. We also extend our analysis to two\npickup and delivery TSP variants to validate our results. Finally, we employ\nour search strategy for offline and online adaptation of the pre-trained\nimprovement policy, leading to improved search performance and surpassing\nrecent adaptive methods for constructive heuristics.\n","authors":["Federico Julian Camerota Verdù","Lorenzo Castelli","Luca Bortolussi"],"pdf_url":"https://arxiv.org/pdf/2412.10163v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10161v1","updated":"2024-12-13T14:24:52Z","published":"2024-12-13T14:24:52Z","title":"Data Integration with Fusion Searchlight: Classifying Brain States from\n  Resting-state fMRI","summary":"  Spontaneous neural activity observed in resting-state fMRI is characterized\nby complex spatio-temporal dynamics. Different measures related to local and\nglobal brain connectivity and fluctuations in low-frequency amplitudes can\nquantify individual aspects of these neural dynamics. Even though such measures\nare derived from the same functional signals, they are often evaluated\nseparately, neglecting their interrelations and potentially reducing the\nanalysis sensitivity. In our study, we present a fusion searchlight (FuSL)\nframework to combine the complementary information contained in different\nresting-state fMRI metrics and demonstrate how this can improve the decoding of\nbrain states. Moreover, we show how explainable AI allows us to reconstruct the\ndifferential impact of each metric on the decoding, which additionally\nincreases spatial specificity of searchlight analysis. In general, this\nframework can be adapted to combine information derived from different imaging\nmodalities or experimental conditions, offering a versatile and interpretable\ntool for data fusion in neuroimaging.\n","authors":["Simon Wein","Marco Riebel","Lisa-Marie Brunner","Caroline Nothdurfter","Rainer Rupprecht","Jens V. Schwarzbach"],"pdf_url":"https://arxiv.org/pdf/2412.10161v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.03551v3","updated":"2024-12-13T14:11:35Z","published":"2024-03-06T08:51:09Z","title":"Enhanced Low-Dose CT Image Reconstruction by Domain and Task Shifting\n  Gaussian Denoisers","summary":"  Computed tomography from a low radiation dose (LDCT) is challenging due to\nhigh noise in the projection data. Popular approaches for LDCT image\nreconstruction are two-stage methods, typically consisting of the filtered\nbackprojection (FBP) algorithm followed by a neural network for LDCT image\nenhancement. Two-stage methods are attractive for their simplicity and\npotential for computational efficiency, typically requiring only a single FBP\nand a neural network forward pass for inference. However, the best\nreconstruction quality is currently achieved by unrolled iterative methods\n(Learned Primal-Dual and ItNet), which are more complex and thus have a higher\ncomputational cost for training and inference. We propose a method combining\nthe simplicity and efficiency of two-stage methods with state-of-the-art\nreconstruction quality. Our strategy utilizes a neural network pretrained for\nGaussian noise removal from natural grayscale images, fine-tuned for LDCT image\nenhancement. We call this method FBP-DTSGD (Domain and Task Shifted Gaussian\nDenoisers) as the fine-tuning is a task shift from Gaussian denoising to\nenhancing LDCT images and a domain shift from natural grayscale to LDCT images.\nAn ablation study with three different pretrained Gaussian denoisers indicates\nthat the performance of FBP-DTSGD does not depend on a specific denoising\narchitecture, suggesting future advancements in Gaussian denoising could\nbenefit the method. The study also shows that pretraining on natural images\nenhances LDCT reconstruction quality, especially with limited training data.\nNotably, pretraining involves no additional cost, as existing pretrained models\nare used. The proposed method currently holds the top mean position in the\nLoDoPaB-CT challenge.\n","authors":["Tim Selig","Thomas März","Martin Storath","Andreas Weinmann"],"pdf_url":"https://arxiv.org/pdf/2403.03551v3.pdf","comment":"13 pages, 4 figures"},{"id":"http://arxiv.org/abs/2401.04402v2","updated":"2024-12-13T14:04:57Z","published":"2024-01-09T07:57:21Z","title":"IGNITE: Individualized GeNeration of Imputations in Time-series\n  Electronic health records","summary":"  Electronic Health Records present a valuable modality for driving\npersonalized medicine, where treatment is tailored to fit individual-level\ndifferences. For this purpose, many data-driven machine learning and\nstatistical models rely on the wealth of longitudinal EHRs to study patients'\nphysiological and treatment effects. However, longitudinal EHRs tend to be\nsparse and highly missing, where missingness could also be informative and\nreflect the underlying patient's health status. Therefore, the success of\ndata-driven models for personalized medicine highly depends on how the EHR data\nis represented from physiological data, treatments, and the missing values in\nthe data. To this end, we propose a novel deep-learning model that learns the\nunderlying patient dynamics over time across multivariate data to generate\npersonalized realistic values conditioning on an individual's demographic\ncharacteristics and treatments. Our proposed model, IGNITE (Individualized\nGeNeration of Imputations in Time-series Electronic health records), utilises a\nconditional dual-variational autoencoder augmented with dual-stage attention to\ngenerate missing values for an individual. In IGNITE, we further propose a\nnovel individualized missingness mask (IMM), which helps our model generate\nvalues based on the individual's observed data and missingness patterns. We\nfurther extend the use of IGNITE from imputing missingness to a personalized\ndata synthesizer, where it generates missing EHRs that were never observed\nprior or even generates new patients for various applications. We validate our\nmodel on three large publicly available datasets and show that IGNITE\noutperforms state-of-the-art approaches in missing data reconstruction and task\nprediction.\n","authors":["Ghadeer O. Ghosheh","Jin Li","Tingting Zhu"],"pdf_url":"https://arxiv.org/pdf/2401.04402v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10146v1","updated":"2024-12-13T14:02:41Z","published":"2024-12-13T14:02:41Z","title":"Investigating generalization capabilities of neural networks by means of\n  loss landscapes and Hessian analysis","summary":"  This paper studies generalization capabilities of neural networks (NNs) using\nnew and improved PyTorch library Loss Landscape Analysis (LLA). LLA facilitates\nvisualization and analysis of loss landscapes along with the properties of NN\nHessian. Different approaches to NN loss landscape plotting are discussed with\nparticular focus on normalization techniques showing that conventional methods\ncannot always ensure correct visualization when batch normalization layers are\npresent in NN architecture. The use of Hessian axes is shown to be able to\nmitigate this effect, and methods for choosing Hessian axes are proposed. In\naddition, spectra of Hessian eigendecomposition are studied and it is shown\nthat typical spectra exist for a wide range of NNs. This allows to propose\nquantitative criteria for Hessian analysis that can be applied to evaluate NN\nperformance and assess its generalization capabilities. Generalization\nexperiments are conducted using ImageNet-1K pre-trained models along with\nseveral models trained as part of this study. The experiment include training\nmodels on one dataset and testing on another one to maximize experiment\nsimilarity to model performance in the Wild. It is shown that when datasets\nchange, the changes in criteria correlate with the changes in accuracy, making\nthe proposed criteria a computationally efficient estimate of generalization\nability, which is especially useful for extremely large datasets.\n","authors":["Nikita Gabdullin"],"pdf_url":"https://arxiv.org/pdf/2412.10146v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.06969v3","updated":"2024-12-13T13:56:04Z","published":"2024-04-10T12:29:05Z","title":"A Fixed-Point Approach for Causal Generative Modeling","summary":"  We propose a novel formalism for describing Structural Causal Models (SCMs)\nas fixed-point problems on causally ordered variables, eliminating the need for\nDirected Acyclic Graphs (DAGs), and establish the weakest known conditions for\ntheir unique recovery given the topological ordering (TO). Based on this, we\ndesign a two-stage causal generative model that first infers in a zero-shot\nmanner a valid TO from observations, and then learns the generative SCM on the\nordered variables. To infer TOs, we propose to amortize the learning of TOs on\nsynthetically generated datasets by sequentially predicting the leaves of\ngraphs seen during training. To learn SCMs, we design a transformer-based\narchitecture that exploits a new attention mechanism enabling the modeling of\ncausal structures, and show that this parameterization is consistent with our\nformalism. Finally, we conduct an extensive evaluation of each method\nindividually, and show that when combined, our model outperforms various\nbaselines on generated out-of-distribution problems. The code is available on\n\\href{https://github.com/microsoft/causica/tree/main/research_experiments/fip}{Github}.\n","authors":["Meyer Scetbon","Joel Jennings","Agrin Hilmkil","Cheng Zhang","Chao Ma"],"pdf_url":"https://arxiv.org/pdf/2404.06969v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10136v1","updated":"2024-12-13T13:32:59Z","published":"2024-12-13T13:32:59Z","title":"Can LLMs Convert Graphs to Text-Attributed Graphs?","summary":"  Graphs are ubiquitous data structures found in numerous real-world\napplications, such as drug discovery, recommender systems, and social network\nanalysis. Graph neural networks (GNNs) have become a popular tool to learn node\nembeddings through message passing on these structures. However, a significant\nchallenge arises when applying GNNs to multiple graphs with different feature\nspaces, as existing GNN architectures are not designed for cross-graph feature\nalignment. To address this, recent approaches introduce text-attributed graphs,\nwhere each node is associated with a textual description, enabling the use of a\nshared textual encoder to project nodes from different graphs into a unified\nfeature space. While promising, this method relies heavily on the availability\nof text-attributed data, which can be difficult to obtain in practice. To\nbridge this gap, we propose a novel method named Topology-Aware Node\ndescription Synthesis (TANS), which leverages large language models (LLMs) to\nautomatically convert existing graphs into text-attributed graphs. The key idea\nis to integrate topological information with each node's properties, enhancing\nthe LLMs' ability to explain how graph topology influences node semantics. We\nevaluate our TANS on text-rich, text-limited, and text-free graphs,\ndemonstrating that it enables a single GNN to operate across diverse graphs.\nNotably, on text-free graphs, our method significantly outperforms existing\napproaches that manually design node features, showcasing the potential of LLMs\nfor preprocessing graph-structured data, even in the absence of textual\ninformation. The code and data are available at\nhttps://github.com/Zehong-Wang/TANS.\n","authors":["Zehong Wang","Sidney Liu","Zheyuan Zhang","Tianyi Ma","Chuxu Zhang","Yanfang Ye"],"pdf_url":"https://arxiv.org/pdf/2412.10136v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10130v1","updated":"2024-12-13T13:22:39Z","published":"2024-12-13T13:22:39Z","title":"Optimal Bounds for Private Minimum Spanning Trees via Input Perturbation","summary":"  We study the problem of privately releasing an approximate minimum spanning\ntree (MST). Given a graph $G = (V, E, \\vec{W})$ where $V$ is a set of $n$\nvertices, $E$ is a set of $m$ undirected edges, and $ \\vec{W} \\in\n\\mathbb{R}^{|E|} $ is an edge-weight vector, our goal is to publish an\napproximate MST under edge-weight differential privacy, as introduced by\nSealfon in PODS 2016, where $V$ and $E$ are considered public and the weight\nvector is private. Our neighboring relation is $\\ell_\\infty$-distance on\nweights: for a sensitivity parameter $\\Delta_\\infty$, graphs $ G = (V, E,\n\\vec{W}) $ and $ G' = (V, E, \\vec{W}') $ are neighboring if\n$\\|\\vec{W}-\\vec{W}'\\|_\\infty \\leq \\Delta_\\infty$.\n  Existing private MST algorithms face a trade-off, sacrificing either\ncomputational efficiency or accuracy. We show that it is possible to get the\nbest of both worlds: With a suitable random perturbation of the input that does\nnot suffice to make the weight vector private, the result of any non-private\nMST algorithm will be private and achieves a state-of-the-art error guarantee.\n  Furthermore, by establishing a connection to Private Top-k Selection [Steinke\nand Ullman, FOCS '17], we give the first privacy-utility trade-off lower bound\nfor MST under approximate differential privacy, demonstrating that the error\nmagnitude, $\\tilde{O}(n^{3/2})$, is optimal up to logarithmic factors. That is,\nour approach matches the time complexity of any non-private MST algorithm and\nat the same time achieves optimal error. We complement our theoretical\ntreatment with experiments that confirm the practicality of our approach.\n","authors":["Rasmus Pagh","Lukas Retschmeier","Hao Wu","Hanwen Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.10130v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10128v1","updated":"2024-12-13T13:20:10Z","published":"2024-12-13T13:20:10Z","title":"Feature Selection for Latent Factor Models","summary":"  Feature selection is crucial for pinpointing relevant features in\nhigh-dimensional datasets, mitigating the 'curse of dimensionality,' and\nenhancing machine learning performance. Traditional feature selection methods\nfor classification use data from all classes to select features for each class.\nThis paper explores feature selection methods that select features for each\nclass separately, using class models based on low-rank generative methods and\nintroducing a signal-to-noise ratio (SNR) feature selection criterion. This\nnovel approach has theoretical true feature recovery guarantees under certain\nassumptions and is shown to outperform some existing feature selection methods\non standard classification datasets.\n","authors":["Rittwika Kansabanik","Adrian Barbu"],"pdf_url":"https://arxiv.org/pdf/2412.10128v1.pdf","comment":"Submitted to the CVPR conference"},{"id":"http://arxiv.org/abs/2410.01774v2","updated":"2024-12-13T13:14:45Z","published":"2024-10-02T17:30:21Z","title":"Trained Transformer Classifiers Generalize and Exhibit Benign\n  Overfitting In-Context","summary":"  Transformers have the capacity to act as supervised learning algorithms: by\nproperly encoding a set of labeled training (\"in-context\") examples and an\nunlabeled test example into an input sequence of vectors of the same dimension,\nthe forward pass of the transformer can produce predictions for that unlabeled\ntest example. A line of recent work has shown that when linear transformers are\npre-trained on random instances for linear regression tasks, these trained\ntransformers make predictions using an algorithm similar to that of ordinary\nleast squares. In this work, we investigate the behavior of linear transformers\ntrained on random linear classification tasks. Via an analysis of the implicit\nregularization of gradient descent, we characterize how many pre-training tasks\nand in-context examples are needed for the trained transformer to generalize\nwell at test-time. We further show that in some settings, these trained\ntransformers can exhibit \"benign overfitting in-context\": when in-context\nexamples are corrupted by label flipping noise, the transformer memorizes all\nof its in-context examples (including those with noisy labels) yet still\ngeneralizes near-optimally for clean test examples.\n","authors":["Spencer Frei","Gal Vardi"],"pdf_url":"https://arxiv.org/pdf/2410.01774v2.pdf","comment":"36 pages; added experiments"},{"id":"http://arxiv.org/abs/2412.10119v1","updated":"2024-12-13T13:04:46Z","published":"2024-12-13T13:04:46Z","title":"AMUSE: Adaptive Model Updating using a Simulated Environment","summary":"  Prediction models frequently face the challenge of concept drift, in which\nthe underlying data distribution changes over time, weakening performance.\nExamples can include models which predict loan default, or those used in\nhealthcare contexts. Typical management strategies involve regular model\nupdates or updates triggered by concept drift detection. However, these simple\npolicies do not necessarily balance the cost of model updating with improved\nclassifier performance. We present AMUSE (Adaptive Model Updating using a\nSimulated Environment), a novel method leveraging reinforcement learning\ntrained within a simulated data generating environment, to determine update\ntimings for classifiers. The optimal updating policy depends on the current\ndata generating process and ongoing drift process. Our key idea is that we can\ntrain an arbitrarily complex model updating policy by creating a training\nenvironment in which possible episodes of drift are simulated by a parametric\nmodel, which represents expectations of possible drift patterns. As a result,\nAMUSE proactively recommends updates based on estimated performance\nimprovements, learning a policy that balances maintaining model performance\nwith minimizing update costs. Empirical results confirm the effectiveness of\nAMUSE in simulated data.\n","authors":["Louis Chislett","Catalina A. Vallejos","Timothy I. Cannings","James Liley"],"pdf_url":"https://arxiv.org/pdf/2412.10119v1.pdf","comment":"12 pages, 2 tables. Submitted to AIStats 2025 (under review)"},{"id":"http://arxiv.org/abs/2412.10117v1","updated":"2024-12-13T12:59:39Z","published":"2024-12-13T12:59:39Z","title":"CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language\n  Models","summary":"  In our previous work, we introduced CosyVoice, a multilingual speech\nsynthesis model based on supervised discrete speech tokens. By employing\nprogressive semantic decoding with two popular generative models, language\nmodels (LMs) and Flow Matching, CosyVoice demonstrated high prosody\nnaturalness, content consistency, and speaker similarity in speech in-context\nlearning. Recently, significant progress has been made in multi-modal large\nlanguage models (LLMs), where the response latency and real-time factor of\nspeech synthesis play a crucial role in the interactive experience. Therefore,\nin this report, we present an improved streaming speech synthesis model,\nCosyVoice 2, which incorporates comprehensive and systematic optimizations.\nSpecifically, we introduce finite-scalar quantization to improve the codebook\nutilization of speech tokens. For the text-speech LM, we streamline the model\narchitecture to allow direct use of a pre-trained LLM as the backbone. In\naddition, we develop a chunk-aware causal flow matching model to support\nvarious synthesis scenarios, enabling both streaming and non-streaming\nsynthesis within a single model. By training on a large-scale multilingual\ndataset, CosyVoice 2 achieves human-parity naturalness, minimal response\nlatency, and virtually lossless synthesis quality in the streaming mode. We\ninvite readers to listen to the demos at\nhttps://funaudiollm.github.io/cosyvoice2.\n","authors":["Zhihao Du","Yuxuan Wang","Qian Chen","Xian Shi","Xiang Lv","Tianyu Zhao","Zhifu Gao","Yexin Yang","Changfeng Gao","Hui Wang","Fan Yu","Huadai Liu","Zhengyan Sheng","Yue Gu","Chong Deng","Wen Wang","Shiliang Zhang","Zhijie Yan","Jingren Zhou"],"pdf_url":"https://arxiv.org/pdf/2412.10117v1.pdf","comment":"Tech report, work in progress"},{"id":"http://arxiv.org/abs/2412.10107v1","updated":"2024-12-13T12:48:15Z","published":"2024-12-13T12:48:15Z","title":"NetOrchLLM: Mastering Wireless Network Orchestration with Large Language\n  Models","summary":"  The transition to 6G networks promises unprecedented advancements in wireless\ncommunication, with increased data rates, ultra-low latency, and enhanced\ncapacity. However, the complexity of managing and optimizing these\nnext-generation networks presents significant challenges. The advent of large\nlanguage models (LLMs) has revolutionized various domains by leveraging their\nsophisticated natural language understanding capabilities. However, the\npractical application of LLMs in wireless network orchestration and management\nremains largely unexplored. Existing literature predominantly offers visionary\nperspectives without concrete implementations, leaving a significant gap in the\nfield. To address this gap, this paper presents NETORCHLLM, a wireless NETwork\nORCHestrator LLM framework that uses LLMs to seamlessly orchestrate diverse\nwireless-specific models from wireless communication communities using their\nlanguage understanding and generation capabilities. A comprehensive framework\nis introduced, demonstrating the practical viability of our approach and\nshowcasing how LLMs can be effectively harnessed to optimize dense network\noperations, manage dynamic environments, and improve overall network\nperformance. NETORCHLLM bridges the theoretical aspirations of prior research\nwith practical, actionable solutions, paving the way for future advancements in\nintegrating generative AI technologies within the wireless communications\nsector.\n","authors":["Asmaa Abdallah","Abdullatif Albaseer","Abdulkadir Celik","Mohamed Abdallah","Ahmed M. Eltawil"],"pdf_url":"https://arxiv.org/pdf/2412.10107v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07205v2","updated":"2024-12-13T12:38:04Z","published":"2024-12-10T05:50:50Z","title":"Crack-EdgeSAM Self-Prompting Crack Segmentation System for Edge Devices","summary":"  Structural health monitoring (SHM) is essential for the early detection of\ninfrastructure defects, such as cracks in concrete bridge pier. but often faces\nchallenges in efficiency and accuracy in complex environments. Although the\nSegment Anything Model (SAM) achieves excellent segmentation performance, its\ncomputational demands limit its suitability for real-time applications on edge\ndevices. To address these challenges, this paper proposes Crack-EdgeSAM, a\nself-prompting crack segmentation system that integrates YOLOv8 for generating\nprompt boxes and a fine-tuned EdgeSAM model for crack segmentation. To ensure\ncomputational efficiency, the method employs ConvLoRA, a Parameter-Efficient\nFine-Tuning (PEFT) technique, along with DiceFocalLoss to fine-tune the EdgeSAM\nmodel. Our experimental results on public datasets and the climbing robot\nautomatic inspections demonstrate that the system achieves high segmentation\naccuracy and significantly enhanced inference speed compared to the most recent\nmethods. Notably, the system processes 1024 x 1024 pixels images at 46 FPS on\nour PC and 8 FPS on Jetson Orin Nano.\n","authors":["Yingchu Wang","Ji He","Shijie Yu"],"pdf_url":"https://arxiv.org/pdf/2412.07205v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10096v1","updated":"2024-12-13T12:32:53Z","published":"2024-12-13T12:32:53Z","title":"Reward Machine Inference for Robotic Manipulation","summary":"  Learning from Demonstrations (LfD) and Reinforcement Learning (RL) have\nenabled robot agents to accomplish complex tasks. Reward Machines (RMs) enhance\nRL's capability to train policies over extended time horizons by structuring\nhigh-level task information. In this work, we introduce a novel LfD approach\nfor learning RMs directly from visual demonstrations of robotic manipulation\ntasks. Unlike previous methods, our approach requires no predefined\npropositions or prior knowledge of the underlying sparse reward signals.\nInstead, it jointly learns the RM structure and identifies key high-level\nevents that drive transitions between RM states. We validate our method on\nvision-based manipulation tasks, showing that the inferred RM accurately\ncaptures task structure and enables an RL agent to effectively learn an optimal\npolicy.\n","authors":["Mattijs Baert","Sam Leroux","Pieter Simoens"],"pdf_url":"https://arxiv.org/pdf/2412.10096v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10095v1","updated":"2024-12-13T12:31:06Z","published":"2024-12-13T12:31:06Z","title":"HiTZ at VarDial 2025 NorSID: Overcoming Data Scarcity with Language\n  Transfer and Automatic Data Annotation","summary":"  In this paper we present our submission for the NorSID Shared Task as part of\nthe 2025 VarDial Workshop (Scherrer et al., 2025), consisting of three tasks:\nIntent Detection, Slot Filling and Dialect Identification, evaluated using data\nin different dialects of the Norwegian language. For Intent Detection and Slot\nFilling, we have fine-tuned a multitask model in a cross-lingual setting, to\nleverage the xSID dataset available in 17 languages. In the case of Dialect\nIdentification, our final submission consists of a model fine-tuned on the\nprovided development set, which has obtained the highest scores within our\nexperiments. Our final results on the test set show that our models do not drop\nin performance compared to the development set, likely due to the\ndomain-specificity of the dataset and the similar distribution of both subsets.\nFinally, we also report an in-depth analysis of the provided datasets and their\nartifacts, as well as other sets of experiments that have been carried out but\ndid not yield the best results. Additionally, we present an analysis on the\nreasons why some methods have been more successful than others; mainly the\nimpact of the combination of languages and domain-specificity of the training\ndata on the results.\n","authors":["Jaione Bengoetxea","Mikel Zubillaga","Ekhi Azurmendi","Maite Heredia","Julen Etxaniz","Markel Ferro","Jeremy Barnes"],"pdf_url":"https://arxiv.org/pdf/2412.10095v1.pdf","comment":"Vardial 2025 NorSID Shared Task"},{"id":"http://arxiv.org/abs/2412.10092v1","updated":"2024-12-13T12:30:09Z","published":"2024-12-13T12:30:09Z","title":"A Survey on Knowledge Graph Structure and Knowledge Graph Embeddings","summary":"  Knowledge Graphs (KGs) and their machine learning counterpart, Knowledge\nGraph Embedding Models (KGEMs), have seen ever-increasing use in a wide variety\nof academic and applied settings. In particular, KGEMs are typically applied to\nKGs to solve the link prediction task; i.e. to predict new facts in the domain\nof a KG based on existing, observed facts. While this approach has been shown\nsubstantial power in many end-use cases, it remains incompletely characterised\nin terms of how KGEMs react differently to KG structure. This is of particular\nconcern in light of recent studies showing that KG structure can be a\nsignificant source of bias as well as partially determinant of overall KGEM\nperformance. This paper seeks to address this gap in the state-of-the-art. This\npaper provides, to the authors' knowledge, the first comprehensive survey\nexploring established relationships of Knowledge Graph Embedding Models and\nGraph structure in the literature. It is the hope of the authors that this work\nwill inspire further studies in this area, and contribute to a more holistic\nunderstanding of KGs, KGEMs, and the link prediction task.\n","authors":["Jeffrey Sardina","John D. Kelleher","Declan O'Sullivan"],"pdf_url":"https://arxiv.org/pdf/2412.10092v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.00489v3","updated":"2024-12-13T12:11:01Z","published":"2024-06-01T16:38:43Z","title":"Efficient Sign-Based Optimization: Accelerating Convergence via Variance\n  Reduction","summary":"  Sign stochastic gradient descent (signSGD) is a communication-efficient\nmethod that transmits only the sign of stochastic gradients for parameter\nupdating. Existing literature has demonstrated that signSGD can achieve a\nconvergence rate of $\\mathcal{O}(d^{1/2}T^{-1/4})$, where $d$ represents the\ndimension and $T$ is the iteration number. In this paper, we improve this\nconvergence rate to $\\mathcal{O}(d^{1/2}T^{-1/3})$ by introducing the\nSign-based Stochastic Variance Reduction (SSVR) method, which employs variance\nreduction estimators to track gradients and leverages their signs to update.\nFor finite-sum problems, our method can be further enhanced to achieve a\nconvergence rate of $\\mathcal{O}(m^{1/4}d^{1/2}T^{-1/2})$, where $m$ denotes\nthe number of component functions. Furthermore, we investigate the\nheterogeneous majority vote in distributed settings and introduce two novel\nalgorithms that attain improved convergence rates of\n$\\mathcal{O}(d^{1/2}T^{-1/2} + dn^{-1/2})$ and $\\mathcal{O}(d^{1/4}T^{-1/4})$\nrespectively, outperforming the previous results of $\\mathcal{O}(dT^{-1/4} +\ndn^{-1/2})$ and $\\mathcal{O}(d^{3/8}T^{-1/8})$, where $n$ represents the number\nof nodes. Numerical experiments across different tasks validate the\neffectiveness of our proposed methods.\n","authors":["Wei Jiang","Sifan Yang","Wenhao Yang","Lijun Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.00489v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10064v1","updated":"2024-12-13T11:50:51Z","published":"2024-12-13T11:50:51Z","title":"Text2Cypher: Bridging Natural Language and Graph Databases","summary":"  Knowledge graphs use nodes, relationships, and properties to represent\narbitrarily complex data. When stored in a graph database, the Cypher query\nlanguage enables efficient modeling and querying of knowledge graphs. However,\nusing Cypher requires specialized knowledge, which can present a challenge for\nnon-expert users. Our work Text2Cypher aims to bridge this gap by translating\nnatural language queries into Cypher query language and extending the utility\nof knowledge graphs to non-technical expert users.\n  While large language models (LLMs) can be used for this purpose, they often\nstruggle to capture complex nuances, resulting in incomplete or incorrect\noutputs. Fine-tuning LLMs on domain-specific datasets has proven to be a more\npromising approach, but the limited availability of high-quality, publicly\navailable Text2Cypher datasets makes this challenging. In this work, we show\nhow we combined, cleaned and organized several publicly available datasets into\na total of 44,387 instances, enabling effective fine-tuning and evaluation.\nModels fine-tuned on this dataset showed significant performance gains, with\nimprovements in Google-BLEU and Exact Match scores over baseline models,\nhighlighting the importance of high-quality datasets and fine-tuning in\nimproving Text2Cypher performance.\n","authors":["Makbule Gulcin Ozsoy","Leila Messallem","Jon Besga","Gianandrea Minneci"],"pdf_url":"https://arxiv.org/pdf/2412.10064v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.03389v2","updated":"2024-12-13T11:01:06Z","published":"2024-07-03T09:06:19Z","title":"A Deterministic Information Bottleneck Method for Clustering Mixed-Type\n  Data","summary":"  In this paper, we present an information-theoretic method for clustering\nmixed-type data, that is, data consisting of both continuous and categorical\nvariables. The proposed approach is built on the deterministic variant of the\nInformation Bottleneck algorithm, designed to optimally compress data while\npreserving its relevant structural information. We evaluate the performance of\nour method against four well-established clustering techniques for mixed-type\ndata -- KAMILA, K-Prototypes, Factor Analysis for Mixed Data with K-Means, and\nPartitioning Around Medoids using Gower's dissimilarity -- using both simulated\nand real-world datasets. The results highlight that the proposed approach\noffers a competitive alternative to traditional clustering techniques,\nparticularly under specific conditions where heterogeneity in data poses\nsignificant challenges.\n","authors":["Efthymios Costa","Ioanna Papatsouma","Angelos Markos"],"pdf_url":"https://arxiv.org/pdf/2407.03389v2.pdf","comment":"Submitted to Pattern Recognition"},{"id":"http://arxiv.org/abs/2401.16920v2","updated":"2024-12-13T10:20:13Z","published":"2024-01-30T11:42:52Z","title":"Sparse Portfolio Selection via Topological Data Analysis based\n  Clustering","summary":"  This paper uses topological data analysis (TDA) tools and introduces a\ndata-driven clustering-based stock selection strategy tailored for sparse\nportfolio construction. Our asset selection strategy exploits the topological\nfeatures of stock price movements to select a subset of topologically similar\n(different) assets for a sparse index tracking (Markowitz) portfolio. We\nintroduce new distance measures, which serve as an input to the clustering\nalgorithm, on the space of persistence diagrams and landscapes that consider\nthe time component of a time series. We conduct an empirical analysis on the\nS\\&P index from 2009 to 2022, including a study on the COVID-19 data to\nvalidate the robustness of our methodology. Our strategy to integrate TDA with\nthe clustering algorithm significantly enhanced the performance of sparse\nportfolios across various performance measures in diverse market scenarios.\n","authors":["Anubha Goel","Damir Filipović","Puneet Pasricha"],"pdf_url":"https://arxiv.org/pdf/2401.16920v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06175v2","updated":"2024-12-13T10:11:31Z","published":"2024-11-09T13:17:39Z","title":"Clustering Algorithms and RAG Enhancing Semi-Supervised Text\n  Classification with Large LLMs","summary":"  This paper introduces a novel semi-supervised learning framework specifically\ndesigned for text classification tasks, effectively addressing the challenge of\nvast datasets with limited labeled examples. By integrating multi-level\nsimilarity based data augmentation techniques from Retrieval-Augmented\nGeneration (RAG) to Large Language Model (LLM) rewriting and traditional word\nsubstitution-we constructed an intelligent augmentation pipeline. This\nframework innovatively employs the selection of representative landmarks\nthrough clustering, which serve as intermediaries in the retrieval and\nrewriting processes, ensuring that the augmented data maintains a distribution\nsimilar to the original dataset. Empirical results show that even in complex\ntext document classification scenarios with over 100 categories, our method\nachieves state-of-the-art accuracies of 95.41% and 82.43% on the Reuters and\nWeb of Science datasets, respectively. These findings highlight the\neffectiveness and broad applicability of our semi-supervised learning approach\nfor text classification tasks.\n","authors":["Shan Zhong","Jiahao Zeng","Yongxin Yu","Bohong Lin"],"pdf_url":"https://arxiv.org/pdf/2411.06175v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.04230v3","updated":"2024-12-13T10:03:10Z","published":"2024-05-07T11:50:25Z","title":"Unveiling the optimization process of Physics Informed Neural Networks:\n  How accurate and competitive can PINNs be?","summary":"  This study investigates the potential accuracy boundaries of physics-informed\nneural networks, contrasting their approach with previous similar works and\ntraditional numerical methods. We find that selecting improved optimization\nalgorithms significantly enhances the accuracy of the results. Simple\nmodifications to the loss function may also improve precision, offering an\nadditional avenue for enhancement. Despite optimization algorithms having a\ngreater impact on convergence than adjustments to the loss function, practical\nconsiderations often favor tweaking the latter due to ease of implementation.\nOn a global scale, the integration of an enhanced optimizer and a marginally\nadjusted loss function enables a reduction in the loss function by several\norders of magnitude across diverse physical problems. Consequently, our results\nobtained using compact networks (typically comprising 2 or 3 layers of 20-30\nneurons) achieve accuracies comparable to finite difference schemes employing\nthousands of grid points. This study encourages the continued advancement of\nPINNs and associated optimization techniques for broader applications across\nvarious fields.\n","authors":["Jorge F. Urbán","Petros Stefanou","José A. Pons"],"pdf_url":"https://arxiv.org/pdf/2405.04230v3.pdf","comment":"63 pages, 25 figures. This is the author-accepted manuscript of the\n  paper published in Journal of Computational Physics"},{"id":"http://arxiv.org/abs/2412.10011v1","updated":"2024-12-13T09:55:03Z","published":"2024-12-13T09:55:03Z","title":"Enhanced Speech Emotion Recognition with Efficient Channel Attention\n  Guided Deep CNN-BiLSTM Framework","summary":"  Speech emotion recognition (SER) is crucial for enhancing affective computing\nand enriching the domain of human-computer interaction. However, the main\nchallenge in SER lies in selecting relevant feature representations from speech\nsignals with lower computational costs. In this paper, we propose a lightweight\nSER architecture that integrates attention-based local feature blocks (ALFBs)\nto capture high-level relevant feature vectors from speech signals. We also\nincorporate a global feature block (GFB) technique to capture sequential,\nglobal information and long-term dependencies in speech signals. By aggregating\nattention-based local and global contextual feature vectors, our model\neffectively captures the internal correlation between salient features that\nreflect complex human emotional cues. To evaluate our approach, we extracted\nfour types of spectral features from speech audio samples: mel-frequency\ncepstral coefficients, mel-spectrogram, root mean square value, and\nzero-crossing rate. Through a 5-fold cross-validation strategy, we tested the\nproposed method on five multi-lingual standard benchmark datasets: TESS,\nRAVDESS, BanglaSER, SUBESCO, and Emo-DB, and obtained a mean accuracy of\n99.65%, 94.88%, 98.12%, 97.94%, and 97.19% respectively. The results indicate\nthat our model achieves state-of-the-art (SOTA) performance compared to most\nexisting methods.\n","authors":["Niloy Kumar Kundu","Sarah Kobir","Md. Rayhan Ahmed","Tahmina Aktar","Niloya Roy"],"pdf_url":"https://arxiv.org/pdf/2412.10011v1.pdf","comment":"42 pages,10 figures"},{"id":"http://arxiv.org/abs/2412.09602v2","updated":"2024-12-13T09:51:22Z","published":"2024-12-12T18:59:13Z","title":"Hidden Biases of End-to-End Driving Datasets","summary":"  End-to-end driving systems have made rapid progress, but have so far not been\napplied to the challenging new CARLA Leaderboard 2.0. Further, while there is a\nlarge body of literature on end-to-end architectures and training strategies,\nthe impact of the training dataset is often overlooked. In this work, we make a\nfirst attempt at end-to-end driving for Leaderboard 2.0. Instead of\ninvestigating architectures, we systematically analyze the training dataset,\nleading to new insights: (1) Expert style significantly affects downstream\npolicy performance. (2) In complex data sets, the frames should not be weighted\non the basis of simplistic criteria such as class frequencies. (3) Instead,\nestimating whether a frame changes the target labels compared to previous\nframes can reduce the size of the dataset without removing important\ninformation. By incorporating these findings, our model ranks first and second\nrespectively on the map and sensors tracks of the 2024 CARLA Challenge, and\nsets a new state-of-the-art on the Bench2Drive test routes. Finally, we uncover\na design flaw in the current evaluation metrics and propose a modification for\nfuture challenges. Our dataset, code, and pre-trained models are publicly\navailable at https://github.com/autonomousvision/carla_garage.\n","authors":["Julian Zimmerlin","Jens Beißwenger","Bernhard Jaeger","Andreas Geiger","Kashyap Chitta"],"pdf_url":"https://arxiv.org/pdf/2412.09602v2.pdf","comment":"Technical report for the CVPR 2024 Workshop on Foundation Models for\n  Autonomous Systems. Runner-up of the track 'CARLA Autonomous Driving\n  Challenge' in the 2024 Autonomous Grand Challenge\n  (https://opendrivelab.com/challenge2024/)"},{"id":"http://arxiv.org/abs/2412.10009v1","updated":"2024-12-13T09:49:40Z","published":"2024-12-13T09:49:40Z","title":"Class flipping for uplift modeling and Heterogeneous Treatment Effect\n  estimation on imbalanced RCT data","summary":"  Uplift modeling and Heterogeneous Treatment Effect (HTE) estimation aim at\npredicting the causal effect of an action, such as a medical treatment or a\nmarketing campaign on a specific individual. In this paper, we focus on data\nfrom Randomized Controlled Experiments which guarantee causal interpretation of\nthe outcomes. Class and treatment imbalance are important problems in uplift\nmodeling/HTE, but classical undersampling or oversampling based approaches are\nhard to apply in this case since they distort the predicted effect. Calibration\nmethods have been proposed in the past, however, they do not guarantee correct\npredictions. In this work, we propose an approach alternative to undersampling,\nbased on flipping the class value of selected records. We show that the\nproposed approach does not distort the predicted effect and does not require\ncalibration. The method is especially useful for models based on class variable\ntransformation (modified outcome models). We address those models separately,\ndesigning a transformation scheme which guarantees correct predictions and\naddresses also the problem of treatment imbalance which is especially important\nfor those models. Experiments fully confirm our theoretical results.\nAdditionally, we demonstrate that our method is a viable alternative also for\nstandard classification problems.\n","authors":["Krzysztof Rudaś","Szymon Jaroszewicz"],"pdf_url":"https://arxiv.org/pdf/2412.10009v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.07450v2","updated":"2024-12-13T09:47:04Z","published":"2024-07-10T08:07:55Z","title":"Using Low-Discrepancy Points for Data Compression in Machine Learning:\n  An Experimental Comparison","summary":"  Low-discrepancy points (also called Quasi-Monte Carlo points) are\ndeterministically and cleverly chosen point sets in the unit cube, which\nprovide an approximation of the uniform distribution. We explore two methods\nbased on such low-discrepancy points to reduce large data sets in order to\ntrain neural networks. The first one is the method of Dick and Feischl [4],\nwhich relies on digital nets and an averaging procedure. Motivated by our\nexperimental findings, we construct a second method, which again uses digital\nnets, but Voronoi clustering instead of averaging. Both methods are compared to\nthe supercompress approach of [14], which is a variant of the K-means\nclustering algorithm. The comparison is done in terms of the compression error\nfor different objective functions and the accuracy of the training of a neural\nnetwork.\n","authors":["Simone Göttlich","Jacob Heieck","Andreas Neuenkirch"],"pdf_url":"https://arxiv.org/pdf/2407.07450v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10005v1","updated":"2024-12-13T09:42:42Z","published":"2024-12-13T09:42:42Z","title":"Matrix Completion via Residual Spectral Matching","summary":"  Noisy matrix completion has attracted significant attention due to its\napplications in recommendation systems, signal processing and image\nrestoration. Most existing works rely on (weighted) least squares methods under\nvarious low-rank constraints. However, minimizing the sum of squared residuals\nis not always efficient, as it may ignore the potential structural information\nin the residuals.In this study, we propose a novel residual spectral matching\ncriterion that incorporates not only the numerical but also locational\ninformation of residuals. This criterion is the first in noisy matrix\ncompletion to adopt the perspective of low-rank perturbation of random matrices\nand exploit the spectral properties of sparse random matrices. We derive\noptimal statistical properties by analyzing the spectral properties of sparse\nrandom matrices and bounding the effects of low-rank perturbations and partial\nobservations. Additionally, we propose algorithms that efficiently approximate\nsolutions by constructing easily computable pseudo-gradients. The iterative\nprocess of the proposed algorithms ensures convergence at a rate consistent\nwith the optimal statistical error bound. Our method and algorithms demonstrate\nimproved numerical performance in both simulated and real data examples,\nparticularly in environments with high noise levels.\n","authors":["Ziyuan Chen","Fang Yao"],"pdf_url":"https://arxiv.org/pdf/2412.10005v1.pdf","comment":"23 pages, 6 figures"},{"id":"http://arxiv.org/abs/2406.18380v3","updated":"2024-12-13T09:34:22Z","published":"2024-06-26T14:21:21Z","title":"KAGNNs: Kolmogorov-Arnold Networks meet Graph Learning","summary":"  In recent years, Graph Neural Networks (GNNs) have become the de facto tool\nfor learning node and graph representations. Most GNNs typically consist of a\nsequence of neighborhood aggregation (a.k.a., message-passing) layers, within\nwhich the representation of each node is updated based on those of its\nneighbors. The most expressive message-passing GNNs can be obtained through the\nuse of the sum aggregator and of MLPs for feature transformation, thanks to\ntheir universal approximation capabilities. However, the limitations of MLPs\nrecently motivated the introduction of another family of universal\napproximators, called Kolmogorov-Arnold Networks (KANs) which rely on a\ndifferent representation theorem. In this work, we compare the performance of\nKANs against that of MLPs on graph learning tasks. We evaluate two different\nimplementations of KANs using two distinct base families of functions, namely\nB-splines and radial basis functions. We perform extensive experiments on node\nclassification, graph classification and graph regression datasets. Our results\nindicate that KANs are on-par with or better than MLPs on all studied tasks,\nmaking them viable alternatives, at the cost of some computational complexity.\nCode is available at https: //github.com/RomanBresson/KAGNN.\n","authors":["Roman Bresson","Giannis Nikolentzos","George Panagopoulos","Michail Chatzianastasis","Jun Pang","Michalis Vazirgiannis"],"pdf_url":"https://arxiv.org/pdf/2406.18380v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14347v2","updated":"2024-12-13T09:32:48Z","published":"2024-06-20T14:14:59Z","title":"$\\nabla^2$DFT: A Universal Quantum Chemistry Dataset of Drug-Like\n  Molecules and a Benchmark for Neural Network Potentials","summary":"  Methods of computational quantum chemistry provide accurate approximations of\nmolecular properties crucial for computer-aided drug discovery and other areas\nof chemical science. However, high computational complexity limits the\nscalability of their applications. Neural network potentials (NNPs) are a\npromising alternative to quantum chemistry methods, but they require large and\ndiverse datasets for training. This work presents a new dataset and benchmark\ncalled $\\nabla^2$DFT that is based on the nablaDFT. It contains twice as much\nmolecular structures, three times more conformations, new data types and tasks,\nand state-of-the-art models. The dataset includes energies, forces, 17\nmolecular properties, Hamiltonian and overlap matrices, and a wavefunction\nobject. All calculations were performed at the DFT level\n($\\omega$B97X-D/def2-SVP) for each conformation. Moreover, $\\nabla^2$DFT is the\nfirst dataset that contains relaxation trajectories for a substantial number of\ndrug-like molecules. We also introduce a novel benchmark for evaluating NNPs in\nmolecular property prediction, Hamiltonian prediction, and conformational\noptimization tasks. Finally, we propose an extendable framework for training\nNNPs and implement 10 models within it.\n","authors":["Kuzma Khrabrov","Anton Ber","Artem Tsypin","Konstantin Ushenin","Egor Rumiantsev","Alexander Telepov","Dmitry Protasov","Ilya Shenbin","Anton Alekseev","Mikhail Shirokikh","Sergey Nikolenko","Elena Tutubalina","Artur Kadurin"],"pdf_url":"https://arxiv.org/pdf/2406.14347v2.pdf","comment":"Published as a conference paper at NeurIPS2024 Track on Datasets and\n  Benchmarks (Poster)"},{"id":"http://arxiv.org/abs/2403.19895v2","updated":"2024-12-13T09:26:53Z","published":"2024-03-29T00:29:57Z","title":"An Information-Theoretic Framework for Out-of-Distribution\n  Generalization with Applications to Stochastic Gradient Langevin Dynamics","summary":"  We study the Out-of-Distribution (OOD) generalization in machine learning and\npropose a general framework that establishes information-theoretic\ngeneralization bounds. Our framework interpolates freely between Integral\nProbability Metric (IPM) and $f$-divergence, which naturally recovers some\nknown results (including Wasserstein- and KL-bounds), as well as yields new\ngeneralization bounds. Additionally, we show that our framework admits an\noptimal transport interpretation. When evaluated in two concrete examples, the\nproposed bounds either strictly improve upon existing bounds in some cases or\nmatch the best existing OOD generalization bounds. Moreover, by focusing on\n$f$-divergence and combining it with the Conditional Mutual Information (CMI)\nmethods, we derive a family of CMI-based generalization bounds, which include\nthe state-of-the-art ICIMI bound as a special instance. Finally, leveraging\nthese findings, we analyze the generalization of the Stochastic Gradient\nLangevin Dynamics (SGLD) algorithm, showing that our derived generalization\nbounds outperform existing information-theoretic generalization bounds in\ncertain scenarios.\n","authors":["Wenliang Liu","Guanding Yu","Lele Wang","Renjie Liao"],"pdf_url":"https://arxiv.org/pdf/2403.19895v2.pdf","comment":"This work was accepted in part at the 2024 IEEE International\n  Symposium on Information Theory and the 2024 Canadian Workshop on Information\n  Theory. This work was submitted to IEEE Transactions on Information Theory"},{"id":"http://arxiv.org/abs/2412.09989v1","updated":"2024-12-13T09:21:02Z","published":"2024-12-13T09:21:02Z","title":"One Filter to Deploy Them All: Robust Safety for Quadrupedal Navigation\n  in Unknown Environments","summary":"  As learning-based methods for legged robots rapidly grow in popularity, it is\nimportant that we can provide safety assurances efficiently across different\ncontrollers and environments. Existing works either rely on a priori knowledge\nof the environment and safety constraints to ensure system safety or provide\nassurances for a specific locomotion policy. To address these limitations, we\npropose an observation-conditioned reachability-based (OCR) safety-filter\nframework. Our key idea is to use an OCR value network (OCR-VN) that predicts\nthe optimal control-theoretic safety value function for new failure regions and\ndynamic uncertainty during deployment time. Specifically, the OCR-VN\nfacilitates rapid safety adaptation through two key components: a LiDAR-based\ninput that allows the dynamic construction of safe regions in light of new\nobstacles and a disturbance estimation module that accounts for dynamics\nuncertainty in the wild. The predicted safety value function is used to\nconstruct an adaptive safety filter that overrides the nominal quadruped\ncontroller when necessary to maintain safety. Through simulation studies and\nhardware experiments on a Unitree Go1 quadruped, we demonstrate that the\nproposed framework can automatically safeguard a wide range of hierarchical\nquadruped controllers, adapts to novel environments, and is robust to unmodeled\ndynamics without a priori access to the controllers or environments - hence,\n\"One Filter to Deploy Them All\". The experiment videos can be found on the\nproject website.\n","authors":["Albert Lin","Shuang Peng","Somil Bansal"],"pdf_url":"https://arxiv.org/pdf/2412.09989v1.pdf","comment":"Project website:\n  https://sia-lab-git.github.io/One_Filter_to_Deploy_Them_All/"},{"id":"http://arxiv.org/abs/2412.09980v1","updated":"2024-12-13T09:07:41Z","published":"2024-12-13T09:07:41Z","title":"Real-Time Fall Detection Using Smartphone Accelerometers and WiFi\n  Channel State Information","summary":"  In recent years, as the population ages, falls have increasingly posed a\nsignificant threat to the health of the elderly. We propose a real-time fall\ndetection system that integrates the inertial measurement unit (IMU) of a\nsmartphone with optimized Wi-Fi channel state information (CSI) for secondary\nvalidation. Initially, the IMU distinguishes falls from routine daily\nactivities with minimal computational demand. Subsequently, the CSI is employed\nfor further assessment, which includes evaluating the individual's post-fall\nmobility. This methodology not only achieves high accuracy but also reduces\nenergy consumption in the smartphone platform. An Android application developed\nspecifically for the purpose issues an emergency alert if the user experiences\na fall and is unable to move. Experimental results indicate that the CSI model,\nbased on convolutional neural networks (CNN), achieves a detection accuracy of\n99%, \\revised{surpassing comparable IMU-only models, and demonstrating\nsignificant resilience in distinguishing between falls and non-fall activities.\n","authors":["Lingyun Wang","Deqi Su","Aohua Zhang","Yujun Zhu","Weiwei Jiang","Xin He","Panlong Yang"],"pdf_url":"https://arxiv.org/pdf/2412.09980v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09972v1","updated":"2024-12-13T08:59:18Z","published":"2024-12-13T08:59:18Z","title":"Efficient Large-Scale Traffic Forecasting with Transformers: A Spatial\n  Data Management Perspective","summary":"  Road traffic forecasting is crucial in real-world intelligent transportation\nscenarios like traffic dispatching and path planning in city management and\npersonal traveling. Spatio-temporal graph neural networks (STGNNs) stand out as\nthe mainstream solution in this task. Nevertheless, the quadratic complexity of\nremarkable dynamic spatial modeling-based STGNNs has become the bottleneck over\nlarge-scale traffic data. From the spatial data management perspective, we\npresent a novel Transformer framework called PatchSTG to efficiently and\ndynamically model spatial dependencies for large-scale traffic forecasting with\ninterpretability and fidelity. Specifically, we design a novel irregular\nspatial patching to reduce the number of points involved in the dynamic\ncalculation of Transformer. The irregular spatial patching first utilizes the\nleaf K-dimensional tree (KDTree) to recursively partition irregularly\ndistributed traffic points into leaf nodes with a small capacity, and then\nmerges leaf nodes belonging to the same subtree into occupancy-equaled and\nnon-overlapped patches through padding and backtracking. Based on the patched\ndata, depth and breadth attention are used interchangeably in the encoder to\ndynamically learn local and global spatial knowledge from points in a patch and\npoints with the same index of patches. Experimental results on four real world\nlarge-scale traffic datasets show that our PatchSTG achieves train speed and\nmemory utilization improvements up to $10\\times$ and $4\\times$ with the\nstate-of-the-art performance.\n","authors":["Yuchen Fang","Yuxuan Liang","Bo Hui","Zezhi Shao","Liwei Deng","Xu Liu","Xinke Jiang","Kai Zheng"],"pdf_url":"https://arxiv.org/pdf/2412.09972v1.pdf","comment":"Accepted by SIGKDD 2025"},{"id":"http://arxiv.org/abs/2412.09968v1","updated":"2024-12-13T08:55:02Z","published":"2024-12-13T08:55:02Z","title":"GraSP: Simple yet Effective Graph Similarity Predictions","summary":"  Graph similarity computation (GSC) is to calculate the similarity between one\npair of graphs, which is a fundamental problem with fruitful applications in\nthe graph community. In GSC, graph edit distance (GED) and maximum common\nsubgraph (MCS) are two important similarity metrics, both of which are NP-hard\nto compute. Instead of calculating the exact values, recent solutions resort to\nleveraging graph neural networks (GNNs) to learn data-driven models for the\nestimation of GED and MCS. Most of them are built on components involving\nnode-level interactions crossing graphs, which engender vast computation\noverhead but are of little avail in effectiveness. In the paper, we present\nGraSP, a simple yet effective GSC approach for GED and MCS prediction. GraSP\nachieves high result efficacy through several key instruments: enhanced node\nfeatures via positional encoding and a GNN model augmented by a gating\nmechanism, residual connections, as well as multi-scale pooling. Theoretically,\nGraSP can surpass the 1-WL test, indicating its high expressiveness.\nEmpirically, extensive experiments comparing GraSP against 10 competitors on\nmultiple widely adopted benchmark datasets showcase the superiority of GraSP\nover prior arts in terms of both effectiveness and efficiency. The code is\navailable at https://github.com/HaoranZ99/GraSP.\n","authors":["Haoran Zheng","Jieming Shi","Renchi Yang"],"pdf_url":"https://arxiv.org/pdf/2412.09968v1.pdf","comment":"Accepted by AAAI2025. 13 pages, 14 figures. The code is available at\n  https://github.com/HaoranZ99/GraSP"},{"id":"http://arxiv.org/abs/2412.09966v1","updated":"2024-12-13T08:49:25Z","published":"2024-12-13T08:49:25Z","title":"EP-CFG: Energy-Preserving Classifier-Free Guidance","summary":"  Classifier-free guidance (CFG) is widely used in diffusion models but often\nintroduces over-contrast and over-saturation artifacts at higher guidance\nstrengths. We present EP-CFG (Energy-Preserving Classifier-Free Guidance),\nwhich addresses these issues by preserving the energy distribution of the\nconditional prediction during the guidance process. Our method simply rescales\nthe energy of the guided output to match that of the conditional prediction at\neach denoising step, with an optional robust variant for improved artifact\nsuppression. Through experiments, we show that EP-CFG maintains natural image\nquality and preserves details across guidance strengths while retaining CFG's\nsemantic alignment benefits, all with minimal computational overhead.\n","authors":["Kai Zhang","Fujun Luan","Sai Bi","Jianming Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.09966v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09265v2","updated":"2024-12-13T08:44:16Z","published":"2024-12-12T13:22:02Z","title":"Score and Distribution Matching Policy: Advanced Accelerated Visuomotor\n  Policies via Matched Distillation","summary":"  Visual-motor policy learning has advanced with architectures like\ndiffusion-based policies, known for modeling complex robotic trajectories.\nHowever, their prolonged inference times hinder high-frequency control tasks\nrequiring real-time feedback. While consistency distillation (CD) accelerates\ninference, it introduces errors that compromise action quality. To address\nthese limitations, we propose the Score and Distribution Matching Policy (SDM\nPolicy), which transforms diffusion-based policies into single-step generators\nthrough a two-stage optimization process: score matching ensures alignment with\ntrue action distributions, and distribution matching minimizes KL divergence\nfor consistency. A dual-teacher mechanism integrates a frozen teacher for\nstability and an unfrozen teacher for adversarial training, enhancing\nrobustness and alignment with target distributions. Evaluated on a 57-task\nsimulation benchmark, SDM Policy achieves a 6x inference speedup while having\nstate-of-the-art action quality, providing an efficient and reliable framework\nfor high-frequency robotic tasks.\n","authors":["Bofang Jia","Pengxiang Ding","Can Cui","Mingyang Sun","Pengfang Qian","Siteng Huang","Zhaoxin Fan","Donglin Wang"],"pdf_url":"https://arxiv.org/pdf/2412.09265v2.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2412.09961v1","updated":"2024-12-13T08:42:19Z","published":"2024-12-13T08:42:19Z","title":"What constitutes a Deep Fake? The blurry line between legitimate\n  processing and manipulation under the EU AI Act","summary":"  When does a digital image resemble reality? The relevance of this question\nincreases as the generation of synthetic images -- so called deep fakes --\nbecomes increasingly popular. Deep fakes have gained much attention for a\nnumber of reasons -- among others, due to their potential to disrupt the\npolitical climate. In order to mitigate these threats, the EU AI Act implements\nspecific transparency regulations for generating synthetic content or\nmanipulating existing content. However, the distinction between real and\nsynthetic images is -- even from a computer vision perspective -- far from\ntrivial. We argue that the current definition of deep fakes in the AI act and\nthe corresponding obligations are not sufficiently specified to tackle the\nchallenges posed by deep fakes. By analyzing the life cycle of a digital photo\nfrom the camera sensor to the digital editing features, we find that: (1.) Deep\nfakes are ill-defined in the EU AI Act. The definition leaves too much scope\nfor what a deep fake is. (2.) It is unclear how editing functions like Google's\n``best take'' feature can be considered as an exception to transparency\nobligations. (3.) The exception for substantially edited images raises\nquestions about what constitutes substantial editing of content and whether or\nnot this editing must be perceptible by a natural person. Our results\ndemonstrate that complying with the current AI Act transparency obligations is\ndifficult for providers and deployers. As a consequence of the unclear\nprovisions, there is a risk that exceptions may be either too broad or too\nlimited. We intend our analysis to foster the discussion on what constitutes a\ndeep fake and to raise awareness about the pitfalls in the current AI Act\ntransparency obligations.\n","authors":["Kristof Meding","Christoph Sorge"],"pdf_url":"https://arxiv.org/pdf/2412.09961v1.pdf","comment":"Preprint. Accepted at ACM CS&Law '25"},{"id":"http://arxiv.org/abs/2412.08050v2","updated":"2024-12-13T08:38:29Z","published":"2024-12-11T02:56:23Z","title":"BSAFusion: A Bidirectional Stepwise Feature Alignment Network for\n  Unaligned Medical Image Fusion","summary":"  If unaligned multimodal medical images can be simultaneously aligned and\nfused using a single-stage approach within a unified processing framework, it\nwill not only achieve mutual promotion of dual tasks but also help reduce the\ncomplexity of the model. However, the design of this model faces the challenge\nof incompatible requirements for feature fusion and alignment; specifically,\nfeature alignment requires consistency among corresponding features, whereas\nfeature fusion requires the features to be complementary to each other. To\naddress this challenge, this paper proposes an unaligned medical image fusion\nmethod called Bidirectional Stepwise Feature Alignment and Fusion (BSFA-F)\nstrategy. To reduce the negative impact of modality differences on cross-modal\nfeature matching, we incorporate the Modal Discrepancy-Free Feature\nRepresentation (MDF-FR) method into BSFA-F. MDF-FR utilizes a Modality Feature\nRepresentation Head (MFRH) to integrate the global information of the input\nimage. By injecting the information contained in MFRH of the current image into\nother modality images, it effectively reduces the impact of modality\ndifferences on feature alignment while preserving the complementary information\ncarried by different images. In terms of feature alignment, BSFA-F employs a\nbidirectional stepwise alignment deformation field prediction strategy based on\nthe path independence of vector displacement between two points. This strategy\nsolves the problem of large spans and inaccurate deformation field prediction\nin single-step alignment. Finally, Multi-Modal Feature Fusion block achieves\nthe fusion of aligned features. The experimental results across multiple\ndatasets demonstrate the effectiveness of our method. The source code is\navailable at https://github.com/slrl123/BSAFusion.\n","authors":["Huafeng Li","Dayong Su","Qing Cai","Yafei Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.08050v2.pdf","comment":"Accepted by AAAI2025"},{"id":"http://arxiv.org/abs/2411.07853v2","updated":"2024-12-13T08:36:29Z","published":"2024-11-12T15:06:04Z","title":"Evidential time-to-event prediction with calibrated uncertainty\n  quantification","summary":"  Time-to-event analysis provides insights into clinical prognosis and\ntreatment recommendations. However, this task is more challenging than standard\nregression problems due to the presence of censored observations. Additionally,\nthe lack of confidence assessment, model robustness, and prediction calibration\nraises concerns about the reliability of predictions. To address these\nchallenges, we propose an evidential regression model specifically designed for\ntime-to-event prediction. The proposed model quantifies both epistemic and\naleatory uncertainties using Gaussian Random Fuzzy Numbers and belief\nfunctions, providing clinicians with uncertainty-aware survival time\npredictions. The model is trained by minimizing a generalized negative\nlog-likelihood function accounting for data censoring. Experimental evaluations\nusing simulated datasets with different data distributions and censoring\nconditions, as well as real-world datasets across diverse clinical\napplications, demonstrate that our model delivers both accurate and reliable\nperformance, outperforming state-of-the-art methods. These results highlight\nthe potential of our approach for enhancing clinical decision-making in\nsurvival analysis.\n","authors":["Ling Huang","Yucheng Xing","Swapnil Mishra","Thierry Denoeux","Mengling Feng"],"pdf_url":"https://arxiv.org/pdf/2411.07853v2.pdf","comment":"Preprint submitted to International Journal of Approximate Reasoning"},{"id":"http://arxiv.org/abs/2412.09952v1","updated":"2024-12-13T08:22:19Z","published":"2024-12-13T08:22:19Z","title":"Llama 3 Meets MoE: Efficient Upcycling","summary":"  Scaling large language models (LLMs) significantly improves performance but\ncomes with prohibitive computational costs. Mixture-of-Experts (MoE) models\noffer an efficient alternative, increasing capacity without a proportional rise\nin compute requirements. However, training MoE models from scratch poses\nchallenges like overfitting and routing instability. We present an efficient\ntraining recipe leveraging pre-trained dense checkpoints, training an 8-Expert\nTop-2 MoE model from Llama 3-8B with less than $1\\%$ of typical pre-training\ncompute. Our approach enhances downstream performance on academic benchmarks,\nachieving a $\\textbf{2%}$ improvement in 0-shot accuracy on MMLU, while\nreaching a Model FLOPs Utilization (MFU) of $\\textbf{46.8%}$ during training\nusing our framework. We also integrate online upcycling in NeMo for seamless\nuse of pre-trained weights, enabling cost-effective development of\nhigh-capacity MoE models.\n","authors":["Aditya Vavre","Ethan He","Dennis Liu","Zijie Yan","June Yang","Nima Tajbakhsh","Ashwath Aithal"],"pdf_url":"https://arxiv.org/pdf/2412.09952v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09947v1","updated":"2024-12-13T08:11:40Z","published":"2024-12-13T08:11:40Z","title":"Towards Fair Graph Neural Networks via Graph Counterfactual without\n  Sensitive Attributes","summary":"  Graph-structured data is ubiquitous in today's connected world, driving\nextensive research in graph analysis. Graph Neural Networks (GNNs) have shown\ngreat success in this field, leading to growing interest in developing fair\nGNNs for critical applications. However, most existing fair GNNs focus on\nstatistical fairness notions, which may be insufficient when dealing with\nstatistical anomalies. Hence, motivated by causal theory, there has been\ngrowing attention to mitigating root causes of unfairness utilizing graph\ncounterfactuals. Unfortunately, existing methods for generating graph\ncounterfactuals invariably require the sensitive attribute. Nevertheless, in\nmany real-world applications, it is usually infeasible to obtain sensitive\nattributes due to privacy or legal issues, which challenge existing methods. In\nthis paper, we propose a framework named Fairwos (improving Fairness without\nsensitive attributes). In particular, we first propose a mechanism to generate\npseudo-sensitive attributes to remedy the problem of missing sensitive\nattributes, and then design a strategy for finding graph counterfactuals from\nthe real dataset. To train fair GNNs, we propose a method to ensure that the\nembeddings from the original data are consistent with those from the graph\ncounterfactuals, and dynamically adjust the weight of each pseudo-sensitive\nattribute to balance its contribution to fairness and utility. Furthermore, we\ntheoretically demonstrate that minimizing the relation between these\npseudo-sensitive attributes and the prediction can enable the fairness of GNNs.\nExperimental results on six real-world datasets show that our approach\noutperforms state-of-the-art methods in balancing utility and fairness.\n","authors":["Xuemin Wang","Tianlong Gu","Xuguang Bao","Liang Chang"],"pdf_url":"https://arxiv.org/pdf/2412.09947v1.pdf","comment":"ICDE 2025"},{"id":"http://arxiv.org/abs/2412.09942v1","updated":"2024-12-13T08:04:21Z","published":"2024-12-13T08:04:21Z","title":"Latent feedback control of distributed systems in multiple scenarios\n  through deep learning-based reduced order models","summary":"  Continuous monitoring and real-time control of high-dimensional distributed\nsystems are often crucial in applications to ensure a desired physical\nbehavior, without degrading stability and system performances. Traditional\nfeedback control design that relies on full-order models, such as\nhigh-dimensional state-space representations or partial differential equations,\nfails to meet these requirements due to the delay in the control computation,\nwhich requires multiple expensive simulations of the physical system. The\ncomputational bottleneck is even more severe when considering parametrized\nsystems, as new strategies have to be determined for every new scenario. To\naddress these challenges, we propose a real-time closed-loop control strategy\nenhanced by nonlinear non-intrusive Deep Learning-based Reduced Order Models\n(DL-ROMs). Specifically, in the offline phase, (i) full-order state-control\npairs are generated for different scenarios through the adjoint method, (ii)\nthe essential features relevant for control design are extracted from the\nsnapshots through a combination of Proper Orthogonal Decomposition (POD) and\ndeep autoencoders, and (iii) the low-dimensional policy bridging latent control\nand state spaces is approximated with a feedforward neural network. After data\ngeneration and neural networks training, the optimal control actions are\nretrieved in real-time for any observed state and scenario. In addition, the\ndynamics may be approximated through a cheap surrogate model in order to close\nthe loop at the latent level, thus continuously controlling the system in\nreal-time even when full-order state measurements are missing. The\neffectiveness of the proposed method, in terms of computational speed,\naccuracy, and robustness against noisy data, is finally assessed on two\ndifferent high-dimensional optimal transport problems, one of which also\ninvolving an underlying fluid flow.\n","authors":["Matteo Tomasetto","Francesco Braghin","Andrea Manzoni"],"pdf_url":"https://arxiv.org/pdf/2412.09942v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09940v1","updated":"2024-12-13T08:03:57Z","published":"2024-12-13T08:03:57Z","title":"Predictive Query-based Pipeline for Graph Data","summary":"  Graphs face challenges when dealing with massive datasets. They are essential\ntools for modeling interconnected data and often become computationally\nexpensive. Graph embedding techniques, on the other hand, provide an efficient\napproach. By projecting complex graphs into a lower-dimensional space, these\ntechniques simplify the analysis and processing of large-scale graphs. By\ntransforming graphs into vectors, it simplifies the analysis and processing of\nlarge-scale datasets. Several approaches, such as GraphSAGE, Node2Vec, and\nFastRP, offer efficient methods for generating graph embeddings. By storing\nembeddings as node properties, it is possible to compare different embedding\ntechniques and evaluate their effectiveness for specific tasks. This\nflexibilityallows for dynamic updates to embeddings and facilitates\nexperimentation with different approaches. By analyzing these embeddings, one\ncan extract valuable insights into the relationships between nodes and their\nsimilarities within the embedding space\n","authors":["Plácido A Souza Neto"],"pdf_url":"https://arxiv.org/pdf/2412.09940v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08160v2","updated":"2024-12-13T08:00:55Z","published":"2024-12-11T07:32:38Z","title":"DG-Mamba: Robust and Efficient Dynamic Graph Structure Learning with\n  Selective State Space Models","summary":"  Dynamic graphs exhibit intertwined spatio-temporal evolutionary patterns,\nwidely existing in the real world. Nevertheless, the structure incompleteness,\nnoise, and redundancy result in poor robustness for Dynamic Graph Neural\nNetworks (DGNNs). Dynamic Graph Structure Learning (DGSL) offers a promising\nway to optimize graph structures. However, aside from encountering unacceptable\nquadratic complexity, it overly relies on heuristic priors, making it hard to\ndiscover underlying predictive patterns. How to efficiently refine the dynamic\nstructures, capture intrinsic dependencies, and learn robust representations,\nremains under-explored. In this work, we propose the novel DG-Mamba, a robust\nand efficient Dynamic Graph structure learning framework with the Selective\nState Space Models (Mamba). To accelerate the spatio-temporal structure\nlearning, we propose a kernelized dynamic message-passing operator that reduces\nthe quadratic time complexity to linear. To capture global intrinsic dynamics,\nwe establish the dynamic graph as a self-contained system with State Space\nModel. By discretizing the system states with the cross-snapshot graph\nadjacency, we enable the long-distance dependencies capturing with the\nselective snapshot scan. To endow learned dynamic structures more expressive\nwith informativeness, we propose the self-supervised Principle of Relevant\nInformation for DGSL to regularize the most relevant yet least redundant\ninformation, enhancing global robustness. Extensive experiments demonstrate the\nsuperiority of the robustness and efficiency of our DG-Mamba compared with the\nstate-of-the-art baselines against adversarial attacks.\n","authors":["Haonan Yuan","Qingyun Sun","Zhaonan Wang","Xingcheng Fu","Cheng Ji","Yongjian Wang","Bo Jin","Jianxin Li"],"pdf_url":"https://arxiv.org/pdf/2412.08160v2.pdf","comment":"Accepted by the Main Technical Track of the 39th Annual AAAI\n  Conference on Artificial Intelligence (AAAI-2025)"},{"id":"http://arxiv.org/abs/2412.09399v2","updated":"2024-12-13T07:40:02Z","published":"2024-12-12T16:05:39Z","title":"A Geometry-Aware Message Passing Neural Network for Modeling\n  Aerodynamics over Airfoils","summary":"  Computational modeling of aerodynamics is a key problem in aerospace\nengineering, often involving flows interacting with solid objects such as\nairfoils. Deep surrogate models have emerged as purely data-driven approaches\nthat learn direct mappings from simulation conditions to solutions based on\neither simulation or experimental data. Here, we consider modeling of\nincompressible flows over solid objects, wherein geometric structures are a key\nfactor in determining aerodynamics. To effectively incorporate geometries, we\npropose a message passing scheme that efficiently and expressively integrates\nthe airfoil shape with the mesh representation. Under this framework, we first\nobtain a representation of the geometry in the form of a latent graph on the\nairfoil surface. We subsequently propagate this representation to all\ncollocation points through message passing on a directed, bipartite graph. We\ndemonstrate that this framework supports efficient training by downsampling the\nsolution mesh while avoiding distribution shifts at test time when evaluated on\nthe full mesh. To enable our model to be able to distinguish between distinct\nspatial regimes of dynamics relative to the airfoil, we represent mesh points\nin both a leading edge and trailing edge coordinate system. We further enhance\nthe expressiveness of our coordinate system representations by embedding our\nhybrid Polar-Cartesian coordinates using sinusoidal and spherical harmonics\nbases. We additionally find that a change of basis to canonicalize input\nrepresentations with respect to inlet velocity substantially improves\ngeneralization. Altogether, these design choices lead to a purely data-driven\nmachine learning framework known as GeoMPNN, which won the Best Student\nSubmission award at the NeurIPS 2024 ML4CFD Competition, placing 4th overall.\nOur code is publicly available as part of the AIRS library\n(https://github.com/divelab/AIRS).\n","authors":["Jacob Helwig","Xuan Zhang","Haiyang Yu","Shuiwang Ji"],"pdf_url":"https://arxiv.org/pdf/2412.09399v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09925v1","updated":"2024-12-13T07:27:42Z","published":"2024-12-13T07:27:42Z","title":"Simulating Hard Attention Using Soft Attention","summary":"  We study conditions under which transformers using soft attention can\nsimulate hard attention, that is, effectively focus all attention on a subset\nof positions. First, we examine several variants of linear temporal logic,\nwhose formulas have been previously been shown to be computable using hard\nattention transformers. We demonstrate how soft attention transformers can\ncompute formulas of these logics using unbounded positional embeddings or\ntemperature scaling. Second, we demonstrate how temperature scaling allows\nsoftmax transformers to simulate a large subclass of average-hard attention\ntransformers, those that have what we call the uniform-tieless property.\n","authors":["Andy Yang","Lena Strobl","David Chiang","Dana Angluin"],"pdf_url":"https://arxiv.org/pdf/2412.09925v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.09066v3","updated":"2024-12-13T07:26:51Z","published":"2024-02-14T10:24:04Z","title":"Solid Waste Detection, Monitoring and Mapping in Remote Sensing Images:\n  A Survey","summary":"  The detection and characterization of illegal solid waste disposal sites are\nessential for environmental protection, particularly for mitigating pollution\nand health hazards. Improperly managed landfills contaminate soil and\ngroundwater via rainwater infiltration, posing threats to both animals and\nhumans. Traditional landfill identification approaches, such as on-site\ninspections, are time-consuming and expensive. Remote sensing is a\ncost-effective solution for the identification and monitoring of solid waste\ndisposal sites that enables broad coverage and repeated acquisitions over time.\nEarth Observation (EO) satellites, equipped with an array of sensors and\nimaging capabilities, have been providing high-resolution data for several\ndecades. Researchers proposed specialized techniques that leverage remote\nsensing imagery to perform a range of tasks such as waste site detection,\ndumping site monitoring, and assessment of suitable locations for new\nlandfills. This review aims to provide a detailed illustration of the most\nrelevant proposals for the detection and monitoring of solid waste sites by\ndescribing and comparing the approaches, the implemented techniques, and the\nemployed data. Furthermore, since the data sources are of the utmost importance\nfor developing an effective solid waste detection model, a comprehensive\noverview of the satellites and publicly available data sets is presented.\nFinally, this paper identifies the open issues in the state-of-the-art and\ndiscusses the relevant research directions for reducing the costs and improving\nthe effectiveness of novel solid waste detection methods.\n","authors":["Piero Fraternali","Luca Morandini","Sergio Luis Herrera González"],"pdf_url":"https://arxiv.org/pdf/2402.09066v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.17053v2","updated":"2024-12-13T07:21:58Z","published":"2024-08-30T07:23:59Z","title":"Estimating Conditional Average Treatment Effects via Sufficient\n  Representation Learning","summary":"  Estimating the conditional average treatment effects (CATE) is very important\nin causal inference and has a wide range of applications across many fields. In\nthe estimation process of CATE, the unconfoundedness assumption is typically\nrequired to ensure the identifiability of the regression problems. When\nestimating CATE using high-dimensional data, there have been many variable\nselection methods and neural network approaches based on representation\nlearning, while these methods do not provide a way to verify whether the subset\nof variables after dimensionality reduction or the learned representations\nstill satisfy the unconfoundedness assumption during the estimation process,\nwhich can lead to ineffective estimates of the treatment effects. Additionally,\nthese methods typically use data from only the treatment or control group when\nestimating the regression functions for each group. This paper proposes a novel\nneural network approach named \\textbf{CrossNet} to learn a sufficient\nrepresentation for the features, based on which we then estimate the CATE,\nwhere cross indicates that in estimating the regression functions, we used data\nfrom their own group as well as cross-utilized data from another group.\nNumerical simulations and empirical results demonstrate that our method\noutperforms the competitive approaches.\n","authors":["Pengfei Shi","Wei Zhong","Xinyu Zhang","Ningtao Wang","Xing Fu","Weiqiang Wang","Yin Jin"],"pdf_url":"https://arxiv.org/pdf/2408.17053v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.16283v2","updated":"2024-12-13T07:01:16Z","published":"2024-04-25T01:56:00Z","title":"Andes: Defining and Enhancing Quality-of-Experience in LLM-Based Text\n  Streaming Services","summary":"  Large language models (LLMs) are now at the core of conversational AI\nservices such as real-time translation and chatbots, which provide live user\ninteraction by incrementally streaming text to the user. However, existing LLM\nserving systems fail to provide good user experience because their optimization\nmetrics are not always aligned with user experience.\n  In this paper, we first introduce and define the notion of\nQuality-of-Experience (QoE) for text streaming services by considering each\nuser's end-to-end interaction timeline. Based on this, we propose Andes, a\nQoE-aware LLM serving system that enhances user experience by ensuring that\nusers receive the first token promptly and subsequent tokens at a smooth,\ndigestible pace, even during surge periods. This is enabled by Andes's\npreemptive request scheduler that dynamically prioritizes requests at the token\ngranularity based on each request's expected QoE gain and GPU resource usage.\nOur evaluations demonstrate that, compared to state-of-the-art LLM serving\nsystems, Andes improves the average QoE by up to $4.7\\times$ given the same GPU\nresource, or saves up to 61% GPU resources while maintaining the same high QoE.\n","authors":["Jiachen Liu","Jae-Won Chung","Zhiyu Wu","Fan Lai","Myungjin Lee","Mosharaf Chowdhury"],"pdf_url":"https://arxiv.org/pdf/2404.16283v2.pdf","comment":"16 pages, 21 figures"},{"id":"http://arxiv.org/abs/2405.19225v4","updated":"2024-12-13T06:58:47Z","published":"2024-05-29T16:05:57Z","title":"Synthetic Potential Outcomes and Causal Mixture Identifiability","summary":"  Heterogeneous data from multiple populations, sub-groups, or sources is often\nrepresented as a ``mixture model'' with a single latent class influencing all\nof the observed covariates. Heterogeneity can be resolved at multiple levels by\ngrouping populations according to different notions of similarity. This paper\nproposes grouping with respect to the causal response of an intervention or\nperturbation on the system. This definition is distinct from previous notions,\nsuch as similar covariate values (e.g. clustering) or similar correlations\nbetween covariates (e.g. Gaussian mixture models). To solve the problem, we\n``synthetically sample'' from a counterfactual distribution using higher-order\nmulti-linear moments of the observable data. To understand how these ``causal\nmixtures'' fit in with more classical notions, we develop a hierarchy of\nmixture identifiability.\n","authors":["Bijan Mazaheri","Chandler Squires","Caroline Uhler"],"pdf_url":"https://arxiv.org/pdf/2405.19225v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.13748v2","updated":"2024-12-13T06:55:46Z","published":"2024-06-19T18:01:08Z","title":"Learn and Unlearn in Multilingual LLMs","summary":"  This paper investigates the propagation of harmful information in\nmultilingual large language models (LLMs) and evaluates the efficacy of various\nunlearning methods. We demonstrate that fake information, regardless of the\nlanguage it is in, once introduced into these models through training data, can\nspread across different languages, compromising the integrity and reliability\nof the generated content. Our findings reveal that standard unlearning\ntechniques, which typically focus on English data, are insufficient in\nmitigating the spread of harmful content in multilingual contexts and could\ninadvertently reinforce harmful content across languages. We show that only by\naddressing harmful responses in both English and the original language of the\nharmful data can we effectively eliminate generations for all languages. This\nunderscores the critical need for comprehensive unlearning strategies that\nconsider the multilingual nature of modern LLMs to enhance their safety and\nreliability across diverse linguistic landscapes.\n","authors":["Taiming Lu","Philipp Koehn"],"pdf_url":"https://arxiv.org/pdf/2406.13748v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14535v3","updated":"2024-12-13T06:48:46Z","published":"2024-10-18T15:23:29Z","title":"Comparing Differentiable and Dynamic Ray Tracing: Introducing the\n  Multipath Lifetime Map","summary":"  With the increasing presence of dynamic scenarios, such as Vehicle-to-Vehicle\ncommunications, radio propagation modeling tools must adapt to the rapidly\nchanging nature of the radio channel. Recently, both Differentiable and Dynamic\nRay Tracing frameworks have emerged to address these challenges. However, there\nis often confusion about how these approaches differ and which one should be\nused in specific contexts. In this paper, we provide an overview of these two\ntechniques and a comparative analysis against two state-of-the-art tools:\n3DSCAT from UniBo and Sionna from NVIDIA. To provide a more precise\ncharacterization of the scope of these methods, we introduce a novel\nsimulation-based metric, the Multipath Lifetime Map, which enables the\nevaluation of spatial and temporal coherence in radio channels only based on\nthe geometrical description of the environment. Finally, our metrics are\nevaluated on a classic urban street canyon scenario, yielding similar results\nto those obtained from measurement campaigns.\n","authors":["Jérome Eertmans","Enrico Maria Vittuci","Vittorio Degli-Esposti","Laurent Jacques","Claude Oestges"],"pdf_url":"https://arxiv.org/pdf/2410.14535v3.pdf","comment":"5 pages, 5 figures, 1 table, accepted at EuCAP 2025"},{"id":"http://arxiv.org/abs/2409.13213v2","updated":"2024-12-13T06:42:48Z","published":"2024-09-20T04:50:49Z","title":"MalMixer: Few-Shot Malware Classification with Retrieval-Augmented\n  Semi-Supervised Learning","summary":"  Recent growth and proliferation of malware has tested practitioners' ability\nto promptly classify new samples according to malware families. In contrast to\nlabor-intensive reverse engineering efforts, machine learning approaches have\ndemonstrated increased speed and accuracy. However, most existing deep-learning\nmalware family classifiers must be calibrated using a large number of samples\nthat are painstakingly manually analyzed before training. Furthermore, as novel\nmalware samples arise that are beyond the scope of the training set, additional\nreverse engineering effort must be employed to update the training set. The\nsheer volume of new samples found in the wild creates substantial pressure on\npractitioners' ability to reverse engineer enough malware to adequately train\nmodern classifiers. In this paper, we present MalMixer, a malware family\nclassifier using semi-supervised learning that achieves high accuracy with\nsparse training data. We present a novel domain-knowledge-aware technique for\naugmenting malware feature representations, enhancing few-shot performance of\nsemi-supervised malware family classification. We show that MalMixer achieves\nstate-of-the-art performance in few-shot malware family classification\nsettings. Our research confirms the feasibility and effectiveness of\nlightweight, domain-knowledge-aware feature augmentation methods and highlights\nthe capabilities of similar semi-supervised classifiers in addressing malware\nclassification issues.\n","authors":["Jiliang Li","Yifan Zhang","Yu Huang","Kevin Leach"],"pdf_url":"https://arxiv.org/pdf/2409.13213v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09902v1","updated":"2024-12-13T06:42:36Z","published":"2024-12-13T06:42:36Z","title":"One Node One Model: Featuring the Missing-Half for Graph Clustering","summary":"  Most existing graph clustering methods primarily focus on exploiting\ntopological structure, often neglecting the ``missing-half\" node feature\ninformation, especially how these features can enhance clustering performance.\nThis issue is further compounded by the challenges associated with\nhigh-dimensional features. Feature selection in graph clustering is\nparticularly difficult because it requires simultaneously discovering clusters\nand identifying the relevant features for these clusters. To address this gap,\nwe introduce a novel paradigm called ``one node one model\", which builds an\nexclusive model for each node and defines the node label as a combination of\npredictions for node groups. Specifically, the proposed ``Feature Personalized\nGraph Clustering (FPGC)\" method identifies cluster-relevant features for each\nnode using a squeeze-and-excitation block, integrating these features into each\nmodel to form the final representations. Additionally, the concept of feature\ncross is developed as a data augmentation technique to learn low-order feature\ninteractions. Extensive experimental results demonstrate that FPGC outperforms\nstate-of-the-art clustering methods. Moreover, the plug-and-play nature of our\nmethod provides a versatile solution to enhance GNN-based models from a feature\nperspective.\n","authors":["Xuanting Xie","Bingheng Li","Erlin Pan","Zhaochen Guo","Zhao Kang","Wenyu Chen"],"pdf_url":"https://arxiv.org/pdf/2412.09902v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.00004v3","updated":"2024-12-13T06:41:02Z","published":"2024-05-12T04:15:05Z","title":"Navigating the Future of Federated Recommendation Systems with\n  Foundation Models","summary":"  In recent years, the integration of federated learning (FL) and\nrecommendation systems (RS), known as Federated Recommendation Systems (FRS),\nhas attracted attention for preserving user privacy by keeping private data on\nclient devices. However, FRS faces inherent limitations such as data\nheterogeneity and scarcity, due to the privacy requirements of FL and the\ntypical data sparsity issues of RSs. Models like ChatGPT are empowered by the\nconcept of transfer learning and self-supervised learning, so they can be\neasily applied to the downstream tasks after fine-tuning or prompting. These\nmodels, so-called Foundation Models (FM), fouce on understanding the human's\nintent and perform following their designed roles in the specific tasks, which\nare widely recognized for producing high-quality content in the image and\nlanguage domains. Thus, the achievements of FMs inspire the design of FRS and\nsuggest a promising research direction: integrating foundation models to\naddress the above limitations. In this study, we conduct a comprehensive review\nof FRSs with FMs. Specifically, we: 1) summarise the common approaches of\ncurrent FRSs and FMs; 2) review the challenges posed by FRSs and FMs; 3)\ndiscuss potential future research directions; and 4) introduce some common\nbenchmarks and evaluation metrics in the FRS field. We hope that this position\npaper provides the necessary background and guidance to explore this\ninteresting and emerging topic.\n","authors":["Zhiwei Li","Guodong Long","Chunxu Zhang","Honglei Zhang","Jing Jiang","Chengqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.00004v3.pdf","comment":"20 pages, position paper, survey"},{"id":"http://arxiv.org/abs/2412.08038v2","updated":"2024-12-13T06:39:00Z","published":"2024-12-11T02:37:32Z","title":"Bootstrapping Heterogeneous Graph Representation Learning via Large\n  Language Models: A Generalized Approach","summary":"  Graph representation learning methods are highly effective in handling\ncomplex non-Euclidean data by capturing intricate relationships and features\nwithin graph structures. However, traditional methods face challenges when\ndealing with heterogeneous graphs that contain various types of nodes and edges\ndue to the diverse sources and complex nature of the data. Existing\nHeterogeneous Graph Neural Networks (HGNNs) have shown promising results but\nrequire prior knowledge of node and edge types and unified node feature\nformats, which limits their applicability. Recent advancements in graph\nrepresentation learning using Large Language Models (LLMs) offer new solutions\nby integrating LLMs' data processing capabilities, enabling the alignment of\nvarious graph representations. Nevertheless, these methods often overlook\nheterogeneous graph data and require extensive preprocessing. To address these\nlimitations, we propose a novel method that leverages the strengths of both LLM\nand GNN, allowing for the processing of graph data with any format and type of\nnodes and edges without the need for type information or special preprocessing.\nOur method employs LLM to automatically summarize and classify different data\nformats and types, aligns node features, and uses a specialized GNN for\ntargeted learning, thus obtaining effective graph representations for\ndownstream tasks. Theoretical analysis and experimental validation have\ndemonstrated the effectiveness of our method.\n","authors":["Hang Gao","Chenhao Zhang","Fengge Wu","Junsuo Zhao","Changwen Zheng","Huaping Liu"],"pdf_url":"https://arxiv.org/pdf/2412.08038v2.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2210.05102v4","updated":"2024-12-13T06:37:17Z","published":"2022-10-11T02:39:06Z","title":"Pre-Training Representations of Binary Code Using Contrastive Learning","summary":"  Binary code analysis and comprehension is critical to applications in reverse\nengineering and computer security tasks where source code is not available.\nUnfortunately, unlike source code, binary code lacks semantics and is more\ndifficult for human engineers to understand and analyze. In this paper, we\npresent ContraBin, a contrastive learning technique that integrates source code\nand comment information along with binaries to create an embedding capable of\naiding binary analysis and comprehension tasks. Specifically, we present three\ncomponents in ContraBin: (1) a primary contrastive learning method for initial\npre-training, (2) a simplex interpolation method to integrate source code,\ncomments, and binary code, and (3) an intermediate representation learning\nalgorithm to train a binary code embedding. We further analyze the impact of\nhuman-written and synthetic comments on binary code comprehension tasks,\nrevealing a significant performance disparity. While synthetic comments provide\nsubstantial benefits, human-written comments are found to introduce noise, even\nresulting in performance drops compared to using no comments. These findings\nreshape the narrative around the role of comment types in binary code analysis.\nWe evaluate the effectiveness of ContraBin through four indicative downstream\ntasks related to binary code: algorithmic functionality classification,\nfunction name recovery, code summarization, and reverse engineering. The\nresults show that ContraBin considerably improves performance on all four\ntasks, measured by accuracy, mean of average precision, and BLEU scores as\nappropriate. ContraBin is the first language representation model to\nincorporate source code, binary code, and comments into contrastive code\nrepresentation learning and is intended to contribute to the field of binary\ncode analysis. The dataset used in this study is available for further\nresearch.\n","authors":["Yifan Zhang","Chen Huang","Yueke Zhang","Kevin Cao","Scott Thomas Andersen","Huajie Shao","Kevin Leach","Yu Huang"],"pdf_url":"https://arxiv.org/pdf/2210.05102v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.10769v5","updated":"2024-12-13T06:36:28Z","published":"2023-05-18T07:23:12Z","title":"Catch-Up Distillation: You Only Need to Train Once for Accelerating\n  Sampling","summary":"  Diffusion Probability Models (DPMs) have made impressive advancements in\nvarious machine learning domains. However, achieving high-quality synthetic\nsamples typically involves performing a large number of sampling steps, which\nimpedes the possibility of real-time sample synthesis. Traditional accelerated\nsampling algorithms via knowledge distillation rely on pre-trained model\nweights and discrete time step scenarios, necessitating additional training\nsessions to achieve their goals. To address these issues, we propose the\nCatch-Up Distillation (CUD), which encourages the current moment output of the\nvelocity estimation model ``catch up'' with its previous moment output.\nSpecifically, CUD adjusts the original Ordinary Differential Equation (ODE)\ntraining objective to align the current moment output with both the ground\ntruth label and the previous moment output, utilizing Runge-Kutta-based\nmulti-step alignment distillation for precise ODE estimation while preventing\nasynchronous updates. Furthermore, we investigate the design space for CUDs\nunder continuous time-step scenarios and analyze how to determine the suitable\nstrategies. To demonstrate CUD's effectiveness, we conduct thorough ablation\nand comparison experiments on CIFAR-10, MNIST, and ImageNet-64. On CIFAR-10, we\nobtain a FID of 2.80 by sampling in 15 steps under one-session training and the\nnew state-of-the-art FID of 3.37 by sampling in one step with additional\ntraining. This latter result necessitated only 620k iterations with a batch\nsize of 128, in contrast to Consistency Distillation, which demanded 2100k\niterations with a larger batch size of 256. Our code is released at\nhttps://anonymous.4open.science/r/Catch-Up-Distillation-E31F.\n","authors":["Shitong Shao","Xu Dai","Lujun Li","Huanran Chen","Yang Hu","Shouyi Yin"],"pdf_url":"https://arxiv.org/pdf/2305.10769v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09900v1","updated":"2024-12-13T06:35:55Z","published":"2024-12-13T06:35:55Z","title":"Analyzing Fairness of Computer Vision and Natural Language Processing\n  Models","summary":"  Machine learning (ML) algorithms play a crucial role in decision making\nacross diverse fields such as healthcare, finance, education, and law\nenforcement. Despite their widespread adoption, these systems raise ethical and\nsocial concerns due to potential biases and fairness issues. This study focuses\non evaluating and improving the fairness of Computer Vision and Natural\nLanguage Processing (NLP) models applied to unstructured datasets, emphasizing\nhow biased predictions can reinforce existing systemic inequalities. A publicly\navailable dataset from Kaggle was utilized to simulate a practical scenario for\nexamining fairness in ML workflows. To address and mitigate biases, the study\nemployed two leading fairness libraries: Fairlearn by Microsoft, and AIF360 by\nIBM. These tools offer comprehensive frameworks for fairness analysis,\nincluding metrics evaluation, result visualization, and bias mitigation\ntechniques. The research aims to measure bias levels in ML models, compare the\neffectiveness of these fairness libraries, and provide actionable\nrecommendations for practitioners. The results demonstrate that each library\npossesses distinct strengths and limitations in evaluating and mitigating\nfairness. By systematically analyzing these tools, the study contributes\nvaluable insights to the growing field of ML fairness, offering practical\nguidance for integrating fairness solutions into real world applications. This\nresearch underscores the importance of building more equitable and responsible\nmachine learning systems.\n","authors":["Ahmed Rashed","Abdelkrim Kallich","Mohamed Eltayeb"],"pdf_url":"https://arxiv.org/pdf/2412.09900v1.pdf","comment":"16 pages, 1 table, 4 figures"},{"id":"http://arxiv.org/abs/2412.09899v1","updated":"2024-12-13T06:34:59Z","published":"2024-12-13T06:34:59Z","title":"TTAQ: Towards Stable Post-training Quantization in Continuous Domain\n  Adaptation","summary":"  Post-training quantization (PTQ) reduces excessive hardware cost by\nquantizing full-precision models into lower bit representations on a tiny\ncalibration set, without retraining. Despite the remarkable progress made\nthrough recent efforts, traditional PTQ methods typically encounter failure in\ndynamic and ever-changing real-world scenarios, involving unpredictable data\nstreams and continual domain shifts, which poses greater challenges. In this\npaper, we propose a novel and stable quantization process for test-time\nadaptation (TTA), dubbed TTAQ, to address the performance degradation of\ntraditional PTQ in dynamically evolving test domains. To tackle domain shifts\nin quantizer, TTAQ proposes the Perturbation Error Mitigation (PEM) and\nPerturbation Consistency Reconstruction (PCR). Specifically, PEM analyzes the\nerror propagation and devises a weight regularization scheme to mitigate the\nimpact of input perturbations. On the other hand, PCR introduces consistency\nlearning to ensure that quantized models provide stable predictions for same\nsample. Furthermore, we introduce Adaptive Balanced Loss (ABL) to adjust the\nlogits by taking advantage of the frequency and complexity of the class, which\ncan effectively address the class imbalance caused by unpredictable data\nstreams during optimization. Extensive experiments are conducted on multiple\ndatasets with generic TTA methods, proving that TTAQ can outperform existing\nbaselines and encouragingly improve the accuracy of low bit PTQ models in\ncontinually changing test domains. For instance, TTAQ decreases the mean error\nof 2-bit models on ImageNet-C dataset by an impressive 10.1\\%.\n","authors":["Junrui Xiao","Zhikai Li","Lianwei Yang","Yiduo Mei","Qingyi Gu"],"pdf_url":"https://arxiv.org/pdf/2412.09899v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09896v1","updated":"2024-12-13T06:31:09Z","published":"2024-12-13T06:31:09Z","title":"Analyzing Fairness of Classification Machine Learning Model with\n  Structured Dataset","summary":"  Machine learning (ML) algorithms have become integral to decision making in\nvarious domains, including healthcare, finance, education, and law enforcement.\nHowever, concerns about fairness and bias in these systems pose significant\nethical and social challenges. This study investigates the fairness of ML\nmodels applied to structured datasets in classification tasks, highlighting the\npotential for biased predictions to perpetuate systemic inequalities. A\npublicly available dataset from Kaggle was selected for analysis, offering a\nrealistic scenario for evaluating fairness in machine learning workflows.\n  To assess and mitigate biases, three prominent fairness libraries; Fairlearn\nby Microsoft, AIF360 by IBM, and the What If Tool by Google were employed.\nThese libraries provide robust frameworks for analyzing fairness, offering\ntools to evaluate metrics, visualize results, and implement bias mitigation\nstrategies. The research aims to assess the extent of bias in the ML models,\ncompare the effectiveness of these libraries, and derive actionable insights\nfor practitioners.\n  The findings reveal that each library has unique strengths and limitations in\nfairness evaluation and mitigation. By systematically comparing their\ncapabilities, this study contributes to the growing field of ML fairness by\nproviding practical guidance for integrating fairness tools into real world\napplications. These insights are intended to support the development of more\nequitable machine learning systems.\n","authors":["Ahmed Rashed","Abdelkrim Kallich","Mohamed Eltayeb"],"pdf_url":"https://arxiv.org/pdf/2412.09896v1.pdf","comment":"12 pages, 3 tables"},{"id":"http://arxiv.org/abs/2405.18944v2","updated":"2024-12-13T06:23:03Z","published":"2024-05-29T09:56:00Z","title":"Predicting Many Crystal Properties via an Adaptive Transformer-based\n  Framework","summary":"  Machine learning has revolutionized many fields, including materials science.\nHowever, predicting properties of crystalline materials using machine learning\nfaces challenges in input encoding, output versatility, and interpretability.\nWe introduce CrystalBERT, an adaptable transformer-based framework integrating\nspace group, elemental, and unit cell information. This novel structure can\nseamlessly combine diverse features and accurately predict various physical\nproperties, including topological properties, superconducting transition\ntemperatures, dielectric constants, and more. CrystalBERT provides insightful\ninterpretations of features influencing target properties. Our results indicate\nthat space group and elemental information are crucial for predicting\ntopological and superconducting properties, underscoring their intricate\nnature. By incorporating these features, we achieve 91\\% accuracy in\ntopological classification, surpassing prior studies and identifying previously\nmisclassified materials. This research demonstrates that integrating diverse\nmaterial information enhances the prediction of complex material properties,\npaving the way for more accurate and interpretable machine learning models in\nmaterials science.\n","authors":["Haosheng Xu","Dongheng Qian","Jing Wang"],"pdf_url":"https://arxiv.org/pdf/2405.18944v2.pdf","comment":"38+20 pages, 5+12 figures. The codes are available upon reasonable\n  request"},{"id":"http://arxiv.org/abs/2408.01129v5","updated":"2024-12-13T06:16:06Z","published":"2024-08-02T09:18:41Z","title":"A Survey of Mamba","summary":"  As one of the most representative DL techniques, Transformer architecture has\nempowered numerous advanced models, especially the large language models (LLMs)\nthat comprise billions of parameters, becoming a cornerstone in deep learning.\nDespite the impressive achievements, Transformers still face inherent\nlimitations, particularly the time-consuming inference resulting from the\nquadratic computation complexity of attention calculation. Recently, a novel\narchitecture named Mamba, drawing inspiration from classical state space models\n(SSMs), has emerged as a promising alternative for building foundation models,\ndelivering comparable modeling abilities to Transformers while preserving\nnear-linear scalability concerning sequence length. This has sparked an\nincreasing number of studies actively exploring Mamba's potential to achieve\nimpressive performance across diverse domains. Given such rapid evolution,\nthere is a critical need for a systematic review that consolidates existing\nMamba-empowered models, offering a comprehensive understanding of this emerging\nmodel architecture. In this survey, we therefore conduct an in-depth\ninvestigation of recent Mamba-associated studies, covering three main aspects:\nthe advancements of Mamba-based models, the techniques of adapting Mamba to\ndiverse data, and the applications where Mamba can excel. Specifically, we\nfirst review the foundational knowledge of various representative deep learning\nmodels and the details of Mamba-1&2 as preliminaries. Then, to showcase the\nsignificance of Mamba for AI, we comprehensively review the related studies\nfocusing on Mamba models' architecture design, data adaptability, and\napplications. Finally, we present a discussion of current limitations and\nexplore various promising research directions to provide deeper insights for\nfuture investigations.\n","authors":["Haohao Qu","Liangbo Ning","Rui An","Wenqi Fan","Tyler Derr","Hui Liu","Xin Xu","Qing Li"],"pdf_url":"https://arxiv.org/pdf/2408.01129v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09889v1","updated":"2024-12-13T06:06:49Z","published":"2024-12-13T06:06:49Z","title":"Semi-Periodic Activation for Time Series Classification","summary":"  This paper investigates the lack of research on activation functions for\nneural network models in time series tasks. It highlights the need to identify\nessential properties of these activations to improve their effectiveness in\nspecific domains. To this end, the study comprehensively analyzes properties,\nsuch as bounded, monotonic, nonlinearity, and periodicity, for activation in\ntime series neural networks. We propose a new activation that maximizes the\ncoverage of these properties, called LeakySineLU. We empirically evaluate the\nLeakySineLU against commonly used activations in the literature using 112\nbenchmark datasets for time series classification, obtaining the best average\nranking in all comparative scenarios.\n","authors":["José Gilberto Barbosa de Medeiros Júnior","Andre Guarnier de Mitri","Diego Furtado Silva"],"pdf_url":"https://arxiv.org/pdf/2412.09889v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09880v1","updated":"2024-12-13T05:51:00Z","published":"2024-12-13T05:51:00Z","title":"Financial Fine-tuning a Large Time Series Model","summary":"  Large models have shown unprecedented capabilities in natural language\nprocessing, image generation, and most recently, time series forecasting. This\nleads us to ask the question: treating market prices as a time series, can\nlarge models be used to predict the market? In this paper, we answer this by\nevaluating the performance of the latest time series foundation model TimesFM\non price prediction. We find that due to the irregular nature of price data,\ndirectly applying TimesFM gives unsatisfactory results and propose to fine-tune\nTimeFM on financial data for the task of price prediction. This is done by\ncontinual pre-training of the latest time series foundation model TimesFM on\nprice data containing 100 million time points, spanning a range of financial\ninstruments spanning hourly and daily granularities. The fine-tuned model\ndemonstrates higher price prediction accuracy than the baseline model. We\nconduct mock trading for our model in various financial markets and show that\nit outperforms various benchmarks in terms of returns, sharpe ratio, max\ndrawdown and trading cost.\n","authors":["Xinghong Fu","Masanori Hirano","Kentaro Imajo"],"pdf_url":"https://arxiv.org/pdf/2412.09880v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09861v1","updated":"2024-12-13T05:02:16Z","published":"2024-12-13T05:02:16Z","title":"Data-Driven Transfer Learning Framework for Estimating Turning Movement\n  Counts","summary":"  Urban transportation networks are vital for the efficient movement of people\nand goods, necessitating effective traffic management and planning. An integral\npart of traffic management is understanding the turning movement counts (TMCs)\nat intersections, Accurate TMCs at intersections are crucial for traffic signal\ncontrol, congestion mitigation, and road safety. In general, TMCs are obtained\nusing physical sensors installed at intersections, but this approach can be\ncost-prohibitive and technically challenging, especially for cities with\nextensive road networks. Recent advancements in machine learning and\ndata-driven approaches have offered promising alternatives for estimating TMCs.\nTraffic patterns can vary significantly across different intersections due to\nfactors such as road geometry, traffic signal settings, and local driver\nbehaviors. This domain discrepancy limits the generalizability and accuracy of\nmachine learning models when applied to new or unseen intersections. In\nresponse to these limitations, this research proposes a novel framework\nleveraging transfer learning (TL) to estimate TMCs at intersections by using\ntraffic controller event-based data, road infrastructure data, and\npoint-of-interest (POI) data. Evaluated on 30 intersections in Tucson, Arizona,\nthe performance of the proposed TL model was compared with eight\nstate-of-the-art regression models and achieved the lowest values in terms of\nMean Absolute Error and Root Mean Square Error.\n","authors":["Xiaobo Ma","Hyunsoo Noh","Ryan Hatch","James Tokishi","Zepu Wang"],"pdf_url":"https://arxiv.org/pdf/2412.09861v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09860v1","updated":"2024-12-13T05:00:57Z","published":"2024-12-13T05:00:57Z","title":"Brain-inspired Chaotic Graph Backpropagation for Large-scale\n  Combinatorial Optimization","summary":"  Graph neural networks (GNNs) with unsupervised learning can solve large-scale\ncombinatorial optimization problems (COPs) with efficient time complexity,\nmaking them versatile for various applications. However, since this method maps\nthe combinatorial optimization problem to the training process of a graph\nneural network, and the current mainstream backpropagation-based training\nalgorithms are prone to fall into local minima, the optimization performance is\nstill inferior to the current state-of-the-art (SOTA) COP methods. To address\nthis issue, inspired by possibly chaotic dynamics of real brain learning, we\nintroduce a chaotic training algorithm, i.e. chaotic graph backpropagation\n(CGBP), which introduces a local loss function in GNN that makes the training\nprocess not only chaotic but also highly efficient. Different from existing\nmethods, we show that the global ergodicity and pseudo-randomness of such\nchaotic dynamics enable CGBP to learn each optimal GNN effectively and\nglobally, thus solving the COP efficiently. We have applied CGBP to solve\nvarious COPs, such as the maximum independent set, maximum cut, and graph\ncoloring. Results on several large-scale benchmark datasets showcase that CGBP\ncan outperform not only existing GNN algorithms but also SOTA methods. In\naddition to solving large-scale COPs, CGBP as a universal learning algorithm\nfor GNNs, i.e. as a plug-in unit, can be easily integrated into any existing\nmethod for improving the performance.\n","authors":["Peng Tao","Kazuyuki Aihara","Luonan Chen"],"pdf_url":"https://arxiv.org/pdf/2412.09860v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09859v1","updated":"2024-12-13T04:59:50Z","published":"2024-12-13T04:59:50Z","title":"Financial Sentiment Analysis: Leveraging Actual and Synthetic Data for\n  Supervised Fine-tuning","summary":"  The Efficient Market Hypothesis (EMH) highlights the essence of financial\nnews in stock price movement. Financial news comes in the form of corporate\nannouncements, news titles, and other forms of digital text. The generation of\ninsights from financial news can be done with sentiment analysis.\nGeneral-purpose language models are too general for sentiment analysis in\nfinance. Curated labeled data for fine-tuning general-purpose language models\nare scare, and existing fine-tuned models for sentiment analysis in finance do\nnot capture the maximum context width. We hypothesize that using actual and\nsynthetic data can improve performance. We introduce BertNSP-finance to\nconcatenate shorter financial sentences into longer financial sentences, and\nfinbert-lc to determine sentiment from digital text. The results show improved\nperformance on the accuracy and the f1 score for the financial phrasebank data\nwith $50\\%$ and $100\\%$ agreement levels.\n","authors":["Abraham Atsiwo"],"pdf_url":"https://arxiv.org/pdf/2412.09859v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09858v1","updated":"2024-12-13T04:57:55Z","published":"2024-12-13T04:57:55Z","title":"RLDG: Robotic Generalist Policy Distillation via Reinforcement Learning","summary":"  Recent advances in robotic foundation models have enabled the development of\ngeneralist policies that can adapt to diverse tasks. While these models show\nimpressive flexibility, their performance heavily depends on the quality of\ntheir training data. In this work, we propose Reinforcement Learning Distilled\nGeneralists (RLDG), a method that leverages reinforcement learning to generate\nhigh-quality training data for finetuning generalist policies. Through\nextensive real-world experiments on precise manipulation tasks like connector\ninsertion and assembly, we demonstrate that generalist policies trained with\nRL-generated data consistently outperform those trained with human\ndemonstrations, achieving up to 40% higher success rates while generalizing\nbetter to new tasks. We also provide a detailed analysis that reveals this\nperformance gain stems from both optimized action distributions and improved\nstate coverage. Our results suggest that combining task-specific RL with\ngeneralist policy distillation offers a promising approach for developing more\ncapable and efficient robotic manipulation systems that maintain the\nflexibility of foundation models while achieving the performance of specialized\ncontrollers. Videos and code can be found on our project website\nhttps://generalist-distillation.github.io\n","authors":["Charles Xu","Qiyang Li","Jianlan Luo","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2412.09858v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09856v1","updated":"2024-12-13T04:55:10Z","published":"2024-12-13T04:55:10Z","title":"LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation\n  with Linear Computational Complexity","summary":"  Text-to-video generation enhances content creation but is highly\ncomputationally intensive: The computational cost of Diffusion Transformers\n(DiTs) scales quadratically in the number of pixels. This makes minute-length\nvideo generation extremely expensive, limiting most existing models to\ngenerating videos of only 10-20 seconds length. We propose a Linear-complexity\ntext-to-video Generation (LinGen) framework whose cost scales linearly in the\nnumber of pixels. For the first time, LinGen enables high-resolution\nminute-length video generation on a single GPU without compromising quality. It\nreplaces the computationally-dominant and quadratic-complexity block,\nself-attention, with a linear-complexity block called MATE, which consists of\nan MA-branch and a TE-branch. The MA-branch targets short-to-long-range\ncorrelations, combining a bidirectional Mamba2 block with our token\nrearrangement method, Rotary Major Scan, and our review tokens developed for\nlong video generation. The TE-branch is a novel TEmporal Swin Attention block\nthat focuses on temporal correlations between adjacent tokens and medium-range\ntokens. The MATE block addresses the adjacency preservation issue of Mamba and\nimproves the consistency of generated videos significantly. Experimental\nresults show that LinGen outperforms DiT (with a 75.6% win rate) in video\nquality with up to 15$\\times$ (11.5$\\times$) FLOPs (latency) reduction.\nFurthermore, both automatic metrics and human evaluation demonstrate our\nLinGen-4B yields comparable video quality to state-of-the-art models (with a\n50.5%, 52.1%, 49.1% win rate with respect to Gen-3, LumaLabs, and Kling,\nrespectively). This paves the way to hour-length movie generation and real-time\ninteractive video generation. We provide 68s video generation results and more\nexamples in our project website: https://lineargen.github.io/.\n","authors":["Hongjie Wang","Chih-Yao Ma","Yen-Cheng Liu","Ji Hou","Tao Xu","Jialiang Wang","Felix Juefei-Xu","Yaqiao Luo","Peizhao Zhang","Tingbo Hou","Peter Vajda","Niraj K. Jha","Xiaoliang Dai"],"pdf_url":"https://arxiv.org/pdf/2412.09856v1.pdf","comment":"20 pages, 20 figures"},{"id":"http://arxiv.org/abs/2409.07089v2","updated":"2024-12-13T04:48:20Z","published":"2024-09-11T08:20:30Z","title":"TrialSynth: Generation of Synthetic Sequential Clinical Trial Data","summary":"  Analyzing data from past clinical trials is part of the ongoing effort to\noptimize the design, implementation, and execution of new clinical trials and\nmore efficiently bring life-saving interventions to market. While there have\nbeen recent advances in the generation of static context synthetic clinical\ntrial data, due to both limited patient availability and constraints imposed by\npatient privacy needs, the generation of fine-grained synthetic time-sequential\nclinical trial data has been challenging. Given that patient trajectories over\nan entire clinical trial are of high importance for optimizing trial design and\nefforts to prevent harmful adverse events, there is a significant need for the\ngeneration of high-fidelity time-sequence clinical trial data. Here we\nintroduce TrialSynth, a Variational Autoencoder (VAE) designed to address the\nspecific challenges of generating synthetic time-sequence clinical trial data.\nDistinct from related clinical data VAE methods, the core of our method\nleverages Hawkes Processes (HP), which are particularly well-suited for\nmodeling event-type and time gap prediction needed to capture the structure of\nsequential clinical trial data. Our experiments demonstrate that TrialSynth\nsurpasses the performance of other comparable methods that can generate\nsequential clinical trial data at varying levels of fidelity / privacy\ntradeoff, enabling the generation of highly accurate event sequences across\nmultiple real-world sequential event datasets with small patient source\npopulations. Notably, our empirical findings highlight that TrialSynth not only\noutperforms existing clinical sequence-generating methods but also produces\ndata with superior utility while empirically preserving patient privacy.\n","authors":["Chufan Gao","Mandis Beigi","Afrah Shafquat","Jacob Aptekar","Jimeng Sun"],"pdf_url":"https://arxiv.org/pdf/2409.07089v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09853v1","updated":"2024-12-13T04:46:17Z","published":"2024-12-13T04:46:17Z","title":"Understand the Effectiveness of Shortcuts through the Lens of DCA","summary":"  Difference-of-Convex Algorithm (DCA) is a well-known nonconvex optimization\nalgorithm for minimizing a nonconvex function that can be expressed as the\ndifference of two convex ones. Many famous existing optimization algorithms,\nsuch as SGD and proximal point methods, can be viewed as special DCAs with\nspecific DC decompositions, making it a powerful framework for optimization. On\nthe other hand, shortcuts are a key architectural feature in modern deep neural\nnetworks, facilitating both training and optimization. We showed that the\nshortcut neural network gradient can be obtained by applying DCA to vanilla\nneural networks, networks without shortcut connections. Therefore, from the\nperspective of DCA, we can better understand the effectiveness of networks with\nshortcuts. Moreover, we proposed a new architecture called NegNet that does not\nfit the previous interpretation but performs on par with ResNet and can be\nincluded in the DCA framework.\n","authors":["Youran Sun","Yihua Liu","Yi-Shuai Niu"],"pdf_url":"https://arxiv.org/pdf/2412.09853v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.03350v2","updated":"2024-12-13T04:32:21Z","published":"2024-01-07T00:58:33Z","title":"Accurate and Scalable Estimation of Epistemic Uncertainty for Graph\n  Neural Networks","summary":"  While graph neural networks (GNNs) are widely used for node and graph\nrepresentation learning tasks, the reliability of GNN uncertainty estimates\nunder distribution shifts remains relatively under-explored. Indeed, while\npost-hoc calibration strategies can be used to improve in-distribution\ncalibration, they need not also improve calibration under distribution shift.\nHowever, techniques which produce GNNs with better intrinsic uncertainty\nestimates are particularly valuable, as they can always be combined with\npost-hoc strategies later. Therefore, in this work, we propose G-$\\Delta$UQ, a\nnovel training framework designed to improve intrinsic GNN uncertainty\nestimates. Our framework adapts the principle of stochastic data centering to\ngraph data through novel graph anchoring strategies, and is able to support\npartially stochastic GNNs. While, the prevalent wisdom is that fully stochastic\nnetworks are necessary to obtain reliable estimates, we find that the\nfunctional diversity induced by our anchoring strategies when sampling\nhypotheses renders this unnecessary and allows us to support G-$\\Delta$UQ on\npretrained models. Indeed, through extensive evaluation under covariate,\nconcept and graph size shifts, we show that G-$\\Delta$UQ leads to better\ncalibrated GNNs for node and graph classification. Further, it also improves\nperformance on the uncertainty-based tasks of out-of-distribution detection and\ngeneralization gap estimation. Overall, our work provides insights into\nuncertainty estimation for GNNs, and demonstrates the utility of G-$\\Delta$UQ\nin obtaining reliable estimates.\n","authors":["Puja Trivedi","Mark Heimann","Rushil Anirudh","Danai Koutra","Jayaraman J. Thiagarajan"],"pdf_url":"https://arxiv.org/pdf/2401.03350v2.pdf","comment":"Published at ICLR 2024; Project page:\n  https://pujacomputes.github.io/gduq/"},{"id":"http://arxiv.org/abs/2412.09843v1","updated":"2024-12-13T04:25:56Z","published":"2024-12-13T04:25:56Z","title":"Learning Structural Causal Models from Ordering: Identifiable Flow\n  Models","summary":"  In this study, we address causal inference when only observational data and a\nvalid causal ordering from the causal graph are available. We introduce a set\nof flow models that can recover component-wise, invertible transformation of\nexogenous variables. Our flow-based methods offer flexible model design while\nmaintaining causal consistency regardless of the number of discretization\nsteps. We propose design improvements that enable simultaneous learning of all\ncausal mechanisms and reduce abduction and prediction complexity to linear O(n)\nrelative to the number of layers, independent of the number of causal\nvariables. Empirically, we demonstrate that our method outperforms previous\nstate-of-the-art approaches and delivers consistent performance across a wide\nrange of structural causal models in answering observational, interventional,\nand counterfactual questions. Additionally, our method achieves a significant\nreduction in computational time compared to existing diffusion-based\ntechniques, making it practical for large structural causal models.\n","authors":["Minh Khoa Le","Kien Do","Truyen Tran"],"pdf_url":"https://arxiv.org/pdf/2412.09843v1.pdf","comment":"Accepted at AAAI 2025"},{"id":"http://arxiv.org/abs/2412.09842v1","updated":"2024-12-13T04:22:23Z","published":"2024-12-13T04:22:23Z","title":"Leveraging Programmatically Generated Synthetic Data for Differentially\n  Private Diffusion Training","summary":"  Programmatically generated synthetic data has been used in differential\nprivate training for classification to enhance performance without privacy\nleakage. However, as the synthetic data is generated from a random process, the\ndistribution of real data and the synthetic data are distinguishable and\ndifficult to transfer. Therefore, the model trained with the synthetic data\ngenerates unrealistic random images, raising challenges to adapt the synthetic\ndata for generative models. In this work, we propose DP-SynGen, which leverages\nprogrammatically generated synthetic data in diffusion models to address this\nchallenge. By exploiting the three stages of diffusion models(coarse, context,\nand cleaning) we identify stages where synthetic data can be effectively\nutilized. We theoretically and empirically verified that cleaning and coarse\nstages can be trained without private data, replacing them with synthetic data\nto reduce the privacy budget. The experimental results show that DP-SynGen\nimproves the quality of generative data by mitigating the negative impact of\nprivacy-induced noise on the generation process.\n","authors":["Yujin Choi","Jinseong Park","Junyoung Byun","Jaewook Lee"],"pdf_url":"https://arxiv.org/pdf/2412.09842v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08894v2","updated":"2024-12-13T04:03:14Z","published":"2024-12-12T03:14:50Z","title":"SMMF: Square-Matricized Momentum Factorization for Memory-Efficient\n  Optimization","summary":"  We propose SMMF (Square-Matricized Momentum Factorization), a\nmemory-efficient optimizer that reduces the memory requirement of the widely\nused adaptive learning rate optimizers, such as Adam, by up to 96%. SMMF\nenables flexible and efficient factorization of an arbitrary rank (shape) of\nthe first and second momentum tensors during optimization, based on the\nproposed square-matricization and one-time single matrix factorization. From\nthis, it becomes effectively applicable to any rank (shape) of momentum\ntensors, i.e., bias, matrix, and any rank-d tensors, prevalent in various deep\nmodel architectures, such as CNNs (high rank) and Transformers (low rank), in\ncontrast to existing memory-efficient optimizers that applies only to a\nparticular (rank-2) momentum tensor, e.g., linear layers. We conduct a regret\nbound analysis of SMMF, which shows that it converges similarly to\nnon-memory-efficient adaptive learning rate optimizers, such as AdamNC,\nproviding a theoretical basis for its competitive optimization capability. In\nour experiment, SMMF takes up to 96% less memory compared to state-of-the-art\nmemory efficient optimizers, e.g., Adafactor, CAME, and SM3, while achieving\ncomparable model performance on various CNN and Transformer tasks.\n","authors":["Kwangryeol Park","Seulki Lee"],"pdf_url":"https://arxiv.org/pdf/2412.08894v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09832v1","updated":"2024-12-13T03:51:39Z","published":"2024-12-13T03:51:39Z","title":"Multivariate Time Series Clustering for Environmental State\n  Characterization of Ground-Based Gravitational-Wave Detectors","summary":"  Gravitational-wave observatories like LIGO are large-scale, terrestrial\ninstruments housed in infrastructure that spans a multi-kilometer geographic\narea and which must be actively controlled to maintain operational stability\nfor long observation periods. Despite exquisite seismic isolation, they remain\nsusceptible to seismic noise and other terrestrial disturbances that can couple\nundesirable vibrations into the instrumental infrastructure, potentially\nleading to control instabilities or noise artifacts in the detector output. It\nis, therefore, critical to characterize the seismic state of these\nobservatories to identify a set of temporal patterns that can inform the\ndetector operators in day-to-day monitoring and diagnostics. On a day-to-day\nbasis, the operators monitor several seismically relevant data streams to\ndiagnose operational instabilities and sources of noise using some simple\nempirically-determined thresholds. It can be untenable for a human operator to\nmonitor multiple data streams in this manual fashion and thus a distillation of\nthese data-streams into a more human-friendly format is sought. In this paper,\nwe present an end-to-end machine learning pipeline for features-based\nmultivariate time series clustering to achieve this goal and to provide\nactionable insights to the detector operators by correlating found clusters\nwith events of interest in the detector.\n","authors":["Rutuja Gurav","Isaac Kelly","Pooyan Goodarzi","Anamaria Effler","Barry Barish","Evangelos Papalexakis","Jonathan Richardson"],"pdf_url":"https://arxiv.org/pdf/2412.09832v1.pdf","comment":"8 pages, 6 figures, Accepted to The 5th International Workshop on Big\n  Data & AI Tools, Methods, and Use Cases for Innovative Scientific Discovery\n  (BTSD 2024)"},{"id":"http://arxiv.org/abs/2412.03506v2","updated":"2024-12-13T03:46:39Z","published":"2024-12-04T17:48:38Z","title":"Self-test loss functions for learning weak-form operators and gradient\n  flows","summary":"  The construction of loss functions presents a major challenge in data-driven\nmodeling involving weak-form operators in PDEs and gradient flows, particularly\ndue to the need to select test functions appropriately. We address this\nchallenge by introducing self-test loss functions, which employ test functions\nthat depend on the unknown parameters, specifically for cases where the\noperator depends linearly on the unknowns. The proposed self-test loss function\nconserves energy for gradient flows and coincides with the expected\nlog-likelihood ratio for stochastic differential equations. Importantly, it is\nquadratic, facilitating theoretical analysis of identifiability and\nwell-posedness of the inverse problem, while also leading to efficient\nparametric or nonparametric regression algorithms. It is computationally\nsimple, requiring only low-order derivatives or even being entirely\nderivative-free, and numerical experiments demonstrate its robustness against\nnoisy and discrete data.\n","authors":["Yuan Gao","Quanjun Lang","Fei Lu"],"pdf_url":"https://arxiv.org/pdf/2412.03506v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.05996v3","updated":"2024-12-13T03:38:34Z","published":"2022-02-12T06:04:13Z","title":"Mixture of Online and Offline Experts for Non-stationary Time Series","summary":"  We consider a general and realistic scenario involving non-stationary time\nseries, consisting of several offline intervals with different distributions\nwithin a fixed offline time horizon, and an online interval that continuously\nreceives new samples. For non-stationary time series, the data distribution in\nthe current online interval may have appeared in previous offline intervals. We\ntheoretically explore the feasibility of applying knowledge from offline\nintervals to the current online interval. To this end, we propose the Mixture\nof Online and Offline Experts (MOOE). MOOE learns static offline experts from\noffline intervals and maintains a dynamic online expert for the current online\ninterval. It then adaptively combines the offline and online experts using a\nmeta expert to make predictions for the samples received in the online\ninterval. Specifically, we focus on theoretical analysis, deriving parameter\nconvergence, regret bounds, and generalization error bounds to prove the\neffectiveness of the algorithm.\n","authors":["Zhilin Zhao","Longbing Cao","Yuanyu Wan"],"pdf_url":"https://arxiv.org/pdf/2202.05996v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09826v1","updated":"2024-12-13T03:36:23Z","published":"2024-12-13T03:36:23Z","title":"Precise Antigen-Antibody Structure Predictions Enhance Antibody\n  Development with HelixFold-Multimer","summary":"  The accurate prediction of antigen-antibody structures is essential for\nadvancing immunology and therapeutic development, as it helps elucidate\nmolecular interactions that underlie immune responses. Despite recent progress\nwith deep learning models like AlphaFold and RoseTTAFold, accurately modeling\nantigen-antibody complexes remains a challenge due to their unique evolutionary\ncharacteristics. HelixFold-Multimer, a specialized model developed for this\npurpose, builds on the framework of AlphaFold-Multimer and demonstrates\nimproved precision for antigen-antibody structures. HelixFold-Multimer not only\nsurpasses other models in accuracy but also provides essential insights into\nantibody development, enabling more precise identification of binding sites,\nimproved interaction prediction, and enhanced design of therapeutic antibodies.\nThese advances underscore HelixFold-Multimer's potential in supporting antibody\nresearch and therapeutic innovation.\n","authors":["Jie Gao","Jing Hu","Lihang Liu","Yang Xue","Kunrui Zhu","Xiaonan Zhang","Xiaomin Fang"],"pdf_url":"https://arxiv.org/pdf/2412.09826v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.00979v2","updated":"2024-12-13T03:31:51Z","published":"2024-12-01T22:02:07Z","title":"Hierarchical Prompt Decision Transformer: Improving Few-Shot Policy\n  Generalization with Global and Adaptive Guidance","summary":"  Decision transformers recast reinforcement learning as a conditional sequence\ngeneration problem, offering a simple but effective alternative to traditional\nvalue or policy-based methods. A recent key development in this area is the\nintegration of prompting in decision transformers to facilitate few-shot policy\ngeneralization. However, current methods mainly use static prompt segments to\nguide rollouts, limiting their ability to provide context-specific guidance.\nAddressing this, we introduce a hierarchical prompting approach enabled by\nretrieval augmentation. Our method learns two layers of soft tokens as guiding\nprompts: (1) global tokens encapsulating task-level information about\ntrajectories, and (2) adaptive tokens that deliver focused, timestep-specific\ninstructions. The adaptive tokens are dynamically retrieved from a curated set\nof demonstration segments, ensuring context-aware guidance. Experiments across\nseven benchmark tasks in the MuJoCo and MetaWorld environments demonstrate the\nproposed approach consistently outperforms all baseline methods, suggesting\nthat hierarchical prompting for decision transformers is an effective strategy\nto enable few-shot policy generalization.\n","authors":["Zhe Wang","Haozhu Wang","Yanjun Qi"],"pdf_url":"https://arxiv.org/pdf/2412.00979v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09819v1","updated":"2024-12-13T03:16:14Z","published":"2024-12-13T03:16:14Z","title":"FDM-Bench: A Comprehensive Benchmark for Evaluating Large Language\n  Models in Additive Manufacturing Tasks","summary":"  Fused Deposition Modeling (FDM) is a widely used additive manufacturing (AM)\ntechnique valued for its flexibility and cost-efficiency, with applications in\na variety of industries including healthcare and aerospace. Recent developments\nhave made affordable FDM machines accessible and encouraged adoption among\ndiverse users. However, the design, planning, and production process in FDM\nrequire specialized interdisciplinary knowledge. Managing the complex\nparameters and resolving print defects in FDM remain challenging. These\ntechnical complexities form the most critical barrier preventing individuals\nwithout technical backgrounds and even professional engineers without training\nin other domains from participating in AM design and manufacturing. Large\nLanguage Models (LLMs), with their advanced capabilities in text and code\nprocessing, offer the potential for addressing these challenges in FDM.\nHowever, existing research on LLM applications in this field is limited,\ntypically focusing on specific use cases without providing comprehensive\nevaluations across multiple models and tasks. To this end, we introduce\nFDM-Bench, a benchmark dataset designed to evaluate LLMs on FDM-specific tasks.\nFDM-Bench enables a thorough assessment by including user queries across\nvarious experience levels and G-code samples that represent a range of\nanomalies. We evaluate two closed-source models (GPT-4o and Claude 3.5 Sonnet)\nand two open-source models (Llama-3.1-70B and Llama-3.1-405B) on FDM-Bench. A\npanel of FDM experts assess the models' responses to user queries in detail.\nResults indicate that closed-source models generally outperform open-source\nmodels in G-code anomaly detection, whereas Llama-3.1-405B demonstrates a\nslight advantage over other models in responding to user queries. These\nfindings underscore FDM-Bench's potential as a foundational tool for advancing\nresearch on LLM capabilities in FDM.\n","authors":["Ahmadreza Eslaminia","Adrian Jackson","Beitong Tian","Avi Stern","Hallie Gordon","Rajiv Malhotra","Klara Nahrstedt","Chenhui Shao"],"pdf_url":"https://arxiv.org/pdf/2412.09819v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09814v1","updated":"2024-12-13T03:09:35Z","published":"2024-12-13T03:09:35Z","title":"Temporal Causal Discovery in Dynamic Bayesian Networks Using Federated\n  Learning","summary":"  Traditionally, learning the structure of a Dynamic Bayesian Network has been\ncentralized, with all data pooled in one location. However, in real-world\nscenarios, data are often dispersed among multiple parties (e.g., companies,\ndevices) that aim to collaboratively learn a Dynamic Bayesian Network while\npreserving their data privacy and security. In this study, we introduce a\nfederated learning approach for estimating the structure of a Dynamic Bayesian\nNetwork from data distributed horizontally across different parties. We propose\na distributed structure learning method that leverages continuous optimization\nso that only model parameters are exchanged during optimization. Experimental\nresults on synthetic and real datasets reveal that our method outperforms other\nstate-of-the-art techniques, particularly when there are many clients with\nlimited individual sample sizes.\n","authors":["Jianhong Chen","Ying Ma","Xubo Yue"],"pdf_url":"https://arxiv.org/pdf/2412.09814v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2412.09810v1","updated":"2024-12-13T02:57:59Z","published":"2024-12-13T02:57:59Z","title":"The Complexity Dynamics of Grokking","summary":"  We investigate the phenomenon of generalization through the lens of\ncompression. In particular, we study the complexity dynamics of neural networks\nto explain grokking, where networks suddenly transition from memorizing to\ngeneralizing solutions long after over-fitting the training data. To this end\nwe introduce a new measure of intrinsic complexity for neural networks based on\nthe theory of Kolmogorov complexity. Tracking this metric throughout network\ntraining, we find a consistent pattern in training dynamics, consisting of a\nrise and fall in complexity. We demonstrate that this corresponds to\nmemorization followed by generalization. Based on insights from\nrate--distortion theory and the minimum description length principle, we lay\nout a principled approach to lossy compression of neural networks, and connect\nour complexity measure to explicit generalization bounds. Based on a careful\nanalysis of information capacity in neural networks, we propose a new\nregularization method which encourages networks towards low-rank\nrepresentations by penalizing their spectral entropy, and find that our\nregularizer outperforms baselines in total compression of the dataset.\n","authors":["Branton DeMoss","Silvia Sapora","Jakob Foerster","Nick Hawes","Ingmar Posner"],"pdf_url":"https://arxiv.org/pdf/2412.09810v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08901v2","updated":"2024-12-13T02:55:30Z","published":"2024-12-12T03:25:13Z","title":"Radiology Report Generation via Multi-objective Preference Optimization","summary":"  Automatic Radiology Report Generation (RRG) is an important topic for\nalleviating the substantial workload of radiologists. Existing RRG approaches\nrely on supervised regression based on different architectures or additional\nknowledge injection,while the generated report may not align optimally with\nradiologists' preferences. Especially, since the preferences of radiologists\nare inherently heterogeneous and multidimensional, e.g., some may prioritize\nreport fluency, while others emphasize clinical accuracy. To address this\nproblem,we propose a new RRG method via Multi-objective Preference Optimization\n(MPO) to align the pre-trained RRG model with multiple human preferences, which\ncan be formulated by multi-dimensional reward functions and optimized by\nmulti-objective reinforcement learning (RL). Specifically, we use a preference\nvector to represent the weight of preferences and use it as a condition for the\nRRG model. Then, a linearly weighed reward is obtained via a dot product\nbetween the preference vector and multi-dimensional reward. Next,the RRG model\nis optimized to align with the preference vector by optimizing such a reward\nvia RL. In the training stage,we randomly sample diverse preference vectors\nfrom the preference space and align the model by optimizing the weighted\nmulti-objective rewards, which leads to an optimal policy on the entire\npreference space. When inference,our model can generate reports aligned with\nspecific preferences without further fine-tuning. Extensive experiments on two\npublic datasets show the proposed method can generate reports that cater to\ndifferent preferences in a single model and achieve state-of-the-art\nperformance.\n","authors":["Ting Xiao","Lei Shi","Peng Liu","Zhe Wang","Chenjia Bai"],"pdf_url":"https://arxiv.org/pdf/2412.08901v2.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2412.09805v1","updated":"2024-12-13T02:44:47Z","published":"2024-12-13T02:44:47Z","title":"Universal Inceptive GNNs by Eliminating the Smoothness-generalization\n  Dilemma","summary":"  Graph Neural Networks (GNNs) have demonstrated remarkable success in various\ndomains, such as transaction and social net-works. However, their application\nis often hindered by the varyinghomophily levels across different orders of\nneighboring nodes, ne-cessitating separate model designs for homophilic and\nheterophilicgraphs. In this paper, we aim to develop a unified framework\nca-pable of handling neighborhoods of various orders and homophilylevels.\nThrough theoretical exploration, we identify a previouslyoverlooked\narchitectural aspect in multi-hop learning: the cascadedependency, which leads\nto asmoothness-generalization dilemma.This dilemma significantly affects the\nlearning process, especiallyin the context of high-order neighborhoods and\nheterophilic graphs.To resolve this issue, we propose an Inceptive Graph Neural\nNet-work (IGNN), a universal message-passing framework that replacesthe cascade\ndependency with an inceptive architecture. IGNN pro-vides independent\nrepresentations for each hop, allowing personal-ized generalization\ncapabilities, and captures neighborhood-wiserelationships to select appropriate\nreceptive fields. Extensive ex-periments show that our IGNN outperforms 23\nbaseline methods,demonstrating superior performance on both homophilic and\nhet-erophilic graphs, while also scaling efficiently to large graphs.\n","authors":["Ming Gu","Zhuonan Zheng","Sheng Zhou","Meihan Liu","Jiawei Chen","Tanyu Qiao","Liangcheng Li","Jiajun Bu"],"pdf_url":"https://arxiv.org/pdf/2412.09805v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2402.09025v6","updated":"2024-12-13T02:44:34Z","published":"2024-02-14T09:01:13Z","title":"SLEB: Streamlining LLMs through Redundancy Verification and Elimination\n  of Transformer Blocks","summary":"  Large language models (LLMs) have proven to be highly effective across\nvarious natural language processing tasks. However, their large number of\nparameters poses significant challenges for practical deployment. Pruning, a\ntechnique aimed at reducing the size and complexity of LLMs, offers a potential\nsolution by removing redundant components from the network. Despite the promise\nof pruning, existing methods often struggle to achieve substantial end-to-end\nLLM inference speedup. In this paper, we introduce SLEB, a novel approach\ndesigned to streamline LLMs by eliminating redundant transformer blocks. We\nchoose the transformer block as the fundamental unit for pruning, because LLMs\nexhibit block-level redundancy with high similarity between the outputs of\nneighboring blocks. This choice allows us to effectively enhance the processing\nspeed of LLMs. Our experimental results demonstrate that SLEB outperforms\nprevious LLM pruning methods in accelerating LLM inference while also\nmaintaining superior perplexity and accuracy, making SLEB as a promising\ntechnique for enhancing the efficiency of LLMs. The code is available at:\nhttps://github.com/jiwonsong-dev/SLEB.\n","authors":["Jiwon Song","Kyungseok Oh","Taesu Kim","Hyungjun Kim","Yulhwa Kim","Jae-Joon Kim"],"pdf_url":"https://arxiv.org/pdf/2402.09025v6.pdf","comment":"ICML 2024"},{"id":"http://arxiv.org/abs/2412.09803v1","updated":"2024-12-13T02:42:56Z","published":"2024-12-13T02:42:56Z","title":"deepNoC: A deep learning system to assign the number of contributors to\n  a short tandem repeat DNA profile","summary":"  A common task in forensic biology is to interpret and evaluate short tandem\nrepeat DNA profiles. The first step in these interpretations is to assign a\nnumber of contributors to the profiles, a task that is most often performed\nmanually by a scientist using their knowledge of DNA profile behaviour. Studies\nusing constructed DNA profiles have shown that as DNA profiles become more\ncomplex, and the number of DNA-donating individuals increases, the ability for\nscientists to assign the target number. There have been a number of machine\nlearning algorithms developed that seek to assign the number of contributors to\na DNA profile, however due to practical limitations in being able to generate\nDNA profiles in a laboratory, the algorithms have been based on summaries of\nthe available information. In this work we develop an analysis pipeline that\nsimulates the electrophoretic signal of an STR profile, allowing virtually\nunlimited, pre-labelled training material to be generated. We show that by\nsimulating 100 000 profiles and training a number of contributors estimation\ntool using a deep neural network architecture (in an algorithm named deepNoC)\nthat a high level of performance is achieved (89% for 1 to 10 contributors).\nThe trained network can then have fine-tuning training performed with only a\nfew hundred profiles in order to achieve the same accuracy within a specific\nlaboratory. We also build into deepNoC secondary outputs that provide a level\nof explainability to a user of algorithm, and show how they can be displayed in\nan intuitive manner.\n","authors":["Duncan Taylor","Melissa A. Humphries"],"pdf_url":"https://arxiv.org/pdf/2412.09803v1.pdf","comment":"29 pages, 8 figures"},{"id":"http://arxiv.org/abs/2412.09800v1","updated":"2024-12-13T02:39:04Z","published":"2024-12-13T02:39:04Z","title":"Infinite-dimensional next-generation reservoir computing","summary":"  Next-generation reservoir computing (NG-RC) has attracted much attention due\nto its excellent performance in spatio-temporal forecasting of complex systems\nand its ease of implementation. This paper shows that NG-RC can be encoded as a\nkernel ridge regression that makes training efficient and feasible even when\nthe space of chosen polynomial features is very large. Additionally, an\nextension to an infinite number of covariates is possible, which makes the\nmethodology agnostic with respect to the lags into the past that are considered\nas explanatory factors, as well as with respect to the number of polynomial\ncovariates, an important hyperparameter in traditional NG-RC. We show that this\napproach has solid theoretical backing and good behavior based on kernel\nuniversality properties previously established in the literature. Various\nnumerical illustrations show that these generalizations of NG-RC outperform the\ntraditional approach in several forecasting applications.\n","authors":["Lyudmila Grigoryeva","Hannah Lim Jing Ting","Juan-Pablo Ortega"],"pdf_url":"https://arxiv.org/pdf/2412.09800v1.pdf","comment":"13 pages, 2 figures, 3 tables"},{"id":"http://arxiv.org/abs/2412.09795v1","updated":"2024-12-13T02:26:58Z","published":"2024-12-13T02:26:58Z","title":"Is it the model or the metric -- On robustness measures of deeplearning\n  models","summary":"  Determining the robustness of deep learning models is an established and\nongoing challenge within automated decision-making systems. With the advent and\nsuccess of techniques that enable advanced deep learning (DL), these models are\nbeing used in widespread applications, including high-stake ones like\nhealthcare, education, border-control. Therefore, it is critical to understand\nthe limitations of these models and predict their regions of failures, in order\nto create the necessary guardrails for their successful and safe deployment. In\nthis work, we revisit robustness, specifically investigating the sufficiency of\nrobust accuracy (RA), within the context of deepfake detection. We present\nrobust ratio (RR) as a complementary metric, that can quantify the changes to\nthe normalized or probability outcomes under input perturbation. We present a\ncomparison of RA and RR and demonstrate that despite similar RA between models,\nthe models show varying RR under different tolerance (perturbation) levels.\n","authors":["Zhijin Lyu","Yutong Jin","Sneha Das"],"pdf_url":"https://arxiv.org/pdf/2412.09795v1.pdf","comment":"Extended abstract at Northern Lights Deep Learning (NLDL) Conference\n  2025"},{"id":"http://arxiv.org/abs/2412.08128v2","updated":"2024-12-13T02:12:40Z","published":"2024-12-11T06:31:06Z","title":"Why Does Dropping Edges Usually Outperform Adding Edges in Graph\n  Contrastive Learning?","summary":"  Graph contrastive learning (GCL) has been widely used as an effective\nself-supervised learning method for graph representation learning. However, how\nto apply adequate and stable graph augmentation to generating proper views for\ncontrastive learning remains an essential problem. Dropping edges is a primary\naugmentation in GCL while adding edges is not a common method due to its\nunstable performance. To our best knowledge, there is no theoretical analysis\nto study why dropping edges usually outperforms adding edges. To answer this\nquestion, we introduce a new metric, namely Error Passing Rate (EPR), to\nquantify how a graph fits the network. Inspired by the theoretical conclusions,\nwe propose a novel GCL algorithm, Error-PAssing-based Graph Contrastive\nLearning (EPAGCL), which uses both edge adding and edge dropping as its\naugmentation. To be specific, we generate views by adding and dropping edges\naccording to the weights derived from EPR. Extensive experiments on various\nreal-world datasets are conducted to validate the correctness of our\ntheoretical analysis and the effectiveness of our proposed algorithm.\n","authors":["Yanchen Xu","Siqi Huang","Hongyuan Zhang","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2412.08128v2.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2112.06657v3","updated":"2024-12-13T02:08:47Z","published":"2021-12-09T12:23:06Z","title":"You Can Wash Hands Better: Accurate Daily Handwashing Assessment with\n  Smartwatches","summary":"  Hand hygiene is among the most effective daily practices for preventing\ninfectious diseases such as influenza, malaria, and skin infections. While\nprofessional guidelines emphasize proper handwashing to reduce the risk of\nviral infections, surveys reveal that adherence to these recommendations\nremains low. To address this gap, we propose UWash, a wearable solution\nleveraging smartwatches to evaluate handwashing procedures, aiming to raise\nawareness and cultivate high-quality handwashing habits. We frame the task of\nhandwashing assessment as an action segmentation problem, similar to those in\ncomputer vision, and introduce a simple yet efficient two-stream UNet-like\nnetwork to achieve this goal. Experiments involving 51 subjects demonstrate\nthat UWash achieves 92.27% accuracy in handwashing gesture recognition, an\nerror of <0.5 seconds in onset/offset detection, and an error of <5 points in\ngesture scoring under user-dependent settings. The system also performs\nrobustly in user-independent and user-independent-location-independent\nevaluations. Remarkably, UWash maintains high performance in real-world tests,\nincluding evaluations with 10 random passersby at a hospital 9 months later and\n10 passersby in an in-the-wild test conducted 2 years later. UWash is the first\nsystem to score handwashing quality based on gesture sequences, offering\nactionable guidance for improving daily hand hygiene. The code and dataset are\npublicly available at \\url{https://github.com/aiotgroup/UWash}.\n","authors":["Fei Wang","Xilei Wu","Tingting Zhang","Xin Wang","Pengcheng Wang","Han Ding","Jingang Shi","Jinsong Han","Dong Huang"],"pdf_url":"https://arxiv.org/pdf/2112.06657v3.pdf","comment":"Under review. 13 pages, 12 figures, 7 tables"},{"id":"http://arxiv.org/abs/2410.04458v3","updated":"2024-12-13T01:58:52Z","published":"2024-10-06T12:15:00Z","title":"A Comprehensive Framework for Analyzing the Convergence of Adam:\n  Bridging the Gap with SGD","summary":"  Adaptive Moment Estimation (Adam) is a cornerstone optimization algorithm in\ndeep learning, widely recognized for its flexibility with adaptive learning\nrates and efficiency in handling large-scale data. However, despite its\npractical success, the theoretical understanding of Adam's convergence has been\nconstrained by stringent assumptions, such as almost surely bounded stochastic\ngradients or uniformly bounded gradients, which are more restrictive than those\ntypically required for analyzing stochastic gradient descent (SGD).\n  In this paper, we introduce a novel and comprehensive framework for analyzing\nthe convergence properties of Adam. This framework offers a versatile approach\nto establishing Adam's convergence. Specifically, we prove that Adam achieves\nasymptotic (last iterate sense) convergence in both the almost sure sense and\nthe \\(L_1\\) sense under the relaxed assumptions typically used for SGD, namely\n\\(L\\)-smoothness and the ABC inequality. Meanwhile, under the same assumptions,\nwe show that Adam attains non-asymptotic sample complexity bounds similar to\nthose of SGD.\n","authors":["Ruinan Jin","Xiao Li","Yaoliang Yu","Baoxiang Wang"],"pdf_url":"https://arxiv.org/pdf/2410.04458v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.04932v2","updated":"2024-12-13T01:46:46Z","published":"2023-04-11T02:09:13Z","title":"Robust Dequantization of the Quantum Singular value Transformation and\n  Quantum Machine Learning Algorithms","summary":"  Several quantum algorithms for linear algebra problems, and in particular\nquantum machine learning problems, have been \"dequantized\" in the past few\nyears. These dequantization results typically hold when classical algorithms\ncan access the data via length-squared sampling. In this work we investigate\nhow robust these dequantization results are. We introduce the notion of\napproximate length-squared sampling, where classical algorithms are only able\nto sample from a distribution close to the ideal distribution in total\nvariation distance. While quantum algorithms are natively robust against small\nperturbations, current techniques in dequantization are not. Our main technical\ncontribution is showing how many techniques from randomized linear algebra can\nbe adapted to work under this weaker assumption as well. We then use these\ntechniques to show that the recent low-rank dequantization framework by Chia,\nGily\\'en, Li, Lin, Tang and Wang (JACM 2022) and the dequantization framework\nfor sparse matrices by Gharibian and Le Gall (STOC 2022), which are both based\non the Quantum Singular Value Transformation, can be generalized to the case of\napproximate length-squared sampling access to the input. We also apply these\nresults to obtain a robust dequantization of many quantum machine learning\nalgorithms, including quantum algorithms for recommendation systems, supervised\nclustering and low-rank matrix inversion.\n","authors":["François Le Gall"],"pdf_url":"https://arxiv.org/pdf/2304.04932v2.pdf","comment":"56 pages; v2: minor changes (final journal version)"},{"id":"http://arxiv.org/abs/2412.09779v1","updated":"2024-12-13T01:15:17Z","published":"2024-12-13T01:15:17Z","title":"A Statistical Analysis for Supervised Deep Learning with Exponential\n  Families for Intrinsically Low-dimensional Data","summary":"  Recent advances have revealed that the rate of convergence of the expected\ntest error in deep supervised learning decays as a function of the intrinsic\ndimension and not the dimension $d$ of the input space. Existing literature\ndefines this intrinsic dimension as the Minkowski dimension or the manifold\ndimension of the support of the underlying probability measures, which often\nresults in sub-optimal rates and unrealistic assumptions. In this paper, we\nconsider supervised deep learning when the response given the explanatory\nvariable is distributed according to an exponential family with a\n$\\beta$-H\\\"older smooth mean function. We consider an entropic notion of the\nintrinsic data-dimension and demonstrate that with $n$ independent and\nidentically distributed samples, the test error scales as\n$\\tilde{\\mathcal{O}}\\left(n^{-\\frac{2\\beta}{2\\beta +\n\\bar{d}_{2\\beta}(\\lambda)}}\\right)$, where $\\bar{d}_{2\\beta}(\\lambda)$ is the\n$2\\beta$-entropic dimension of $\\lambda$, the distribution of the explanatory\nvariables. This improves on the best-known rates. Furthermore, under the\nassumption of an upper-bounded density of the explanatory variables, we\ncharacterize the rate of convergence as $\\tilde{\\mathcal{O}}\\left(\nd^{\\frac{2\\lfloor\\beta\\rfloor(\\beta + d)}{2\\beta + d}}n^{-\\frac{2\\beta}{2\\beta\n+ d}}\\right)$, establishing that the dependence on $d$ is not exponential but\nat most polynomial. We also demonstrate that when the explanatory variable has\na lower bounded density, this rate in terms of the number of data samples, is\nnearly optimal for learning the dependence structure for exponential families.\n","authors":["Saptarshi Chakraborty","Peter L. Bartlett"],"pdf_url":"https://arxiv.org/pdf/2412.09779v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14856v4","updated":"2024-12-13T00:46:38Z","published":"2024-06-21T04:02:19Z","title":"Accessible, At-Home Detection of Parkinson's Disease via Multi-task\n  Video Analysis","summary":"  Limited accessibility to neurological care leads to underdiagnosed\nParkinson's Disease (PD), preventing early intervention. Existing AI-based PD\ndetection methods primarily focus on unimodal analysis of motor or speech\ntasks, overlooking the multifaceted nature of the disease. To address this, we\nintroduce a large-scale, multi-task video dataset consisting of 1102 sessions\n(each containing videos of finger tapping, facial expression, and speech tasks\ncaptured via webcam) from 845 participants (272 with PD). We propose a novel\nUncertainty-calibrated Fusion Network (UFNet) that leverages this multimodal\ndata to enhance diagnostic accuracy. UFNet employs independent task-specific\nnetworks, trained with Monte Carlo Dropout for uncertainty quantification,\nfollowed by self-attended fusion of features, with attention weights\ndynamically adjusted based on task-specific uncertainties. To ensure\npatient-centered evaluation, the participants were randomly split into three\nsets: 60% for training, 20% for model selection, and 20% for final performance\nevaluation. UFNet significantly outperformed single-task models in terms of\naccuracy, area under the ROC curve (AUROC), and sensitivity while maintaining\nnon-inferior specificity. Withholding uncertain predictions further boosted the\nperformance, achieving 88.0+-0.3%$ accuracy, 93.0+-0.2% AUROC, 79.3+-0.9%\nsensitivity, and 92.6+-0.3% specificity, at the expense of not being able to\npredict for 2.3+-0.3% data (+- denotes 95% confidence interval). Further\nanalysis suggests that the trained model does not exhibit any detectable bias\nacross sex and ethnic subgroups and is most effective for individuals aged\nbetween 50 and 80. Requiring only a webcam and microphone, our approach\nfacilitates accessible home-based PD screening, especially in regions with\nlimited healthcare resources.\n","authors":["Md Saiful Islam","Tariq Adnan","Jan Freyberg","Sangwu Lee","Abdelrahman Abdelkader","Meghan Pawlik","Cathe Schwartz","Karen Jaffe","Ruth B. Schneider","E Ray Dorsey","Ehsan Hoque"],"pdf_url":"https://arxiv.org/pdf/2406.14856v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06291v3","updated":"2024-12-13T00:38:11Z","published":"2023-06-09T22:48:13Z","title":"Optimal Multitask Linear Regression and Contextual Bandits under Sparse\n  Heterogeneity","summary":"  Large and complex datasets are often collected from several, possibly\nheterogeneous sources. Multitask learning methods improve efficiency by\nleveraging commonalities across datasets while accounting for possible\ndifferences among them. Here, we study multitask linear regression and\ncontextual bandits under sparse heterogeneity, where the source/task-associated\nparameters are equal to a global parameter plus a sparse task-specific term. We\npropose a novel two-stage estimator called MOLAR that leverages this structure\nby first constructing a covariate-wise weighted median of the task-wise linear\nregression estimates and then shrinking the task-wise estimates towards the\nweighted median. Compared to task-wise least squares estimates, MOLAR improves\nthe dependence of the estimation error on the data dimension. Extensions of\nMOLAR to generalized linear models and constructing confidence intervals are\ndiscussed in the paper. We then apply MOLAR to develop methods for sparsely\nheterogeneous multitask contextual bandits, obtaining improved regret\nguarantees over single-task bandit methods. We further show that our methods\nare minimax optimal by providing a number of lower bounds. Finally, we support\nthe efficiency of our methods by performing experiments on both synthetic data\nand the PISA dataset on student educational outcomes from heterogeneous\ncountries.\n","authors":["Xinmeng Huang","Kan Xu","Donghwan Lee","Hamed Hassani","Hamsa Bastani","Edgar Dobriban"],"pdf_url":"https://arxiv.org/pdf/2306.06291v3.pdf","comment":"Journal of the American Statistical Association, 2024"},{"id":"http://arxiv.org/abs/2412.09769v1","updated":"2024-12-13T00:26:36Z","published":"2024-12-13T00:26:36Z","title":"A Novel Methodology in Credit Spread Prediction Based on Ensemble\n  Learning and Feature Selection","summary":"  The credit spread is a key indicator in bond investments, offering valuable\ninsights for fixed-income investors to devise effective trading strategies.\nThis study proposes a novel credit spread forecasting model leveraging ensemble\nlearning techniques. To enhance predictive accuracy, a feature selection method\nbased on mutual information is incorporated. Empirical results demonstrate that\nthe proposed methodology delivers superior accuracy in credit spread\npredictions. Additionally, we present a forecast of future credit spread trends\nusing current data, providing actionable insights for investment\ndecision-making.\n","authors":["Yu Shao","Jiawen Bai","Yingze Hou","Xia'an Zhou","Zhanhao Pan"],"pdf_url":"https://arxiv.org/pdf/2412.09769v1.pdf","comment":"7 pages, 5 figures"},{"id":"http://arxiv.org/abs/2410.10041v2","updated":"2024-12-13T00:23:09Z","published":"2024-10-13T23:05:37Z","title":"WormKAN: Are KAN Effective for Identifying and Tracking Concept Drift in\n  Time Series?","summary":"  Dynamic concepts in time series are crucial for understanding complex systems\nsuch as financial markets, healthcare, and online activity logs. These concepts\nhelp reveal structures and behaviors in sequential data for better\ndecision-making and forecasting. However, existing models often struggle to\ndetect and track concept drift due to limitations in interpretability and\nadaptability. To address this challenge, inspired by the flexibility of the\nrecent Kolmogorov-Arnold Network (KAN), we propose WormKAN, a concept-aware\nKAN-based model to address concept drift in co-evolving time series. WormKAN\nconsists of three key components: Patch Normalization, Temporal Representation\nModule, and Concept Dynamics. Patch normalization processes co-evolving time\nseries into patches, treating them as fundamental modeling units to capture\nlocal dependencies while ensuring consistent scaling. The temporal\nrepresentation module learns robust latent representations by leveraging a\nKAN-based autoencoder, complemented by a smoothness constraint, to uncover\ninter-patch correlations. Concept dynamics identifies and tracks dynamic\ntransitions, revealing structural shifts in the time series through concept\nidentification and drift detection. These transitions, akin to passing through\na \\textit{wormhole}, are identified by abrupt changes in the latent space.\nExperiments show that KAN and KAN-based models (WormKAN) effectively segment\ntime series into meaningful concepts, enhancing the identification and tracking\nof concept drift.\n","authors":["Kunpeng Xu","Lifei Chen","Shengrui Wang"],"pdf_url":"https://arxiv.org/pdf/2410.10041v2.pdf","comment":null}]," Artificial Intelligence":[{"id":"http://arxiv.org/abs/2412.10373v1","updated":"2024-12-13T18:59:54Z","published":"2024-12-13T18:59:54Z","title":"GaussianWorld: Gaussian World Model for Streaming 3D Occupancy\n  Prediction","summary":"  3D occupancy prediction is important for autonomous driving due to its\ncomprehensive perception of the surroundings. To incorporate sequential inputs,\nmost existing methods fuse representations from previous frames to infer the\ncurrent 3D occupancy. However, they fail to consider the continuity of driving\nscenarios and ignore the strong prior provided by the evolution of 3D scenes\n(e.g., only dynamic objects move). In this paper, we propose a\nworld-model-based framework to exploit the scene evolution for perception. We\nreformulate 3D occupancy prediction as a 4D occupancy forecasting problem\nconditioned on the current sensor input. We decompose the scene evolution into\nthree factors: 1) ego motion alignment of static scenes; 2) local movements of\ndynamic objects; and 3) completion of newly-observed scenes. We then employ a\nGaussian world model (GaussianWorld) to explicitly exploit these priors and\ninfer the scene evolution in the 3D Gaussian space considering the current RGB\nobservation. We evaluate the effectiveness of our framework on the widely used\nnuScenes dataset. Our GaussianWorld improves the performance of the\nsingle-frame counterpart by over 2% in mIoU without introducing additional\ncomputations. Code: https://github.com/zuosc19/GaussianWorld.\n","authors":["Sicheng Zuo","Wenzhao Zheng","Yuanhui Huang","Jie Zhou","Jiwen Lu"],"pdf_url":"https://arxiv.org/pdf/2412.10373v1.pdf","comment":"Code is available at: https://github.com/zuosc19/GaussianWorld"},{"id":"http://arxiv.org/abs/2412.10371v1","updated":"2024-12-13T18:59:30Z","published":"2024-12-13T18:59:30Z","title":"GaussianAD: Gaussian-Centric End-to-End Autonomous Driving","summary":"  Vision-based autonomous driving shows great potential due to its satisfactory\nperformance and low costs. Most existing methods adopt dense representations\n(e.g., bird's eye view) or sparse representations (e.g., instance boxes) for\ndecision-making, which suffer from the trade-off between comprehensiveness and\nefficiency. This paper explores a Gaussian-centric end-to-end autonomous\ndriving (GaussianAD) framework and exploits 3D semantic Gaussians to\nextensively yet sparsely describe the scene. We initialize the scene with\nuniform 3D Gaussians and use surrounding-view images to progressively refine\nthem to obtain the 3D Gaussian scene representation. We then use sparse\nconvolutions to efficiently perform 3D perception (e.g., 3D detection, semantic\nmap construction). We predict 3D flows for the Gaussians with dynamic semantics\nand plan the ego trajectory accordingly with an objective of future scene\nforecasting. Our GaussianAD can be trained in an end-to-end manner with\noptional perception labels when available. Extensive experiments on the widely\nused nuScenes dataset verify the effectiveness of our end-to-end GaussianAD on\nvarious tasks including motion planning, 3D occupancy prediction, and 4D\noccupancy forecasting. Code: https://github.com/wzzheng/GaussianAD.\n","authors":["Wenzhao Zheng","Junjie Wu","Yao Zheng","Sicheng Zuo","Zixun Xie","Longchao Yang","Yong Pan","Zhihui Hao","Peng Jia","Xianpeng Lang","Shanghang Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.10371v1.pdf","comment":"Code is available at: https://github.com/wzzheng/GaussianAD"},{"id":"http://arxiv.org/abs/2402.01886v2","updated":"2024-12-13T18:59:14Z","published":"2024-02-02T20:21:09Z","title":"Inverse Reinforcement Learning by Estimating Expertise of Demonstrators","summary":"  In Imitation Learning (IL), utilizing suboptimal and heterogeneous\ndemonstrations presents a substantial challenge due to the varied nature of\nreal-world data. However, standard IL algorithms consider these datasets as\nhomogeneous, thereby inheriting the deficiencies of suboptimal demonstrators.\nPrevious approaches to this issue rely on impractical assumptions like\nhigh-quality data subsets, confidence rankings, or explicit environmental\nknowledge. This paper introduces IRLEED, Inverse Reinforcement Learning by\nEstimating Expertise of Demonstrators, a novel framework that overcomes these\nhurdles without prior knowledge of demonstrator expertise. IRLEED enhances\nexisting Inverse Reinforcement Learning (IRL) algorithms by combining a general\nmodel for demonstrator suboptimality to address reward bias and action\nvariance, with a Maximum Entropy IRL framework to efficiently derive the\noptimal policy from diverse, suboptimal demonstrations. Experiments in both\nonline and offline IL settings, with simulated and human-generated data,\ndemonstrate IRLEED's adaptability and effectiveness, making it a versatile\nsolution for learning from suboptimal demonstrations.\n","authors":["Mark Beliaev","Ramtin Pedarsani"],"pdf_url":"https://arxiv.org/pdf/2402.01886v2.pdf","comment":"11 pages, 4 figures, extended version of AAAI publication"},{"id":"http://arxiv.org/abs/2412.10360v1","updated":"2024-12-13T18:53:24Z","published":"2024-12-13T18:53:24Z","title":"Apollo: An Exploration of Video Understanding in Large Multimodal Models","summary":"  Despite the rapid integration of video perception capabilities into Large\nMultimodal Models (LMMs), the underlying mechanisms driving their video\nunderstanding remain poorly understood. Consequently, many design decisions in\nthis domain are made without proper justification or analysis. The high\ncomputational cost of training and evaluating such models, coupled with limited\nopen research, hinders the development of video-LMMs. To address this, we\npresent a comprehensive study that helps uncover what effectively drives video\nunderstanding in LMMs.\n  We begin by critically examining the primary contributors to the high\ncomputational requirements associated with video-LMM research and discover\nScaling Consistency, wherein design and training decisions made on smaller\nmodels and datasets (up to a critical size) effectively transfer to larger\nmodels. Leveraging these insights, we explored many video-specific aspects of\nvideo-LMMs, including video sampling, architectures, data composition, training\nschedules, and more. For example, we demonstrated that fps sampling during\ntraining is vastly preferable to uniform frame sampling and which vision\nencoders are the best for video representation.\n  Guided by these findings, we introduce Apollo, a state-of-the-art family of\nLMMs that achieve superior performance across different model sizes. Our models\ncan perceive hour-long videos efficiently, with Apollo-3B outperforming most\nexisting $7$B models with an impressive 55.1 on LongVideoBench. Apollo-7B is\nstate-of-the-art compared to 7B LMMs with a 70.9 on MLVU, and 63.3 on\nVideo-MME.\n","authors":["Orr Zohar","Xiaohan Wang","Yann Dubois","Nikhil Mehta","Tong Xiao","Philippe Hansen-Estruch","Licheng Yu","Xiaofang Wang","Felix Juefei-Xu","Ning Zhang","Serena Yeung-Levy","Xide Xia"],"pdf_url":"https://arxiv.org/pdf/2412.10360v1.pdf","comment":"https://apollo-lmms.github.io"},{"id":"http://arxiv.org/abs/2412.10354v1","updated":"2024-12-13T18:49:37Z","published":"2024-12-13T18:49:37Z","title":"A Library for Learning Neural Operators","summary":"  We present NeuralOperator, an open-source Python library for operator\nlearning. Neural operators generalize neural networks to maps between function\nspaces instead of finite-dimensional Euclidean spaces. They can be trained and\ninferenced on input and output functions given at various discretizations,\nsatisfying a discretization convergence properties. Built on top of PyTorch,\nNeuralOperator provides all the tools for training and deploying neural\noperator models, as well as developing new ones, in a high-quality, tested,\nopen-source package. It combines cutting-edge models and customizability with a\ngentle learning curve and simple user interface for newcomers.\n","authors":["Jean Kossaifi","Nikola Kovachki","Zongyi Li","Davit Pitt","Miguel Liu-Schiaffini","Robert Joseph George","Boris Bonev","Kamyar Azizzadenesheli","Julius Berner","Anima Anandkumar"],"pdf_url":"https://arxiv.org/pdf/2412.10354v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10348v1","updated":"2024-12-13T18:45:18Z","published":"2024-12-13T18:45:18Z","title":"A dual contrastive framework","summary":"  In current multimodal tasks, models typically freeze the encoder and decoder\nwhile adapting intermediate layers to task-specific goals, such as region\ncaptioning. Region-level visual understanding presents significant challenges\nfor large-scale vision-language models. While limited spatial awareness is a\nknown issue, coarse-grained pretraining, in particular, exacerbates the\ndifficulty of optimizing latent representations for effective encoder-decoder\nalignment. We propose AlignCap, a framework designed to enhance region-level\nunderstanding through fine-grained alignment of latent spaces. Our approach\nintroduces a novel latent feature refinement module that enhances conditioned\nlatent space representations to improve region-level captioning performance. We\nalso propose an innovative alignment strategy, the semantic space alignment\nmodule, which boosts the quality of multimodal representations. Additionally,\nwe incorporate contrastive learning in a novel manner within both modules to\nfurther enhance region-level captioning performance. To address spatial\nlimitations, we employ a General Object Detection (GOD) method as a data\npreprocessing pipeline that enhances spatial reasoning at the regional level.\nExtensive experiments demonstrate that our approach significantly improves\nregion-level captioning performance across various tasks\n","authors":["Yuan Sun","Zhao Zhang","Jorge Ortiz"],"pdf_url":"https://arxiv.org/pdf/2412.10348v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10347v1","updated":"2024-12-13T18:42:00Z","published":"2024-12-13T18:42:00Z","title":"COMET: Benchmark for Comprehensive Biological Multi-omics Evaluation\n  Tasks and Language Models","summary":"  As key elements within the central dogma, DNA, RNA, and proteins play crucial\nroles in maintaining life by guaranteeing accurate genetic expression and\nimplementation. Although research on these molecules has profoundly impacted\nfields like medicine, agriculture, and industry, the diversity of machine\nlearning approaches-from traditional statistical methods to deep learning\nmodels and large language models-poses challenges for researchers in choosing\nthe most suitable models for specific tasks, especially for cross-omics and\nmulti-omics tasks due to the lack of comprehensive benchmarks. To address this,\nwe introduce the first comprehensive multi-omics benchmark COMET (Benchmark for\nBiological COmprehensive Multi-omics Evaluation Tasks and Language Models),\ndesigned to evaluate models across single-omics, cross-omics, and multi-omics\ntasks. First, we curate and develop a diverse collection of downstream tasks\nand datasets covering key structural and functional aspects in DNA, RNA, and\nproteins, including tasks that span multiple omics levels. Then, we evaluate\nexisting foundational language models for DNA, RNA, and proteins, as well as\nthe newly proposed multi-omics method, offering valuable insights into their\nperformance in integrating and analyzing data from different biological\nmodalities. This benchmark aims to define critical issues in multi-omics\nresearch and guide future directions, ultimately promoting advancements in\nunderstanding biological processes through integrated and different omics data\nanalysis.\n","authors":["Yuchen Ren","Wenwei Han","Qianyuan Zhang","Yining Tang","Weiqiang Bai","Yuchen Cai","Lifeng Qiao","Hao Jiang","Dong Yuan","Tao Chen","Siqi Sun","Pan Tan","Wanli Ouyang","Nanqing Dong","Xinzhu Ma","Peng Ye"],"pdf_url":"https://arxiv.org/pdf/2412.10347v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10345v1","updated":"2024-12-13T18:40:51Z","published":"2024-12-13T18:40:51Z","title":"TraceVLA: Visual Trace Prompting Enhances Spatial-Temporal Awareness for\n  Generalist Robotic Policies","summary":"  Although large vision-language-action (VLA) models pretrained on extensive\nrobot datasets offer promising generalist policies for robotic learning, they\nstill struggle with spatial-temporal dynamics in interactive robotics, making\nthem less effective in handling complex tasks, such as manipulation. In this\nwork, we introduce visual trace prompting, a simple yet effective approach to\nfacilitate VLA models' spatial-temporal awareness for action prediction by\nencoding state-action trajectories visually. We develop a new TraceVLA model by\nfinetuning OpenVLA on our own collected dataset of 150K robot manipulation\ntrajectories using visual trace prompting. Evaluations of TraceVLA across 137\nconfigurations in SimplerEnv and 4 tasks on a physical WidowX robot demonstrate\nstate-of-the-art performance, outperforming OpenVLA by 10% on SimplerEnv and\n3.5x on real-robot tasks and exhibiting robust generalization across diverse\nembodiments and scenarios. To further validate the effectiveness and generality\nof our method, we present a compact VLA model based on 4B Phi-3-Vision,\npretrained on the Open-X-Embodiment and finetuned on our dataset, rivals the 7B\nOpenVLA baseline while significantly improving inference efficiency.\n","authors":["Ruijie Zheng","Yongyuan Liang","Shuaiyi Huang","Jianfeng Gao","Hal Daumé III","Andrey Kolobov","Furong Huang","Jianwei Yang"],"pdf_url":"https://arxiv.org/pdf/2412.10345v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10342v1","updated":"2024-12-13T18:40:10Z","published":"2024-12-13T18:40:10Z","title":"Iris: Breaking GUI Complexity with Adaptive Focus and Self-Refining","summary":"  Digital agents are increasingly employed to automate tasks in interactive\ndigital environments such as web pages, software applications, and operating\nsystems. While text-based agents built on Large Language Models (LLMs) often\nrequire frequent updates due to platform-specific APIs, visual agents\nleveraging Multimodal Large Language Models (MLLMs) offer enhanced adaptability\nby interacting directly with Graphical User Interfaces (GUIs). However, these\nagents face significant challenges in visual perception, particularly when\nhandling high-resolution, visually complex digital environments. This paper\nintroduces Iris, a foundational visual agent that addresses these challenges\nthrough two key innovations: Information-Sensitive Cropping (ISC) and\nSelf-Refining Dual Learning (SRDL). ISC dynamically identifies and prioritizes\nvisually dense regions using a edge detection algorithm, enabling efficient\nprocessing by allocating more computational resources to areas with higher\ninformation density. SRDL enhances the agent's ability to handle complex tasks\nby leveraging a dual-learning loop, where improvements in referring (describing\nUI elements) reinforce grounding (locating elements) and vice versa, all\nwithout requiring additional annotated data. Empirical evaluations demonstrate\nthat Iris achieves state-of-the-art performance across multiple benchmarks with\nonly 850K GUI annotations, outperforming methods using 10x more training data.\nThese improvements further translate to significant gains in both web and OS\nagent downstream tasks.\n","authors":["Zhiqi Ge","Juncheng Li","Xinglei Pang","Minghe Gao","Kaihang Pan","Wang Lin","Hao Fei","Wenqiao Zhang","Siliang Tang","Yueting Zhuang"],"pdf_url":"https://arxiv.org/pdf/2412.10342v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10337v1","updated":"2024-12-13T18:32:21Z","published":"2024-12-13T18:32:21Z","title":"Generative AI in Medicine","summary":"  The increased capabilities of generative AI have dramatically expanded its\npossible use cases in medicine. We provide a comprehensive overview of\ngenerative AI use cases for clinicians, patients, clinical trial organizers,\nresearchers, and trainees. We then discuss the many challenges -- including\nmaintaining privacy and security, improving transparency and interpretability,\nupholding equity, and rigorously evaluating models -- which must be overcome to\nrealize this potential, and the open research directions they give rise to.\n","authors":["Divya Shanmugam","Monica Agrawal","Rajiv Movva","Irene Y. Chen","Marzyeh Ghassemi","Emma Pierson"],"pdf_url":"https://arxiv.org/pdf/2412.10337v1.pdf","comment":"To appear in the Annual Review of Biomedical Data Science, August\n  2025"},{"id":"http://arxiv.org/abs/2412.10321v1","updated":"2024-12-13T18:00:57Z","published":"2024-12-13T18:00:57Z","title":"AdvPrefix: An Objective for Nuanced LLM Jailbreaks","summary":"  Many jailbreak attacks on large language models (LLMs) rely on a common\nobjective: making the model respond with the prefix \"Sure, here is (harmful\nrequest)\". While straightforward, this objective has two limitations: limited\ncontrol over model behaviors, often resulting in incomplete or unrealistic\nresponses, and a rigid format that hinders optimization. To address these\nlimitations, we introduce AdvPrefix, a new prefix-forcing objective that\nenables more nuanced control over model behavior while being easy to optimize.\nOur objective leverages model-dependent prefixes, automatically selected based\non two criteria: high prefilling attack success rates and low negative\nlog-likelihood. It can further simplify optimization by using multiple prefixes\nfor a single user request. AdvPrefix can integrate seamlessly into existing\njailbreak attacks to improve their performance for free. For example, simply\nreplacing GCG attack's target prefixes with ours on Llama-3 improves nuanced\nattack success rates from 14% to 80%, suggesting that current alignment\nstruggles to generalize to unseen prefixes. Our work demonstrates the\nimportance of jailbreak objectives in achieving nuanced jailbreaks.\n","authors":["Sicheng Zhu","Brandon Amos","Yuandong Tian","Chuan Guo","Ivan Evtimov"],"pdf_url":"https://arxiv.org/pdf/2412.10321v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10320v1","updated":"2024-12-13T18:00:21Z","published":"2024-12-13T18:00:21Z","title":"MeshA*: Efficient Path Planing With Motion Primitives","summary":"  We study a path planning problem where the possible move actions are\nrepresented as a finite set of motion primitives aligned with the grid\nrepresentation of the environment. That is, each primitive corresponds to a\nshort kinodynamically-feasible motion of an agent and is represented as a\nsequence of the swept cells of a grid. Typically heuristic search, i.e. A*, is\nconducted over the lattice induced by these primitives (lattice-based planning)\nto find a path. However due to the large branching factor such search may be\ninefficient in practice. To this end we suggest a novel technique rooted in the\nidea of searching over the grid cells (as in vanilla A*) simultaneously fitting\nthe possible sequences of the motion primitives into these cells. The resultant\nalgorithm, MeshA*, provably preserves the guarantees on completeness and\noptimality, on the one hand, and is shown to notably outperform conventional\nlattice-based planning (x1.5 decrease in the runtime), on the other hand.\nMoreover, we suggest an additional pruning technique that additionally\ndecreases the search space of MeshA*. The resultant planner is combined with\nthe regular A* to retain completeness and is shown to further increase the\nsearch performance at the cost of negligible decrease of the solution quality.\n","authors":["Marat Agranovskiy","Konstantin Yakovlev"],"pdf_url":"https://arxiv.org/pdf/2412.10320v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10316v1","updated":"2024-12-13T17:58:06Z","published":"2024-12-13T17:58:06Z","title":"BrushEdit: All-In-One Image Inpainting and Editing","summary":"  Image editing has advanced significantly with the development of diffusion\nmodels using both inversion-based and instruction-based methods. However,\ncurrent inversion-based approaches struggle with big modifications (e.g.,\nadding or removing objects) due to the structured nature of inversion noise,\nwhich hinders substantial changes. Meanwhile, instruction-based methods often\nconstrain users to black-box operations, limiting direct interaction for\nspecifying editing regions and intensity. To address these limitations, we\npropose BrushEdit, a novel inpainting-based instruction-guided image editing\nparadigm, which leverages multimodal large language models (MLLMs) and image\ninpainting models to enable autonomous, user-friendly, and interactive\nfree-form instruction editing. Specifically, we devise a system enabling\nfree-form instruction editing by integrating MLLMs and a dual-branch image\ninpainting model in an agent-cooperative framework to perform editing category\nclassification, main object identification, mask acquisition, and editing area\ninpainting. Extensive experiments show that our framework effectively combines\nMLLMs and inpainting models, achieving superior performance across seven\nmetrics including mask region preservation and editing effect coherence.\n","authors":["Yaowei Li","Yuxuan Bian","Xuan Ju","Zhaoyang Zhang","Ying Shan","Qiang Xu"],"pdf_url":"https://arxiv.org/pdf/2412.10316v1.pdf","comment":"WebPage available at\n  https://liyaowei-stu.github.io/project/BrushEdit/"},{"id":"http://arxiv.org/abs/2411.02820v2","updated":"2024-12-13T17:53:25Z","published":"2024-11-05T05:41:41Z","title":"DroidSpeak: KV Cache Sharing for Efficient Multi-LLM Serving","summary":"  Large Language Models (LLMs) are increasingly employed in complex workflows,\nwhere different LLMs and fine-tuned variants collaboratively address complex\ntasks. However, these systems face significant inefficiencies due to redundant\ncontext processing of the shared context. We propose DroidSpeak, a framework\nthat optimizes context sharing between fine-tuned LLMs derived from the same\nfoundational model. DroidSpeak identifies critical layers in the KV cache and\nselectively recomputes them, enabling effective reuse of intermediate data\nwhile maintaining high accuracy.\n  Our approach balances computational efficiency and task fidelity,\nsignificantly reducing inference latency and throughput bottlenecks.\nExperiments on diverse datasets and model pairs demonstrate that DroidSpeak\nachieves up to 3x higher throughputs and 2.6x faster prefill times with\nnegligible accuracy loss compared to full recomputation.\n","authors":["Yuhan Liu","Yuyang Huang","Jiayi Yao","Zhuohan Gu","Kuntai Du","Hanchen Li","Yihua Cheng","Junchen Jiang","Shan Lu","Madan Musuvathi","Esha Choukse"],"pdf_url":"https://arxiv.org/pdf/2411.02820v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10312v1","updated":"2024-12-13T17:52:48Z","published":"2024-12-13T17:52:48Z","title":"Interlocking-free Selective Rationalization Through Genetic-based\n  Learning","summary":"  A popular end-to-end architecture for selective rationalization is the\nselect-then-predict pipeline, comprising a generator to extract highlights fed\nto a predictor. Such a cooperative system suffers from suboptimal equilibrium\nminima due to the dominance of one of the two modules, a phenomenon known as\ninterlocking. While several contributions aimed at addressing interlocking,\nthey only mitigate its effect, often by introducing feature-based heuristics,\nsampling, and ad-hoc regularizations. We present GenSPP, the first\ninterlocking-free architecture for selective rationalization that does not\nrequire any learning overhead, as the above-mentioned. GenSPP avoids\ninterlocking by performing disjoint training of the generator and predictor via\ngenetic global search. Experiments on a synthetic and a real-world benchmark\nshow that our model outperforms several state-of-the-art competitors.\n","authors":["Federico Ruggeri","Gaetano Signorelli"],"pdf_url":"https://arxiv.org/pdf/2412.10312v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10302v1","updated":"2024-12-13T17:37:48Z","published":"2024-12-13T17:37:48Z","title":"DeepSeek-VL2: Mixture-of-Experts Vision-Language Models for Advanced\n  Multimodal Understanding","summary":"  We present DeepSeek-VL2, an advanced series of large Mixture-of-Experts (MoE)\nVision-Language Models that significantly improves upon its predecessor,\nDeepSeek-VL, through two key major upgrades. For the vision component, we\nincorporate a dynamic tiling vision encoding strategy designed for processing\nhigh-resolution images with different aspect ratios. For the language\ncomponent, we leverage DeepSeekMoE models with the Multi-head Latent Attention\nmechanism, which compresses Key-Value cache into latent vectors, to enable\nefficient inference and high throughput. Trained on an improved vision-language\ndataset, DeepSeek-VL2 demonstrates superior capabilities across various tasks,\nincluding but not limited to visual question answering, optical character\nrecognition, document/table/chart understanding, and visual grounding. Our\nmodel series is composed of three variants: DeepSeek-VL2-Tiny,\nDeepSeek-VL2-Small and DeepSeek-VL2, with 1.0B, 2.8B and 4.5B activated\nparameters respectively. DeepSeek-VL2 achieves competitive or state-of-the-art\nperformance with similar or fewer activated parameters compared to existing\nopen-source dense and MoE-based models. Codes and pre-trained models are\npublicly accessible at https://github.com/deepseek-ai/DeepSeek-VL2.\n","authors":["Zhiyu Wu","Xiaokang Chen","Zizheng Pan","Xingchao Liu","Wen Liu","Damai Dai","Huazuo Gao","Yiyang Ma","Chengyue Wu","Bingxuan Wang","Zhenda Xie","Yu Wu","Kai Hu","Jiawei Wang","Yaofeng Sun","Yukun Li","Yishi Piao","Kang Guan","Aixin Liu","Xin Xie","Yuxiang You","Kai Dong","Xingkai Yu","Haowei Zhang","Liang Zhao","Yisong Wang","Chong Ruan"],"pdf_url":"https://arxiv.org/pdf/2412.10302v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10291v1","updated":"2024-12-13T17:21:29Z","published":"2024-12-13T17:21:29Z","title":"Still \"Talking About Large Language Models\": Some Clarifications","summary":"  My paper \"Talking About Large Language Models\" has more than once been\ninterpreted as advocating a reductionist stance towards large language models.\nBut the paper was not intended that way, and I do not endorse such positions.\nThis short note situates the paper in the context of a larger philosophical\nproject that is concerned with the (mis)use of words rather than metaphysics,\nin the spirit of Wittgenstein's later writing.\n","authors":["Murray Shanahan"],"pdf_url":"https://arxiv.org/pdf/2412.10291v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10278v1","updated":"2024-12-13T17:00:31Z","published":"2024-12-13T17:00:31Z","title":"Envisioning National Resources for Artificial Intelligence Research: NSF\n  Workshop Report","summary":"  This is a report of an NSF workshop titled \"Envisioning National Resources\nfor Artificial Intelligence Research\" held in Alexandria, Virginia, in May\n2024. The workshop aimed to identify initial challenges and opportunities for\nnational resources for AI research (e.g., compute, data, models, etc.) and to\nfacilitate planning for the envisioned National AI Research Resource.\nParticipants included AI and cyberinfrastructure (CI) experts. The report\noutlines significant findings and identifies needs and recommendations from the\nworkshop.\n","authors":["Shantenu Jha","Yolanda Gil"],"pdf_url":"https://arxiv.org/pdf/2412.10278v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.04482v2","updated":"2024-12-13T16:56:21Z","published":"2024-11-20T15:44:58Z","title":"NLP Cluster Analysis of Common Core State Standards and NAEP Item\n  Specifications","summary":"  Camilli (2024) proposed a methodology using natural language processing (NLP)\nto map the relationship of a set of content standards to item specifications.\nThis study provided evidence that NLP can be used to improve the mapping\nprocess. As part of this investigation, the nominal classifications of\nstandards and items specifications were used to examine construct equivalence.\nIn the current paper, we determine the strength of empirical support for the\nsemantic distinctiveness of these classifications, which are known as \"domains\"\nfor Common Core standards, and \"strands\" for National Assessment of Educational\nProgress (NAEP) item specifications. This is accomplished by separate k-means\nclustering for standards and specifications of their corresponding embedding\nvectors. We then briefly illustrate an application of these findings.\n","authors":["Gregory Camilli","Larry Suter"],"pdf_url":"https://arxiv.org/pdf/2412.04482v2.pdf","comment":"10 pages, 5 tables"},{"id":"http://arxiv.org/abs/2412.10272v1","updated":"2024-12-13T16:46:13Z","published":"2024-12-13T16:46:13Z","title":"Trustworthy and Explainable Decision-Making for Workforce allocation","summary":"  In industrial contexts, effective workforce allocation is crucial for\noperational efficiency. This paper presents an ongoing project focused on\ndeveloping a decision-making tool designed for workforce allocation,\nemphasising the explainability to enhance its trustworthiness. Our objective is\nto create a system that not only optimises the allocation of teams to scheduled\ntasks but also provides clear, understandable explanations for its decisions,\nparticularly in cases where the problem is infeasible. By incorporating\nhuman-in-the-loop mechanisms, the tool aims to enhance user trust and\nfacilitate interactive conflict resolution. We implemented our approach on a\nprototype tool/digital demonstrator intended to be evaluated on a real\nindustrial scenario both in terms of performance and user acceptability.\n","authors":["Guillaume Povéda","Ryma Boumazouza","Andreas Strahl","Mark Hall","Santiago Quintana-Amate","Nahum Alvarez","Ignace Bleukx","Dimos Tsouros","Hélène Verhaeghe","Tias Guns"],"pdf_url":"https://arxiv.org/pdf/2412.10272v1.pdf","comment":"Accepted for presentation at PTHG-24: The Seventh Workshop on\n  Progress Towards the Holy Grail, part of the 30th International Conference on\n  Principles and Practice of Constraint Programming. For more details, visit\n  the workshop webpage:\n  https://freuder.wordpress.com/progress-towards-the-holy-grail-workshops/pthg-24-the-seventh-workshop-on-progress-towards-the-holy-grail/"},{"id":"http://arxiv.org/abs/2412.10270v1","updated":"2024-12-13T16:45:49Z","published":"2024-12-13T16:45:49Z","title":"Cultural Evolution of Cooperation among LLM Agents","summary":"  Large language models (LLMs) provide a compelling foundation for building\ngenerally-capable AI agents. These agents may soon be deployed at scale in the\nreal world, representing the interests of individual humans (e.g., AI\nassistants) or groups of humans (e.g., AI-accelerated corporations). At\npresent, relatively little is known about the dynamics of multiple LLM agents\ninteracting over many generations of iterative deployment. In this paper, we\nexamine whether a \"society\" of LLM agents can learn mutually beneficial social\nnorms in the face of incentives to defect, a distinctive feature of human\nsociality that is arguably crucial to the success of civilization. In\nparticular, we study the evolution of indirect reciprocity across generations\nof LLM agents playing a classic iterated Donor Game in which agents can observe\nthe recent behavior of their peers. We find that the evolution of cooperation\ndiffers markedly across base models, with societies of Claude 3.5 Sonnet agents\nachieving significantly higher average scores than Gemini 1.5 Flash, which, in\nturn, outperforms GPT-4o. Further, Claude 3.5 Sonnet can make use of an\nadditional mechanism for costly punishment to achieve yet higher scores, while\nGemini 1.5 Flash and GPT-4o fail to do so. For each model class, we also\nobserve variation in emergent behavior across random seeds, suggesting an\nunderstudied sensitive dependence on initial conditions. We suggest that our\nevaluation regime could inspire an inexpensive and informative new class of LLM\nbenchmarks, focussed on the implications of LLM agent deployment for the\ncooperative infrastructure of society.\n","authors":["Aron Vallinder","Edward Hughes"],"pdf_url":"https://arxiv.org/pdf/2412.10270v1.pdf","comment":"15 pages, 6 figures"},{"id":"http://arxiv.org/abs/2412.10267v1","updated":"2024-12-13T16:37:20Z","published":"2024-12-13T16:37:20Z","title":"Does Multiple Choice Have a Future in the Age of Generative AI? A\n  Posttest-only RCT","summary":"  The role of multiple-choice questions (MCQs) as effective learning tools has\nbeen debated in past research. While MCQs are widely used due to their ease in\ngrading, open response questions are increasingly used for instruction, given\nadvances in large language models (LLMs) for automated grading. This study\nevaluates MCQs effectiveness relative to open-response questions, both\nindividually and in combination, on learning. These activities are embedded\nwithin six tutor lessons on advocacy. Using a posttest-only randomized control\ndesign, we compare the performance of 234 tutors (790 lesson completions)\nacross three conditions: MCQ only, open response only, and a combination of\nboth. We find no significant learning differences across conditions at\nposttest, but tutors in the MCQ condition took significantly less time to\ncomplete instruction. These findings suggest that MCQs are as effective, and\nmore efficient, than open response tasks for learning when practice time is\nlimited. To further enhance efficiency, we autograded open responses using\nGPT-4o and GPT-4-turbo. GPT models demonstrate proficiency for purposes of\nlow-stakes assessment, though further research is needed for broader use. This\nstudy contributes a dataset of lesson log data, human annotation rubrics, and\nLLM prompts to promote transparency and reproducibility.\n","authors":["Danielle R. Thomas","Conrad Borchers","Sanjit Kakarla","Jionghao Lin","Shambhavi Bhushan","Boyuan Guo","Erin Gatz","Kenneth R. Koedinger"],"pdf_url":"https://arxiv.org/pdf/2412.10267v1.pdf","comment":"Full research paper accepted to Learning Analytics and Knowledge (LAK\n  2025)"},{"id":"http://arxiv.org/abs/2412.10257v1","updated":"2024-12-13T16:26:34Z","published":"2024-12-13T16:26:34Z","title":"Targeted Angular Reversal of Weights (TARS) for Knowledge Removal in\n  Large Language Models","summary":"  The sheer scale of data required to train modern large language models (LLMs)\nposes significant risks, as models are likely to gain knowledge of sensitive\ntopics such as bio-security, as well the ability to replicate copyrighted\nworks. Methods designed to remove such knowledge must do so from all prompt\ndirections, in a multi-lingual capacity and without degrading general model\nperformance. To this end, we introduce the targeted angular reversal (TARS)\nmethod of knowledge removal from LLMs. The TARS method firstly leverages the\nLLM in combination with a detailed prompt to aggregate information about a\nselected concept in the internal representation space of the LLM. It then\nrefines this approximate concept vector to trigger the concept token with high\nprobability, by perturbing the approximate concept vector with noise and\ntransforming it into token scores with the language model head. The feedforward\nweight vectors in the LLM which operate directly on the internal representation\nspace, and have the highest cosine similarity with this targeting vector, are\nthen replaced by a reversed targeting vector, thus limiting the ability of the\nconcept to propagate through the model. The modularity of the TARS method\nallows for a sequential removal of concepts from Llama 3.1 8B, such as the\nfamous literary detective Sherlock Holmes, and the planet Saturn. It is\ndemonstrated that the probability of triggering target concepts can be reduced\nto 0.00 with as few as 1 TARS edit, whilst simultaneously removing the\nknowledge bi-directionally. Moreover, knowledge is shown to be removed across\nall languages despite only being targeted in English. Importantly, TARS has\nminimal impact on the general model capabilities, as after removing 5 diverse\nconcepts in a modular fashion, there is minimal KL divergence in the next token\nprobabilities of the LLM on large corpora of Wikipedia text (median of 0.002).\n","authors":["Harry J. Davies","Giorgos Iacovides","Danilo P. Mandic"],"pdf_url":"https://arxiv.org/pdf/2412.10257v1.pdf","comment":"14 pages, 5 figures, 1 table"},{"id":"http://arxiv.org/abs/2412.10255v1","updated":"2024-12-13T16:24:58Z","published":"2024-12-13T16:24:58Z","title":"Exploring the Frontiers of Animation Video Generation in the Sora Era:\n  Method, Dataset and Benchmark","summary":"  Animation has gained significant interest in the recent film and TV industry.\nDespite the success of advanced video generation models like Sora, Kling, and\nCogVideoX in generating natural videos, they lack the same effectiveness in\nhandling animation videos. Evaluating animation video generation is also a\ngreat challenge due to its unique artist styles, violating the laws of physics\nand exaggerated motions. In this paper, we present a comprehensive system,\nAniSora, designed for animation video generation, which includes a data\nprocessing pipeline, a controllable generation model, and an evaluation\ndataset. Supported by the data processing pipeline with over 10M high-quality\ndata, the generation model incorporates a spatiotemporal mask module to\nfacilitate key animation production functions such as image-to-video\ngeneration, frame interpolation, and localized image-guided animation. We also\ncollect an evaluation benchmark of 948 various animation videos, the evaluation\non VBench and human double-blind test demonstrates consistency in character and\nmotion, achieving state-of-the-art results in animation video generation. %We\nalso collect an evaluation benchmark of 948 various animation videos, with\nspecifically developed metrics for animation video generation. Our model access\nAPI and evaluation benchmark will be publicly available.\n","authors":["Yudong Jiang","Baohan Xu","Siqian Yang","Mingyu Yin","Jing Liu","Chao Xu","Siqi Wang","Yidi Wu","Bingwen Zhu","Jixuan Xu","Yue Zhang","Jinlong Hou","Huyang Sun"],"pdf_url":"https://arxiv.org/pdf/2412.10255v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10237v1","updated":"2024-12-13T16:08:28Z","published":"2024-12-13T16:08:28Z","title":"Physics Instrument Design with Reinforcement Learning","summary":"  We present a case for the use of Reinforcement Learning (RL) for the design\nof physics instrument as an alternative to gradient-based\ninstrument-optimization methods. It's applicability is demonstrated using two\nempirical studies. One is longitudinal segmentation of calorimeters and the\nsecond is both transverse segmentation as well longitudinal placement of\ntrackers in a spectrometer. Based on these experiments, we propose an\nalternative approach that offers unique advantages over differentiable\nprogramming and surrogate-based differentiable design optimization methods.\nFirst, Reinforcement Learning (RL) algorithms possess inherent exploratory\ncapabilities, which help mitigate the risk of convergence to local optima.\nSecond, this approach eliminates the necessity of constraining the design to a\npredefined detector model with fixed parameters. Instead, it allows for the\nflexible placement of a variable number of detector components and facilitates\ndiscrete decision-making. We then discuss the road map of how this idea can be\nextended into designing very complex instruments. The presented study sets the\nstage for a novel framework in physics instrument design, offering a scalable\nand efficient framework that can be pivotal for future projects such as the\nFuture Circular Collider (FCC), where most optimized detectors are essential\nfor exploring physics at unprecedented energy scales.\n","authors":["Shah Rukh Qasim","Patrick Owen","Nicola Serra"],"pdf_url":"https://arxiv.org/pdf/2412.10237v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.22130v2","updated":"2024-12-13T16:05:14Z","published":"2024-10-29T15:28:40Z","title":"Solving Epistemic Logic Programs using Generate-and-Test with\n  Propagation","summary":"  This paper introduces a general framework for generate-and-test-based solvers\nfor epistemic logic programs that can be instantiated with different generator\nand tester programs, and we prove sufficient conditions on those programs for\nthe correctness of the solvers built using this framework. It also introduces a\nnew generator program that incorporates the propagation of epistemic\nconsequences and shows that this can exponentially reduce the number of\ncandidates that need to be tested while only incurring a linear overhead. We\nimplement a new solver based on these theoretical findings and experimentally\nshow that it outperforms existing solvers by achieving a ~3.3x speed-up and\nsolving 91% more instances on well-known benchmarks.\n","authors":["Jorge Fandinno","Lute Lillo"],"pdf_url":"https://arxiv.org/pdf/2410.22130v2.pdf","comment":"Accepted for publication in the Proceedings of the 39th Annual AAAI\n  Conference on Artificial Intelligence"},{"id":"http://arxiv.org/abs/2412.10220v1","updated":"2024-12-13T15:45:45Z","published":"2024-12-13T15:45:45Z","title":"How good is my story? Towards quantitative metrics for evaluating\n  LLM-generated XAI narratives","summary":"  A rapidly developing application of LLMs in XAI is to convert quantitative\nexplanations such as SHAP into user-friendly narratives to explain the\ndecisions made by smaller prediction models. Evaluating the narratives without\nrelying on human preference studies or surveys is becoming increasingly\nimportant in this field. In this work we propose a framework and explore\nseveral automated metrics to evaluate LLM-generated narratives for explanations\nof tabular classification tasks. We apply our approach to compare several\nstate-of-the-art LLMs across different datasets and prompt types. As a\ndemonstration of their utility, these metrics allow us to identify new\nchallenges related to LLM hallucinations for XAI narratives.\n","authors":["Timour Ichmoukhamedov","James Hinns","David Martens"],"pdf_url":"https://arxiv.org/pdf/2412.10220v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.12741v3","updated":"2024-12-13T15:37:01Z","published":"2024-09-19T13:03:24Z","title":"Fine Tuning Large Language Models for Medicine: The Role and Importance\n  of Direct Preference Optimization","summary":"  Large Language Model (LLM) fine tuning is underutilized in the field of\nmedicine. Two of the most common methods of fine tuning are Supervised Fine\nTuning (SFT) and Direct Preference Optimization (DPO), but there is little\nguidance informing users when to use either technique. In this investigation,\nwe compare the performance of SFT and DPO for five common natural language\ntasks in medicine: Classification with text data, Classification with numeric\ndata, Clinical Reasoning, Summarization, and Clinical Triage. We find that SFT\nalone is sufficient for Classification with text data, whereas DPO improves\nperformance for the more complex tasks of Clinical Reasoning, Summarization and\nClinical Triage. Our results establish the role and importance of DPO fine\ntuning within medicine, and consequently call attention to current software\ngaps that prevent widespread deployment of this technique.\n","authors":["Thomas Savage","Stephen Ma","Abdessalem Boukil","Vishwesh Patel","Ekanath Rangan","Ivan Lopez","Jonathan H Chen"],"pdf_url":"https://arxiv.org/pdf/2409.12741v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10209v1","updated":"2024-12-13T15:31:22Z","published":"2024-12-13T15:31:22Z","title":"GAF: Gaussian Avatar Reconstruction from Monocular Videos via Multi-view\n  Diffusion","summary":"  We propose a novel approach for reconstructing animatable 3D Gaussian avatars\nfrom monocular videos captured by commodity devices like smartphones.\nPhotorealistic 3D head avatar reconstruction from such recordings is\nchallenging due to limited observations, which leaves unobserved regions\nunder-constrained and can lead to artifacts in novel views. To address this\nproblem, we introduce a multi-view head diffusion model, leveraging its priors\nto fill in missing regions and ensure view consistency in Gaussian splatting\nrenderings. To enable precise viewpoint control, we use normal maps rendered\nfrom FLAME-based head reconstruction, which provides pixel-aligned inductive\nbiases. We also condition the diffusion model on VAE features extracted from\nthe input image to preserve details of facial identity and appearance. For\nGaussian avatar reconstruction, we distill multi-view diffusion priors by using\niteratively denoised images as pseudo-ground truths, effectively mitigating\nover-saturation issues. To further improve photorealism, we apply latent\nupsampling to refine the denoised latent before decoding it into an image. We\nevaluate our method on the NeRSemble dataset, showing that GAF outperforms the\nprevious state-of-the-art methods in novel view synthesis by a 5.34\\% higher\nSSIM score. Furthermore, we demonstrate higher-fidelity avatar reconstructions\nfrom monocular videos captured on commodity devices.\n","authors":["Jiapeng Tang","Davide Davoli","Tobias Kirschstein","Liam Schoneveld","Matthias Niessner"],"pdf_url":"https://arxiv.org/pdf/2412.10209v1.pdf","comment":"Paper Video: https://youtu.be/QuIYTljvhyg Project Page:\n  https://tangjiapeng.github.io/projects/GAF"},{"id":"http://arxiv.org/abs/2411.10197v2","updated":"2024-12-13T15:22:39Z","published":"2024-11-15T13:53:05Z","title":"A logic for reasoning with inconsistent knowledge -- A reformulation\n  using nowadays terminology (2024)","summary":"  In many situations humans have to reason with inconsistent knowledge. These\ninconsistencies may occur due to not fully reliable sources of information. In\norder to reason with inconsistent knowledge, it is not possible to view a set\nof premisses as absolute truths as is done in predicate logic. Viewing the set\nof premisses as a set of assumptions, however, it is possible to deduce useful\nconclusions from an inconsistent set of premisses. In this paper a logic for\nreasoning with inconsistent knowledge is described. This logic is a\ngeneralization of the work of N. Rescher [15]. In the logic a reliability\nrelation is used to choose between incompatible assumptions. These choices are\nonly made when a contradiction is derived. As long as no contradiction is\nderived, the knowledge is assumed to be consistent. This makes it possible to\ndefine an argumentation-based deduction process for the logic. For the logic a\nsemantics based on the ideas of Y. Shoham [22, 23], is defined. It turns out\nthat the semantics for the logic is a preferential semantics according to the\ndefinition S. Kraus, D. Lehmann and M. Magidor [12]. Therefore the logic is a\nlogic of system P and possesses all the properties of an ideal non-monotonic\nlogic.\n","authors":["Nico Roos"],"pdf_url":"https://arxiv.org/pdf/2411.10197v2.pdf","comment":"The original version was published in the Artificial Intelligence\n  journal. This original version uses 'justifications' in the proof system,\n  which we would call nowadays 'arguments'. The current version presents the\n  same results but now using the terminology of an assumption-based\n  argumentation system"},{"id":"http://arxiv.org/abs/2406.18916v2","updated":"2024-12-13T15:15:46Z","published":"2024-06-27T06:13:05Z","title":"TrustUQA: A Trustful Framework for Unified Structured Data Question\n  Answering","summary":"  Natural language question answering (QA) over structured data sources such as\ntables and knowledge graphs have been widely investigated, especially with\nLarge Language Models (LLMs) in recent years. The main solutions include\nquestion to formal query parsing and retrieval-based answer generation.\nHowever, current methods of the former often suffer from weak generalization,\nfailing to dealing with multi-types of sources, while the later is limited in\ntrustfulness. In this paper, we propose TrustUQA, a trustful QA framework that\ncan simultaneously support multiple types of structured data in a unified way.\nTo this end, it adopts an LLM-friendly and unified knowledge representation\nmethod called Condition Graph(CG), and uses an LLM and demonstration-based\ntwo-level method for CG querying. For enhancement, it is also equipped with\ndynamic demonstration retrieval. We have evaluated TrustUQA with 5 benchmarks\ncovering 3 types of structured data. It outperforms 2 existing unified\nstructured data QA methods. In comparison with the baselines that are specific\nto one data type, it achieves state-of-the-art on 2 of the datasets. Further\nmore, we have demonstrated the potential of our method for more general QA\ntasks, QA over mixed structured data and QA across structured data. The code is\navailable at https://github.com/zjukg/TrustUQA.\n","authors":["Wen Zhang","Long Jin","Yushan Zhu","Jiaoyan Chen","Zhiwei Huang","Junjie Wang","Yin Hua","Lei Liang","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2406.18916v2.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2412.10198v1","updated":"2024-12-13T15:15:24Z","published":"2024-12-13T15:15:24Z","title":"From Allies to Adversaries: Manipulating LLM Tool-Calling through\n  Adversarial Injection","summary":"  Tool-calling has changed Large Language Model (LLM) applications by\nintegrating external tools, significantly enhancing their functionality across\ndiverse tasks. However, this integration also introduces new security\nvulnerabilities, particularly in the tool scheduling mechanisms of LLM, which\nhave not been extensively studied. To fill this gap, we present ToolCommander,\na novel framework designed to exploit vulnerabilities in LLM tool-calling\nsystems through adversarial tool injection. Our framework employs a\nwell-designed two-stage attack strategy. Firstly, it injects malicious tools to\ncollect user queries, then dynamically updates the injected tools based on the\nstolen information to enhance subsequent attacks. These stages enable\nToolCommander to execute privacy theft, launch denial-of-service attacks, and\neven manipulate business competition by triggering unscheduled tool-calling.\nNotably, the ASR reaches 91.67% for privacy theft and hits 100% for\ndenial-of-service and unscheduled tool calling in certain cases. Our work\ndemonstrates that these vulnerabilities can lead to severe consequences beyond\nsimple misuse of tool-calling systems, underscoring the urgent need for robust\ndefensive strategies to secure LLM Tool-calling systems.\n","authors":["Haowei Wang","Rupeng Zhang","Junjie Wang","Mingyang Li","Yuekai Huang","Dandan Wang","Qing Wang"],"pdf_url":"https://arxiv.org/pdf/2412.10198v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.17461v2","updated":"2024-12-13T15:08:32Z","published":"2024-11-26T14:28:25Z","title":"SoK: Decentralized AI (DeAI)","summary":"  The centralization of Artificial Intelligence (AI) poses significant\nchallenges, including single points of failure, inherent biases, data privacy\nconcerns, and scalability issues. These problems are especially prevalent in\nclosed-source large language models (LLMs), where user data is collected and\nused without transparency. To mitigate these issues, blockchain-based\ndecentralized AI (DeAI) has emerged as a promising solution. DeAI combines the\nstrengths of both blockchain and AI technologies to enhance the transparency,\nsecurity, decentralization, and trustworthiness of AI systems. However, a\ncomprehensive understanding of state-of-the-art DeAI development, particularly\nfor active industry solutions, is still lacking. In this work, we present a\nSystematization of Knowledge (SoK) for blockchain-based DeAI solutions. We\npropose a taxonomy to classify existing DeAI protocols based on the model\nlifecycle. Based on this taxonomy, we provide a structured way to clarify the\nlandscape of DeAI protocols and identify their similarities and differences. We\nanalyze the functionalities of blockchain in DeAI, investigating how blockchain\nfeatures contribute to enhancing the security, transparency, and\ntrustworthiness of AI processes, while also ensuring fair incentives for AI\ndata and model contributors. In addition, we identify key insights and research\ngaps in developing DeAI protocols, highlighting several critical avenues for\nfuture research.\n","authors":["Zhipeng Wang","Rui Sun","Elizabeth Lui","Vatsal Shah","Xihan Xiong","Jiahao Sun","Davide Crapis","William Knottenbelt"],"pdf_url":"https://arxiv.org/pdf/2411.17461v2.pdf","comment":"This is a Systematization of Knowledge (SoK) for the rapidly evolving\n  field of Decentralized AI (DeAI). We welcome valuable comments, suggestions,\n  and collaboration to further refine and enhance this work. We hope our\n  contribution will help accelerate the advancement of DeAI"},{"id":"http://arxiv.org/abs/2412.10186v1","updated":"2024-12-13T14:56:39Z","published":"2024-12-13T14:56:39Z","title":"BiCert: A Bilinear Mixed Integer Programming Formulation for Precise\n  Certified Bounds Against Data Poisoning Attacks","summary":"  Data poisoning attacks pose one of the biggest threats to modern AI systems,\nnecessitating robust defenses. While extensive efforts have been made to\ndevelop empirical defenses, attackers continue to evolve, creating\nsophisticated methods to circumvent these measures. To address this, we must\nmove beyond empirical defenses and establish provable certification methods\nthat guarantee robustness. This paper introduces a novel certification\napproach, BiCert, using Bilinear Mixed Integer Programming (BMIP) to compute\nsound deterministic bounds that provide such provable robustness. Using BMIP,\nwe compute the reachable set of parameters that could result from training with\npotentially manipulated data. A key element to make this computation feasible\nis to relax the reachable parameter set to a convex set between training\niterations. At test time, this parameter set allows us to predict all possible\noutcomes, guaranteeing robustness. BiCert is more precise than previous\nmethods, which rely solely on interval and polyhedral bounds. Crucially, our\napproach overcomes the fundamental limitation of prior approaches where\nparameter bounds could only grow, often uncontrollably. We show that BiCert's\ntighter bounds eliminate a key source of divergence issues, resulting in more\nstable training and higher certified accuracy.\n","authors":["Tobias Lorenz","Marta Kwiatkowska","Mario Fritz"],"pdf_url":"https://arxiv.org/pdf/2412.10186v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10185v1","updated":"2024-12-13T14:55:48Z","published":"2024-12-13T14:55:48Z","title":"Solving Robust Markov Decision Processes: Generic, Reliable, Efficient","summary":"  Markov decision processes (MDP) are a well-established model for sequential\ndecision-making in the presence of probabilities. In robust MDP (RMDP), every\naction is associated with an uncertainty set of probability distributions,\nmodelling that transition probabilities are not known precisely. Based on the\nknown theoretical connection to stochastic games, we provide a framework for\nsolving RMDPs that is generic, reliable, and efficient. It is *generic* both\nwith respect to the model, allowing for a wide range of uncertainty sets,\nincluding but not limited to intervals, $L^1$- or $L^2$-balls, and polytopes;\nand with respect to the objective, including long-run average reward,\nundiscounted total reward, and stochastic shortest path. It is *reliable*, as\nour approach not only converges in the limit, but provides precision guarantees\nat any time during the computation. It is *efficient* because -- in contrast to\nstate-of-the-art approaches -- it avoids explicitly constructing the underlying\nstochastic game. Consequently, our prototype implementation outperforms\nexisting tools by several orders of magnitude and can solve RMDPs with a\nmillion states in under a minute.\n","authors":["Tobias Meggendorfer","Maximilian Weininger","Patrick Wienhöft"],"pdf_url":"https://arxiv.org/pdf/2412.10185v1.pdf","comment":"Accepted for publication at AAAI'25. Extended version with full\n  appendix, 26 pages"},{"id":"http://arxiv.org/abs/2412.10182v1","updated":"2024-12-13T14:53:47Z","published":"2024-12-13T14:53:47Z","title":"Multi-Head Encoding for Extreme Label Classification","summary":"  The number of categories of instances in the real world is normally huge, and\neach instance may contain multiple labels. To distinguish these massive labels\nutilizing machine learning, eXtreme Label Classification (XLC) has been\nestablished. However, as the number of categories increases, the number of\nparameters and nonlinear operations in the classifier also rises. This results\nin a Classifier Computational Overload Problem (CCOP). To address this, we\npropose a Multi-Head Encoding (MHE) mechanism, which replaces the vanilla\nclassifier with a multi-head classifier. During the training process, MHE\ndecomposes extreme labels into the product of multiple short local labels, with\neach head trained on these local labels. During testing, the predicted labels\ncan be directly calculated from the local predictions of each head. This\nreduces the computational load geometrically. Then, according to the\ncharacteristics of different XLC tasks, e.g., single-label, multi-label, and\nmodel pretraining tasks, three MHE-based implementations, i.e., Multi-Head\nProduct, Multi-Head Cascade, and Multi-Head Sampling, are proposed to more\neffectively cope with CCOP. Moreover, we theoretically demonstrate that MHE can\nachieve performance approximately equivalent to that of the vanilla classifier\nby generalizing the low-rank approximation problem from Frobenius-norm to\nCross-Entropy. Experimental results show that the proposed methods achieve\nstate-of-the-art performance while significantly streamlining the training and\ninference processes of XLC tasks. The source code has been made public at\nhttps://github.com/Anoise/MHE.\n","authors":["Daojun Liang","Haixia Zhang","Dongfeng Yuan","Minggao Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.10182v1.pdf","comment":"20 pages, 12 figs, Published in TPAMI"},{"id":"http://arxiv.org/abs/2412.10178v1","updated":"2024-12-13T14:50:26Z","published":"2024-12-13T14:50:26Z","title":"SwiftTry: Fast and Consistent Video Virtual Try-On with Diffusion Models","summary":"  Given an input video of a person and a new garment, the objective of this\npaper is to synthesize a new video where the person is wearing the specified\ngarment while maintaining spatiotemporal consistency. While significant\nadvances have been made in image-based virtual try-ons, extending these\nsuccesses to video often results in frame-to-frame inconsistencies. Some\napproaches have attempted to address this by increasing the overlap of frames\nacross multiple video chunks, but this comes at a steep computational cost due\nto the repeated processing of the same frames, especially for long video\nsequence. To address these challenges, we reconceptualize video virtual try-on\nas a conditional video inpainting task, with garments serving as input\nconditions. Specifically, our approach enhances image diffusion models by\nincorporating temporal attention layers to improve temporal coherence. To\nreduce computational overhead, we introduce ShiftCaching, a novel technique\nthat maintains temporal consistency while minimizing redundant computations.\nFurthermore, we introduce the \\dataname~dataset, a new video try-on dataset\nfeaturing more complex backgrounds, challenging movements, and higher\nresolution compared to existing public datasets. Extensive experiments show\nthat our approach outperforms current baselines, particularly in terms of video\nconsistency and inference speed. Data and code are available at\nhttps://github.com/VinAIResearch/swift-try\n","authors":["Hung Nguyen","Quang Qui-Vinh Nguyen","Khoi Nguyen","Rang Nguyen"],"pdf_url":"https://arxiv.org/pdf/2412.10178v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.13438v2","updated":"2024-12-13T14:27:12Z","published":"2024-11-20T16:26:51Z","title":"Robust Monocular Visual Odometry using Curriculum Learning","summary":"  Curriculum Learning (CL), drawing inspiration from natural learning patterns\nobserved in humans and animals, employs a systematic approach of gradually\nintroducing increasingly complex training data during model development. Our\nwork applies innovative CL methodologies to address the challenging geometric\nproblem of monocular Visual Odometry (VO) estimation, which is essential for\nrobot navigation in constrained environments. The primary objective of our\nresearch is to push the boundaries of current state-of-the-art (SOTA)\nbenchmarks in monocular VO by investigating various curriculum learning\nstrategies. We enhance the end-to-end Deep-Patch-Visual Odometry (DPVO)\nframework through the integration of novel CL approaches, with the goal of\ndeveloping more resilient models capable of maintaining high performance across\nchallenging environments and complex motion scenarios. Our research encompasses\nseveral distinctive CL strategies. We develop methods to evaluate sample\ndifficulty based on trajectory motion characteristics, implement sophisticated\nadaptive scheduling through self-paced weighted loss mechanisms, and utilize\nreinforcement learning agents for dynamic adjustment of training emphasis.\nThrough comprehensive evaluation on the diverse synthetic TartanAir dataset and\ncomplex real-world benchmarks such as EuRoC and TUM-RGBD, our Curriculum\nLearning-based Deep-Patch-Visual Odometry (CL-DPVO) demonstrates superior\nperformance compared to existing SOTA methods, including both feature-based and\nlearning-based VO approaches. The results validate the effectiveness of\nintegrating curriculum learning principles into visual odometry systems.\n","authors":["Assaf Lahiany","Oren Gal"],"pdf_url":"https://arxiv.org/pdf/2411.13438v2.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2412.10163v1","updated":"2024-12-13T14:25:27Z","published":"2024-12-13T14:25:27Z","title":"Scaling Combinatorial Optimization Neural Improvement Heuristics with\n  Online Search and Adaptation","summary":"  We introduce Limited Rollout Beam Search (LRBS), a beam search strategy for\ndeep reinforcement learning (DRL) based combinatorial optimization improvement\nheuristics. Utilizing pre-trained models on the Euclidean Traveling Salesperson\nProblem, LRBS significantly enhances both in-distribution performance and\ngeneralization to larger problem instances, achieving optimality gaps that\noutperform existing improvement heuristics and narrowing the gap with\nstate-of-the-art constructive methods. We also extend our analysis to two\npickup and delivery TSP variants to validate our results. Finally, we employ\nour search strategy for offline and online adaptation of the pre-trained\nimprovement policy, leading to improved search performance and surpassing\nrecent adaptive methods for constructive heuristics.\n","authors":["Federico Julian Camerota Verdù","Lorenzo Castelli","Luca Bortolussi"],"pdf_url":"https://arxiv.org/pdf/2412.10163v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10155v1","updated":"2024-12-13T14:12:55Z","published":"2024-12-13T14:12:55Z","title":"WordVIS: A Color Worth A Thousand Words","summary":"  Document classification is considered a critical element in automated\ndocument processing systems. In recent years multi-modal approaches have become\nincreasingly popular for document classification. Despite their improvements,\nthese approaches are underutilized in the industry due to their requirement for\na tremendous volume of training data and extensive computational power. In this\npaper, we attempt to address these issues by embedding textual features\ndirectly into the visual space, allowing lightweight image-based classifiers to\nachieve state-of-the-art results using small-scale datasets in document\nclassification. To evaluate the efficacy of the visual features generated from\nour approach on limited data, we tested on the standard dataset Tobacco-3482.\nOur experiments show a tremendous improvement in image-based classifiers,\nachieving an improvement of 4.64% using ResNet50 with no document pre-training.\nIt also sets a new record for the best accuracy of the Tobacco-3482 dataset\nwith a score of 91.14% using the image-based DocXClassifier with no document\npre-training. The simplicity of the approach, its resource requirements, and\nsubsequent results provide a good prospect for its use in industrial use cases.\n","authors":["Umar Khan"," Saifullah","Stefan Agne","Andreas Dengel","Sheraz Ahmed"],"pdf_url":"https://arxiv.org/pdf/2412.10155v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10152v1","updated":"2024-12-13T14:11:33Z","published":"2024-12-13T14:11:33Z","title":"Direct Encoding of Declare Constraints in ASP","summary":"  Answer Set Programming (ASP), a well-known declarative logic programming\nparadigm, has recently found practical application in Process Mining. In\nparticular, ASP has been used to model tasks involving declarative\nspecifications of business processes. In this area, Declare stands out as the\nmost widely adopted declarative process modeling language, offering a means to\nmodel processes through sets of constraints valid traces must satisfy, that can\nbe expressed in Linear Temporal Logic over Finite Traces (LTLf). Existing\nASP-based solutions encode Declare constraints by modeling the corresponding\nLTLf formula or its equivalent automaton which can be obtained using\nestablished techniques. In this paper, we introduce a novel encoding for\nDeclare constraints that directly models their semantics as ASP rules,\neliminating the need for intermediate representations. We assess the\neffectiveness of this novel approach on two Process Mining tasks by comparing\nit with alternative ASP encodings and a Python library for Declare. Under\nconsideration in Theory and Practice of Logic Programming (TPLP).\n","authors":["Francesco Chiariello","Valeria Fionda","Antonio Ielo","Francesco Ricca"],"pdf_url":"https://arxiv.org/pdf/2412.10152v1.pdf","comment":"Under consideration in Theory and Practice of Logic Programming\n  (TPLP)"},{"id":"http://arxiv.org/abs/2412.10151v1","updated":"2024-12-13T14:11:26Z","published":"2024-12-13T14:11:26Z","title":"VLR-Bench: Multilingual Benchmark Dataset for Vision-Language Retrieval\n  Augmented Generation","summary":"  We propose the VLR-Bench, a visual question answering (VQA) benchmark for\nevaluating vision language models (VLMs) based on retrieval augmented\ngeneration (RAG). Unlike existing evaluation datasets for external\nknowledge-based VQA, the proposed VLR-Bench includes five input passages. This\nallows testing of the ability to determine which passage is useful for\nanswering a given query, a capability lacking in previous research. In this\ncontext, we constructed a dataset of 32,000 automatically generated\ninstruction-following examples, which we denote as VLR-IF. This dataset is\nspecifically designed to enhance the RAG capabilities of VLMs by enabling them\nto learn how to generate appropriate answers based on input passages. We\nevaluated the validity of the proposed benchmark and training data and verified\nits performance using the state-of-the-art Llama3-based VLM, the Llava-Llama-3\nmodel. The proposed VLR-Bench and VLR-IF datasets are publicly available\nonline.\n","authors":["Hyeonseok Lim","Dongjae Shin","Seohyun Song","Inho Won","Minjun Kim","Junghun Yuk","Haneol Jang","KyungTae Lim"],"pdf_url":"https://arxiv.org/pdf/2412.10151v1.pdf","comment":"The 31st International Conference on Computational Linguistics\n  (COLING 2025), 19 pages"},{"id":"http://arxiv.org/abs/2401.04402v2","updated":"2024-12-13T14:04:57Z","published":"2024-01-09T07:57:21Z","title":"IGNITE: Individualized GeNeration of Imputations in Time-series\n  Electronic health records","summary":"  Electronic Health Records present a valuable modality for driving\npersonalized medicine, where treatment is tailored to fit individual-level\ndifferences. For this purpose, many data-driven machine learning and\nstatistical models rely on the wealth of longitudinal EHRs to study patients'\nphysiological and treatment effects. However, longitudinal EHRs tend to be\nsparse and highly missing, where missingness could also be informative and\nreflect the underlying patient's health status. Therefore, the success of\ndata-driven models for personalized medicine highly depends on how the EHR data\nis represented from physiological data, treatments, and the missing values in\nthe data. To this end, we propose a novel deep-learning model that learns the\nunderlying patient dynamics over time across multivariate data to generate\npersonalized realistic values conditioning on an individual's demographic\ncharacteristics and treatments. Our proposed model, IGNITE (Individualized\nGeNeration of Imputations in Time-series Electronic health records), utilises a\nconditional dual-variational autoencoder augmented with dual-stage attention to\ngenerate missing values for an individual. In IGNITE, we further propose a\nnovel individualized missingness mask (IMM), which helps our model generate\nvalues based on the individual's observed data and missingness patterns. We\nfurther extend the use of IGNITE from imputing missingness to a personalized\ndata synthesizer, where it generates missing EHRs that were never observed\nprior or even generates new patients for various applications. We validate our\nmodel on three large publicly available datasets and show that IGNITE\noutperforms state-of-the-art approaches in missing data reconstruction and task\nprediction.\n","authors":["Ghadeer O. Ghosheh","Jin Li","Tingting Zhu"],"pdf_url":"https://arxiv.org/pdf/2401.04402v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10138v1","updated":"2024-12-13T13:41:18Z","published":"2024-12-13T13:41:18Z","title":"ROUTE: Robust Multitask Tuning and Collaboration for Text-to-SQL","summary":"  Despite the significant advancements in Text-to-SQL (Text2SQL) facilitated by\nlarge language models (LLMs), the latest state-of-the-art techniques are still\ntrapped in the in-context learning of closed-source LLMs (e.g., GPT-4), which\nlimits their applicability in open scenarios. To address this challenge, we\npropose a novel RObust mUltitask Tuning and collaboration mEthod (ROUTE) to\nimprove the comprehensive capabilities of open-source LLMs for Text2SQL,\nthereby providing a more practical solution. Our approach begins with\nmulti-task supervised fine-tuning (SFT) using various synthetic training data\nrelated to SQL generation. Unlike existing SFT-based Text2SQL methods, we\nintroduced several additional SFT tasks, including schema linking, noise\ncorrection, and continuation writing. Engaging in a variety of SQL generation\ntasks enhances the model's understanding of SQL syntax and improves its ability\nto generate high-quality SQL queries. Additionally, inspired by the\ncollaborative modes of LLM agents, we introduce a Multitask Collaboration\nPrompting (MCP) strategy. This strategy leverages collaboration across several\nSQL-related tasks to reduce hallucinations during SQL generation, thereby\nmaximizing the potential of enhancing Text2SQL performance through explicit\nmultitask capabilities. Extensive experiments and in-depth analyses have been\nperformed on eight open-source LLMs and five widely-used benchmarks. The\nresults demonstrate that our proposal outperforms the latest Text2SQL methods\nand yields leading performance.\n","authors":["Yang Qin","Chao Chen","Zhihang Fu","Ze Chen","Dezhong Peng","Peng Hu","Jieping Ye"],"pdf_url":"https://arxiv.org/pdf/2412.10138v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.02512v2","updated":"2024-12-13T13:38:42Z","published":"2024-11-18T11:25:28Z","title":"Pre-Deployment Information Sharing: A Zoning Taxonomy for Precursory\n  Capabilities","summary":"  High-impact and potentially dangerous capabilities can and should be broken\ndown into early warning shots long before reaching red lines. Each of these\nearly warning shots should correspond to a precursory capability. Each\nprecursory capability sits on a spectrum indicating its proximity to a final\nhigh-impact capability, corresponding to a red line. To meaningfully detect and\ntrack capability progress, we propose a taxonomy of dangerous capability zones\n(a zoning taxonomy) tied to a staggered information exchange framework that\nenables relevant bodies to take action accordingly. In the Frontier AI Safety\nCommitments, signatories commit to sharing more detailed information with\ntrusted actors, including an appointed body, as appropriate (Commitment VII).\nBuilding on our zoning taxonomy, this paper makes four recommendations for\nspecifying information sharing as detailed in Commitment VII. (1) Precursory\ncapabilities should be shared as soon as they become known through internal\nevaluations before deployment. (2) AI Safety Institutes (AISIs) should be the\ntrusted actors appointed to receive and coordinate information on precursory\ncomponents. (3) AISIs should establish adequate information protection\ninfrastructure and guarantee increased information security as precursory\ncapabilities move through the zones and towards red lines, including, if\nnecessary, by classifying the information on precursory capabilities or marking\nit as controlled. (4) High-impact capability progress in one geographical\nregion may translate to risk in other regions and necessitates more\ncomprehensive risk assessment internationally. As such, AISIs should exchange\ninformation on precursory capabilities with other AISIs, relying on the\nexisting frameworks on international classified exchanges and applying lessons\nlearned from other regulated high-risk sectors.\n","authors":["Matteo Pistillo","Charlotte Stix"],"pdf_url":"https://arxiv.org/pdf/2412.02512v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10136v1","updated":"2024-12-13T13:32:59Z","published":"2024-12-13T13:32:59Z","title":"Can LLMs Convert Graphs to Text-Attributed Graphs?","summary":"  Graphs are ubiquitous data structures found in numerous real-world\napplications, such as drug discovery, recommender systems, and social network\nanalysis. Graph neural networks (GNNs) have become a popular tool to learn node\nembeddings through message passing on these structures. However, a significant\nchallenge arises when applying GNNs to multiple graphs with different feature\nspaces, as existing GNN architectures are not designed for cross-graph feature\nalignment. To address this, recent approaches introduce text-attributed graphs,\nwhere each node is associated with a textual description, enabling the use of a\nshared textual encoder to project nodes from different graphs into a unified\nfeature space. While promising, this method relies heavily on the availability\nof text-attributed data, which can be difficult to obtain in practice. To\nbridge this gap, we propose a novel method named Topology-Aware Node\ndescription Synthesis (TANS), which leverages large language models (LLMs) to\nautomatically convert existing graphs into text-attributed graphs. The key idea\nis to integrate topological information with each node's properties, enhancing\nthe LLMs' ability to explain how graph topology influences node semantics. We\nevaluate our TANS on text-rich, text-limited, and text-free graphs,\ndemonstrating that it enables a single GNN to operate across diverse graphs.\nNotably, on text-free graphs, our method significantly outperforms existing\napproaches that manually design node features, showcasing the potential of LLMs\nfor preprocessing graph-structured data, even in the absence of textual\ninformation. The code and data are available at\nhttps://github.com/Zehong-Wang/TANS.\n","authors":["Zehong Wang","Sidney Liu","Zheyuan Zhang","Tianyi Ma","Chuxu Zhang","Yanfang Ye"],"pdf_url":"https://arxiv.org/pdf/2412.10136v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10133v1","updated":"2024-12-13T13:30:51Z","published":"2024-12-13T13:30:51Z","title":"You Name It, I Run It: An LLM Agent to Execute Tests of Arbitrary\n  Projects","summary":"  The ability to execute the test suite of a project is essential in many\nscenarios, e.g., to assess code quality and code coverage, to validate code\nchanges made by developers or automated tools, and to ensure compatibility with\ndependencies. Despite its importance, executing the test suite of a project can\nbe challenging in practice because different projects use different programming\nlanguages, software ecosystems, build systems, testing frameworks, and other\ntools. These challenges make it difficult to create a reliable, universal test\nexecution method that works across different projects. This paper presents\nExecutionAgent, an automated technique that installs arbitrary projects,\nconfigures them to run test cases, and produces project-specific scripts to\nreproduce the setup. Inspired by the way a human developer would address this\ntask, our approach is a large language model-based agent that autonomously\nexecutes commands and interacts with the host system. The agent uses\nmeta-prompting to gather guidelines on the latest technologies related to the\ngiven project, and it iteratively refines its process based on feedback from\nthe previous steps. Our evaluation applies ExecutionAgent to 50 open-source\nprojects that use 14 different programming languages and many different build\nand testing tools. The approach successfully executes the test suites of 33/55\nprojects, while matching the test results of ground truth test suite executions\nwith a deviation of only 7.5\\%. These results improve over the best previously\navailable technique by 6.6x. The costs imposed by the approach are reasonable,\nwith an execution time of 74 minutes and LLM costs of 0.16 dollars, on average\nper project. We envision ExecutionAgent to serve as a valuable tool for\ndevelopers, automated programming tools, and researchers that need to execute\ntests across a wide variety of projects.\n","authors":["Islem Bouzenia","Michael Pradel"],"pdf_url":"https://arxiv.org/pdf/2412.10133v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10117v1","updated":"2024-12-13T12:59:39Z","published":"2024-12-13T12:59:39Z","title":"CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language\n  Models","summary":"  In our previous work, we introduced CosyVoice, a multilingual speech\nsynthesis model based on supervised discrete speech tokens. By employing\nprogressive semantic decoding with two popular generative models, language\nmodels (LMs) and Flow Matching, CosyVoice demonstrated high prosody\nnaturalness, content consistency, and speaker similarity in speech in-context\nlearning. Recently, significant progress has been made in multi-modal large\nlanguage models (LLMs), where the response latency and real-time factor of\nspeech synthesis play a crucial role in the interactive experience. Therefore,\nin this report, we present an improved streaming speech synthesis model,\nCosyVoice 2, which incorporates comprehensive and systematic optimizations.\nSpecifically, we introduce finite-scalar quantization to improve the codebook\nutilization of speech tokens. For the text-speech LM, we streamline the model\narchitecture to allow direct use of a pre-trained LLM as the backbone. In\naddition, we develop a chunk-aware causal flow matching model to support\nvarious synthesis scenarios, enabling both streaming and non-streaming\nsynthesis within a single model. By training on a large-scale multilingual\ndataset, CosyVoice 2 achieves human-parity naturalness, minimal response\nlatency, and virtually lossless synthesis quality in the streaming mode. We\ninvite readers to listen to the demos at\nhttps://funaudiollm.github.io/cosyvoice2.\n","authors":["Zhihao Du","Yuxuan Wang","Qian Chen","Xian Shi","Xiang Lv","Tianyu Zhao","Zhifu Gao","Yexin Yang","Changfeng Gao","Hui Wang","Fan Yu","Huadai Liu","Zhengyan Sheng","Yue Gu","Chong Deng","Wen Wang","Shiliang Zhang","Zhijie Yan","Jingren Zhou"],"pdf_url":"https://arxiv.org/pdf/2412.10117v1.pdf","comment":"Tech report, work in progress"},{"id":"http://arxiv.org/abs/2412.10110v1","updated":"2024-12-13T12:51:50Z","published":"2024-12-13T12:51:50Z","title":"Label-template based Few-Shot Text Classification with Contrastive\n  Learning","summary":"  As an algorithmic framework for learning to learn, meta-learning provides a\npromising solution for few-shot text classification. However, most existing\nresearch fail to give enough attention to class labels. Traditional basic\nframework building meta-learner based on prototype networks heavily relies on\ninter-class variance, and it is easily influenced by noise. To address these\nlimitations, we proposes a simple and effective few-shot text classification\nframework. In particular, the corresponding label templates are embed into\ninput sentences to fully utilize the potential value of class labels, guiding\nthe pre-trained model to generate more discriminative text representations\nthrough the semantic information conveyed by labels. With the continuous\ninfluence of label semantics, supervised contrastive learning is utilized to\nmodel the interaction information between support samples and query samples.\nFurthermore, the averaging mechanism is replaced with an attention mechanism to\nhighlight vital semantic information. To verify the proposed scheme, four\ntypical datasets are employed to assess the performance of different methods.\nExperimental results demonstrate that our method achieves substantial\nperformance enhancements and outperforms existing state-of-the-art models on\nfew-shot text classification tasks.\n","authors":["Guanghua Hou","Shuhui Cao","Deqiang Ouyang","Ning Wang"],"pdf_url":"https://arxiv.org/pdf/2412.10110v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10107v1","updated":"2024-12-13T12:48:15Z","published":"2024-12-13T12:48:15Z","title":"NetOrchLLM: Mastering Wireless Network Orchestration with Large Language\n  Models","summary":"  The transition to 6G networks promises unprecedented advancements in wireless\ncommunication, with increased data rates, ultra-low latency, and enhanced\ncapacity. However, the complexity of managing and optimizing these\nnext-generation networks presents significant challenges. The advent of large\nlanguage models (LLMs) has revolutionized various domains by leveraging their\nsophisticated natural language understanding capabilities. However, the\npractical application of LLMs in wireless network orchestration and management\nremains largely unexplored. Existing literature predominantly offers visionary\nperspectives without concrete implementations, leaving a significant gap in the\nfield. To address this gap, this paper presents NETORCHLLM, a wireless NETwork\nORCHestrator LLM framework that uses LLMs to seamlessly orchestrate diverse\nwireless-specific models from wireless communication communities using their\nlanguage understanding and generation capabilities. A comprehensive framework\nis introduced, demonstrating the practical viability of our approach and\nshowcasing how LLMs can be effectively harnessed to optimize dense network\noperations, manage dynamic environments, and improve overall network\nperformance. NETORCHLLM bridges the theoretical aspirations of prior research\nwith practical, actionable solutions, paving the way for future advancements in\nintegrating generative AI technologies within the wireless communications\nsector.\n","authors":["Asmaa Abdallah","Abdullatif Albaseer","Abdulkadir Celik","Mohamed Abdallah","Ahmed M. Eltawil"],"pdf_url":"https://arxiv.org/pdf/2412.10107v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10106v1","updated":"2024-12-13T12:47:30Z","published":"2024-12-13T12:47:30Z","title":"A Cascaded Dilated Convolution Approach for Mpox Lesion Classification","summary":"  The global outbreak of Mpox virus, classified as a Public Health Emergency of\nInternational Concern by WHO, presents significant diagnostic challenges due to\nits visual similarity to other skin lesion diseases. Current clinical detection\ntechniques face limitations in accuracy and efficiency, necessitating improved\nautomated diagnostic solutions. This study introduces a novel Cascaded Atrous\nGroup Attention (CAGA) module, specifically designed to enhance multi-scale\nfeature representation while optimizing computational efficiency. By\nintegrating CAGA with EfficientViT-L1 as the backbone architecture, our\napproach achieves state-of-the-art performance with a score of 0.98% on the\nMCSI dataset, while reducing model parameters by 37.5% compared to the original\nEfficientViT-L1. This reduction in computational complexity maintains\ndiagnostic accuracy while enabling broader deployment across\nresource-constrained healthcare settings. Extensive validation across two other\nbenchmark datasets, including MSID and MSLD, demonstrate the model's\nrobustness, consistently outperforming existing approaches. Our findings\nsuggest that CAGA's efficient feature extraction mechanism could be adapted for\nother medical imaging tasks requiring fine-grained visual discrimination.\n","authors":["Ayush Deshmukh"],"pdf_url":"https://arxiv.org/pdf/2412.10106v1.pdf","comment":"(7 pages, 2 figures, 5 tables)"},{"id":"http://arxiv.org/abs/2412.10104v1","updated":"2024-12-13T12:45:14Z","published":"2024-12-13T12:45:14Z","title":"RETQA: A Large-Scale Open-Domain Tabular Question Answering Dataset for\n  Real Estate Sector","summary":"  The real estate market relies heavily on structured data, such as property\ndetails, market trends, and price fluctuations. However, the lack of\nspecialized Tabular Question Answering datasets in this domain limits the\ndevelopment of automated question-answering systems. To fill this gap, we\nintroduce RETQA, the first large-scale open-domain Chinese Tabular Question\nAnswering dataset for Real Estate. RETQA comprises 4,932 tables and 20,762\nquestion-answer pairs across 16 sub-fields within three major domains: property\ninformation, real estate company finance information and land auction\ninformation. Compared with existing tabular question answering datasets, RETQA\nposes greater challenges due to three key factors: long-table structures,\nopen-domain retrieval, and multi-domain queries. To tackle these challenges, we\npropose the SLUTQA framework, which integrates large language models with\nspoken language understanding tasks to enhance retrieval and answering\naccuracy. Extensive experiments demonstrate that SLUTQA significantly improves\nthe performance of large language models on RETQA by in-context learning. RETQA\nand SLUTQA provide essential resources for advancing tabular question answering\nresearch in the real estate domain, addressing critical challenges in\nopen-domain and long-table question-answering. The dataset and code are\npublicly available at \\url{https://github.com/jensen-w/RETQA}.\n","authors":["Zhensheng Wang","Wenmian Yang","Kun Zhou","Yiquan Zhang","Weijia Jia"],"pdf_url":"https://arxiv.org/pdf/2412.10104v1.pdf","comment":"This paper is accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2412.10095v1","updated":"2024-12-13T12:31:06Z","published":"2024-12-13T12:31:06Z","title":"HiTZ at VarDial 2025 NorSID: Overcoming Data Scarcity with Language\n  Transfer and Automatic Data Annotation","summary":"  In this paper we present our submission for the NorSID Shared Task as part of\nthe 2025 VarDial Workshop (Scherrer et al., 2025), consisting of three tasks:\nIntent Detection, Slot Filling and Dialect Identification, evaluated using data\nin different dialects of the Norwegian language. For Intent Detection and Slot\nFilling, we have fine-tuned a multitask model in a cross-lingual setting, to\nleverage the xSID dataset available in 17 languages. In the case of Dialect\nIdentification, our final submission consists of a model fine-tuned on the\nprovided development set, which has obtained the highest scores within our\nexperiments. Our final results on the test set show that our models do not drop\nin performance compared to the development set, likely due to the\ndomain-specificity of the dataset and the similar distribution of both subsets.\nFinally, we also report an in-depth analysis of the provided datasets and their\nartifacts, as well as other sets of experiments that have been carried out but\ndid not yield the best results. Additionally, we present an analysis on the\nreasons why some methods have been more successful than others; mainly the\nimpact of the combination of languages and domain-specificity of the training\ndata on the results.\n","authors":["Jaione Bengoetxea","Mikel Zubillaga","Ekhi Azurmendi","Maite Heredia","Julen Etxaniz","Markel Ferro","Jeremy Barnes"],"pdf_url":"https://arxiv.org/pdf/2412.10095v1.pdf","comment":"Vardial 2025 NorSID Shared Task"},{"id":"http://arxiv.org/abs/2412.10093v1","updated":"2024-12-13T12:30:11Z","published":"2024-12-13T12:30:11Z","title":"AI in the Cosmos","summary":"  Artificial intelligence (AI) is revolutionizing research by enabling the\nefficient analysis of large datasets and the discovery of hidden patterns. In\nastrophysics, AI has become essential, transforming the classification of\ncelestial sources, data modeling, and the interpretation of observations. In\nthis review, I highlight examples of AI applications in astrophysics, including\nsource classification, spectral energy distribution modeling, and discuss the\nadvancements achievable through generative AI. However, the use of AI\nintroduces challenges, including biases, errors, and the \"black box\" nature of\nAI models, which must be resolved before their application. These issues can be\naddressed through the concept of Human-Guided AI (HG-AI), which integrates\nhuman expertise and domain-specific knowledge into AI applications. This\napproach aims to ensure that AI is applied in a robust, interpretable, and\nethical manner, leading to deeper insights and fostering scientific excellence.\n","authors":["N. Sahakyan"],"pdf_url":"https://arxiv.org/pdf/2412.10093v1.pdf","comment":"In press in the International Journal of Modern Physics D; invited\n  talk at the 17th Marcel Grossmann Meeting"},{"id":"http://arxiv.org/abs/2412.09612v2","updated":"2024-12-13T12:27:52Z","published":"2024-12-12T18:59:40Z","title":"Olympus: A Universal Task Router for Computer Vision Tasks","summary":"  We introduce Olympus, a new approach that transforms Multimodal Large\nLanguage Models (MLLMs) into a unified framework capable of handling a wide\narray of computer vision tasks. Utilizing a controller MLLM, Olympus delegates\nover 20 specialized tasks across images, videos, and 3D objects to dedicated\nmodules. This instruction-based routing enables complex workflows through\nchained actions without the need for training heavy generative models. Olympus\neasily integrates with existing MLLMs, expanding their capabilities with\ncomparable performance. Experimental results demonstrate that Olympus achieves\nan average routing accuracy of 94.75% across 20 tasks and precision of 91.82%\nin chained action scenarios, showcasing its effectiveness as a universal task\nrouter that can solve a diverse range of computer vision tasks. Project page:\nhttp://yuanze-lin.me/Olympus_page/\n","authors":["Yuanze Lin","Yunsheng Li","Dongdong Chen","Weijian Xu","Ronald Clark","Philip H. S. Torr"],"pdf_url":"https://arxiv.org/pdf/2412.09612v2.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2412.10091v1","updated":"2024-12-13T12:27:47Z","published":"2024-12-13T12:27:47Z","title":"Data Pruning Can Do More: A Comprehensive Data Pruning Approach for\n  Object Re-identification","summary":"  Previous studies have demonstrated that not each sample in a dataset is of\nequal importance during training. Data pruning aims to remove less important or\ninformative samples while still achieving comparable results as training on the\noriginal (untruncated) dataset, thereby reducing storage and training costs.\nHowever, the majority of data pruning methods are applied to image\nclassification tasks. To our knowledge, this work is the first to explore the\nfeasibility of these pruning methods applied to object re-identification (ReID)\ntasks, while also presenting a more comprehensive data pruning approach. By\nfully leveraging the logit history during training, our approach offers a more\naccurate and comprehensive metric for quantifying sample importance, as well as\ncorrecting mislabeled samples and recognizing outliers. Furthermore, our\napproach is highly efficient, reducing the cost of importance score estimation\nby 10 times compared to existing methods. Our approach is a plug-and-play,\narchitecture-agnostic framework that can eliminate/reduce 35%, 30%, and 5% of\nsamples/training time on the VeRi, MSMT17 and Market1501 datasets,\nrespectively, with negligible loss in accuracy (< 0.1%). The lists of\nimportant, mislabeled, and outlier samples from these ReID datasets are\navailable at https://github.com/Zi-Y/data-pruning-reid.\n","authors":["Zi Yang","Haojin Yang","Soumajit Majumder","Jorge Cardoso","Guillermo Gallego"],"pdf_url":"https://arxiv.org/pdf/2412.10091v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08841v2","updated":"2024-12-13T12:23:58Z","published":"2024-12-12T00:37:53Z","title":"Structural Entropy Guided Probabilistic Coding","summary":"  Probabilistic embeddings have several advantages over deterministic\nembeddings as they map each data point to a distribution, which better\ndescribes the uncertainty and complexity of data. Many works focus on adjusting\nthe distribution constraint under the Information Bottleneck (IB) principle to\nenhance representation learning. However, these proposed regularization terms\nonly consider the constraint of each latent variable, omitting the structural\ninformation between latent variables. In this paper, we propose a novel\nstructural entropy-guided probabilistic coding model, named SEPC. Specifically,\nwe incorporate the relationship between latent variables into the optimization\nby proposing a structural entropy regularization loss. Besides, as traditional\nstructural information theory is not well-suited for regression tasks, we\npropose a probabilistic encoding tree, transferring regression tasks to\nclassification tasks while diminishing the influence of the transformation.\nExperimental results across 12 natural language understanding tasks, including\nboth classification and regression tasks, demonstrate the superior performance\nof SEPC compared to other state-of-the-art models in terms of effectiveness,\ngeneralization capability, and robustness to label noise. The codes and\ndatasets are available at https://github.com/SELGroup/SEPC.\n","authors":["Xiang Huang","Hao Peng","Li Sun","Hui Lin","Chunyang Liu","Jiang Cao","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2412.08841v2.pdf","comment":"This paper is accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2408.12772v2","updated":"2024-12-13T12:01:44Z","published":"2024-08-23T00:15:43Z","title":"Symmetric masking strategy enhances the performance of Masked Image\n  Modeling","summary":"  Masked Image Modeling (MIM) is a technique in self-supervised learning that\nfocuses on acquiring detailed visual representations from unlabeled images by\nestimating the missing pixels in randomly masked sections. It has proven to be\na powerful tool for the preliminary training of Vision Transformers (ViTs),\nyielding impressive results across various tasks. Nevertheless, most MIM\nmethods heavily depend on the random masking strategy to formulate the pretext\ntask. This strategy necessitates numerous trials to ascertain the optimal\ndropping ratio, which can be resource-intensive, requiring the model to be\npre-trained for anywhere between 800 to 1600 epochs. Furthermore, this approach\nmay not be suitable for all datasets. In this work, we propose a new masking\nstrategy that effectively helps the model capture global and local features.\nBased on this masking strategy, SymMIM, our proposed training pipeline for MIM\nis introduced. SymMIM achieves a new SOTA accuracy of 85.9\\% on ImageNet using\nViT-Large and surpasses previous SOTA across downstream tasks such as image\nclassification, semantic segmentation, object detection, instance segmentation\ntasks, and so on.\n","authors":["Khanh-Binh Nguyen","Chae Jung Park"],"pdf_url":"https://arxiv.org/pdf/2408.12772v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.01408v3","updated":"2024-12-13T11:59:06Z","published":"2024-12-02T11:51:19Z","title":"Towards Cross-Lingual Audio Abuse Detection in Low-Resource Settings\n  with Few-Shot Learning","summary":"  Online abusive content detection, particularly in low-resource settings and\nwithin the audio modality, remains underexplored. We investigate the potential\nof pre-trained audio representations for detecting abusive language in\nlow-resource languages, in this case, in Indian languages using Few Shot\nLearning (FSL). Leveraging powerful representations from models such as Wav2Vec\nand Whisper, we explore cross-lingual abuse detection using the ADIMA dataset\nwith FSL. Our approach integrates these representations within the\nModel-Agnostic Meta-Learning (MAML) framework to classify abusive language in\n10 languages. We experiment with various shot sizes (50-200) evaluating the\nimpact of limited data on performance. Additionally, a feature visualization\nstudy was conducted to better understand model behaviour. This study highlights\nthe generalization ability of pre-trained models in low-resource scenarios and\noffers valuable insights into detecting abusive language in multilingual\ncontexts.\n","authors":["Aditya Narayan Sankaran","Reza Farahbakhsh","Noel Crespi"],"pdf_url":"https://arxiv.org/pdf/2412.01408v3.pdf","comment":"Accepted as part of the proceedings of COLING 2025"},{"id":"http://arxiv.org/abs/2412.10059v1","updated":"2024-12-13T11:44:09Z","published":"2024-12-13T11:44:09Z","title":"Panacea: Novel DNN Accelerator using Accuracy-Preserving Asymmetric\n  Quantization and Energy-Saving Bit-Slice Sparsity","summary":"  Low bit-precisions and their bit-slice sparsity have recently been studied to\naccelerate general matrix-multiplications (GEMM) during large-scale deep neural\nnetwork (DNN) inferences. While the conventional symmetric quantization\nfacilitates low-resolution processing with bit-slice sparsity for both weight\nand activation, its accuracy loss caused by the activation's asymmetric\ndistributions cannot be acceptable, especially for large-scale DNNs. In efforts\nto mitigate this accuracy loss, recent studies have actively utilized\nasymmetric quantization for activations without requiring additional\noperations. However, the cutting-edge asymmetric quantization produces numerous\nnonzero slices that cannot be compressed and skipped by recent bit-slice GEMM\naccelerators, naturally consuming more processing energy to handle the\nquantized DNN models.\n  To simultaneously achieve high accuracy and hardware efficiency for\nlarge-scale DNN inferences, this paper proposes an Asymmetrically-Quantized\nbit-Slice GEMM (AQS-GEMM) for the first time. In contrast to the previous\nbit-slice computing, which only skips operations of zero slices, the AQS-GEMM\ncompresses frequent nonzero slices, generated by asymmetric quantization, and\nskips their operations. To increase the slice-level sparsity of activations, we\nalso introduce two algorithm-hardware co-optimization methods: a zero-point\nmanipulation and a distribution-based bit-slicing. To support the proposed\nAQS-GEMM and optimizations at the hardware-level, we newly introduce a DNN\naccelerator, Panacea, which efficiently handles sparse/dense workloads of the\ntiled AQS-GEMM to increase data reuse and utilization. Panacea supports a\nspecialized dataflow and run-length encoding to maximize data reuse and\nminimize external memory accesses, significantly improving its hardware\nefficiency. Our benchmark evaluations show Panacea outperforms existing DNN\naccelerators.\n","authors":["Dongyun Kam","Myeongji Yun","Sunwoo Yoo","Seungwoo Hong","Zhengya Zhang","Youngjoo Lee"],"pdf_url":"https://arxiv.org/pdf/2412.10059v1.pdf","comment":"15 pages, 20 figures, Accepted to HPCA 2025"},{"id":"http://arxiv.org/abs/2411.17832v2","updated":"2024-12-13T11:40:57Z","published":"2024-11-26T19:13:38Z","title":"SVGDreamer++: Advancing Editability and Diversity in Text-Guided SVG\n  Generation","summary":"  Recently, text-guided scalable vector graphics (SVG) synthesis has\ndemonstrated significant potential in domains such as iconography and\nsketching. However, SVGs generated from existing Text-to-SVG methods often lack\neditability and exhibit deficiencies in visual quality and diversity. In this\npaper, we propose a novel text-guided vector graphics synthesis method to\naddress these limitations. To enhance the editability of output SVGs, we\nintroduce a Hierarchical Image VEctorization (HIVE) framework that operates at\nthe semantic object level and supervises the optimization of components within\nthe vector object. This approach facilitates the decoupling of vector graphics\ninto distinct objects and component levels. Our proposed HIVE algorithm,\ninformed by image segmentation priors, not only ensures a more precise\nrepresentation of vector graphics but also enables fine-grained editing\ncapabilities within vector objects. To improve the diversity of output SVGs, we\npresent a Vectorized Particle-based Score Distillation (VPSD) approach. VPSD\naddresses over-saturation issues in existing methods and enhances sample\ndiversity. A pre-trained reward model is incorporated to re-weight vector\nparticles, improving aesthetic appeal and enabling faster convergence.\nAdditionally, we design a novel adaptive vector primitives control strategy,\nwhich allows for the dynamic adjustment of the number of primitives, thereby\nenhancing the presentation of graphic details. Extensive experiments validate\nthe effectiveness of the proposed method, demonstrating its superiority over\nbaseline methods in terms of editability, visual quality, and diversity. We\nalso show that our new method supports up to six distinct vector styles,\ncapable of generating high-quality vector assets suitable for stylized vector\ndesign and poster design. Code and demo will be released at:\nhttp://ximinng.github.io/SVGDreamerV2Project/\n","authors":["Ximing Xing","Qian Yu","Chuang Wang","Haitao Zhou","Jing Zhang","Dong Xu"],"pdf_url":"https://arxiv.org/pdf/2411.17832v2.pdf","comment":"17 pages, 17 figures. Project Page:\n  http://ximinng.github.io/SVGDreamerV2Project/. arXiv admin note: text overlap\n  with arXiv:2312.16476"},{"id":"http://arxiv.org/abs/2412.10056v1","updated":"2024-12-13T11:38:10Z","published":"2024-12-13T11:38:10Z","title":"GAOKAO-Eval: Does high scores truly reflect strong capabilities in LLMs?","summary":"  Large Language Models (LLMs) are commonly evaluated using human-crafted\nbenchmarks, under the premise that higher scores implicitly reflect stronger\nhuman-like performance. However, there is growing concern that LLMs may ``game\"\nthese benchmarks due to data leakage, achieving high scores while struggling\nwith tasks simple for humans. To substantively address the problem, we create\nGAOKAO-Eval, a comprehensive benchmark based on China's National College\nEntrance Examination (Gaokao), and conduct ``closed-book\" evaluations for\nrepresentative models released prior to Gaokao. Contrary to prevailing\nconsensus, even after addressing data leakage and comprehensiveness,\nGAOKAO-Eval reveals that high scores still fail to truly reflect human-aligned\ncapabilities. To better understand this mismatch, We introduce the Rasch model\nfrom cognitive psychology to analyze LLM scoring patterns and identify two key\ndiscrepancies: 1) anomalous consistent performance across various question\ndifficulties, and 2) high variance in performance on questions of similar\ndifficulty. In addition, We identified inconsistent grading of LLM-generated\nanswers among teachers and recurring mistake patterns. we find that the\nphenomenons are well-grounded in the motivations behind OpenAI o1, and o1's\nreasoning-as-difficulties can mitigate the mismatch. These results show that\nGAOKAO-Eval can reveal limitations in LLM capabilities not captured by current\nbenchmarks and highlight the need for more LLM-aligned difficulty analysis.\n","authors":["Zhikai Lei","Tianyi Liang","Hanglei Hu","Jin Zhang","Yunhua Zhou","Yunfan Shao","Linyang Li","Chenchui Li","Changbo Wang","Hang Yan","Qipeng Guo"],"pdf_url":"https://arxiv.org/pdf/2412.10056v1.pdf","comment":"10 pages, 13 figures"},{"id":"http://arxiv.org/abs/2412.10051v1","updated":"2024-12-13T11:26:38Z","published":"2024-12-13T11:26:38Z","title":"TSGaussian: Semantic and Depth-Guided Target-Specific Gaussian Splatting\n  from Sparse Views","summary":"  Recent advances in Gaussian Splatting have significantly advanced the field,\nachieving both panoptic and interactive segmentation of 3D scenes. However,\nexisting methodologies often overlook the critical need for reconstructing\nspecified targets with complex structures from sparse views. To address this\nissue, we introduce TSGaussian, a novel framework that combines semantic\nconstraints with depth priors to avoid geometry degradation in challenging\nnovel view synthesis tasks. Our approach prioritizes computational resources on\ndesignated targets while minimizing background allocation. Bounding boxes from\nYOLOv9 serve as prompts for Segment Anything Model to generate 2D mask\npredictions, ensuring semantic accuracy and cost efficiency. TSGaussian\neffectively clusters 3D gaussians by introducing a compact identity encoding\nfor each Gaussian ellipsoid and incorporating 3D spatial consistency\nregularization. Leveraging these modules, we propose a pruning strategy to\neffectively reduce redundancy in 3D gaussians. Extensive experiments\ndemonstrate that TSGaussian outperforms state-of-the-art methods on three\nstandard datasets and a new challenging dataset we collected, achieving\nsuperior results in novel view synthesis of specific objects. Code is available\nat: https://github.com/leon2000-ai/TSGaussian.\n","authors":["Liang Zhao","Zehan Bao","Yi Xie","Hong Chen","Yaohui Chen","Weifu Li"],"pdf_url":"https://arxiv.org/pdf/2412.10051v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10047v1","updated":"2024-12-13T11:19:56Z","published":"2024-12-13T11:19:56Z","title":"Large Action Models: From Inception to Implementation","summary":"  As AI continues to advance, there is a growing demand for systems that go\nbeyond language-based assistance and move toward intelligent agents capable of\nperforming real-world actions. This evolution requires the transition from\ntraditional Large Language Models (LLMs), which excel at generating textual\nresponses, to Large Action Models (LAMs), designed for action generation and\nexecution within dynamic environments. Enabled by agent systems, LAMs hold the\npotential to transform AI from passive language understanding to active task\ncompletion, marking a significant milestone in the progression toward\nartificial general intelligence.\n  In this paper, we present a comprehensive framework for developing LAMs,\noffering a systematic approach to their creation, from inception to deployment.\nWe begin with an overview of LAMs, highlighting their unique characteristics\nand delineating their differences from LLMs. Using a Windows OS-based agent as\na case study, we provide a detailed, step-by-step guide on the key stages of\nLAM development, including data collection, model training, environment\nintegration, grounding, and evaluation. This generalizable workflow can serve\nas a blueprint for creating functional LAMs in various application domains. We\nconclude by identifying the current limitations of LAMs and discussing\ndirections for future research and industrial deployment, emphasizing the\nchallenges and opportunities that lie ahead in realizing the full potential of\nLAMs in real-world applications.\n  The code for the data collection process utilized in this paper is publicly\navailable at: https://github.com/microsoft/UFO/tree/main/dataflow, and\ncomprehensive documentation can be found at\nhttps://microsoft.github.io/UFO/dataflow/overview/.\n","authors":["Lu Wang","Fangkai Yang","Chaoyun Zhang","Junting Lu","Jiaxu Qian","Shilin He","Pu Zhao","Bo Qiao","Ray Huang","Si Qin","Qisheng Su","Jiayi Ye","Yudi Zhang","Jian-Guang Lou","Qingwei Lin","Saravan Rajmohan","Dongmei Zhang","Qi Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.10047v1.pdf","comment":"25pages,12 figures"},{"id":"http://arxiv.org/abs/2410.15633v2","updated":"2024-12-13T11:16:57Z","published":"2024-10-21T04:30:53Z","title":"GATEAU: Selecting Influential Sample for Long Context Alignment","summary":"  Aligning large language models to handle instructions with extremely long\ncontexts has yet to be fully investigated. Previous studies attempt to scale up\nthe available data volume by synthesizing long instruction-following samples,\nas constructing such a dataset tends to be challenging for annotators. However,\na lack of a well-defined strategy for ensuring data quality may introduce\nlow-quality samples and restrict the model performance. Thus, we propose\nGATEAU, a novel framework to address the unique challenge of long context\nalignment by identifying the influential samples enriched with long-range\ndependency relations. Specifically, GATEAU measures the long-range dependencies\nfrom two essential aspects: the difficulty of generating target responses due\nto the long-range dependencies, and the difficulty of understanding long inputs\ndue to such dependencies. Comprehensive experiments indicate that GATEAU\neffectively identifies influential samples and the model trained on these\nselected samples exhibits better instruction-following and long-context\nunderstanding capabilities.\n","authors":["Shuzheng Si","Haozhe Zhao","Gang Chen","Yunshui Li","Kangyang Luo","Chuancheng Lv","Kaikai An","Fanchao Qi","Baobao Chang","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2410.15633v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.08728v3","updated":"2024-12-13T11:12:33Z","published":"2024-01-16T15:32:41Z","title":"AgentMixer: Multi-Agent Correlated Policy Factorization","summary":"  In multi-agent reinforcement learning, centralized training with\ndecentralized execution (CTDE) methods typically assume that agents make\ndecisions based on their local observations independently, which may not lead\nto a correlated joint policy with coordination. Coordination can be explicitly\nencouraged during training and individual policies can be trained to imitate\nthe correlated joint policy. However, this may lead to an \\textit{asymmetric\nlearning failure} due to the observation mismatch between the joint and\nindividual policies. Inspired by the concept of correlated equilibrium, we\nintroduce a \\textit{strategy modification} called AgentMixer that allows agents\nto correlate their policies. AgentMixer combines individual partially\nobservable policies into a joint fully observable policy non-linearly. To\nenable decentralized execution, we introduce\n\\textit{Individual-Global-Consistency} to guarantee mode consistency during\njoint training of the centralized and decentralized policies and prove that\nAgentMixer converges to an $\\epsilon$-approximate Correlated Equilibrium. In\nthe Multi-Agent MuJoCo, SMAC-v2, Matrix Game, and Predator-Prey benchmarks,\nAgentMixer outperforms or matches state-of-the-art methods.\n","authors":["Zhiyuan Li","Wenshuai Zhao","Lijun Wu","Joni Pajarinen"],"pdf_url":"https://arxiv.org/pdf/2401.08728v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.13125v2","updated":"2024-12-13T10:48:13Z","published":"2024-02-20T16:38:33Z","title":"TreeEval: Benchmark-Free Evaluation of Large Language Models through\n  Tree Planning","summary":"  Recently, numerous new benchmarks have been established to evaluate the\nperformance of large language models (LLMs) via either computing a holistic\nscore or employing another LLM as a judge. However, these approaches suffer\nfrom data leakage due to the open access of the benchmark and inflexible\nevaluation process. To address this issue, we introduce $\\textbf{TreeEval}$, a\nbenchmark-free evaluation method for LLMs that let a high-performance LLM host\nan irreproducible evaluation session and essentially avoids the data leakage.\nMoreover, this LLM performs as an examiner to raise up a series of questions\nunder a topic with a tree planing strategy, which considers the current\nevaluation status to decide the next question generation and ensures the\ncompleteness and efficiency of the evaluation process. We evaluate $6$ models\nof different parameter sizes, including $7$B, $13$B, and $33$B, and ultimately\nachieved the highest correlation coefficient with AlpacaEval2.0 using only\naround $45$ questions. We also conduct more analysis to show the robustness and\nreliability of TreeEval. Our code can be accessed via the provided\nhttps://github.com/Ashura5/TreeEval.\n","authors":["Xiang Li","Yunshi Lan","Chao Yang"],"pdf_url":"https://arxiv.org/pdf/2402.13125v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.04230v3","updated":"2024-12-13T10:03:10Z","published":"2024-05-07T11:50:25Z","title":"Unveiling the optimization process of Physics Informed Neural Networks:\n  How accurate and competitive can PINNs be?","summary":"  This study investigates the potential accuracy boundaries of physics-informed\nneural networks, contrasting their approach with previous similar works and\ntraditional numerical methods. We find that selecting improved optimization\nalgorithms significantly enhances the accuracy of the results. Simple\nmodifications to the loss function may also improve precision, offering an\nadditional avenue for enhancement. Despite optimization algorithms having a\ngreater impact on convergence than adjustments to the loss function, practical\nconsiderations often favor tweaking the latter due to ease of implementation.\nOn a global scale, the integration of an enhanced optimizer and a marginally\nadjusted loss function enables a reduction in the loss function by several\norders of magnitude across diverse physical problems. Consequently, our results\nobtained using compact networks (typically comprising 2 or 3 layers of 20-30\nneurons) achieve accuracies comparable to finite difference schemes employing\nthousands of grid points. This study encourages the continued advancement of\nPINNs and associated optimization techniques for broader applications across\nvarious fields.\n","authors":["Jorge F. Urbán","Petros Stefanou","José A. Pons"],"pdf_url":"https://arxiv.org/pdf/2405.04230v3.pdf","comment":"63 pages, 25 figures. This is the author-accepted manuscript of the\n  paper published in Journal of Computational Physics"},{"id":"http://arxiv.org/abs/2412.10011v1","updated":"2024-12-13T09:55:03Z","published":"2024-12-13T09:55:03Z","title":"Enhanced Speech Emotion Recognition with Efficient Channel Attention\n  Guided Deep CNN-BiLSTM Framework","summary":"  Speech emotion recognition (SER) is crucial for enhancing affective computing\nand enriching the domain of human-computer interaction. However, the main\nchallenge in SER lies in selecting relevant feature representations from speech\nsignals with lower computational costs. In this paper, we propose a lightweight\nSER architecture that integrates attention-based local feature blocks (ALFBs)\nto capture high-level relevant feature vectors from speech signals. We also\nincorporate a global feature block (GFB) technique to capture sequential,\nglobal information and long-term dependencies in speech signals. By aggregating\nattention-based local and global contextual feature vectors, our model\neffectively captures the internal correlation between salient features that\nreflect complex human emotional cues. To evaluate our approach, we extracted\nfour types of spectral features from speech audio samples: mel-frequency\ncepstral coefficients, mel-spectrogram, root mean square value, and\nzero-crossing rate. Through a 5-fold cross-validation strategy, we tested the\nproposed method on five multi-lingual standard benchmark datasets: TESS,\nRAVDESS, BanglaSER, SUBESCO, and Emo-DB, and obtained a mean accuracy of\n99.65%, 94.88%, 98.12%, 97.94%, and 97.19% respectively. The results indicate\nthat our model achieves state-of-the-art (SOTA) performance compared to most\nexisting methods.\n","authors":["Niloy Kumar Kundu","Sarah Kobir","Md. Rayhan Ahmed","Tahmina Aktar","Niloya Roy"],"pdf_url":"https://arxiv.org/pdf/2412.10011v1.pdf","comment":"42 pages,10 figures"},{"id":"http://arxiv.org/abs/2412.09602v2","updated":"2024-12-13T09:51:22Z","published":"2024-12-12T18:59:13Z","title":"Hidden Biases of End-to-End Driving Datasets","summary":"  End-to-end driving systems have made rapid progress, but have so far not been\napplied to the challenging new CARLA Leaderboard 2.0. Further, while there is a\nlarge body of literature on end-to-end architectures and training strategies,\nthe impact of the training dataset is often overlooked. In this work, we make a\nfirst attempt at end-to-end driving for Leaderboard 2.0. Instead of\ninvestigating architectures, we systematically analyze the training dataset,\nleading to new insights: (1) Expert style significantly affects downstream\npolicy performance. (2) In complex data sets, the frames should not be weighted\non the basis of simplistic criteria such as class frequencies. (3) Instead,\nestimating whether a frame changes the target labels compared to previous\nframes can reduce the size of the dataset without removing important\ninformation. By incorporating these findings, our model ranks first and second\nrespectively on the map and sensors tracks of the 2024 CARLA Challenge, and\nsets a new state-of-the-art on the Bench2Drive test routes. Finally, we uncover\na design flaw in the current evaluation metrics and propose a modification for\nfuture challenges. Our dataset, code, and pre-trained models are publicly\navailable at https://github.com/autonomousvision/carla_garage.\n","authors":["Julian Zimmerlin","Jens Beißwenger","Bernhard Jaeger","Andreas Geiger","Kashyap Chitta"],"pdf_url":"https://arxiv.org/pdf/2412.09602v2.pdf","comment":"Technical report for the CVPR 2024 Workshop on Foundation Models for\n  Autonomous Systems. Runner-up of the track 'CARLA Autonomous Driving\n  Challenge' in the 2024 Autonomous Grand Challenge\n  (https://opendrivelab.com/challenge2024/)"},{"id":"http://arxiv.org/abs/2412.01272v2","updated":"2024-12-13T09:50:35Z","published":"2024-12-02T08:38:20Z","title":"Uncertainty-Aware Artificial Intelligence for Gear Fault Diagnosis in\n  Motor Drives","summary":"  This paper introduces a novel approach to quantify the uncertainties in fault\ndiagnosis of motor drives using Bayesian neural networks (BNN). Conventional\ndata-driven approaches used for fault diagnosis often rely on point-estimate\nneural networks, which merely provide deterministic outputs and fail to capture\nthe uncertainty associated with the inference process. In contrast, BNNs offer\na principled framework to model uncertainty by treating network weights as\nprobability distributions rather than fixed values. It offers several\nadvantages: (a) improved robustness to noisy data, (b) enhanced\ninterpretability of model predictions, and (c) the ability to quantify\nuncertainty in the decision-making processes. To test the robustness of the\nproposed BNN, it has been tested under a conservative dataset of gear fault\ndata from an experimental prototype of three fault types at first, and is then\nincrementally trained on new fault classes and datasets to explore its\nuncertainty quantification features and model interpretability under noisy data\nand unseen fault scenarios.\n","authors":["Subham Sahoo","Huai Wang","Frede Blaabjerg"],"pdf_url":"https://arxiv.org/pdf/2412.01272v2.pdf","comment":"The manuscript has been accepted for publication in 2025 IEEE Applied\n  Power Electronics Conference and Exposition (APEC)"},{"id":"http://arxiv.org/abs/2412.08378v2","updated":"2024-12-13T09:49:53Z","published":"2024-12-11T13:41:21Z","title":"HyViLM: Enhancing Fine-Grained Recognition with a Hybrid Encoder for\n  Vision-Language Models","summary":"  Recently, there has been growing interest in the capability of multimodal\nlarge language models (MLLMs) to process high-resolution images. A common\napproach currently involves dynamically cropping the original high-resolution\nimage into smaller sub-images, which are then fed into a vision encoder that\nwas pre-trained on lower-resolution images. However, this cropping approach\noften truncates objects and connected areas in the original image, causing\nsemantic breaks. To address this limitation, we introduce HyViLM, designed to\nprocess images of any resolution while retaining the overall context during\nencoding. Specifically, we: (i) Design a new visual encoder called Hybrid\nEncoder that not only encodes individual sub-images but also interacts with\ndetailed global visual features, significantly improving the model's ability to\nencode high-resolution images. (ii) Propose an optimal feature fusion strategy\nfor the dynamic cropping approach, effectively leveraging information from\ndifferent layers of the vision encoder. Compared with the state-of-the-art\nMLLMs under the same setting, our HyViLM outperforms existing MLLMs in nine out\nof ten tasks. Specifically, HyViLM achieves a 9.6% improvement in performance\non the TextVQA task and a 6.9% enhancement on the DocVQA task.\n","authors":["Shiding Zhu","Wenhui Dong","Jun Song","Yingbo Wang","Yanan Guo","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2412.08378v2.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2412.09998v1","updated":"2024-12-13T09:35:34Z","published":"2024-12-13T09:35:34Z","title":"Cycle-Consistent Bridge Diffusion Model for Accelerated MRI\n  Reconstruction","summary":"  Accelerated MRI reconstruction techniques aim to reduce examination time\nwhile maintaining high image fidelity, which is highly desirable in clinical\nsettings for improving patient comfort and hospital efficiency. Existing deep\nlearning methods typically reconstruct images from under-sampled data with\ntraditional reconstruction approaches, but they still struggle to provide\nhigh-fidelity results. Diffusion models show great potential to improve\nfidelity of generated images in recent years. However, their inference process\nstarting with a random Gaussian noise introduces instability into the results\nand usually requires thousands of sampling steps, resulting in sub-optimal\nreconstruction quality and low efficiency. To address these challenges, we\npropose Cycle-Consistent Bridge Diffusion Model (CBDM). CBDM employs two bridge\ndiffusion models to construct a cycle-consistent diffusion process with a\nconsistency loss, enhancing the fine-grained details of reconstructed images\nand reducing the number of diffusion steps. Moreover, CBDM incorporates a\nContourlet Decomposition Embedding Module (CDEM) which captures multi-scale\nstructural texture knowledge in images through frequency domain decomposition\npyramids and directional filter banks to improve structural fidelity. Extensive\nexperiments demonstrate the superiority of our model by higher reconstruction\nquality and fewer training iterations, achieving a new state of the art for\naccelerated MRI reconstruction in both fastMRI and IXI datasets.\n","authors":["Tao Song","Yicheng Wu","Minhao Hu","Xiangde Luo","Guoting Luo","Guotai Wang","Yi Guo","Feng Xu","Shaoting Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.09998v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09318v2","updated":"2024-12-13T09:30:36Z","published":"2024-12-12T14:43:03Z","title":"Benchmarking LLMs for Mimicking Child-Caregiver Language in Interaction","summary":"  LLMs can generate human-like dialogues, yet their ability to simulate early\nchild-adult interactions remains largely unexplored. In this paper, we examined\nhow effectively LLMs can capture the distinctive features of child-caregiver\nlanguage in interaction, using both static and interactive benchmarking\nmethods. We found that state-of-the-art LLMs like Llama 3 and GPT-4o can\napproximate child-caregiver dialogues at the word and utterance level, but they\nstruggle to reproduce the child and caregiver's discursive patterns, exaggerate\nalignment, and fail to reach the level of diversity shown by humans. The\nbroader goal of this work is to initiate the development of a comprehensive\nbenchmark for LLMs in child-oriented applications.\n","authors":["Jing Liu","Abdellah Fourtassi"],"pdf_url":"https://arxiv.org/pdf/2412.09318v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09991v1","updated":"2024-12-13T09:25:18Z","published":"2024-12-13T09:25:18Z","title":"Visual Object Tracking across Diverse Data Modalities: A Review","summary":"  Visual Object Tracking (VOT) is an attractive and significant research area\nin computer vision, which aims to recognize and track specific targets in video\nsequences where the target objects are arbitrary and class-agnostic. The VOT\ntechnology could be applied in various scenarios, processing data of diverse\nmodalities such as RGB, thermal infrared and point cloud. Besides, since no one\nsensor could handle all the dynamic and varying environments, multi-modal VOT\nis also investigated. This paper presents a comprehensive survey of the recent\nprogress of both single-modal and multi-modal VOT, especially the deep learning\nmethods. Specifically, we first review three types of mainstream single-modal\nVOT, including RGB, thermal infrared and point cloud tracking. In particular,\nwe conclude four widely-used single-modal frameworks, abstracting their schemas\nand categorizing the existing inheritors. Then we summarize four kinds of\nmulti-modal VOT, including RGB-Depth, RGB-Thermal, RGB-LiDAR and RGB-Language.\nMoreover, the comparison results in plenty of VOT benchmarks of the discussed\nmodalities are presented. Finally, we provide recommendations and insightful\nobservations, inspiring the future development of this fast-growing literature.\n","authors":["Mengmeng Wang","Teli Ma","Shuo Xin","Xiaojun Hou","Jiazheng Xing","Guang Dai","Jingdong Wang","Yong Liu"],"pdf_url":"https://arxiv.org/pdf/2412.09991v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09990v1","updated":"2024-12-13T09:23:58Z","published":"2024-12-13T09:23:58Z","title":"Small Language Model as Data Prospector for Large Language Model","summary":"  The quality of instruction data directly affects the performance of\nfine-tuned Large Language Models (LLMs). Previously, \\cite{li2023one} proposed\n\\texttt{NUGGETS}, which identifies and selects high-quality quality data from a\nlarge dataset by identifying those individual instruction examples that can\nsignificantly improve the performance of different tasks after being learnt as\none-shot instances. In this work, we propose \\texttt{SuperNUGGETS}, an improved\nvariant of \\texttt{NUGGETS} optimised for efficiency and performance. Our\n\\texttt{SuperNUGGETS} uses a small language model (SLM) instead of a large\nlanguage model (LLM) to filter the data for outstanding one-shot instances and\nrefines the predefined set of tests. The experimental results show that the\nperformance of \\texttt{SuperNUGGETS} only decreases by 1-2% compared to\n\\texttt{NUGGETS}, but the efficiency can be increased by a factor of 58.\nCompared to the original \\texttt{NUGGETS}, our \\texttt{SuperNUGGETS} has a\nhigher utility value due to the significantly lower resource consumption.\n","authors":["Shiwen Ni","Haihong Wu","Di Yang","Qiang Qu","Hamid Alinejad-Rokny","Min Yang"],"pdf_url":"https://arxiv.org/pdf/2412.09990v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09989v1","updated":"2024-12-13T09:21:02Z","published":"2024-12-13T09:21:02Z","title":"One Filter to Deploy Them All: Robust Safety for Quadrupedal Navigation\n  in Unknown Environments","summary":"  As learning-based methods for legged robots rapidly grow in popularity, it is\nimportant that we can provide safety assurances efficiently across different\ncontrollers and environments. Existing works either rely on a priori knowledge\nof the environment and safety constraints to ensure system safety or provide\nassurances for a specific locomotion policy. To address these limitations, we\npropose an observation-conditioned reachability-based (OCR) safety-filter\nframework. Our key idea is to use an OCR value network (OCR-VN) that predicts\nthe optimal control-theoretic safety value function for new failure regions and\ndynamic uncertainty during deployment time. Specifically, the OCR-VN\nfacilitates rapid safety adaptation through two key components: a LiDAR-based\ninput that allows the dynamic construction of safe regions in light of new\nobstacles and a disturbance estimation module that accounts for dynamics\nuncertainty in the wild. The predicted safety value function is used to\nconstruct an adaptive safety filter that overrides the nominal quadruped\ncontroller when necessary to maintain safety. Through simulation studies and\nhardware experiments on a Unitree Go1 quadruped, we demonstrate that the\nproposed framework can automatically safeguard a wide range of hierarchical\nquadruped controllers, adapts to novel environments, and is robust to unmodeled\ndynamics without a priori access to the controllers or environments - hence,\n\"One Filter to Deploy Them All\". The experiment videos can be found on the\nproject website.\n","authors":["Albert Lin","Shuang Peng","Somil Bansal"],"pdf_url":"https://arxiv.org/pdf/2412.09989v1.pdf","comment":"Project website:\n  https://sia-lab-git.github.io/One_Filter_to_Deploy_Them_All/"},{"id":"http://arxiv.org/abs/2412.09988v1","updated":"2024-12-13T09:15:20Z","published":"2024-12-13T09:15:20Z","title":"AI and the Future of Digital Public Squares","summary":"  Two substantial technological advances have reshaped the public square in\nrecent decades: first with the advent of the internet and second with the\nrecent introduction of large language models (LLMs). LLMs offer opportunities\nfor a paradigm shift towards more decentralized, participatory online spaces\nthat can be used to facilitate deliberative dialogues at scale, but also create\nrisks of exacerbating societal schisms. Here, we explore four applications of\nLLMs to improve digital public squares: collective dialogue systems, bridging\nsystems, community moderation, and proof-of-humanity systems. Building on the\ninput from over 70 civil society experts and technologists, we argue that LLMs\nboth afford promising opportunities to shift the paradigm for conversations at\nscale and pose distinct risks for digital public squares. We lay out an agenda\nfor future research and investments in AI that will strengthen digital public\nsquares and safeguard against potential misuses of AI.\n","authors":["Beth Goldberg","Diana Acosta-Navas","Michiel Bakker","Ian Beacock","Matt Botvinick","Prateek Buch","Renée DiResta","Nandika Donthi","Nathanael Fast","Ravi Iyer","Zaria Jalan","Andrew Konya","Grace Kwak Danciu","Hélène Landemore","Alice Marwick","Carl Miller","Aviv Ovadya","Emily Saltz","Lisa Schirch","Dalit Shalom","Divya Siddarth","Felix Sieker","Christopher Small","Jonathan Stray","Audrey Tang","Michael Henry Tessler","Amy Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.09988v1.pdf","comment":"40 pages, 5 figures"},{"id":"http://arxiv.org/abs/2412.09981v1","updated":"2024-12-13T09:08:02Z","published":"2024-12-13T09:08:02Z","title":"SUMI-IFL: An Information-Theoretic Framework for Image Forgery\n  Localization with Sufficiency and Minimality Constraints","summary":"  Image forgery localization (IFL) is a crucial technique for preventing\ntampered image misuse and protecting social safety. However, due to the rapid\ndevelopment of image tampering technologies, extracting more comprehensive and\naccurate forgery clues remains an urgent challenge. To address these\nchallenges, we introduce a novel information-theoretic IFL framework named\nSUMI-IFL that imposes sufficiency-view and minimality-view constraints on\nforgery feature representation. First, grounded in the theoretical analysis of\nmutual information, the sufficiency-view constraint is enforced on the feature\nextraction network to ensure that the latent forgery feature contains\ncomprehensive forgery clues. Considering that forgery clues obtained from a\nsingle aspect alone may be incomplete, we construct the latent forgery feature\nby integrating several individual forgery features from multiple perspectives.\nSecond, based on the information bottleneck, the minimality-view constraint is\nimposed on the feature reasoning network to achieve an accurate and concise\nforgery feature representation that counters the interference of task-unrelated\nfeatures. Extensive experiments show the superior performance of SUMI-IFL to\nexisting state-of-the-art methods, not only on in-dataset comparisons but also\non cross-dataset comparisons.\n","authors":["Ziqi Sheng","Wei Lu","Xiangyang Luo","Jiantao Zhou","Xiaochun Cao"],"pdf_url":"https://arxiv.org/pdf/2412.09981v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09972v1","updated":"2024-12-13T08:59:18Z","published":"2024-12-13T08:59:18Z","title":"Efficient Large-Scale Traffic Forecasting with Transformers: A Spatial\n  Data Management Perspective","summary":"  Road traffic forecasting is crucial in real-world intelligent transportation\nscenarios like traffic dispatching and path planning in city management and\npersonal traveling. Spatio-temporal graph neural networks (STGNNs) stand out as\nthe mainstream solution in this task. Nevertheless, the quadratic complexity of\nremarkable dynamic spatial modeling-based STGNNs has become the bottleneck over\nlarge-scale traffic data. From the spatial data management perspective, we\npresent a novel Transformer framework called PatchSTG to efficiently and\ndynamically model spatial dependencies for large-scale traffic forecasting with\ninterpretability and fidelity. Specifically, we design a novel irregular\nspatial patching to reduce the number of points involved in the dynamic\ncalculation of Transformer. The irregular spatial patching first utilizes the\nleaf K-dimensional tree (KDTree) to recursively partition irregularly\ndistributed traffic points into leaf nodes with a small capacity, and then\nmerges leaf nodes belonging to the same subtree into occupancy-equaled and\nnon-overlapped patches through padding and backtracking. Based on the patched\ndata, depth and breadth attention are used interchangeably in the encoder to\ndynamically learn local and global spatial knowledge from points in a patch and\npoints with the same index of patches. Experimental results on four real world\nlarge-scale traffic datasets show that our PatchSTG achieves train speed and\nmemory utilization improvements up to $10\\times$ and $4\\times$ with the\nstate-of-the-art performance.\n","authors":["Yuchen Fang","Yuxuan Liang","Bo Hui","Zezhi Shao","Liwei Deng","Xu Liu","Xinke Jiang","Kai Zheng"],"pdf_url":"https://arxiv.org/pdf/2412.09972v1.pdf","comment":"Accepted by SIGKDD 2025"},{"id":"http://arxiv.org/abs/2412.09966v1","updated":"2024-12-13T08:49:25Z","published":"2024-12-13T08:49:25Z","title":"EP-CFG: Energy-Preserving Classifier-Free Guidance","summary":"  Classifier-free guidance (CFG) is widely used in diffusion models but often\nintroduces over-contrast and over-saturation artifacts at higher guidance\nstrengths. We present EP-CFG (Energy-Preserving Classifier-Free Guidance),\nwhich addresses these issues by preserving the energy distribution of the\nconditional prediction during the guidance process. Our method simply rescales\nthe energy of the guided output to match that of the conditional prediction at\neach denoising step, with an optional robust variant for improved artifact\nsuppression. Through experiments, we show that EP-CFG maintains natural image\nquality and preserves details across guidance strengths while retaining CFG's\nsemantic alignment benefits, all with minimal computational overhead.\n","authors":["Kai Zhang","Fujun Luan","Sai Bi","Jianming Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.09966v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04680v2","updated":"2024-12-13T08:44:55Z","published":"2024-08-08T04:49:21Z","title":"Dynamic Fog Computing for Enhanced LLM Execution in Medical Applications","summary":"  The ability of large language models (LLMs) to transform, interpret, and\ncomprehend vast quantities of heterogeneous data presents a significant\nopportunity to enhance data-driven care delivery. However, the sensitive nature\nof protected health information (PHI) raises valid concerns about data privacy\nand trust in remote LLM platforms. In addition, the cost associated with\ncloud-based artificial intelligence (AI) services continues to impede\nwidespread adoption. To address these challenges, we propose a shift in the LLM\nexecution environment from opaque, centralized cloud providers to a\ndecentralized and dynamic fog computing architecture. By executing open-weight\nLLMs in more trusted environments, such as the user's edge device or a fog\nlayer within a local network, we aim to mitigate the privacy, trust, and\nfinancial challenges associated with cloud-based LLMs. We further present\nSpeziLLM, an open-source framework designed to facilitate rapid and seamless\nleveraging of different LLM execution layers and lowering barriers to LLM\nintegration in digital health applications. We demonstrate SpeziLLM's broad\napplicability across six digital health applications, showcasing its\nversatility in various healthcare settings.\n","authors":["Philipp Zagar","Vishnu Ravi","Lauren Aalami","Stephan Krusche","Oliver Aalami","Paul Schmiedmayer"],"pdf_url":"https://arxiv.org/pdf/2408.04680v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09961v1","updated":"2024-12-13T08:42:19Z","published":"2024-12-13T08:42:19Z","title":"What constitutes a Deep Fake? The blurry line between legitimate\n  processing and manipulation under the EU AI Act","summary":"  When does a digital image resemble reality? The relevance of this question\nincreases as the generation of synthetic images -- so called deep fakes --\nbecomes increasingly popular. Deep fakes have gained much attention for a\nnumber of reasons -- among others, due to their potential to disrupt the\npolitical climate. In order to mitigate these threats, the EU AI Act implements\nspecific transparency regulations for generating synthetic content or\nmanipulating existing content. However, the distinction between real and\nsynthetic images is -- even from a computer vision perspective -- far from\ntrivial. We argue that the current definition of deep fakes in the AI act and\nthe corresponding obligations are not sufficiently specified to tackle the\nchallenges posed by deep fakes. By analyzing the life cycle of a digital photo\nfrom the camera sensor to the digital editing features, we find that: (1.) Deep\nfakes are ill-defined in the EU AI Act. The definition leaves too much scope\nfor what a deep fake is. (2.) It is unclear how editing functions like Google's\n``best take'' feature can be considered as an exception to transparency\nobligations. (3.) The exception for substantially edited images raises\nquestions about what constitutes substantial editing of content and whether or\nnot this editing must be perceptible by a natural person. Our results\ndemonstrate that complying with the current AI Act transparency obligations is\ndifficult for providers and deployers. As a consequence of the unclear\nprovisions, there is a risk that exceptions may be either too broad or too\nlimited. We intend our analysis to foster the discussion on what constitutes a\ndeep fake and to raise awareness about the pitfalls in the current AI Act\ntransparency obligations.\n","authors":["Kristof Meding","Christoph Sorge"],"pdf_url":"https://arxiv.org/pdf/2412.09961v1.pdf","comment":"Preprint. Accepted at ACM CS&Law '25"},{"id":"http://arxiv.org/abs/2412.09946v1","updated":"2024-12-13T08:10:56Z","published":"2024-12-13T08:10:56Z","title":"Enhancing Nursing and Elderly Care with Large Language Models: An\n  AI-Driven Framework","summary":"  This paper explores the application of large language models (LLMs) in\nnursing and elderly care, focusing on AI-driven patient monitoring and\ninteraction. We introduce a novel Chinese nursing dataset and implement\nincremental pre-training (IPT) and supervised fine-tuning (SFT) techniques to\nenhance LLM performance in specialized tasks. Using LangChain, we develop a\ndynamic nursing assistant capable of real-time care and personalized\ninterventions. Experimental results demonstrate significant improvements,\npaving the way for AI-driven solutions to meet the growing demands of\nhealthcare in aging populations.\n","authors":["Qiao Sun","Jiexin Xie","Nanyang Ye","Qinying Gu","Shijie Guo"],"pdf_url":"https://arxiv.org/pdf/2412.09946v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.09066v3","updated":"2024-12-13T07:26:51Z","published":"2024-02-14T10:24:04Z","title":"Solid Waste Detection, Monitoring and Mapping in Remote Sensing Images:\n  A Survey","summary":"  The detection and characterization of illegal solid waste disposal sites are\nessential for environmental protection, particularly for mitigating pollution\nand health hazards. Improperly managed landfills contaminate soil and\ngroundwater via rainwater infiltration, posing threats to both animals and\nhumans. Traditional landfill identification approaches, such as on-site\ninspections, are time-consuming and expensive. Remote sensing is a\ncost-effective solution for the identification and monitoring of solid waste\ndisposal sites that enables broad coverage and repeated acquisitions over time.\nEarth Observation (EO) satellites, equipped with an array of sensors and\nimaging capabilities, have been providing high-resolution data for several\ndecades. Researchers proposed specialized techniques that leverage remote\nsensing imagery to perform a range of tasks such as waste site detection,\ndumping site monitoring, and assessment of suitable locations for new\nlandfills. This review aims to provide a detailed illustration of the most\nrelevant proposals for the detection and monitoring of solid waste sites by\ndescribing and comparing the approaches, the implemented techniques, and the\nemployed data. Furthermore, since the data sources are of the utmost importance\nfor developing an effective solid waste detection model, a comprehensive\noverview of the satellites and publicly available data sets is presented.\nFinally, this paper identifies the open issues in the state-of-the-art and\ndiscusses the relevant research directions for reducing the costs and improving\nthe effectiveness of novel solid waste detection methods.\n","authors":["Piero Fraternali","Luca Morandini","Sergio Luis Herrera González"],"pdf_url":"https://arxiv.org/pdf/2402.09066v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09919v1","updated":"2024-12-13T07:13:40Z","published":"2024-12-13T07:13:40Z","title":"B-VLLM: A Vision Large Language Model with Balanced Spatio-Temporal\n  Tokens","summary":"  Recently, Vision Large Language Models (VLLMs) integrated with vision\nencoders have shown promising performance in vision understanding. The key of\nVLLMs is to encode visual content into sequences of visual tokens, enabling\nVLLMs to simultaneously process both visual and textual content. However,\nunderstanding videos, especially long videos, remain a challenge to VLLMs as\nthe number of visual tokens grows rapidly when encoding videos, resulting in\nthe risk of exceeding the context window of VLLMs and introducing heavy\ncomputation burden. To restrict the number of visual tokens, existing VLLMs\neither: (1) uniformly downsample videos into a fixed number of frames or (2)\nreducing the number of visual tokens encoded from each frame. We argue the\nformer solution neglects the rich temporal cue in videos and the later\noverlooks the spatial details in each frame. In this work, we present\nBalanced-VLLM (B-VLLM): a novel VLLM framework that aims to effectively\nleverage task relevant spatio-temporal cues while restricting the number of\nvisual tokens under the VLLM context window length. At the core of our method,\nwe devise a text-conditioned adaptive frame selection module to identify frames\nrelevant to the visual understanding task. The selected frames are then\nde-duplicated using a temporal frame token merging technique. The visual tokens\nof the selected frames are processed through a spatial token sampling module\nand an optional spatial token merging strategy to achieve precise control over\nthe token count. Experimental results show that B-VLLM is effective in\nbalancing the number of frames and visual tokens in video understanding,\nyielding superior performance on various video understanding benchmarks. Our\ncode is available at https://github.com/zhuqiangLu/B-VLLM.\n","authors":["Zhuqiang Lu","Zhenfei Yin","Mengwei He","Zhihui Wang","Zicheng Liu","Zhiyong Wang","Kun Hu"],"pdf_url":"https://arxiv.org/pdf/2412.09919v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07214v2","updated":"2024-12-13T07:08:54Z","published":"2024-12-10T06:11:23Z","title":"Towards Automated Cross-domain Exploratory Data Analysis through Large\n  Language Models","summary":"  Exploratory data analysis (EDA), coupled with SQL, is essential for data\nanalysts involved in data exploration and analysis. However, data analysts\noften encounter two primary challenges: (1) the need to craft SQL queries\nskillfully, and (2) the requirement to generate suitable visualization types\nthat enhance the interpretation of query results. Due to its significance,\nsubstantial research efforts have been made to explore different approaches to\naddress these challenges, including leveraging large language models (LLMs).\nHowever, existing methods fail to meet real-world data exploration requirements\nprimarily due to (1) complex database schema; (2) unclear user intent; (3)\nlimited cross-domain generalization capability; and (4) insufficient end-to-end\ntext-to-visualization capability.\n  This paper presents TiInsight, an automated SQL-based cross-domain\nexploratory data analysis system. First, we propose hierarchical data context\n(i.e., HDC), which leverages LLMs to summarize the contexts related to the\ndatabase schema, which is crucial for open-world EDA systems to generalize\nacross data domains. Second, the EDA system is divided into four components\n(i.e., stages): HDC generation, question clarification and decomposition,\ntext-to-SQL generation (i.e., TiSQL), and data visualization (i.e., TiChart).\nFinally, we implemented an end-to-end EDA system with a user-friendly GUI\ninterface in the production environment at PingCAP. We have also open-sourced\nall APIs of TiInsight to facilitate research within the EDA community. Through\nextensive evaluations by a real-world user study, we demonstrate that TiInsight\noffers remarkable performance compared to human experts. Specifically, TiSQL\nachieves an execution accuracy of 86.3% on the Spider dataset using GPT-4. It\nalso demonstrates state-of-the-art performance on the Bird dataset.\n","authors":["Jun-Peng Zhu","Boyan Niu","Peng Cai","Zheming Ni","Jianwei Wan","Kai Xu","Jiajun Huang","Shengbo Ma","Bing Wang","Xuan Zhou","Guanglei Bao","Donghui Zhang","Liu Tang","Qi Liu"],"pdf_url":"https://arxiv.org/pdf/2412.07214v2.pdf","comment":"14 pages, 10 figures. Submitted to SIGMOD 2025"},{"id":"http://arxiv.org/abs/2411.11930v3","updated":"2024-12-13T06:54:04Z","published":"2024-11-18T11:54:58Z","title":"AtomThink: A Slow Thinking Framework for Multimodal Mathematical\n  Reasoning","summary":"  In this paper, we address the challenging task of multimodal mathematical\nreasoning by incorporating the ability of ``slow thinking\" into multimodal\nlarge language models (MLLMs). Contrary to existing methods that rely on direct\nor fast thinking, our key idea is to construct long chains of thought (CoT)\nconsisting of atomic actions in a step-by-step manner, guiding MLLMs to perform\ncomplex reasoning. To this end, we design a novel AtomThink framework composed\nof three key modules: (i) a CoT annotation engine that automatically generates\nhigh-quality CoT annotations to address the lack of high-quality visual\nmathematical data; (ii) an atomic step fine-tuning strategy that jointly\noptimizes an MLLM and a policy reward model (PRM) for step-wise reasoning; and\n(iii) four different search strategies that can be applied with the PRM to\ncomplete reasoning. Additionally, we propose AtomMATH, a large-scale multimodal\ndataset of long CoTs, and an atomic capability evaluation metric for\nmathematical tasks. Extensive experimental results show that the proposed\nAtomThink significantly improves the performance of baseline MLLMs, achieving\napproximately 50\\% relative accuracy gains on MathVista and 120\\% on MathVerse.\nTo support the advancement of multimodal slow-thinking models, we will make our\ncode and dataset publicly available on https://github.com/Quinn777/AtomThink.\n","authors":["Kun Xiang","Zhili Liu","Zihao Jiang","Yunshuang Nie","Runhui Huang","Haoxiang Fan","Hanhui Li","Weiran Huang","Yihan Zeng","Jianhua Han","Lanqing Hong","Hang Xu","Xiaodan Liang"],"pdf_url":"https://arxiv.org/pdf/2411.11930v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.00004v3","updated":"2024-12-13T06:41:02Z","published":"2024-05-12T04:15:05Z","title":"Navigating the Future of Federated Recommendation Systems with\n  Foundation Models","summary":"  In recent years, the integration of federated learning (FL) and\nrecommendation systems (RS), known as Federated Recommendation Systems (FRS),\nhas attracted attention for preserving user privacy by keeping private data on\nclient devices. However, FRS faces inherent limitations such as data\nheterogeneity and scarcity, due to the privacy requirements of FL and the\ntypical data sparsity issues of RSs. Models like ChatGPT are empowered by the\nconcept of transfer learning and self-supervised learning, so they can be\neasily applied to the downstream tasks after fine-tuning or prompting. These\nmodels, so-called Foundation Models (FM), fouce on understanding the human's\nintent and perform following their designed roles in the specific tasks, which\nare widely recognized for producing high-quality content in the image and\nlanguage domains. Thus, the achievements of FMs inspire the design of FRS and\nsuggest a promising research direction: integrating foundation models to\naddress the above limitations. In this study, we conduct a comprehensive review\nof FRSs with FMs. Specifically, we: 1) summarise the common approaches of\ncurrent FRSs and FMs; 2) review the challenges posed by FRSs and FMs; 3)\ndiscuss potential future research directions; and 4) introduce some common\nbenchmarks and evaluation metrics in the FRS field. We hope that this position\npaper provides the necessary background and guidance to explore this\ninteresting and emerging topic.\n","authors":["Zhiwei Li","Guodong Long","Chunxu Zhang","Honglei Zhang","Jing Jiang","Chengqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.00004v3.pdf","comment":"20 pages, position paper, survey"},{"id":"http://arxiv.org/abs/2412.09896v1","updated":"2024-12-13T06:31:09Z","published":"2024-12-13T06:31:09Z","title":"Analyzing Fairness of Classification Machine Learning Model with\n  Structured Dataset","summary":"  Machine learning (ML) algorithms have become integral to decision making in\nvarious domains, including healthcare, finance, education, and law enforcement.\nHowever, concerns about fairness and bias in these systems pose significant\nethical and social challenges. This study investigates the fairness of ML\nmodels applied to structured datasets in classification tasks, highlighting the\npotential for biased predictions to perpetuate systemic inequalities. A\npublicly available dataset from Kaggle was selected for analysis, offering a\nrealistic scenario for evaluating fairness in machine learning workflows.\n  To assess and mitigate biases, three prominent fairness libraries; Fairlearn\nby Microsoft, AIF360 by IBM, and the What If Tool by Google were employed.\nThese libraries provide robust frameworks for analyzing fairness, offering\ntools to evaluate metrics, visualize results, and implement bias mitigation\nstrategies. The research aims to assess the extent of bias in the ML models,\ncompare the effectiveness of these libraries, and derive actionable insights\nfor practitioners.\n  The findings reveal that each library has unique strengths and limitations in\nfairness evaluation and mitigation. By systematically comparing their\ncapabilities, this study contributes to the growing field of ML fairness by\nproviding practical guidance for integrating fairness tools into real world\napplications. These insights are intended to support the development of more\nequitable machine learning systems.\n","authors":["Ahmed Rashed","Abdelkrim Kallich","Mohamed Eltayeb"],"pdf_url":"https://arxiv.org/pdf/2412.09896v1.pdf","comment":"12 pages, 3 tables"},{"id":"http://arxiv.org/abs/2412.09263v2","updated":"2024-12-13T06:28:11Z","published":"2024-12-12T13:21:09Z","title":"First Train to Generate, then Generate to Train: UnitedSynT5 for\n  Few-Shot NLI","summary":"  Natural Language Inference (NLI) tasks require identifying the relationship\nbetween sentence pairs, typically classified as entailment, contradiction, or\nneutrality. While the current state-of-the-art (SOTA) model, Entailment\nFew-Shot Learning (EFL), achieves a 93.1% accuracy on the Stanford Natural\nLanguage Inference (SNLI) dataset, further advancements are constrained by the\ndataset's limitations. To address this, we propose a novel approach leveraging\nsynthetic data augmentation to enhance dataset diversity and complexity. We\npresent UnitedSynT5, an advanced extension of EFL that leverages a T5-based\ngenerator to synthesize additional premise-hypothesis pairs, which are\nrigorously cleaned and integrated into the training data. These augmented\nexamples are processed within the EFL framework, embedding labels directly into\nhypotheses for consistency. We train a GTR-T5-XL model on this expanded\ndataset, achieving a new benchmark of 94.7% accuracy on the SNLI dataset, 94.0%\naccuracy on the E-SNLI dataset, and 92.6% accuracy on the MultiNLI dataset,\nsurpassing the previous SOTA models. This research demonstrates the potential\nof synthetic data augmentation in improving NLI models, offering a path forward\nfor further advancements in natural language understanding tasks.\n","authors":["Sourav Banerjee","Anush Mahajan","Ayushi Agarwal","Eishkaran Singh"],"pdf_url":"https://arxiv.org/pdf/2412.09263v2.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2408.01129v5","updated":"2024-12-13T06:16:06Z","published":"2024-08-02T09:18:41Z","title":"A Survey of Mamba","summary":"  As one of the most representative DL techniques, Transformer architecture has\nempowered numerous advanced models, especially the large language models (LLMs)\nthat comprise billions of parameters, becoming a cornerstone in deep learning.\nDespite the impressive achievements, Transformers still face inherent\nlimitations, particularly the time-consuming inference resulting from the\nquadratic computation complexity of attention calculation. Recently, a novel\narchitecture named Mamba, drawing inspiration from classical state space models\n(SSMs), has emerged as a promising alternative for building foundation models,\ndelivering comparable modeling abilities to Transformers while preserving\nnear-linear scalability concerning sequence length. This has sparked an\nincreasing number of studies actively exploring Mamba's potential to achieve\nimpressive performance across diverse domains. Given such rapid evolution,\nthere is a critical need for a systematic review that consolidates existing\nMamba-empowered models, offering a comprehensive understanding of this emerging\nmodel architecture. In this survey, we therefore conduct an in-depth\ninvestigation of recent Mamba-associated studies, covering three main aspects:\nthe advancements of Mamba-based models, the techniques of adapting Mamba to\ndiverse data, and the applications where Mamba can excel. Specifically, we\nfirst review the foundational knowledge of various representative deep learning\nmodels and the details of Mamba-1&2 as preliminaries. Then, to showcase the\nsignificance of Mamba for AI, we comprehensively review the related studies\nfocusing on Mamba models' architecture design, data adaptability, and\napplications. Finally, we present a discussion of current limitations and\nexplore various promising research directions to provide deeper insights for\nfuture investigations.\n","authors":["Haohao Qu","Liangbo Ning","Rui An","Wenqi Fan","Tyler Derr","Hui Liu","Xin Xu","Qing Li"],"pdf_url":"https://arxiv.org/pdf/2408.01129v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09889v1","updated":"2024-12-13T06:06:49Z","published":"2024-12-13T06:06:49Z","title":"Semi-Periodic Activation for Time Series Classification","summary":"  This paper investigates the lack of research on activation functions for\nneural network models in time series tasks. It highlights the need to identify\nessential properties of these activations to improve their effectiveness in\nspecific domains. To this end, the study comprehensively analyzes properties,\nsuch as bounded, monotonic, nonlinearity, and periodicity, for activation in\ntime series neural networks. We propose a new activation that maximizes the\ncoverage of these properties, called LeakySineLU. We empirically evaluate the\nLeakySineLU against commonly used activations in the literature using 112\nbenchmark datasets for time series classification, obtaining the best average\nranking in all comparative scenarios.\n","authors":["José Gilberto Barbosa de Medeiros Júnior","Andre Guarnier de Mitri","Diego Furtado Silva"],"pdf_url":"https://arxiv.org/pdf/2412.09889v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09887v1","updated":"2024-12-13T06:05:53Z","published":"2024-12-13T06:05:53Z","title":"CSL-L2M: Controllable Song-Level Lyric-to-Melody Generation Based on\n  Conditional Transformer with Fine-Grained Lyric and Musical Controls","summary":"  Lyric-to-melody generation is a highly challenging task in the field of AI\nmusic generation. Due to the difficulty of learning strict yet weak\ncorrelations between lyrics and melodies, previous methods have suffered from\nweak controllability, low-quality and poorly structured generation. To address\nthese challenges, we propose CSL-L2M, a controllable song-level lyric-to-melody\ngeneration method based on an in-attention Transformer decoder with\nfine-grained lyric and musical controls, which is able to generate full-song\nmelodies matched with the given lyrics and user-specified musical attributes.\nSpecifically, we first introduce REMI-Aligned, a novel music representation\nthat incorporates strict syllable- and sentence-level alignments between lyrics\nand melodies, facilitating precise alignment modeling. Subsequently,\nsentence-level semantic lyric embeddings independently extracted from a\nsentence-wise Transformer encoder are combined with word-level part-of-speech\nembeddings and syllable-level tone embeddings as fine-grained controls to\nenhance the controllability of lyrics over melody generation. Then we introduce\nhuman-labeled musical tags, sentence-level statistical musical attributes, and\nlearned musical features extracted from a pre-trained VQ-VAE as coarse-grained,\nfine-grained and high-fidelity controls, respectively, to the generation\nprocess, thereby enabling user control over melody generation. Finally, an\nin-attention Transformer decoder technique is leveraged to exert fine-grained\ncontrol over the full-song melody generation with the aforementioned lyric and\nmusical conditions. Experimental results demonstrate that our proposed CSL-L2M\noutperforms the state-of-the-art models, generating melodies with higher\nquality, better controllability and enhanced structure. Demos and source code\nare available at https://lichaiustc.github.io/CSL-L2M/.\n","authors":["Li Chai","Donglin Wang"],"pdf_url":"https://arxiv.org/pdf/2412.09887v1.pdf","comment":"Accepted at AAAI-25"},{"id":"http://arxiv.org/abs/2411.08299v3","updated":"2024-12-13T05:48:45Z","published":"2024-11-13T02:41:02Z","title":"DNN Task Assignment in UAV Networks: A Generative AI Enhanced\n  Multi-Agent Reinforcement Learning Approach","summary":"  Unmanned Aerial Vehicles (UAVs) possess high mobility and flexible deployment\ncapabilities, prompting the development of UAVs for various application\nscenarios within the Internet of Things (IoT). The unique capabilities of UAVs\ngive rise to increasingly critical and complex tasks in uncertain and\npotentially harsh environments. The substantial amount of data generated from\nthese applications necessitates processing and analysis through deep neural\nnetworks (DNNs). However, UAVs encounter challenges due to their limited\ncomputing resources when managing DNN models. This paper presents a joint\napproach that combines multiple-agent reinforcement learning (MARL) and\ngenerative diffusion models (GDM) for assigning DNN tasks to a UAV swarm, aimed\nat reducing latency from task capture to result output. To address these\nchallenges, we first consider the task size of the target area to be inspected\nand the shortest flying path as optimization constraints, employing a greedy\nalgorithm to resolve the subproblem with a focus on minimizing the UAV's flying\npath and the overall system cost. In the second stage, we introduce a novel DNN\ntask assignment algorithm, termed GDM-MADDPG, which utilizes the reverse\ndenoising process of GDM to replace the actor network in multi-agent deep\ndeterministic policy gradient (MADDPG). This approach generates specific DNN\ntask assignment actions based on agents' observations in a dynamic environment.\nSimulation results indicate that our algorithm performs favorably compared to\nbenchmarks in terms of path planning, Age of Information (AoI), energy\nconsumption, and task load balancing.\n","authors":["Xin Tang","Qian Chen","Wenjie Weng","Binhan Liao","Jiacheng Wang","Xianbin Cao","Xiaohuan Li"],"pdf_url":"https://arxiv.org/pdf/2411.08299v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09860v1","updated":"2024-12-13T05:00:57Z","published":"2024-12-13T05:00:57Z","title":"Brain-inspired Chaotic Graph Backpropagation for Large-scale\n  Combinatorial Optimization","summary":"  Graph neural networks (GNNs) with unsupervised learning can solve large-scale\ncombinatorial optimization problems (COPs) with efficient time complexity,\nmaking them versatile for various applications. However, since this method maps\nthe combinatorial optimization problem to the training process of a graph\nneural network, and the current mainstream backpropagation-based training\nalgorithms are prone to fall into local minima, the optimization performance is\nstill inferior to the current state-of-the-art (SOTA) COP methods. To address\nthis issue, inspired by possibly chaotic dynamics of real brain learning, we\nintroduce a chaotic training algorithm, i.e. chaotic graph backpropagation\n(CGBP), which introduces a local loss function in GNN that makes the training\nprocess not only chaotic but also highly efficient. Different from existing\nmethods, we show that the global ergodicity and pseudo-randomness of such\nchaotic dynamics enable CGBP to learn each optimal GNN effectively and\nglobally, thus solving the COP efficiently. We have applied CGBP to solve\nvarious COPs, such as the maximum independent set, maximum cut, and graph\ncoloring. Results on several large-scale benchmark datasets showcase that CGBP\ncan outperform not only existing GNN algorithms but also SOTA methods. In\naddition to solving large-scale COPs, CGBP as a universal learning algorithm\nfor GNNs, i.e. as a plug-in unit, can be easily integrated into any existing\nmethod for improving the performance.\n","authors":["Peng Tao","Kazuyuki Aihara","Luonan Chen"],"pdf_url":"https://arxiv.org/pdf/2412.09860v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09858v1","updated":"2024-12-13T04:57:55Z","published":"2024-12-13T04:57:55Z","title":"RLDG: Robotic Generalist Policy Distillation via Reinforcement Learning","summary":"  Recent advances in robotic foundation models have enabled the development of\ngeneralist policies that can adapt to diverse tasks. While these models show\nimpressive flexibility, their performance heavily depends on the quality of\ntheir training data. In this work, we propose Reinforcement Learning Distilled\nGeneralists (RLDG), a method that leverages reinforcement learning to generate\nhigh-quality training data for finetuning generalist policies. Through\nextensive real-world experiments on precise manipulation tasks like connector\ninsertion and assembly, we demonstrate that generalist policies trained with\nRL-generated data consistently outperform those trained with human\ndemonstrations, achieving up to 40% higher success rates while generalizing\nbetter to new tasks. We also provide a detailed analysis that reveals this\nperformance gain stems from both optimized action distributions and improved\nstate coverage. Our results suggest that combining task-specific RL with\ngeneralist policy distillation offers a promising approach for developing more\ncapable and efficient robotic manipulation systems that maintain the\nflexibility of foundation models while achieving the performance of specialized\ncontrollers. Videos and code can be found on our project website\nhttps://generalist-distillation.github.io\n","authors":["Charles Xu","Qiyang Li","Jianlan Luo","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2412.09858v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09856v1","updated":"2024-12-13T04:55:10Z","published":"2024-12-13T04:55:10Z","title":"LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation\n  with Linear Computational Complexity","summary":"  Text-to-video generation enhances content creation but is highly\ncomputationally intensive: The computational cost of Diffusion Transformers\n(DiTs) scales quadratically in the number of pixels. This makes minute-length\nvideo generation extremely expensive, limiting most existing models to\ngenerating videos of only 10-20 seconds length. We propose a Linear-complexity\ntext-to-video Generation (LinGen) framework whose cost scales linearly in the\nnumber of pixels. For the first time, LinGen enables high-resolution\nminute-length video generation on a single GPU without compromising quality. It\nreplaces the computationally-dominant and quadratic-complexity block,\nself-attention, with a linear-complexity block called MATE, which consists of\nan MA-branch and a TE-branch. The MA-branch targets short-to-long-range\ncorrelations, combining a bidirectional Mamba2 block with our token\nrearrangement method, Rotary Major Scan, and our review tokens developed for\nlong video generation. The TE-branch is a novel TEmporal Swin Attention block\nthat focuses on temporal correlations between adjacent tokens and medium-range\ntokens. The MATE block addresses the adjacency preservation issue of Mamba and\nimproves the consistency of generated videos significantly. Experimental\nresults show that LinGen outperforms DiT (with a 75.6% win rate) in video\nquality with up to 15$\\times$ (11.5$\\times$) FLOPs (latency) reduction.\nFurthermore, both automatic metrics and human evaluation demonstrate our\nLinGen-4B yields comparable video quality to state-of-the-art models (with a\n50.5%, 52.1%, 49.1% win rate with respect to Gen-3, LumaLabs, and Kling,\nrespectively). This paves the way to hour-length movie generation and real-time\ninteractive video generation. We provide 68s video generation results and more\nexamples in our project website: https://lineargen.github.io/.\n","authors":["Hongjie Wang","Chih-Yao Ma","Yen-Cheng Liu","Ji Hou","Tao Xu","Jialiang Wang","Felix Juefei-Xu","Yaqiao Luo","Peizhao Zhang","Tingbo Hou","Peter Vajda","Niraj K. Jha","Xiaoliang Dai"],"pdf_url":"https://arxiv.org/pdf/2412.09856v1.pdf","comment":"20 pages, 20 figures"},{"id":"http://arxiv.org/abs/2409.19454v4","updated":"2024-12-13T04:44:31Z","published":"2024-09-28T20:40:18Z","title":"See Where You Read with Eye Gaze Tracking and Large Language Model","summary":"  Losing track of reading progress during line switching can be frustrating.\nEye gaze tracking technology offers a potential solution by highlighting read\nparagraphs, aiding users in avoiding wrong line switches. However, the gap\nbetween gaze tracking accuracy (2-3 cm) and text line spacing (3-5 mm) makes\ndirect application impractical. Existing methods leverage the linear reading\npattern but fail during jump reading. This paper presents a reading tracking\nand highlighting system that supports both linear and jump reading. Based on\nexperimental insights from the gaze nature study of 16 users, two gaze error\nmodels are designed to enable both jump reading detection and relocation. The\nsystem further leverages the large language model's contextual perception\ncapability in aiding reading tracking. A reading tracking domain-specific\nline-gaze alignment opportunity is also exploited to enable dynamic and\nfrequent calibration of the gaze results. Controlled experiments demonstrate\nreliable linear reading tracking, as well as 84% accuracy in tracking jump\nreading. Furthermore, real field tests with 18 volunteers demonstrated the\nsystem's effectiveness in tracking and highlighting read paragraphs, improving\nreading efficiency, and enhancing user experience.\n","authors":["Sikai Yang","Gang Yan","Wan Du"],"pdf_url":"https://arxiv.org/pdf/2409.19454v4.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2403.12196v3","updated":"2024-12-13T04:41:50Z","published":"2024-03-18T19:10:12Z","title":"Leveraging Large Language Models to Detect npm Malicious Packages","summary":"  Existing malicious code detection techniques demand the integration of\nmultiple tools to detect different malware patterns, often suffering from high\nmisclassification rates. Therefore, malicious code detection techniques could\nbe enhanced by adopting advanced, more automated approaches to achieve high\naccuracy and a low misclassification rate. The goal of this study is to aid\nsecurity analysts in detecting malicious packages by empirically studying the\neffectiveness of Large Language Models (LLMs) in detecting malicious code. We\npresent SocketAI, a malicious code review workflow to detect malicious code. To\nevaluate the effectiveness of SocketAI, we leverage a benchmark dataset of\n5,115 npm packages, of which 2,180 packages have malicious code. We conducted a\nbaseline comparison of GPT-3 and GPT-4 models with the state-of-the-art CodeQL\nstatic analysis tool, using 39 custom CodeQL rules developed in prior research\nto detect malicious Javascript code. We also compare the effectiveness of\nstatic analysis as a pre-screener with SocketAI workflow, measuring the number\nof files that need to be analyzed. and the associated costs. Additionally, we\nperformed a qualitative study to understand the types of malicious activities\ndetected or missed by our workflow. Our baseline comparison demonstrates a 16%\nand 9% improvement over static analysis in precision and F1 scores,\nrespectively. GPT-4 achieves higher accuracy with 99% precision and 97% F1\nscores, while GPT-3 offers a more cost-effective balance at 91% precision and\n94% F1 scores. Pre-screening files with a static analyzer reduces the number of\nfiles requiring LLM analysis by 77.9% and decreases costs by 60.9% for GPT-3\nand 76.1% for GPT-4. Our qualitative analysis identified data theft, suspicious\ndomain connection, and arbitrary code execution as the top detected malicious\nactivities.\n","authors":["Nusrat Zahan","Philipp Burckhardt","Mikola Lysenko","Feross Aboukhadijeh","Laurie Williams"],"pdf_url":"https://arxiv.org/pdf/2403.12196v3.pdf","comment":"13 pages, 2 Figure, 6 tables"},{"id":"http://arxiv.org/abs/2412.09849v1","updated":"2024-12-13T04:36:05Z","published":"2024-12-13T04:36:05Z","title":"Deep Learning for Spectrum Prediction in Cognitive Radio Networks:\n  State-of-the-Art, New Opportunities, and Challenges","summary":"  Spectrum prediction is considered to be a promising technology that enhances\nspectrum efficiency by assisting dynamic spectrum access (DSA) in cognitive\nradio networks (CRN). Nonetheless, the highly nonlinear nature of spectrum data\nacross time, frequency, and space domains, coupled with the intricate spectrum\nusage patterns, poses challenges for accurate spectrum prediction. Deep\nlearning (DL), recognized for its capacity to extract nonlinear features, has\nbeen applied to solve these challenges. This paper first shows the advantages\nof applying DL by comparing with traditional prediction methods. Then, the\ncurrent state-of-the-art DL-based spectrum prediction techniques are reviewed\nand summarized in terms of intra-band and crossband prediction. Notably, this\npaper uses a real-world spectrum dataset to prove the advancements of DL-based\nmethods. Then, this paper proposes a novel intra-band spatiotemporal spectrum\nprediction framework named ViTransLSTM. This framework integrates visual\nself-attention and long short-term memory to capture both local and global\nlong-term spatiotemporal dependencies of spectrum usage patterns. Similarly,\nthe effectiveness of the proposed framework is validated on the aforementioned\nreal-world dataset. Finally, the paper presents new related challenges and\npotential opportunities for future research.\n","authors":["Guangliang Pan","David K. Y. Yau","Bo Zhou","Qihui Wu"],"pdf_url":"https://arxiv.org/pdf/2412.09849v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09843v1","updated":"2024-12-13T04:25:56Z","published":"2024-12-13T04:25:56Z","title":"Learning Structural Causal Models from Ordering: Identifiable Flow\n  Models","summary":"  In this study, we address causal inference when only observational data and a\nvalid causal ordering from the causal graph are available. We introduce a set\nof flow models that can recover component-wise, invertible transformation of\nexogenous variables. Our flow-based methods offer flexible model design while\nmaintaining causal consistency regardless of the number of discretization\nsteps. We propose design improvements that enable simultaneous learning of all\ncausal mechanisms and reduce abduction and prediction complexity to linear O(n)\nrelative to the number of layers, independent of the number of causal\nvariables. Empirically, we demonstrate that our method outperforms previous\nstate-of-the-art approaches and delivers consistent performance across a wide\nrange of structural causal models in answering observational, interventional,\nand counterfactual questions. Additionally, our method achieves a significant\nreduction in computational time compared to existing diffusion-based\ntechniques, making it practical for large structural causal models.\n","authors":["Minh Khoa Le","Kien Do","Truyen Tran"],"pdf_url":"https://arxiv.org/pdf/2412.09843v1.pdf","comment":"Accepted at AAAI 2025"},{"id":"http://arxiv.org/abs/2412.07144v2","updated":"2024-12-13T04:05:05Z","published":"2024-12-10T03:06:28Z","title":"Political Actor Agent: Simulating Legislative System for Roll Call Votes\n  Prediction with Large Language Models","summary":"  Predicting roll call votes through modeling political actors has emerged as a\nfocus in quantitative political science and computer science. Widely used\nembedding-based methods generate vectors for legislators from diverse data sets\nto predict legislative behaviors. However, these methods often contend with\nchallenges such as the need for manually predefined features, reliance on\nextensive training data, and a lack of interpretability. Achieving more\ninterpretable predictions under flexible conditions remains an unresolved\nissue. This paper introduces the Political Actor Agent (PAA), a novel\nagent-based framework that utilizes Large Language Models to overcome these\nlimitations. By employing role-playing architectures and simulating legislative\nsystem, PAA provides a scalable and interpretable paradigm for predicting\nroll-call votes. Our approach not only enhances the accuracy of predictions but\nalso offers multi-view, human-understandable decision reasoning, providing new\ninsights into political actor behaviors. We conducted comprehensive experiments\nusing voting records from the 117-118th U.S. House of Representatives,\nvalidating the superior performance and interpretability of PAA. This study not\nonly demonstrates PAA's effectiveness but also its potential in political\nscience research.\n","authors":["Hao Li","Ruoyuan Gong","Hao Jiang"],"pdf_url":"https://arxiv.org/pdf/2412.07144v2.pdf","comment":"Accepted at AAAI 2025"},{"id":"http://arxiv.org/abs/2412.08894v2","updated":"2024-12-13T04:03:14Z","published":"2024-12-12T03:14:50Z","title":"SMMF: Square-Matricized Momentum Factorization for Memory-Efficient\n  Optimization","summary":"  We propose SMMF (Square-Matricized Momentum Factorization), a\nmemory-efficient optimizer that reduces the memory requirement of the widely\nused adaptive learning rate optimizers, such as Adam, by up to 96%. SMMF\nenables flexible and efficient factorization of an arbitrary rank (shape) of\nthe first and second momentum tensors during optimization, based on the\nproposed square-matricization and one-time single matrix factorization. From\nthis, it becomes effectively applicable to any rank (shape) of momentum\ntensors, i.e., bias, matrix, and any rank-d tensors, prevalent in various deep\nmodel architectures, such as CNNs (high rank) and Transformers (low rank), in\ncontrast to existing memory-efficient optimizers that applies only to a\nparticular (rank-2) momentum tensor, e.g., linear layers. We conduct a regret\nbound analysis of SMMF, which shows that it converges similarly to\nnon-memory-efficient adaptive learning rate optimizers, such as AdamNC,\nproviding a theoretical basis for its competitive optimization capability. In\nour experiment, SMMF takes up to 96% less memory compared to state-of-the-art\nmemory efficient optimizers, e.g., Adafactor, CAME, and SM3, while achieving\ncomparable model performance on various CNN and Transformer tasks.\n","authors":["Kwangryeol Park","Seulki Lee"],"pdf_url":"https://arxiv.org/pdf/2412.08894v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.05025v3","updated":"2024-12-13T03:49:02Z","published":"2024-03-08T04:03:54Z","title":"Debiased Multimodal Understanding for Human Language Sequences","summary":"  Human multimodal language understanding (MLU) is an indispensable component\nof expression analysis (e.g., sentiment or humor) from heterogeneous\nmodalities, including visual postures, linguistic contents, and acoustic\nbehaviours. Existing works invariably focus on designing sophisticated\nstructures or fusion strategies to achieve impressive improvements.\nUnfortunately, they all suffer from the subject variation problem due to data\ndistribution discrepancies among subjects. Concretely, MLU models are easily\nmisled by distinct subjects with different expression customs and\ncharacteristics in the training data to learn subject-specific spurious\ncorrelations, limiting performance and generalizability across new subjects.\nMotivated by this observation, we introduce a recapitulative causal graph to\nformulate the MLU procedure and analyze the confounding effect of subjects.\nThen, we propose SuCI, a simple yet effective causal intervention module to\ndisentangle the impact of subjects acting as unobserved confounders and achieve\nmodel training via true causal effects. As a plug-and-play component, SuCI can\nbe widely applied to most methods that seek unbiased predictions. Comprehensive\nexperiments on several MLU benchmarks clearly show the effectiveness of the\nproposed module.\n","authors":["Zhi Xu","Dingkang Yang","Mingcheng Li","Yuzheng Wang","Zhaoyu Chen","Jiawei Chen","Jinjie Wei","Lihua Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.05025v3.pdf","comment":"Accepted by AAAI2025"},{"id":"http://arxiv.org/abs/2412.09826v1","updated":"2024-12-13T03:36:23Z","published":"2024-12-13T03:36:23Z","title":"Precise Antigen-Antibody Structure Predictions Enhance Antibody\n  Development with HelixFold-Multimer","summary":"  The accurate prediction of antigen-antibody structures is essential for\nadvancing immunology and therapeutic development, as it helps elucidate\nmolecular interactions that underlie immune responses. Despite recent progress\nwith deep learning models like AlphaFold and RoseTTAFold, accurately modeling\nantigen-antibody complexes remains a challenge due to their unique evolutionary\ncharacteristics. HelixFold-Multimer, a specialized model developed for this\npurpose, builds on the framework of AlphaFold-Multimer and demonstrates\nimproved precision for antigen-antibody structures. HelixFold-Multimer not only\nsurpasses other models in accuracy but also provides essential insights into\nantibody development, enabling more precise identification of binding sites,\nimproved interaction prediction, and enhanced design of therapeutic antibodies.\nThese advances underscore HelixFold-Multimer's potential in supporting antibody\nresearch and therapeutic innovation.\n","authors":["Jie Gao","Jing Hu","Lihang Liu","Yang Xue","Kunrui Zhu","Xiaonan Zhang","Xiaomin Fang"],"pdf_url":"https://arxiv.org/pdf/2412.09826v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09237v2","updated":"2024-12-13T03:33:38Z","published":"2024-12-12T12:47:09Z","title":"LMAgent: A Large-scale Multimodal Agents Society for Multi-user\n  Simulation","summary":"  The believable simulation of multi-user behavior is crucial for understanding\ncomplex social systems. Recently, large language models (LLMs)-based AI agents\nhave made significant progress, enabling them to achieve human-like\nintelligence across various tasks. However, real human societies are often\ndynamic and complex, involving numerous individuals engaging in multimodal\ninteractions. In this paper, taking e-commerce scenarios as an example, we\npresent LMAgent, a very large-scale and multimodal agents society based on\nmultimodal LLMs. In LMAgent, besides freely chatting with friends, the agents\ncan autonomously browse, purchase, and review products, even perform live\nstreaming e-commerce. To simulate this complex system, we introduce a\nself-consistency prompting mechanism to augment agents' multimodal\ncapabilities, resulting in significantly improved decision-making performance\nover the existing multi-agent system. Moreover, we propose a fast memory\nmechanism combined with the small-world model to enhance system efficiency,\nwhich supports more than 10,000 agent simulations in a society. Experiments on\nagents' behavior show that these agents achieve comparable performance to\nhumans in behavioral indicators. Furthermore, compared with the existing\nLLMs-based multi-agent system, more different and valuable phenomena are\nexhibited, such as herd behavior, which demonstrates the potential of LMAgent\nin credible large-scale social behavior simulations.\n","authors":["Yijun Liu","Wu Liu","Xiaoyan Gu","Yong Rui","Xiaodong He","Yongdong Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.09237v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09818v1","updated":"2024-12-13T03:15:05Z","published":"2024-12-13T03:15:05Z","title":"MERaLiON-AudioLLM: Technical Report","summary":"  We introduce MERaLiON-AudioLLM (Multimodal Empathetic Reasoning and Learning\nin One Network), the first speech-text model tailored for Singapore's\nmultilingual and multicultural landscape. Developed under the National Large\nLanguage Models Funding Initiative, Singapore, MERaLiON-AudioLLM integrates\nadvanced speech and text processing to address the diverse linguistic nuances\nof local accents and dialects, enhancing accessibility and usability in\ncomplex, multilingual environments. Our results demonstrate improvements in\nboth speech recognition and task-specific understanding, positioning\nMERaLiON-AudioLLM as a pioneering solution for region specific AI applications.\nWe envision this release to set a precedent for future models designed to\naddress localised linguistic and cultural contexts in a global framework.\n","authors":["Yingxu He","Zhuohan Liu","Shuo Sun","Bin Wang","Wenyu Zhang","Xunlong Zou","Nancy F. Chen","Ai Ti Aw"],"pdf_url":"https://arxiv.org/pdf/2412.09818v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09814v1","updated":"2024-12-13T03:09:35Z","published":"2024-12-13T03:09:35Z","title":"Temporal Causal Discovery in Dynamic Bayesian Networks Using Federated\n  Learning","summary":"  Traditionally, learning the structure of a Dynamic Bayesian Network has been\ncentralized, with all data pooled in one location. However, in real-world\nscenarios, data are often dispersed among multiple parties (e.g., companies,\ndevices) that aim to collaboratively learn a Dynamic Bayesian Network while\npreserving their data privacy and security. In this study, we introduce a\nfederated learning approach for estimating the structure of a Dynamic Bayesian\nNetwork from data distributed horizontally across different parties. We propose\na distributed structure learning method that leverages continuous optimization\nso that only model parameters are exchanged during optimization. Experimental\nresults on synthetic and real datasets reveal that our method outperforms other\nstate-of-the-art techniques, particularly when there are many clients with\nlimited individual sample sizes.\n","authors":["Jianhong Chen","Ying Ma","Xubo Yue"],"pdf_url":"https://arxiv.org/pdf/2412.09814v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2412.08901v2","updated":"2024-12-13T02:55:30Z","published":"2024-12-12T03:25:13Z","title":"Radiology Report Generation via Multi-objective Preference Optimization","summary":"  Automatic Radiology Report Generation (RRG) is an important topic for\nalleviating the substantial workload of radiologists. Existing RRG approaches\nrely on supervised regression based on different architectures or additional\nknowledge injection,while the generated report may not align optimally with\nradiologists' preferences. Especially, since the preferences of radiologists\nare inherently heterogeneous and multidimensional, e.g., some may prioritize\nreport fluency, while others emphasize clinical accuracy. To address this\nproblem,we propose a new RRG method via Multi-objective Preference Optimization\n(MPO) to align the pre-trained RRG model with multiple human preferences, which\ncan be formulated by multi-dimensional reward functions and optimized by\nmulti-objective reinforcement learning (RL). Specifically, we use a preference\nvector to represent the weight of preferences and use it as a condition for the\nRRG model. Then, a linearly weighed reward is obtained via a dot product\nbetween the preference vector and multi-dimensional reward. Next,the RRG model\nis optimized to align with the preference vector by optimizing such a reward\nvia RL. In the training stage,we randomly sample diverse preference vectors\nfrom the preference space and align the model by optimizing the weighted\nmulti-objective rewards, which leads to an optimal policy on the entire\npreference space. When inference,our model can generate reports aligned with\nspecific preferences without further fine-tuning. Extensive experiments on two\npublic datasets show the proposed method can generate reports that cater to\ndifferent preferences in a single model and achieve state-of-the-art\nperformance.\n","authors":["Ting Xiao","Lei Shi","Peng Liu","Zhe Wang","Chenjia Bai"],"pdf_url":"https://arxiv.org/pdf/2412.08901v2.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2404.03514v2","updated":"2024-12-13T02:45:14Z","published":"2024-04-04T15:21:22Z","title":"Embedding-Informed Adaptive Retrieval-Augmented Generation of Large\n  Language Models","summary":"  Retrieval-augmented large language models (LLMs) have been remarkably\ncompetent in various NLP tasks. However, it was observed by previous works that\nretrieval is not always helpful, especially when the LLM is already\nknowledgeable on the query to answer. Motivated by this, Adaptive\nRetrieval-Augmented Generation (ARAG) studies retrieving only when the\nknowledge asked by the query is absent in the LLM. Previous works of ARAG\neither require accessing the pre-training corpus or prompting with additional\nmodel inferences. Aiming to avoid such drawbacks, we propose to determine\nwhether the model is knowledgeable on a query via inspecting the\n(contextualized) pre-trained token embeddings of LLMs. We hypothesize that such\nembeddings capture rich information on the model's intrinsic knowledge base,\nwhich enables an efficient way of judging the necessity to retrieve from an\nexternal corpus. Extensive experiments demonstrate our ARAG approach's superior\nperformance across various benchmarks.\n","authors":["Chengkai Huang","Yu Xia","Rui Wang","Kaige Xie","Tong Yu","Julian McAuley","Lina Yao"],"pdf_url":"https://arxiv.org/pdf/2404.03514v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09805v1","updated":"2024-12-13T02:44:47Z","published":"2024-12-13T02:44:47Z","title":"Universal Inceptive GNNs by Eliminating the Smoothness-generalization\n  Dilemma","summary":"  Graph Neural Networks (GNNs) have demonstrated remarkable success in various\ndomains, such as transaction and social net-works. However, their application\nis often hindered by the varyinghomophily levels across different orders of\nneighboring nodes, ne-cessitating separate model designs for homophilic and\nheterophilicgraphs. In this paper, we aim to develop a unified framework\nca-pable of handling neighborhoods of various orders and homophilylevels.\nThrough theoretical exploration, we identify a previouslyoverlooked\narchitectural aspect in multi-hop learning: the cascadedependency, which leads\nto asmoothness-generalization dilemma.This dilemma significantly affects the\nlearning process, especiallyin the context of high-order neighborhoods and\nheterophilic graphs.To resolve this issue, we propose an Inceptive Graph Neural\nNet-work (IGNN), a universal message-passing framework that replacesthe cascade\ndependency with an inceptive architecture. IGNN pro-vides independent\nrepresentations for each hop, allowing personal-ized generalization\ncapabilities, and captures neighborhood-wiserelationships to select appropriate\nreceptive fields. Extensive ex-periments show that our IGNN outperforms 23\nbaseline methods,demonstrating superior performance on both homophilic and\nhet-erophilic graphs, while also scaling efficiently to large graphs.\n","authors":["Ming Gu","Zhuonan Zheng","Sheng Zhou","Meihan Liu","Jiawei Chen","Tanyu Qiao","Liangcheng Li","Jiajun Bu"],"pdf_url":"https://arxiv.org/pdf/2412.09805v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2412.09799v1","updated":"2024-12-13T02:36:29Z","published":"2024-12-13T02:36:29Z","title":"CP-DETR: Concept Prompt Guide DETR Toward Stronger Universal Object\n  Detection","summary":"  Recent research on universal object detection aims to introduce language in a\nSoTA closed-set detector and then generalize the open-set concepts by\nconstructing large-scale (text-region) datasets for training. However, these\nmethods face two main challenges: (i) how to efficiently use the prior\ninformation in the prompts to genericise objects and (ii) how to reduce\nalignment bias in the downstream tasks, both leading to sub-optimal performance\nin some scenarios beyond pre-training. To address these challenges, we propose\na strong universal detection foundation model called CP-DETR, which is\ncompetitive in almost all scenarios, with only one pre-training weight.\nSpecifically, we design an efficient prompt visual hybrid encoder that enhances\nthe information interaction between prompt and visual through scale-by-scale\nand multi-scale fusion modules. Then, the hybrid encoder is facilitated to\nfully utilize the prompted information by prompt multi-label loss and auxiliary\ndetection head. In addition to text prompts, we have designed two practical\nconcept prompt generation methods, visual prompt and optimized prompt, to\nextract abstract concepts through concrete visual examples and stably reduce\nalignment bias in downstream tasks. With these effective designs, CP-DETR\ndemonstrates superior universal detection performance in a broad spectrum of\nscenarios. For example, our Swin-T backbone model achieves 47.6 zero-shot AP on\nLVIS, and the Swin-L backbone model achieves 32.2 zero-shot AP on ODinW35.\nFurthermore, our visual prompt generation method achieves 68.4 AP on COCO val\nby interactive detection, and the optimized prompt achieves 73.1 fully-shot AP\non ODinW13.\n","authors":["Qibo Chen","Weizhong Jin","Jianyue Ge","Mengdi Liu","Yuchao Yan","Jian Jiang","Li Yu","Xuanjiang Guo","Shuchang Li","Jianzhong Chen"],"pdf_url":"https://arxiv.org/pdf/2412.09799v1.pdf","comment":"Accepted by AAAI2025"},{"id":"http://arxiv.org/abs/2412.09796v1","updated":"2024-12-13T02:27:34Z","published":"2024-12-13T02:27:34Z","title":"AutoPatent: A Multi-Agent Framework for Automatic Patent Generation","summary":"  As the capabilities of Large Language Models (LLMs) continue to advance, the\nfield of patent processing has garnered increased attention within the natural\nlanguage processing community. However, the majority of research has been\nconcentrated on classification tasks, such as patent categorization and\nexamination, or on short text generation tasks like patent summarization and\npatent quizzes. In this paper, we introduce a novel and practical task known as\nDraft2Patent, along with its corresponding D2P benchmark, which challenges LLMs\nto generate full-length patents averaging 17K tokens based on initial drafts.\nPatents present a significant challenge to LLMs due to their specialized\nnature, standardized terminology, and extensive length. We propose a\nmulti-agent framework called AutoPatent which leverages the LLM-based planner\nagent, writer agents, and examiner agent with PGTree and RRAG to generate\nlengthy, intricate, and high-quality complete patent documents. The\nexperimental results demonstrate that our AutoPatent framework significantly\nenhances the ability to generate comprehensive patents across various LLMs.\nFurthermore, we have discovered that patents generated solely with the\nAutoPatent framework based on the Qwen2.5-7B model outperform those produced by\nlarger and more powerful LLMs, such as GPT-4o, Qwen2.5-72B, and LLAMA3.1-70B,\nin both objective metrics and human evaluations. We will make the data and code\navailable upon acceptance at \\url{https://github.com/QiYao-Wang/AutoPatent}.\n","authors":["Qiyao Wang","Shiwen Ni","Huaren Liu","Shule Lu","Guhong Chen","Xi Feng","Chi Wei","Qiang Qu","Hamid Alinejad-Rokny","Yuan Lin","Min Yang"],"pdf_url":"https://arxiv.org/pdf/2412.09796v1.pdf","comment":"19 pages, 7 figures"},{"id":"http://arxiv.org/abs/2409.00755v3","updated":"2024-12-13T02:10:35Z","published":"2024-09-01T15:48:20Z","title":"Trusted Unified Feature-Neighborhood Dynamics for Multi-View\n  Classification","summary":"  Multi-view classification (MVC) faces inherent challenges due to domain gaps\nand inconsistencies across different views, often resulting in uncertainties\nduring the fusion process. While Evidential Deep Learning (EDL) has been\neffective in addressing view uncertainty, existing methods predominantly rely\non the Dempster-Shafer combination rule, which is sensitive to conflicting\nevidence and often neglects the critical role of neighborhood structures within\nmulti-view data. To address these limitations, we propose a Trusted Unified\nFeature-NEighborhood Dynamics (TUNED) model for robust MVC. This method\neffectively integrates local and global feature-neighborhood (F-N) structures\nfor robust decision-making. Specifically, we begin by extracting local F-N\nstructures within each view. To further mitigate potential uncertainties and\nconflicts in multi-view fusion, we employ a selective Markov random field that\nadaptively manages cross-view neighborhood dependencies. Additionally, we\nemploy a shared parameterized evidence extractor that learns global consensus\nconditioned on local F-N structures, thereby enhancing the global integration\nof multi-view features. Experiments on benchmark datasets show that our method\nimproves accuracy and robustness over existing approaches, particularly in\nscenarios with high uncertainty and conflicting views. The code will be made\navailable at https://github.com/JethroJames/TUNED.\n","authors":["Haojian Huang","Chuanyu Qin","Zhe Liu","Kaijing Ma","Jin Chen","Han Fang","Chao Ban","Hao Sun","Zhongjiang He"],"pdf_url":"https://arxiv.org/pdf/2409.00755v3.pdf","comment":"Accepted to AAAI 2025"},{"id":"http://arxiv.org/abs/2410.00324v2","updated":"2024-12-13T01:57:19Z","published":"2024-10-01T01:52:01Z","title":"Vision Language Models See What You Want but not What You See","summary":"  Knowing others' intentions and taking others' perspectives are two core\ncomponents of human intelligence that are typically considered to be\ninstantiations of theory-of-mind. Infiltrating machines with these abilities is\nan important step towards building human-level artificial intelligence.\nRecently, Li et al. built CogDevelop2K, a data-intensive cognitive experiment\nbenchmark to assess the developmental trajectory of machine intelligence. Here,\nto investigate intentionality understanding and perspective-taking in Vision\nLanguage Models, we leverage the IntentBench and PerspectBench of CogDevelop2K,\nwhich contains over 300 cognitive experiments grounded in real-world scenarios\nand classic cognitive tasks, respectively. Surprisingly, we find VLMs achieving\nhigh performance on intentionality understanding but lower performance on\nperspective-taking. This challenges the common belief in cognitive science\nliterature that perspective-taking at the corresponding modality is necessary\nfor intentionality understanding. For website see\nhttps://growing-ai-like-a-child.github.io/pages/Three%20Mountain%20Task/\n","authors":["Qingying Gao","Yijiang Li","Haiyun Lyu","Haoran Sun","Dezhi Luo","Hokin Deng"],"pdf_url":"https://arxiv.org/pdf/2410.00324v2.pdf","comment":"$\\href{https://growing-ai-like-a-child.github.io/pages/Three%20Mountain%20Task/}{Website}$"},{"id":"http://arxiv.org/abs/2403.18963v2","updated":"2024-12-13T01:57:16Z","published":"2024-03-27T19:16:56Z","title":"Leveraging Quantum Superposition to Infer the Dynamic Behavior of a\n  Spatial-Temporal Neural Network Signaling Model","summary":"  The exploration of new problem classes for quantum computation is an active\narea of research. In this paper, we introduce and solve a novel problem class\nrelated to dynamics on large-scale networks relevant to neurobiology and\nmachine learning. Specifically, we ask if a network can sustain inherent\ndynamic activity beyond some arbitrary observation time or if the activity\nceases through quiescence or saturation via an 'epileptic'-like state. We show\nthat this class of problems can be formulated and structured to take advantage\nof quantum superposition and solved efficiently using the Deutsch-Jozsa and\nGrover quantum algorithms. To do so, we extend their functionality to address\nthe unique requirements of how input (sub)sets into the algorithms must be\nmathematically structured while simultaneously constructing the inputs so that\nmeasurement outputs can be interpreted as meaningful properties of the network\ndynamics. This, in turn, allows us to answer the question we pose.\n","authors":["Gabriel A. Silva"],"pdf_url":"https://arxiv.org/pdf/2403.18963v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09784v1","updated":"2024-12-13T01:48:07Z","published":"2024-12-13T01:48:07Z","title":"Semi-IIN: Semi-supervised Intra-inter modal Interaction Learning Network\n  for Multimodal Sentiment Analysis","summary":"  Despite multimodal sentiment analysis being a fertile research ground that\nmerits further investigation, current approaches take up high annotation cost\nand suffer from label ambiguity, non-amicable to high-quality labeled data\nacquisition. Furthermore, choosing the right interactions is essential because\nthe significance of intra- or inter-modal interactions can differ among various\nsamples. To this end, we propose Semi-IIN, a Semi-supervised Intra-inter modal\nInteraction learning Network for multimodal sentiment analysis. Semi-IIN\nintegrates masked attention and gating mechanisms, enabling effective dynamic\nselection after independently capturing intra- and inter-modal interactive\ninformation. Combined with the self-training approach, Semi-IIN fully utilizes\nthe knowledge learned from unlabeled data. Experimental results on two public\ndatasets, MOSI and MOSEI, demonstrate the effectiveness of Semi-IIN,\nestablishing a new state-of-the-art on several metrics. Code is available at\nhttps://github.com/flow-ljh/Semi-IIN.\n","authors":["Jinhao Lin","Yifei Wang","Yanwu Xu","Qi Liu"],"pdf_url":"https://arxiv.org/pdf/2412.09784v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.11793v2","updated":"2024-12-13T01:11:25Z","published":"2024-08-21T17:25:45Z","title":"Leveraging Chemistry Foundation Models to Facilitate Structure Focused\n  Retrieval Augmented Generation in Multi-Agent Workflows for Catalyst and\n  Materials Design","summary":"  Molecular property prediction and generative design via deep learning models\nhas been the subject of intense research given its potential to accelerate\ndevelopment of new, high-performance materials. More recently, these workflows\nhave been significantly augmented with the advent of large language models\n(LLMs) and systems of autonomous agents capable of utilizing pre-trained models\nto make predictions in the context of more complex research tasks. While\neffective, there is still room for substantial improvement within agentic\nsystems on the retrieval of salient information for material design tasks.\nWithin this context, alternative uses of predictive deep learning models, such\nas leveraging their latent representations to facilitate cross-modal retrieval\naugmented generation within agentic systems for task-specific materials design,\nhas remained unexplored. Herein, we demonstrate that large, pre-trained\nchemistry foundation models can serve as a basis for enabling\nstructure-focused, semantic chemistry information retrieval for both\nsmall-molecules, complex polymeric materials, and reactions. Additionally, we\nshow the use of chemistry foundation models in conjunction with multi-modal\nmodels such as OpenCLIP facilitate unprecedented queries and information\nretrieval across multiple characterization data domains. Finally, we\ndemonstrate the integration of these models within multi-agent systems to\nfacilitate structure and topological-based natural language queries and\ninformation retrieval for different research tasks.\n","authors":["Nathaniel H. Park","Tiffany J. Callahan","James L. Hedrick","Tim Erdmann","Sara Capponi"],"pdf_url":"https://arxiv.org/pdf/2408.11793v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09770v1","updated":"2024-12-13T00:28:21Z","published":"2024-12-13T00:28:21Z","title":"Learning Visually Grounded Domain Ontologies via Embodied Conversation\n  and Explanation","summary":"  In this paper, we offer a learning framework in which the agent's knowledge\ngaps are overcome through corrective feedback from a teacher whenever the agent\nexplains its (incorrect) predictions. We test it in a low-resource visual\nprocessing scenario, in which the agent must learn to recognize distinct types\nof toy truck. The agent starts the learning process with no ontology about what\ntypes of trucks exist nor which parts they have, and a deficient model for\nrecognizing those parts from visual input. The teacher's feedback to the\nagent's explanations addresses its lack of relevant knowledge in the ontology\nvia a generic rule (e.g., \"dump trucks have dumpers\"), whereas an inaccurate\npart recognition is corrected by a deictic statement (e.g., \"this is not a\ndumper\"). The learner utilizes this feedback not only to improve its estimate\nof the hypothesis space of possible domain ontologies and probability\ndistributions over them, but also to use those estimates to update its visual\ninterpretation of the scene. Our experiments demonstrate that teacher-learner\npairs utilizing explanations and corrections are more data-efficient than those\nwithout such a faculty.\n","authors":["Jonghyuk Park","Alex Lascarides","Subramanian Ramamoorthy"],"pdf_url":"https://arxiv.org/pdf/2412.09770v1.pdf","comment":"Accepted to, and to appear in the Thirty-Ninth AAAI Conference on\n  Artificial Intelligence (AAAI-25)"},{"id":"http://arxiv.org/abs/2410.10041v2","updated":"2024-12-13T00:23:09Z","published":"2024-10-13T23:05:37Z","title":"WormKAN: Are KAN Effective for Identifying and Tracking Concept Drift in\n  Time Series?","summary":"  Dynamic concepts in time series are crucial for understanding complex systems\nsuch as financial markets, healthcare, and online activity logs. These concepts\nhelp reveal structures and behaviors in sequential data for better\ndecision-making and forecasting. However, existing models often struggle to\ndetect and track concept drift due to limitations in interpretability and\nadaptability. To address this challenge, inspired by the flexibility of the\nrecent Kolmogorov-Arnold Network (KAN), we propose WormKAN, a concept-aware\nKAN-based model to address concept drift in co-evolving time series. WormKAN\nconsists of three key components: Patch Normalization, Temporal Representation\nModule, and Concept Dynamics. Patch normalization processes co-evolving time\nseries into patches, treating them as fundamental modeling units to capture\nlocal dependencies while ensuring consistent scaling. The temporal\nrepresentation module learns robust latent representations by leveraging a\nKAN-based autoencoder, complemented by a smoothness constraint, to uncover\ninter-patch correlations. Concept dynamics identifies and tracks dynamic\ntransitions, revealing structural shifts in the time series through concept\nidentification and drift detection. These transitions, akin to passing through\na \\textit{wormhole}, are identified by abrupt changes in the latent space.\nExperiments show that KAN and KAN-based models (WormKAN) effectively segment\ntime series into meaningful concepts, enhancing the identification and tracking\nof concept drift.\n","authors":["Kunpeng Xu","Lifei Chen","Shengrui Wang"],"pdf_url":"https://arxiv.org/pdf/2410.10041v2.pdf","comment":null}]},"2024-12-12T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2412.09764v1","updated":"2024-12-12T23:56:57Z","published":"2024-12-12T23:56:57Z","title":"Memory Layers at Scale","summary":"  Memory layers use a trainable key-value lookup mechanism to add extra\nparameters to a model without increasing FLOPs. Conceptually, sparsely\nactivated memory layers complement compute-heavy dense feed-forward layers,\nproviding dedicated capacity to store and retrieve information cheaply. This\nwork takes memory layers beyond proof-of-concept, proving their utility at\ncontemporary scale. On downstream tasks, language models augmented with our\nimproved memory layer outperform dense models with more than twice the\ncomputation budget, as well as mixture-of-expert models when matched for both\ncompute and parameters. We find gains are especially pronounced for factual\ntasks. We provide a fully parallelizable memory layer implementation,\ndemonstrating scaling laws with up to 128B memory parameters, pretrained to 1\ntrillion tokens, comparing to base models with up to 8B parameters.\n","authors":["Vincent-Pierre Berges","Barlas Oğuz","Daniel Haziza","Wen-tau Yih","Luke Zettlemoyer","Gargi Gosh"],"pdf_url":"https://arxiv.org/pdf/2412.09764v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.03626v3","updated":"2024-12-12T23:03:54Z","published":"2024-04-04T17:48:28Z","title":"Training LLMs over Neurally Compressed Text","summary":"  In this paper, we explore the idea of training large language models (LLMs)\nover highly compressed text. While standard subword tokenizers compress text by\na small factor, neural text compressors can achieve much higher rates of\ncompression. If it were possible to train LLMs directly over neurally\ncompressed text, this would confer advantages in training and serving\nefficiency, as well as easier handling of long text spans. The main obstacle to\nthis goal is that strong compression tends to produce opaque outputs that are\nnot well-suited for learning. In particular, we find that text na\\\"ively\ncompressed via Arithmetic Coding is not readily learnable by LLMs. To overcome\nthis, we propose Equal-Info Windows, a novel compression technique whereby text\nis segmented into blocks that each compress to the same bit length. Using this\nmethod, we demonstrate effective learning over neurally compressed text that\nimproves with scale, and outperforms byte-level baselines by a wide margin on\nperplexity and inference speed benchmarks. While our method delivers worse\nperplexity than subword tokenizers for models trained with the same parameter\ncount, it has the benefit of shorter sequence lengths. Shorter sequence lengths\nrequire fewer autoregressive generation steps, and reduce latency. Finally, we\nprovide extensive analysis of the properties that contribute to learnability,\nand offer concrete suggestions for how to further improve the performance of\nhigh-compression tokenizers.\n","authors":["Brian Lester","Jaehoon Lee","Alex Alemi","Jeffrey Pennington","Adam Roberts","Jascha Sohl-Dickstein","Noah Constant"],"pdf_url":"https://arxiv.org/pdf/2404.03626v3.pdf","comment":"Accepted in TMLR https://openreview.net/forum?id=pRvhMSV48t"},{"id":"http://arxiv.org/abs/2410.10829v2","updated":"2024-12-12T22:56:26Z","published":"2024-09-28T03:13:40Z","title":"Test Case-Informed Knowledge Tracing for Open-ended Coding Tasks","summary":"  Open-ended coding tasks, which ask students to construct programs according\nto certain specifications, are common in computer science education. Student\nmodeling can be challenging since their open-ended nature means that student\ncode can be diverse. Traditional knowledge tracing (KT) models that only\nanalyze response correctness may not fully capture nuances in student knowledge\nfrom student code. In this paper, we introduce Test case-Informed Knowledge\nTracing for Open-ended Coding (TIKTOC), a framework to simultaneously analyze\nand predict both open-ended student code and whether the code passes each test\ncase. We augment the existing CodeWorkout dataset with the test cases used for\na subset of the open-ended coding questions, and propose a multi-task learning\nKT method to simultaneously analyze and predict 1) whether a student's code\nsubmission passes each test case and 2) the student's open-ended code, using a\nlarge language model as the backbone. We quantitatively show that these methods\noutperform existing KT methods for coding that only use the overall score a\ncode submission receives. We also qualitatively demonstrate how test case\ninformation, combined with open-ended code, helps us gain fine-grained insights\ninto student knowledge.\n","authors":["Zhangqi Duan","Nigel Fernandez","Alexander Hicks","Andrew Lan"],"pdf_url":"https://arxiv.org/pdf/2410.10829v2.pdf","comment":"Published in LAK 2025: The 15th International Learning Analytics and\n  Knowledge Conference"},{"id":"http://arxiv.org/abs/2412.09722v1","updated":"2024-12-12T20:59:43Z","published":"2024-12-12T20:59:43Z","title":"GReaTer: Gradients over Reasoning Makes Smaller Language Models Strong\n  Prompt Optimizers","summary":"  The effectiveness of large language models (LLMs) is closely tied to the\ndesign of prompts, making prompt optimization essential for enhancing their\nperformance across a wide range of tasks. Many existing approaches to\nautomating prompt engineering rely exclusively on textual feedback, refining\nprompts based solely on inference errors identified by large, computationally\nexpensive LLMs. Unfortunately, smaller models struggle to generate high-quality\nfeedback, resulting in complete dependence on large LLM judgment. Moreover,\nthese methods fail to leverage more direct and finer-grained information, such\nas gradients, due to operating purely in text space. To this end, we introduce\nGReaTer, a novel prompt optimization technique that directly incorporates\ngradient information over task-specific reasoning. By utilizing task loss\ngradients, GReaTer enables self-optimization of prompts for open-source,\nlightweight language models without the need for costly closed-source LLMs.\nThis allows high-performance prompt optimization without dependence on massive\nLLMs, closing the gap between smaller models and the sophisticated reasoning\noften needed for prompt refinement. Extensive evaluations across diverse\nreasoning tasks including BBH, GSM8k, and FOLIO demonstrate that GReaTer\nconsistently outperforms previous state-of-the-art prompt optimization methods,\neven those reliant on powerful LLMs. Additionally, GReaTer-optimized prompts\nfrequently exhibit better transferability and, in some cases, boost task\nperformance to levels comparable to or surpassing those achieved by larger\nlanguage models, highlighting the effectiveness of prompt optimization guided\nby gradients over reasoning. Code of GReaTer is available at\nhttps://github.com/psunlpgroup/GreaTer.\n","authors":["Sarkar Snigdha Sarathi Das","Ryo Kamoi","Bo Pang","Yusen Zhang","Caiming Xiong","Rui Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.09722v1.pdf","comment":"32 pages, 8 figures"},{"id":"http://arxiv.org/abs/2412.09715v1","updated":"2024-12-12T20:37:52Z","published":"2024-12-12T20:37:52Z","title":"Human vs. AI: A Novel Benchmark and a Comparative Study on the Detection\n  of Generated Images and the Impact of Prompts","summary":"  With the advent of publicly available AI-based text-to-image systems, the\nprocess of creating photorealistic but fully synthetic images has been largely\ndemocratized. This can pose a threat to the public through a simplified spread\nof disinformation. Machine detectors and human media expertise can help to\ndifferentiate between AI-generated (fake) and real images and counteract this\ndanger. Although AI generation models are highly prompt-dependent, the impact\nof the prompt on the fake detection performance has rarely been investigated\nyet. This work therefore examines the influence of the prompt's level of detail\non the detectability of fake images, both with an AI detector and in a user\nstudy. For this purpose, we create a novel dataset, COCOXGEN, which consists of\nreal photos from the COCO dataset as well as images generated with SDXL and\nFooocus using prompts of two standardized lengths. Our user study with 200\nparticipants shows that images generated with longer, more detailed prompts are\ndetected significantly more easily than those generated with short prompts.\nSimilarly, an AI-based detection model achieves better performance on images\ngenerated with longer prompts. However, humans and AI models seem to pay\nattention to different details, as we show in a heat map analysis.\n","authors":["Philipp Moeßner","Heike Adel"],"pdf_url":"https://arxiv.org/pdf/2412.09715v1.pdf","comment":"Accepted at Workshop on Detecting AI Generated Content (at COLING\n  2025)"},{"id":"http://arxiv.org/abs/2411.09547v2","updated":"2024-12-12T19:23:28Z","published":"2024-11-14T16:01:33Z","title":"Piecing It All Together: Verifying Multi-Hop Multimodal Claims","summary":"  Existing claim verification datasets often do not require systems to perform\ncomplex reasoning or effectively interpret multimodal evidence. To address\nthis, we introduce a new task: multi-hop multimodal claim verification. This\ntask challenges models to reason over multiple pieces of evidence from diverse\nsources, including text, images, and tables, and determine whether the combined\nmultimodal evidence supports or refutes a given claim. To study this task, we\nconstruct MMCV, a large-scale dataset comprising 15k multi-hop claims paired\nwith multimodal evidence, generated and refined using large language models,\nwith additional input from human feedback. We show that MMCV is challenging\neven for the latest state-of-the-art multimodal large language models,\nespecially as the number of reasoning hops increases. Additionally, we\nestablish a human performance benchmark on a subset of MMCV. We hope this\ndataset and its evaluation task will encourage future research in multimodal\nmulti-hop claim verification.\n","authors":["Haoran Wang","Aman Rangapur","Xiongxiao Xu","Yueqing Liang","Haroon Gharwi","Carl Yang","Kai Shu"],"pdf_url":"https://arxiv.org/pdf/2411.09547v2.pdf","comment":"COLING 2025"},{"id":"http://arxiv.org/abs/2412.09688v1","updated":"2024-12-12T19:07:31Z","published":"2024-12-12T19:07:31Z","title":"Formal Languages and TQFTs with Defects","summary":"  A construction that assigns a Boolean 1D TQFT with defects to a finite state\nautomaton was recently developed by Gustafson, Im, Kaldawy, Khovanov, and Lihn.\nWe show that the construction is functorial with respect to the category of\nfinite state automata with transducers as morphisms. Certain classes of\nsubregular languages correspond to additional cohomological structures on the\nassociated TQFTs. We also show that the construction generalizes to\ncontext-free grammars through a categorical version of the\nChomsky-Sch\\\"utzenberger representation theorem, due to Melli\\`es and\nZeilberger. The corresponding TQFTs are then described as morphisms of colored\noperads on an operad of cobordisms with defects.\n","authors":["Luisa Boateng","Matilde Marcolli"],"pdf_url":"https://arxiv.org/pdf/2412.09688v1.pdf","comment":"28 pages, 9 figures"},{"id":"http://arxiv.org/abs/2412.09614v1","updated":"2024-12-12T18:59:41Z","published":"2024-12-12T18:59:41Z","title":"Context Canvas: Enhancing Text-to-Image Diffusion Models with Knowledge\n  Graph-Based RAG","summary":"  We introduce a novel approach to enhance the capabilities of text-to-image\nmodels by incorporating a graph-based RAG. Our system dynamically retrieves\ndetailed character information and relational data from the knowledge graph,\nenabling the generation of visually accurate and contextually rich images. This\ncapability significantly improves upon the limitations of existing T2I models,\nwhich often struggle with the accurate depiction of complex or culturally\nspecific subjects due to dataset constraints. Furthermore, we propose a novel\nself-correcting mechanism for text-to-image models to ensure consistency and\nfidelity in visual outputs, leveraging the rich context from the graph to guide\ncorrections. Our qualitative and quantitative experiments demonstrate that\nContext Canvas significantly enhances the capabilities of popular models such\nas Flux, Stable Diffusion, and DALL-E, and improves the functionality of\nControlNet for fine-grained image editing tasks. To our knowledge, Context\nCanvas represents the first application of graph-based RAG in enhancing T2I\nmodels, representing a significant advancement for producing high-fidelity,\ncontext-aware multi-faceted images.\n","authors":["Kavana Venkatesh","Yusuf Dalva","Ismini Lourentzou","Pinar Yanardag"],"pdf_url":"https://arxiv.org/pdf/2412.09614v1.pdf","comment":"Project Page: https://context-canvas.github.io/"},{"id":"http://arxiv.org/abs/2412.09605v1","updated":"2024-12-12T18:59:27Z","published":"2024-12-12T18:59:27Z","title":"AgentTrek: Agent Trajectory Synthesis via Guiding Replay with Web\n  Tutorials","summary":"  Graphical User Interface (GUI) agents hold great potential for automating\ncomplex tasks across diverse digital environments, from web applications to\ndesktop software. However, the development of such agents is hindered by the\nlack of high-quality, multi-step trajectory data required for effective\ntraining. Existing approaches rely on expensive and labor-intensive human\nannotation, making them unsustainable at scale. To address this challenge, we\npropose AgentTrek, a scalable data synthesis pipeline that generates\nhigh-quality GUI agent trajectories by leveraging web tutorials. Our method\nautomatically gathers tutorial-like texts from the internet, transforms them\ninto task goals with step-by-step instructions, and employs a visual-language\nmodel agent to simulate their execution in a real digital environment. A\nVLM-based evaluator ensures the correctness of the generated trajectories. We\ndemonstrate that training GUI agents with these synthesized trajectories\nsignificantly improves their grounding and planning performance over the\ncurrent models. Moreover, our approach is more cost-efficient compared to\ntraditional human annotation methods. This work underscores the potential of\nguided replay with web tutorials as a viable strategy for large-scale GUI agent\ntraining, paving the way for more capable and autonomous digital agents.\n","authors":["Yiheng Xu","Dunjie Lu","Zhennan Shen","Junli Wang","Zekun Wang","Yuchen Mao","Caiming Xiong","Tao Yu"],"pdf_url":"https://arxiv.org/pdf/2412.09605v1.pdf","comment":"https://agenttrek.github.io"},{"id":"http://arxiv.org/abs/2412.09601v1","updated":"2024-12-12T18:59:11Z","published":"2024-12-12T18:59:11Z","title":"TimeRefine: Temporal Grounding with Time Refining Video LLM","summary":"  Video temporal grounding aims to localize relevant temporal boundaries in a\nvideo given a textual prompt. Recent work has focused on enabling Video LLMs to\nperform video temporal grounding via next-token prediction of temporal\ntimestamps. However, accurately localizing timestamps in videos remains\nchallenging for Video LLMs when relying solely on temporal token prediction.\nOur proposed TimeRefine addresses this challenge in two ways. First, instead of\ndirectly predicting the start and end timestamps, we reformulate the temporal\ngrounding task as a temporal refining task: the model first makes rough\npredictions and then refines them by predicting offsets to the target segment.\nThis refining process is repeated multiple times, through which the model\nprogressively self-improves its temporal localization accuracy. Second, to\nenhance the model's temporal perception capabilities, we incorporate an\nauxiliary prediction head that penalizes the model more if a predicted segment\ndeviates further from the ground truth, thus encouraging the model to make\ncloser and more accurate predictions. Our plug-and-play method can be\nintegrated into most LLM-based temporal grounding approaches. The experimental\nresults demonstrate that TimeRefine achieves 3.6% and 5.0% mIoU improvements on\nthe ActivityNet and Charades-STA datasets, respectively. Code and pretrained\nmodels will be released.\n","authors":["Xizi Wang","Feng Cheng","Ziyang Wang","Huiyu Wang","Md Mohaiminul Islam","Lorenzo Torresani","Mohit Bansal","Gedas Bertasius","David Crandall"],"pdf_url":"https://arxiv.org/pdf/2412.09601v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09596v1","updated":"2024-12-12T18:58:30Z","published":"2024-12-12T18:58:30Z","title":"InternLM-XComposer2.5-OmniLive: A Comprehensive Multimodal System for\n  Long-term Streaming Video and Audio Interactions","summary":"  Creating AI systems that can interact with environments over long periods,\nsimilar to human cognition, has been a longstanding research goal. Recent\nadvancements in multimodal large language models (MLLMs) have made significant\nstrides in open-world understanding. However, the challenge of continuous and\nsimultaneous streaming perception, memory, and reasoning remains largely\nunexplored. Current MLLMs are constrained by their sequence-to-sequence\narchitecture, which limits their ability to process inputs and generate\nresponses simultaneously, akin to being unable to think while perceiving.\nFurthermore, relying on long contexts to store historical data is impractical\nfor long-term interactions, as retaining all information becomes costly and\ninefficient. Therefore, rather than relying on a single foundation model to\nperform all functions, this project draws inspiration from the concept of the\nSpecialized Generalist AI and introduces disentangled streaming perception,\nreasoning, and memory mechanisms, enabling real-time interaction with streaming\nvideo and audio input. The proposed framework InternLM-XComposer2.5-OmniLive\n(IXC2.5-OL) consists of three key modules: (1) Streaming Perception Module:\nProcesses multimodal information in real-time, storing key details in memory\nand triggering reasoning in response to user queries. (2) Multi-modal Long\nMemory Module: Integrates short-term and long-term memory, compressing\nshort-term memories into long-term ones for efficient retrieval and improved\naccuracy. (3) Reasoning Module: Responds to queries and executes reasoning\ntasks, coordinating with the perception and memory modules. This project\nsimulates human-like cognition, enabling multimodal large language models to\nprovide continuous and adaptive service over time.\n","authors":["Pan Zhang","Xiaoyi Dong","Yuhang Cao","Yuhang Zang","Rui Qian","Xilin Wei","Lin Chen","Yifei Li","Junbo Niu","Shuangrui Ding","Qipeng Guo","Haodong Duan","Xin Chen","Han Lv","Zheng Nie","Min Zhang","Bin Wang","Wenwei Zhang","Xinyue Zhang","Jiaye Ge","Wei Li","Jingwen Li","Zhongying Tu","Conghui He","Xingcheng Zhang","Kai Chen","Yu Qiao","Dahua Lin","Jiaqi Wang"],"pdf_url":"https://arxiv.org/pdf/2412.09596v1.pdf","comment":"Github Repo:\n  https://github.com/InternLM/InternLM-XComposer/tree/main/InternLM-XComposer-2.5-OmniLive"},{"id":"http://arxiv.org/abs/2412.09587v1","updated":"2024-12-12T18:55:53Z","published":"2024-12-12T18:55:53Z","title":"OpenNER 1.0: Standardized Open-Access Named Entity Recognition Datasets\n  in 50+ Languages","summary":"  We present OpenNER 1.0, a standardized collection of openly available named\nentity recognition (NER) datasets. OpenNER contains 34 datasets spanning 51\nlanguages, annotated in varying named entity ontologies. We correct annotation\nformat issues, standardize the original datasets into a uniform representation,\nmap entity type names to be more consistent across corpora, and provide the\ncollection in a structure that enables research in multilingual and\nmulti-ontology NER. We provide baseline models using three pretrained\nmultilingual language models to compare the performance of recent models and\nfacilitate future research in NER.\n","authors":["Chester Palen-Michel","Maxwell Pickering","Maya Kruse","Jonne Sälevä","Constantine Lignos"],"pdf_url":"https://arxiv.org/pdf/2412.09587v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09578v1","updated":"2024-12-12T18:53:46Z","published":"2024-12-12T18:53:46Z","title":"DISHONEST: Dissecting misInformation Spread using Homogeneous sOcial\n  NEtworks and Semantic Topic classification","summary":"  The emergence of the COVID-19 pandemic resulted in a significant rise in the\nspread of misinformation on online platforms such as Twitter. Oftentimes this\ngrowth is blamed on the idea of the \"echo chamber.\" However, the behavior said\nto characterize these echo chambers exists in two dimensions. The first is in a\nuser's social interactions, where they are said to stick with the same clique\nof like-minded users. The second is in the content of their posts, where they\nare said to repeatedly espouse homogeneous ideas. In this study, we link the\ntwo by using Twitter's network of retweets to study social interactions and\ntopic modeling to study tweet content. In order to measure the diversity of a\nuser's interactions over time, we develop a novel metric to track the speed at\nwhich they travel through the social network. The application of these analysis\nmethods to misinformation-focused data from the pandemic demonstrates\ncorrelation between social behavior and tweet content. We believe this\ncorrelation supports the common intuition about how antisocial users behave,\nand further suggests that it holds even in subcommunities already rife with\nmisinformation.\n","authors":["Caleb Stam","Emily Saldanha","Mahantesh Halappanavar","Anurag Acharya"],"pdf_url":"https://arxiv.org/pdf/2412.09578v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09572v1","updated":"2024-12-12T18:52:40Z","published":"2024-12-12T18:52:40Z","title":"DiverseAgentEntropy: Quantifying Black-Box LLM Uncertainty through\n  Diverse Perspectives and Multi-Agent Interaction","summary":"  Quantifying the uncertainty in the factual parametric knowledge of Large\nLanguage Models (LLMs), especially in a black-box setting, poses a significant\nchallenge. Existing methods, which gauge a model's uncertainty through\nevaluating self-consistency in responses to the original query, do not always\ncapture true uncertainty. Models might respond consistently to the origin query\nwith a wrong answer, yet respond correctly to varied questions from different\nperspectives about the same query, and vice versa. In this paper, we propose a\nnovel method, DiverseAgentEntropy, for evaluating a model's uncertainty using\nmulti-agent interaction under the assumption that if a model is certain, it\nshould consistently recall the answer to the original query across a diverse\ncollection of questions about the same original query. We further implement an\nabstention policy to withhold responses when uncertainty is high. Our method\noffers a more accurate prediction of the model's reliability and further\ndetects hallucinations, outperforming other self-consistency-based methods.\nAdditionally, it demonstrates that existing models often fail to consistently\nretrieve the correct answer to the same query under diverse varied questions\neven when knowing the correct answer.\n","authors":["Yu Feng","Phu Mon Htut","Zheng Qi","Wei Xiao","Manuel Mager","Nikolaos Pappas","Kishaloy Halder","Yang Li","Yassine Benajiba","Dan Roth"],"pdf_url":"https://arxiv.org/pdf/2412.09572v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09569v1","updated":"2024-12-12T18:51:13Z","published":"2024-12-12T18:51:13Z","title":"JuStRank: Benchmarking LLM Judges for System Ranking","summary":"  Given the rapid progress of generative AI, there is a pressing need to\nsystematically compare and choose between the numerous models and\nconfigurations available. The scale and versatility of such evaluations make\nthe use of LLM-based judges a compelling solution for this challenge.\nCrucially, this approach requires first to validate the quality of the LLM\njudge itself. Previous work has focused on instance-based assessment of LLM\njudges, where a judge is evaluated over a set of responses, or response pairs,\nwhile being agnostic to their source systems. We argue that this setting\noverlooks critical factors affecting system-level ranking, such as a judge's\npositive or negative bias towards certain systems. To address this gap, we\nconduct the first large-scale study of LLM judges as system rankers. System\nscores are generated by aggregating judgment scores over multiple system\noutputs, and the judge's quality is assessed by comparing the resulting system\nranking to a human-based ranking. Beyond overall judge assessment, our analysis\nprovides a fine-grained characterization of judge behavior, including their\ndecisiveness and bias.\n","authors":["Ariel Gera","Odellia Boni","Yotam Perlitz","Roy Bar-Haim","Lilach Eden","Asaf Yehudai"],"pdf_url":"https://arxiv.org/pdf/2412.09569v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09563v1","updated":"2024-12-12T18:48:51Z","published":"2024-12-12T18:48:51Z","title":"Does Representation Matter? Exploring Intermediate Layers in Large\n  Language Models","summary":"  Understanding what defines a good representation in large language models\n(LLMs) is fundamental to both theoretical understanding and practical\napplications. In this paper, we investigate the quality of intermediate\nrepresentations in various LLM architectures, including Transformers and State\nSpace Models (SSMs). We find that intermediate layers often yield more\ninformative representations for downstream tasks than the final layers. To\nmeasure the representation quality, we adapt and apply a suite of metrics -\nsuch as prompt entropy, curvature, and augmentation-invariance - originally\nproposed in other contexts. Our empirical study reveals significant\narchitectural differences, how representations evolve throughout training, and\nhow factors like input randomness and prompt length affect each layer. Notably,\nwe observe a bimodal pattern in the entropy of some intermediate layers and\nconsider potential explanations tied to training data. Overall, our results\nilluminate the internal mechanics of LLMs and guide strategies for\narchitectural optimization and training.\n","authors":["Oscar Skean","Md Rifat Arefin","Yann LeCun","Ravid Shwartz-Ziv"],"pdf_url":"https://arxiv.org/pdf/2412.09563v1.pdf","comment":"Accepted to 2024 NeurIPs Workshop on Machine Learning and Compression"},{"id":"http://arxiv.org/abs/2412.09560v1","updated":"2024-12-12T18:46:38Z","published":"2024-12-12T18:46:38Z","title":"Foundational Large Language Models for Materials Research","summary":"  Materials discovery and development are critical for addressing global\nchallenges. Yet, the exponential growth in materials science literature\ncomprising vast amounts of textual data has created significant bottlenecks in\nknowledge extraction, synthesis, and scientific reasoning. Large Language\nModels (LLMs) offer unprecedented opportunities to accelerate materials\nresearch through automated analysis and prediction. Still, their effective\ndeployment requires domain-specific adaptation for understanding and solving\ndomain-relevant tasks. Here, we present LLaMat, a family of foundational models\nfor materials science developed through continued pretraining of LLaMA models\non an extensive corpus of materials literature and crystallographic data.\nThrough systematic evaluation, we demonstrate that LLaMat excels in\nmaterials-specific NLP and structured information extraction while maintaining\ngeneral linguistic capabilities. The specialized LLaMat-CIF variant\ndemonstrates unprecedented capabilities in crystal structure generation,\npredicting stable crystals with high coverage across the periodic table.\nIntriguingly, despite LLaMA-3's superior performance in comparison to LLaMA-2,\nwe observe that LLaMat-2 demonstrates unexpectedly enhanced domain-specific\nperformance across diverse materials science tasks, including structured\ninformation extraction from text and tables, more particularly in crystal\nstructure generation, a potential adaptation rigidity in overtrained LLMs.\nAltogether, the present work demonstrates the effectiveness of domain\nadaptation towards developing practically deployable LLM copilots for materials\nresearch. Beyond materials science, our findings reveal important\nconsiderations for domain adaptation of LLMs, such as model selection, training\nmethodology, and domain-specific performance, which may influence the\ndevelopment of specialized scientific AI systems.\n","authors":["Vaibhav Mishra","Somaditya Singh","Dhruv Ahlawat","Mohd Zaki","Vaibhav Bihani","Hargun Singh Grover","Biswajit Mishra","Santiago Miret"," Mausam","N. M. Anoop Krishnan"],"pdf_url":"https://arxiv.org/pdf/2412.09560v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.20535v2","updated":"2024-12-12T18:45:33Z","published":"2024-05-30T23:20:25Z","title":"Unveiling the Impact of Coding Data Instruction Fine-Tuning on Large\n  Language Models Reasoning","summary":"  Instruction Fine-Tuning (IFT) significantly enhances the zero-shot\ncapabilities of pretrained Large Language Models (LLMs). While coding data is\nknown to boost LLM reasoning abilities during pretraining, its role in\nactivating internal reasoning capacities during IFT remains understudied. This\npaper investigates a key question: How does coding data impact LLMs' reasoning\ncapacities during IFT stage? To explore this, we thoroughly examine the impact\nof coding data across different coding data proportions, model families, sizes,\nand reasoning domains, from various perspectives. Specifically, we create three\nIFT datasets with increasing coding data proportions, fine-tune six LLM\nbackbones across different families and scales on these datasets, evaluate the\ntuned models' performance across twelve tasks in three reasoning domains, and\nanalyze the outcomes from three broad-to-granular perspectives: overall,\ndomain-level, and task-specific. Our holistic analysis provides valuable\ninsights into each perspective. First, coding data tuning enhances the overall\nreasoning capabilities of LLMs across different model families and scales.\nMoreover, while the impact of coding data varies by domain, it shows consistent\ntrends within each domain across different model families and scales.\nAdditionally, coding data generally provides comparable task-specific benefits\nacross model families, with optimal proportions in IFT datasets being\ntask-dependent.\n","authors":["Xinlu Zhang","Zhiyu Zoey Chen","Xi Ye","Xianjun Yang","Lichang Chen","William Yang Wang","Linda Ruth Petzold"],"pdf_url":"https://arxiv.org/pdf/2405.20535v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17251v2","updated":"2024-12-12T18:26:45Z","published":"2024-10-22T17:59:57Z","title":"Altogether: Image Captioning via Re-aligning Alt-text","summary":"  This paper focuses on creating synthetic data to improve the quality of image\ncaptions. Existing works typically have two shortcomings. First, they caption\nimages from scratch, ignoring existing alt-text metadata, and second, lack\ntransparency if the captioners' training data (e.g. GPT) is unknown. In this\npaper, we study a principled approach Altogether based on the key idea to edit\nand re-align existing alt-texts associated with the images. To generate\ntraining data, we perform human annotation where annotators start with the\nexisting alt-text and re-align it to the image content in multiple rounds,\nconsequently constructing captions with rich visual concepts. This differs from\nprior work that carries out human annotation as a one-time description task\nsolely based on images and annotator knowledge. We train a captioner on this\ndata that generalizes the process of re-aligning alt-texts at scale. Our\nresults show our Altogether approach leads to richer image captions that also\nimprove text-to-image generation and zero-shot image classification tasks.\n","authors":["Hu Xu","Po-Yao Huang","Xiaoqing Ellen Tan","Ching-Feng Yeh","Jacob Kahn","Christine Jou","Gargi Ghosh","Omer Levy","Luke Zettlemoyer","Wen-tau Yih","Shang-Wen Li","Saining Xie","Christoph Feichtenhofer"],"pdf_url":"https://arxiv.org/pdf/2410.17251v2.pdf","comment":"accepted by EMNLP 2024; Meta CLIP 1.2 Data Engine"},{"id":"http://arxiv.org/abs/2412.09666v1","updated":"2024-12-12T18:16:46Z","published":"2024-12-12T18:16:46Z","title":"Systematic Analysis of LLM Contributions to Planning: Solver, Verifier,\n  Heuristic","summary":"  In this work, we provide a systematic analysis of how large language models\n(LLMs) contribute to solving planning problems. In particular, we examine how\nLLMs perform when they are used as problem solver, solution verifier, and\nheuristic guidance to improve intermediate solutions. Our analysis reveals that\nalthough it is difficult for LLMs to generate correct plans out-of-the-box,\nLLMs are much better at providing feedback signals to intermediate/incomplete\nsolutions in the form of comparative heuristic functions. This evaluation\nframework provides insights into how future work may design better LLM-based\ntree-search algorithms to solve diverse planning and reasoning problems. We\nalso propose a novel benchmark to evaluate LLM's ability to learn user\npreferences on the fly, which has wide applications in practical settings.\n","authors":["Haoming Li","Zhaoliang Chen","Songyuan Liu","Yiming Lu","Fei Liu"],"pdf_url":"https://arxiv.org/pdf/2412.09666v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08268v2","updated":"2024-12-12T17:32:23Z","published":"2024-12-11T10:35:45Z","title":"LCFO: Long Context and Long Form Output Dataset and Benchmarking","summary":"  This paper presents the Long Context and Form Output (LCFO) benchmark, a\nnovel evaluation framework for assessing gradual summarization and summary\nexpansion capabilities across diverse domains. LCFO consists of long input\ndocuments (5k words average length), each of which comes with three summaries\nof different lengths (20%, 10%, and 5% of the input text), as well as\napproximately 15 questions and answers (QA) related to the input content.\nNotably, LCFO also provides alignments between specific QA pairs and\ncorresponding summaries in 7 domains. The primary motivation behind providing\nsummaries of different lengths is to establish a controllable framework for\ngenerating long texts from shorter inputs, i.e. summary expansion. To establish\nan evaluation metric framework for summarization and summary expansion, we\nprovide human evaluation scores for human-generated outputs, as well as results\nfrom various state-of-the-art large language models (LLMs). GPT-4o-mini\nachieves best human scores among automatic systems in both summarization and\nsummary expansion tasks (~ +10% and +20%, respectively). It even surpasses\nhuman output quality in the case of short summaries (~ +7%). Overall automatic\nmetrics achieve low correlations with human evaluation scores (~ 0.4) but\nmoderate correlation on specific evaluation aspects such as fluency and\nattribution (~ 0.6). The LCFO benchmark offers a standardized platform for\nevaluating summarization and summary expansion performance, as well as\ncorresponding automatic metrics, thereby providing an important evaluation\nframework to advance generative AI.\n","authors":["Marta R. Costa-jussà","Pierre Andrews","Mariano Coria Meglioli","Joy Chen","Joe Chuang","David Dale","Christophe Ropers","Alexandre Mourachko","Eduardo Sánchez","Holger Schwenk","Tuan Tran","Arina Turkatenko","Carleigh Wood"],"pdf_url":"https://arxiv.org/pdf/2412.08268v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.01304v2","updated":"2024-12-12T17:26:04Z","published":"2024-03-02T20:25:50Z","title":"Improving the Validity of Automatically Generated Feedback via\n  Reinforcement Learning","summary":"  Automatically generating feedback via large language models (LLMs) in\nintelligent tutoring systems and online learning platforms has the potential to\nimprove the learning outcomes of many students. However, both feedback\ngeneration and evaluation are challenging: feedback content has to be valid\nespecially in subjects like math, which requires models to understand the\nproblem, the solution, and where the student's error lies. Feedback also has to\nbe pedagogically valid to reflect effective tutoring strategies, such as\nexplaining possible misconceptions and encouraging the student, among other\ndesirable features. In this work, we address both problems of automatically\ngenerating and evaluating feedback while considering both correctness and\nalignment. First, we propose a rubric for evaluating math feedback and show\nthat GPT-4 is able to effectively use it to annotate human-written and\nLLM-generated feedback. Second, we propose a framework for feedback generation\nthat optimizes both correctness and alignment using reinforcement learning\n(RL). Specifically, we use GPT-4's annotations to create preferences over\nfeedback pairs in an augmented dataset for training via direct preference\noptimization (DPO). We show that our methods significantly increase the\ncorrectness and alignment of generated feedback with Llama 2, an open-source\nLLM, qualitatively analyze our generation and evaluation systems using case\nstudies, and outline several areas for future work.\n","authors":["Alexander Scarlatos","Digory Smith","Simon Woodhead","Andrew Lan"],"pdf_url":"https://arxiv.org/pdf/2403.01304v2.pdf","comment":"Best student paper award, Published in AIED 2024: The 25th\n  International Conference on Artificial Intelligence in Education"},{"id":"http://arxiv.org/abs/2412.09467v1","updated":"2024-12-12T17:15:49Z","published":"2024-12-12T17:15:49Z","title":"Audios Don't Lie: Multi-Frequency Channel Attention Mechanism for Audio\n  Deepfake Detection","summary":"  With the rapid development of artificial intelligence technology, the\napplication of deepfake technology in the audio field has gradually increased,\nresulting in a wide range of security risks. Especially in the financial and\nsocial security fields, the misuse of deepfake audios has raised serious\nconcerns. To address this challenge, this study proposes an audio deepfake\ndetection method based on multi-frequency channel attention mechanism (MFCA)\nand 2D discrete cosine transform (DCT). By processing the audio signal into a\nmelspectrogram, using MobileNet V2 to extract deep features, and combining it\nwith the MFCA module to weight different frequency channels in the audio\nsignal, this method can effectively capture the fine-grained frequency domain\nfeatures in the audio signal and enhance the Classification capability of fake\naudios. Experimental results show that compared with traditional methods, the\nmodel proposed in this study shows significant advantages in accuracy,\nprecision,recall, F1 score and other indicators. Especially in complex audio\nscenarios, this method shows stronger robustness and generalization\ncapabilities and provides a new idea for audio deepfake detection and has\nimportant practical application value. In the future, more advanced audio\ndetection technologies and optimization strategies will be explored to further\nimprove the accuracy and generalization capabilities of audio deepfake\ndetection.\n","authors":["Yangguang Feng"],"pdf_url":"https://arxiv.org/pdf/2412.09467v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09460v1","updated":"2024-12-12T17:11:22Z","published":"2024-12-12T17:11:22Z","title":"The Impact of Copyrighted Material on Large Language Models: A Norwegian\n  Perspective","summary":"  The use of copyrighted materials in training generative language models\nraises critical legal and ethical questions. This paper presents a framework\nfor and the results of empirically assessing the impact of copyrighted\nmaterials on the performance of large language models (LLMs) for Norwegian. We\nfound that both books and newspapers contribute positively when the models are\nevaluated on a diverse set of Norwegian benchmarks, while fiction works\npossibly lead to decreased performance. Our experiments could inform the\ncreation of a compensation scheme for authors whose works contribute to AI\ndevelopment.\n","authors":["Javier de la Rosa","Vladislav Mikhailov","Lemei Zhang","Freddy Wetjen","David Samuel","Peng Liu","Rolv-Arild Braaten","Petter Mæhlum","Magnus Breder Birkenes","Andrey Kutuzov","Tita Enstad","Svein Arne Brygfjeld","Jon Atle Gulla","Stephan Oepen","Erik Velldal","Wilfred Østgulen","Liljia Øvrelid","Aslak Sira Myhre"],"pdf_url":"https://arxiv.org/pdf/2412.09460v1.pdf","comment":"pre-print, under review"},{"id":"http://arxiv.org/abs/2411.05231v2","updated":"2024-12-12T16:40:18Z","published":"2024-11-07T22:51:47Z","title":"Evaluating GPT-4 at Grading Handwritten Solutions in Math Exams","summary":"  Recent advances in generative artificial intelligence (AI) have shown promise\nin accurately grading open-ended student responses. However, few prior works\nhave explored grading handwritten responses due to a lack of data and the\nchallenge of combining visual and textual information. In this work, we\nleverage state-of-the-art multi-modal AI models, in particular GPT-4o, to\nautomatically grade handwritten responses to college-level math exams. Using\nreal student responses to questions in a probability theory exam, we evaluate\nGPT-4o's alignment with ground-truth scores from human graders using various\nprompting techniques. We find that while providing rubrics improves alignment,\nthe model's overall accuracy is still too low for real-world settings, showing\nthere is significant room for growth in this task.\n","authors":["Adriana Caraeni","Alexander Scarlatos","Andrew Lan"],"pdf_url":"https://arxiv.org/pdf/2411.05231v2.pdf","comment":"Published in LAK 2025: The 15th International Learning Analytics and\n  Knowledge Conference"},{"id":"http://arxiv.org/abs/2412.09429v1","updated":"2024-12-12T16:35:05Z","published":"2024-12-12T16:35:05Z","title":"From Intention To Implementation: Automating Biomedical Research via\n  LLMs","summary":"  Conventional biomedical research is increasingly labor-intensive due to the\nexponential growth of scientific literature and datasets. Artificial\nintelligence (AI), particularly Large Language Models (LLMs), has the potential\nto revolutionize this process by automating various steps. Still, significant\nchallenges remain, including the need for multidisciplinary expertise,\nlogicality of experimental design, and performance measurements. This paper\nintroduces BioResearcher, the first end-to-end automated system designed to\nstreamline the entire biomedical research process involving dry lab\nexperiments. BioResearcher employs a modular multi-agent architecture,\nintegrating specialized agents for search, literature processing, experimental\ndesign, and programming. By decomposing complex tasks into logically related\nsub-tasks and utilizing a hierarchical learning approach, BioResearcher\neffectively addresses the challenges of multidisciplinary requirements and\nlogical complexity. Furthermore, BioResearcher incorporates an LLM-based\nreviewer for in-process quality control and introduces novel evaluation metrics\nto assess the quality and automation of experimental protocols. BioResearcher\nsuccessfully achieves an average execution success rate of 63.07% across eight\npreviously unmet research objectives. The generated protocols averagely\noutperform typical agent systems by 22.0% on five quality metrics. The system\ndemonstrates significant potential to reduce researchers' workloads and\naccelerate biomedical discoveries, paving the way for future innovations in\nautomated research systems.\n","authors":["Yi Luo","Linghang Shi","Yihao Li","Aobo Zhuang","Yeyun Gong","Ling Liu","Lin Chen"],"pdf_url":"https://arxiv.org/pdf/2412.09429v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.11149v5","updated":"2024-12-12T16:33:01Z","published":"2024-09-17T13:03:12Z","title":"SAGED: A Holistic Bias-Benchmarking Pipeline for Language Models with\n  Customisable Fairness Calibration","summary":"  The development of unbiased large language models is widely recognized as\ncrucial, yet existing benchmarks fall short in detecting biases due to limited\nscope, contamination, and lack of a fairness baseline. SAGED(bias) is the first\nholistic benchmarking pipeline to address these problems. The pipeline\nencompasses five core stages: scraping materials, assembling benchmarks,\ngenerating responses, extracting numeric features, and diagnosing with\ndisparity metrics. SAGED includes metrics for max disparity, such as impact\nratio, and bias concentration, such as Max Z-scores. Noticing that metric tool\nbias and contextual bias in prompts can distort evaluation, SAGED implements\ncounterfactual branching and baseline calibration for mitigation. For\ndemonstration, we use SAGED on G20 Countries with popular 8b-level models\nincluding Gemma2, Llama3.1, Mistral, and Qwen2. With sentiment analysis, we\nfind that while Mistral and Qwen2 show lower max disparity and higher bias\nconcentration than Gemma2 and Llama3.1, all models are notably biased against\ncountries like Russia and (except for Qwen2) China. With further experiments to\nhave models role-playing U.S. presidents, we see bias amplifies and shifts in\nheterogeneous directions. Moreover, we see Qwen2 and Mistral not engage in\nrole-playing, while Llama3.1 and Gemma2 role-play Trump notably more\nintensively than Biden and Harris, indicating role-playing performance bias in\nthese models.\n","authors":["Xin Guan","Nathaniel Demchak","Saloni Gupta","Ze Wang","Ediz Ertekin Jr.","Adriano Koshiyama","Emre Kazim","Zekun Wu"],"pdf_url":"https://arxiv.org/pdf/2409.11149v5.pdf","comment":"COLING 2025 Main Conference"},{"id":"http://arxiv.org/abs/2412.09416v1","updated":"2024-12-12T16:24:35Z","published":"2024-12-12T16:24:35Z","title":"Unifying AI Tutor Evaluation: An Evaluation Taxonomy for Pedagogical\n  Ability Assessment of LLM-Powered AI Tutors","summary":"  In this paper, we investigate whether current state-of-the-art large language\nmodels (LLMs) are effective as AI tutors and whether they demonstrate\npedagogical abilities necessary for good AI tutoring in educational dialogues.\nPrevious efforts towards evaluation have been limited to subjective protocols\nand benchmarks. To bridge this gap, we propose a unified evaluation taxonomy\nwith eight pedagogical dimensions based on key learning sciences principles,\nwhich is designed to assess the pedagogical value of LLM-powered AI tutor\nresponses grounded in student mistakes or confusion in the mathematical domain.\nWe release MRBench -- a new evaluation benchmark containing 192 conversations\nand 1,596 responses from seven state-of-the-art LLM-based and human tutors,\nproviding gold annotations for eight pedagogical dimensions. We assess\nreliability of the popular Prometheus2 LLM as an evaluator and analyze each\ntutor's pedagogical abilities, highlighting which LLMs are good tutors and\nwhich ones are more suitable as question-answering systems. We believe that the\npresented taxonomy, benchmark, and human-annotated labels will streamline the\nevaluation process and help track the progress in AI tutors' development.\n","authors":["Kaushal Kumar Maurya","KV Aditya Srivatsa","Kseniia Petukhova","Ekaterina Kochmar"],"pdf_url":"https://arxiv.org/pdf/2412.09416v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2412.09415v1","updated":"2024-12-12T16:23:12Z","published":"2024-12-12T16:23:12Z","title":"Text Generation Models for Luxembourgish with Limited Data: A Balanced\n  Multilingual Strategy","summary":"  This paper addresses the challenges in developing language models for\nless-represented languages, with a focus on Luxembourgish. Despite its active\ndevelopment, Luxembourgish faces a digital data scarcity, exacerbated by\nLuxembourg's multilingual context. We propose a novel text generation model\nbased on the T5 architecture, combining limited Luxembourgish data with equal\namounts, in terms of size and type, of German and French data. We hypothesise\nthat a model trained on Luxembourgish, German, and French will improve the\nmodel's cross-lingual transfer learning capabilities and outperform monolingual\nand large multilingual models. To verify this, the study at hand explores\nwhether multilingual or monolingual training is more beneficial for\nLuxembourgish language generation. For the evaluation, we introduce LuxGen, a\ntext generation benchmark that is the first of its kind for Luxembourgish.\n","authors":["Alistair Plum","Tharindu Ranasinghe","Christoph Purschke"],"pdf_url":"https://arxiv.org/pdf/2412.09415v1.pdf","comment":"Accepted at VarDial 2025"},{"id":"http://arxiv.org/abs/2412.09413v1","updated":"2024-12-12T16:20:36Z","published":"2024-12-12T16:20:36Z","title":"Imitate, Explore, and Self-Improve: A Reproduction Report on\n  Slow-thinking Reasoning Systems","summary":"  Recently, slow-thinking reasoning systems, such as o1, have demonstrated\nremarkable capabilities in solving complex reasoning tasks. These systems\ntypically engage in an extended thinking process before responding to a query,\nallowing them to generate more thorough, accurate, and well-reasoned solutions.\nThese systems are primarily developed and maintained by industry, with their\ncore techniques not publicly disclosed. In response, an increasing number of\nstudies from the research community aim to explore the technical foundations\nunderlying these powerful reasoning systems. Building on these prior efforts,\nthis paper presents a reproduction report on implementing o1-like reasoning\nsystems. We introduce an \"imitate, explore, and self-improve\" framework as our\nprimary technical approach to train the reasoning model. In the initial phase,\nwe use distilled long-form thought data to fine-tune the reasoning model,\nenabling it to invoke a slow-thinking mode. The model is then encouraged to\nexplore challenging problems by generating multiple rollouts, which can result\nin increasingly more high-quality trajectories that lead to correct answers.\nFurthermore, the model undergoes self-improvement by iteratively refining its\ntraining dataset. To verify the effectiveness of this approach, we conduct\nextensive experiments on three challenging benchmarks. The experimental results\ndemonstrate that our approach achieves competitive performance compared to\nindustry-level reasoning systems on these benchmarks.\n","authors":["Yingqian Min","Zhipeng Chen","Jinhao Jiang","Jie Chen","Jia Deng","Yiwen Hu","Yiru Tang","Jiapeng Wang","Xiaoxue Cheng","Huatong Song","Wayne Xin Zhao","Zheng Liu","Zhongyuan Wang","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2412.09413v1.pdf","comment":"Technical Report on Slow Thinking with LLMs: Part II"},{"id":"http://arxiv.org/abs/2412.00426v2","updated":"2024-12-12T16:19:14Z","published":"2024-11-30T10:52:24Z","title":"Few-Shot Domain Adaptation for Named-Entity Recognition via Joint\n  Constrained k-Means and Subspace Selection","summary":"  Named-entity recognition (NER) is a task that typically requires large\nannotated datasets, which limits its applicability across domains with varying\nentity definitions. This paper addresses few-shot NER, aiming to transfer\nknowledge to new domains with minimal supervision. Unlike previous approaches\nthat rely solely on limited annotated data, we propose a weakly supervised\nalgorithm that combines small labeled datasets with large amounts of unlabeled\ndata. Our method extends the k-means algorithm with label supervision, cluster\nsize constraints and domain-specific discriminative subspace selection. This\nunified framework achieves state-of-the-art results in few-shot NER on several\nEnglish datasets.\n","authors":["Ayoub Hammal","Benno Uthayasooriyar","Caio Corro"],"pdf_url":"https://arxiv.org/pdf/2412.00426v2.pdf","comment":"COLING 2025"},{"id":"http://arxiv.org/abs/2411.18564v2","updated":"2024-12-12T16:03:30Z","published":"2024-11-27T18:04:05Z","title":"Dspy-based Neural-Symbolic Pipeline to Enhance Spatial Reasoning in LLMs","summary":"  Large Language Models (LLMs) have demonstrated remarkable capabilities across\nvarious tasks, yet they often struggle with spatial reasoning. This paper\npresents a novel neural-symbolic framework that enhances LLMs' spatial\nreasoning abilities through iterative feedback between LLMs and Answer Set\nProgramming (ASP). We evaluate our approach on two benchmark datasets: StepGame\nand SparQA, implementing three distinct strategies: (1) direct prompting\nbaseline, (2) Facts+Rules prompting, and (3) DSPy-based LLM+ASP pipeline with\niterative refinement. Our experimental results demonstrate that the LLM+ASP\npipeline significantly outperforms baseline methods, achieving an average 82%\naccuracy on StepGame and 69% on SparQA, marking improvements of 40-50% and\n8-15% respectively over direct prompting. The success stems from three key\ninnovations: (1) effective separation of semantic parsing and logical reasoning\nthrough a modular pipeline, (2) iterative feedback mechanism between LLMs and\nASP solvers that improves program rate, and (3) robust error handling that\naddresses parsing, grounding, and solving failures. Additionally, we propose\nFacts+Rules as a lightweight alternative that achieves comparable performance\non complex SparQA dataset, while reducing computational overhead.Our analysis\nacross different LLM architectures (Deepseek, Llama3-70B, GPT-4.0 mini)\ndemonstrates the framework's generalizability and provides insights into the\ntrade-offs between implementation complexity and reasoning capability,\ncontributing to the development of more interpretable and reliable AI systems.\n","authors":["Rong Wang","Kun Sun","Jonas Kuhn"],"pdf_url":"https://arxiv.org/pdf/2411.18564v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09378v1","updated":"2024-12-12T15:46:43Z","published":"2024-12-12T15:46:43Z","title":"From Bench to Bedside: A Review of Clinical Trialsin Drug Discovery and\n  Development","summary":"  Clinical trials are an indispensable part of the drug development process,\nbridging the gap between basic research and clinical application. During the\ndevelopment of new drugs, clinical trials are used not only to evaluate the\nsafety and efficacy of the drug but also to explore its dosage, treatment\nregimens, and potential side effects. This review discusses the various stages\nof clinical trials, including Phase I (safety assessment), Phase II\n(preliminary efficacy evaluation), Phase III (large-scale validation), and\nPhase IV (post-marketing surveillance), highlighting the characteristics of\neach phase and their interrelationships. Additionally, the paper addresses the\nmajor challenges encountered in clinical trials, such as ethical issues,\nsubject recruitment difficulties, diversity and representativeness concerns,\nand proposes strategies for overcoming these challenges. With the advancement\nof technology, innovative technologies such as artificial intelligence, big\ndata, and digitalization are gradually transforming clinical trial design and\nimplementation, improving trial efficiency and data quality. The article also\nlooks forward to the future of clinical trials, particularly the impact of\nemerging therapies such as gene therapy and immunotherapy on trial design, as\nwell as the importance of regulatory reforms and global collaboration. In\nconclusion, the core role of clinical trials in drug development will continue\nto drive the progress of innovative drug development and clinical treatment.\n","authors":["Tianyang Wang","Ming Liu","Benji Peng","Xinyuan Song","Charles Zhang","Xintian Sun","Qian Niu","Junyu Liu","Silin Chen","Keyu Chen","Ming Li","Pohsun Feng","Ziqian Bi","Yunze Wang","Yichao Zhang","Cheng Fei","Lawrence KQ Yan"],"pdf_url":"https://arxiv.org/pdf/2412.09378v1.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2411.06908v2","updated":"2024-12-12T15:40:54Z","published":"2024-11-11T12:11:36Z","title":"EVQAScore: Efficient Video Question Answering Data Evaluation","summary":"  Video question-answering (QA) is a core task in video understanding.\nEvaluating the quality of video QA and video caption data quality for training\nvideo large language models (VideoLLMs) is an essential challenge. Although\nvarious methods have been proposed for assessing video caption quality, there\nremains a lack of dedicated evaluation methods for Video QA. To address this\ngap, we introduce EVQAScore, a reference-free method that leverages keyword\nextraction to assess both video caption and video QA data quality.\nAdditionally, we incorporate frame sampling and rescaling techniques to enhance\nthe efficiency and robustness of our evaluation, this enables our score to\nevaluate the quality of extremely long videos. Our approach achieves\nstate-of-the-art (SOTA) performance (32.8 for Kendall correlation and 42.3 for\nSpearman correlation, 4.7 and 5.9 higher than the previous method PAC-S++) on\nthe VATEX-EVAL benchmark for video caption evaluation. Furthermore, by using\nEVQAScore for data selection, we achieved SOTA results with only 12.5\\% of the\noriginal data volume, outperforming the previous SOTA method PAC-S and 100\\% of\ndata.\n","authors":["Hao Liang","Zirong Chen","Wentao Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.06908v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09370v1","updated":"2024-12-12T15:38:34Z","published":"2024-12-12T15:38:34Z","title":"Word Sense Linking: Disambiguating Outside the Sandbox","summary":"  Word Sense Disambiguation (WSD) is the task of associating a word in a given\ncontext with its most suitable meaning among a set of possible candidates.\nWhile the task has recently witnessed renewed interest, with systems achieving\nperformances above the estimated inter-annotator agreement, at the time of\nwriting it still struggles to find downstream applications. We argue that one\nof the reasons behind this is the difficulty of applying WSD to plain text.\nIndeed, in the standard formulation, models work under the assumptions that a)\nall the spans to disambiguate have already been identified, and b) all the\npossible candidate senses of each span are provided, both of which are\nrequirements that are far from trivial. In this work, we present a new task\ncalled Word Sense Linking (WSL) where, given an input text and a reference\nsense inventory, systems have to both identify which spans to disambiguate and\nthen link them to their most suitable meaning.We put forward a\ntransformer-based architecture for the task and thoroughly evaluate both its\nperformance and those of state-of-the-art WSD systems scaled to WSL,\niteratively relaxing the assumptions of WSD. We hope that our work will foster\neasier integration of lexical semantics into downstream applications.\n","authors":["Andrei Stefan Bejgu","Edoardo Barba","Luigi Procopio","Alberte Fernández-Castro","Roberto Navigli"],"pdf_url":"https://arxiv.org/pdf/2412.09370v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09362v1","updated":"2024-12-12T15:29:36Z","published":"2024-12-12T15:29:36Z","title":"Falcon-UI: Understanding GUI Before Following User Instructions","summary":"  Pursuing human-like interaction for Graphical User Interface (GUI) agents\nrequires understanding the GUI context and following user instructions.\nHowever, existing works typically couple these two aspects and focus more on\ninstruct-following abilities, while ignoring the importance of understanding\nthe GUI context. In this paper, we introduce an instruction-free GUI navigation\ndataset, termed Insight-UI Dataset, to enhance model comprehension of GUI\nenvironments. Insight-UI Dataset is automatically generated from the Common\nCrawl corpus, simulating various platforms -- including iOS, Android, Windows,\nand Linux -- across multiple resolutions on 312K domains. Although GUI\ninteractions vary by context, diverse interfaces share common internal\npatterns, such as clicking an item to view its details. It implies the\nfeasibility of independent GUI operation learning, followed by joint\noptimization with instruction tuning. Thereby, we develop the GUI agent model\nFalcon-UI, which is initially pretrained on Insight-UI Dataset and subsequently\nfine-tuned on Android and Web GUI datasets, including AITW, AITZ, Android\nControl, and Mind2Web. With 7 billion parameters, Falcon-UI achieves accuracy\ncomparable to the 72 billion-parameter Qwen2VL on AITZ, validating the\nalignment between GUI context comprehension and agent performance. Our code and\ndataset will be open-sourced.\n","authors":["Huawen Shen","Chang Liu","Gengluo Li","Xinlong Wang","Yu Zhou","Can Ma","Xiangyang Ji"],"pdf_url":"https://arxiv.org/pdf/2412.09362v1.pdf","comment":"18 pages, 14 figures"},{"id":"http://arxiv.org/abs/2412.09353v1","updated":"2024-12-12T15:22:03Z","published":"2024-12-12T15:22:03Z","title":"Causal Graphical Models for Vision-Language Compositional Understanding","summary":"  Recent work has empirically shown that Vision-Language Models (VLMs) struggle\nto fully understand the compositional properties of the human language, usually\nmodeling an image caption as a \"bag of words\". As a result, they perform poorly\non compositional tasks, which require a deeper understanding of the different\nentities of a sentence (subject, verb, etc.) jointly with their mutual\nrelationships in order to be solved. In this paper, we model the dependency\nrelations among textual and visual tokens using a Causal Graphical Model (CGM),\nbuilt using a dependency parser, and we train a decoder conditioned by the VLM\nvisual encoder. Differently from standard autoregressive or parallel\npredictions, our decoder's generative process is partially-ordered following\nthe CGM structure. This structure encourages the decoder to learn only the main\ncausal dependencies in a sentence discarding spurious correlations. Using\nextensive experiments on five compositional benchmarks, we show that our method\nsignificantly outperforms all the state-of-the-art compositional approaches by\na large margin, and it also improves over methods trained using much larger\ndatasets.\n","authors":["Fiorenzo Parascandolo","Nicholas Moratelli","Enver Sangineto","Lorenzo Baraldi","Rita Cucchiara"],"pdf_url":"https://arxiv.org/pdf/2412.09353v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09341v1","updated":"2024-12-12T15:09:44Z","published":"2024-12-12T15:09:44Z","title":"Training LayoutLM from Scratch for Efficient Named-Entity Recognition in\n  the Insurance Domain","summary":"  Generic pre-trained neural networks may struggle to produce good results in\nspecialized domains like finance and insurance. This is due to a domain\nmismatch between training data and downstream tasks, as in-domain data are\noften scarce due to privacy constraints. In this work, we compare different\npre-training strategies for LayoutLM. We show that using domain-relevant\ndocuments improves results on a named-entity recognition (NER) problem using a\nnovel dataset of anonymized insurance-related financial documents called\nPayslips. Moreover, we show that we can achieve competitive results using a\nsmaller and faster model.\n","authors":["Benno Uthayasooriyar","Antoine Ly","Franck Vermet","Caio Corro"],"pdf_url":"https://arxiv.org/pdf/2412.09341v1.pdf","comment":"Coling 2025 workshop (FinNLP)"},{"id":"http://arxiv.org/abs/2403.02285v2","updated":"2024-12-12T15:06:07Z","published":"2024-03-04T18:15:14Z","title":"Detection of Non-recorded Word Senses in English and Swedish","summary":"  This study addresses the task of Unknown Sense Detection in English and\nSwedish. The primary objective of this task is to determine whether the meaning\nof a particular word usage is documented in a dictionary or not. For this\npurpose, sense entries are compared with word usages from modern and historical\ncorpora using a pre-trained Word-in-Context embedder that allows us to model\nthis task in a few-shot scenario. Additionally, we use human annotations on the\ntarget corpora to adapt hyperparameters and evaluate our models using 5-fold\ncross-validation. Compared to a random sample from a corpus, our model is able\nto considerably increase the detected number of word usages with non-recorded\nsenses.\n","authors":["Jonathan Lautenschlager","Emma Sköldberg","Simon Hengchen","Dominik Schlechtweg"],"pdf_url":"https://arxiv.org/pdf/2403.02285v2.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2408.09849v2","updated":"2024-12-12T14:56:20Z","published":"2024-08-19T09:51:02Z","title":"Importance Weighting Can Help Large Language Models Self-Improve","summary":"  Large language models (LLMs) have shown remarkable capability in numerous\ntasks and applications. However, fine-tuning LLMs using high-quality datasets\nunder external supervision remains prohibitively expensive. In response, LLM\nself-improvement approaches have been vibrantly developed recently. The typical\nparadigm of LLM self-improvement involves training LLM on self-generated data,\npart of which may be detrimental and should be filtered out due to the unstable\ndata quality. While current works primarily employs filtering strategies based\non answer correctness, in this paper, we demonstrate that filtering out correct\nbut with high distribution shift extent (DSE) samples could also benefit the\nresults of self-improvement. Given that the actual sample distribution is\nusually inaccessible, we propose a new metric called DS weight to approximate\nDSE, inspired by the Importance Weighting methods. Consequently, we integrate\nDS weight with self-consistency to comprehensively filter the self-generated\nsamples and fine-tune the language model. Experiments show that with only a\ntiny valid set (up to 5\\% size of the training set) to compute DS weight, our\napproach can notably promote the reasoning ability of current LLM\nself-improvement methods. The resulting performance is on par with methods that\nrely on external supervision from pre-trained reward models.\n","authors":["Chunyang Jiang","Chi-min Chan","Wei Xue","Qifeng Liu","Yike Guo"],"pdf_url":"https://arxiv.org/pdf/2408.09849v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06651v3","updated":"2024-12-12T14:07:42Z","published":"2024-12-09T16:50:02Z","title":"Chatbots im Schulunterricht: Wir testen das Fobizz-Tool zur\n  automatischen Bewertung von Hausaufgaben","summary":"  [Study in German language.] This study examines the AI-powered grading tool\n\"AI Grading Assistant\" by the German company Fobizz, designed to support\nteachers in evaluating and providing feedback on student assignments. Against\nthe societal backdrop of an overburdened education system and rising\nexpectations for artificial intelligence as a solution to these challenges, the\ninvestigation evaluates the tool's functional suitability through two test\nseries. The results reveal significant shortcomings: The tool's numerical\ngrades and qualitative feedback are often random and do not improve even when\nits suggestions are incorporated. The highest ratings are achievable only with\ntexts generated by ChatGPT. False claims and nonsensical submissions frequently\ngo undetected, while the implementation of some grading criteria is unreliable\nand opaque. Since these deficiencies stem from the inherent limitations of\nlarge language models (LLMs), fundamental improvements to this or similar tools\nare not immediately foreseeable. The study critiques the broader trend of\nadopting AI as a quick fix for systemic problems in education, concluding that\nFobizz's marketing of the tool as an objective and time-saving solution is\nmisleading and irresponsible. Finally, the study calls for systematic\nevaluation and subject-specific pedagogical scrutiny of the use of AI tools in\neducational contexts.\n","authors":["Rainer Muehlhoff","Marte Henningsen"],"pdf_url":"https://arxiv.org/pdf/2412.06651v3.pdf","comment":"33 pages, in German language"},{"id":"http://arxiv.org/abs/2409.18446v2","updated":"2024-12-12T13:48:44Z","published":"2024-09-27T05:06:43Z","title":"Exploring Language Model Generalization in Low-Resource Extractive QA","summary":"  In this paper, we investigate Extractive Question Answering (EQA) with Large\nLanguage Models (LLMs) under domain drift, i.e., can LLMs generalize to domains\nthat require specific knowledge such as medicine and law in a zero-shot fashion\nwithout additional in-domain training? To this end, we devise a series of\nexperiments to explain the performance gap empirically. Our findings suggest\nthat: (a) LLMs struggle with dataset demands of closed domains such as\nretrieving long answer spans; (b) Certain LLMs, despite showing strong overall\nperformance, display weaknesses in meeting basic requirements as discriminating\nbetween domain-specific senses of words which we link to pre-processing\ndecisions; (c) Scaling model parameters is not always effective for cross\ndomain generalization; and (d) Closed-domain datasets are quantitatively much\ndifferent than open-domain EQA datasets and current LLMs struggle to deal with\nthem. Our findings point out important directions for improving existing LLMs.\n","authors":["Saptarshi Sengupta","Wenpeng Yin","Preslav Nakov","Shreya Ghosh","Suhang Wang"],"pdf_url":"https://arxiv.org/pdf/2409.18446v2.pdf","comment":"Accepted to COLING 2025"},{"id":"http://arxiv.org/abs/2412.09282v1","updated":"2024-12-12T13:45:11Z","published":"2024-12-12T13:45:11Z","title":"CRVQ: Channel-relaxed Vector Quantization for Extreme Compression of\n  LLMs","summary":"  Powerful large language models (LLMs) are increasingly expected to be\ndeployed with lower computational costs, enabling their capabilities on\nresource-constrained devices. Post-training quantization (PTQ) has emerged as a\nstar approach to achieve this ambition, with best methods compressing weights\nto less than 2 bit on average. In this paper, we propose Channel-Relaxed Vector\nQuantization (CRVQ), a novel technique that significantly improves the\nperformance of PTQ baselines at the cost of only minimal additional bits. This\nstate-of-the-art extreme compression method achieves its results through two\nkey innovations: (1) carefully selecting and reordering a very small subset of\ncritical weight channels, and (2) leveraging multiple codebooks to relax the\nconstraint of critical channels. With our method, we demonstrate a 38.9%\nimprovement over the current strongest sub-2-bit PTQ baseline, enabling nearer\nlossless 1-bit compression. Furthermore, our approach offers flexible\ncustomization of quantization bit-width and performance, providing a wider\nrange of deployment options for diverse hardware platforms.\n","authors":["Yuzhuang Xu","Shiyu Ji","Qingfu Zhu","Wanxiang Che"],"pdf_url":"https://arxiv.org/pdf/2412.09282v1.pdf","comment":"5 figures, 4 tables"},{"id":"http://arxiv.org/abs/2412.09280v1","updated":"2024-12-12T13:42:58Z","published":"2024-12-12T13:42:58Z","title":"Learning to Solve Domain-Specific Calculation Problems with\n  Knowledge-Intensive Programs Generator","summary":"  Domain Large Language Models (LLMs) are developed for domain-specific tasks\nbased on general LLMs. But it still requires professional knowledge to\nfacilitate the expertise for some domain-specific tasks. In this paper, we\ninvestigate into knowledge-intensive calculation problems. We find that the\nmath problems to be challenging for LLMs, when involving complex\ndomain-specific rules and knowledge documents, rather than simple formulations\nof terminologies. Therefore, we propose a pipeline to solve the domain-specific\ncalculation problems with Knowledge-Intensive Programs Generator more\neffectively, named as KIPG. It generates knowledge-intensive programs according\nto the domain-specific documents. For each query, key variables are extracted,\nthen outcomes which are dependent on domain knowledge are calculated with the\nprograms. By iterative preference alignment, the code generator learns to\nimprove the logic consistency with the domain knowledge. Taking legal domain as\nan example, we have conducted experiments to prove the effectiveness of our\npipeline, and extensive analysis on the modules. We also find that the code\ngenerator is also adaptable to other domains, without training on the new\nknowledge.\n","authors":["Chengyuan Liu","Shihang Wang","Lizhi Qing","Jun Lin","Ji Zhang","Fei Wu","Kun Kuang"],"pdf_url":"https://arxiv.org/pdf/2412.09280v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2310.16995v2","updated":"2024-12-12T13:33:56Z","published":"2023-10-25T20:48:16Z","title":"TOP-Training: Target-Oriented Pretraining for Medical Extractive\n  Question Answering","summary":"  We study extractive question-answering in the medical domain (Medical-EQA).\nThis problem has two main challenges: (i) domain specificity, as most AI models\nlack necessary domain knowledge, and (ii) extraction-based answering style,\nwhich restricts most autoregressive LLMs due to potential hallucinations. To\nhandle those challenges, we propose TOP-Training, a target-oriented\npre-training paradigm that stands out among all domain adaptation techniques\nwith two desirable features: (i) TOP-Training moves one step further than\npopular domain-oriented fine-tuning since it not only moves closer to the\ntarget domain, but also familiarizes itself with the target dataset, and (ii)\nit does not assume the existence of a large set of unlabeled instances from the\ntarget domain. Specifically, for a target Medical-EQA dataset, we extract its\nentities and leverage large language models (LLMs) to generate synthetic texts\ncontaining those entities; we then demonstrate that pretraining on this\nsynthetic text data yields better performance on the target Medical-EQA\nbenchmarks. Overall, our contributions are threefold: (i) TOP-Training, a new\npretraining technique to effectively adapt LLMs to better solve a target\nproblem, (ii) TOP-Training has a wide application scope because it does not\nrequire the target problem to have a large set of unlabeled data, and (iii) our\nexperiments highlight the limitations of autoregressive LLMs, emphasizing\nTOP-Training as a means to unlock the true potential of bidirectional LLMs.\n","authors":["Saptarshi Sengupta","Connor Heaton","Shreya Ghosh","Wenpeng Yin","Preslav Nakov","Suhang Wang"],"pdf_url":"https://arxiv.org/pdf/2310.16995v2.pdf","comment":"Accepted to COLING 2025"},{"id":"http://arxiv.org/abs/2412.09269v1","updated":"2024-12-12T13:31:58Z","published":"2024-12-12T13:31:58Z","title":"Towards Understanding the Robustness of LLM-based Evaluations under\n  Perturbations","summary":"  Traditional evaluation metrics like BLEU and ROUGE fall short when capturing\nthe nuanced qualities of generated text, particularly when there is no single\nground truth. In this paper, we explore the potential of Large Language Models\n(LLMs), specifically Google Gemini 1, to serve as automatic evaluators for\nnon-standardized metrics in summarization and dialog-based tasks. We conduct\nexperiments across multiple prompting strategies to examine how LLMs fare as\nquality evaluators when compared with human judgments on the SummEval and USR\ndatasets, asking the model to generate both a score as well as a justification\nfor the score. Furthermore, we explore the robustness of the LLM evaluator by\nusing perturbed inputs. Our findings suggest that while LLMs show promise,\ntheir alignment with human evaluators is limited, they are not robust against\nperturbations and significant improvements are required for their standalone\nuse as reliable evaluators for subjective metrics.\n","authors":["Manav Chaudhary","Harshit Gupta","Savita Bhat","Vasudeva Varma"],"pdf_url":"https://arxiv.org/pdf/2412.09269v1.pdf","comment":"Accepted at ICON 2024"},{"id":"http://arxiv.org/abs/2412.09247v1","updated":"2024-12-12T12:57:55Z","published":"2024-12-12T12:57:55Z","title":"Make Satire Boring Again: Reducing Stylistic Bias of Satirical Corpus by\n  Utilizing Generative LLMs","summary":"  Satire detection is essential for accurately extracting opinions from textual\ndata and combating misinformation online. However, the lack of diverse corpora\nfor satire leads to the problem of stylistic bias which impacts the models'\ndetection performances. This study proposes a debiasing approach for satire\ndetection, focusing on reducing biases in training data by utilizing generative\nlarge language models. The approach is evaluated in both cross-domain (irony\ndetection) and cross-lingual (English) settings. Results show that the\ndebiasing method enhances the robustness and generalizability of the models for\nsatire and irony detection tasks in Turkish and English. However, its impact on\ncausal language models, such as Llama-3.1, is limited. Additionally, this work\ncurates and presents the Turkish Satirical News Dataset with detailed human\nannotations, with case studies on classification, debiasing, and\nexplainability.\n","authors":["Asli Umay Ozturk","Recep Firat Cekinel","Pinar Karagoz"],"pdf_url":"https://arxiv.org/pdf/2412.09247v1.pdf","comment":"Accepted to BUCC2025 Workshop @COLING2025"},{"id":"http://arxiv.org/abs/2408.02976v2","updated":"2024-12-12T12:52:51Z","published":"2024-08-06T06:16:00Z","title":"Empathy Level Alignment via Reinforcement Learning for Empathetic\n  Response Generation","summary":"  Empathetic response generation, aiming to understand the user's situation and\nfeelings and respond empathically, is crucial in building human-like dialogue\nsystems. Traditional approaches typically employ maximum likelihood estimation\nas the optimization objective during training, yet fail to align the empathy\nlevels between generated and target responses. To this end, we propose an\nempathetic response generation framework using reinforcement learning (EmpRL).\nThe framework develops an effective empathy reward function and generates\nempathetic responses by maximizing the expected reward through reinforcement\nlearning. EmpRL utilizes the pre-trained T5 model as the generator and further\nfine-tunes it to initialize the policy. To align the empathy levels between\ngenerated and target responses within a given context, an empathy reward\nfunction containing three empathy communication mechanisms -- emotional\nreaction, interpretation, and exploration -- is constructed using pre-designed\nand pre-trained empathy identifiers. During reinforcement learning training,\nthe proximal policy optimization algorithm is used to fine-tune the policy,\nenabling the generation of empathetic responses. Both automatic and human\nevaluations demonstrate that the proposed EmpRL framework significantly\nimproves the quality of generated responses, enhances the similarity in empathy\nlevels between generated and target responses, and produces empathetic\nresponses covering both affective and cognitive aspects.\n","authors":["Hui Ma","Bo Zhang","Bo Xu","Jian Wang","Hongfei Lin","Xiao Sun"],"pdf_url":"https://arxiv.org/pdf/2408.02976v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.16048v3","updated":"2024-12-12T12:01:43Z","published":"2024-02-25T10:13:04Z","title":"How Likely Do LLMs with CoT Mimic Human Reasoning?","summary":"  Chain-of-thought emerges as a promising technique for eliciting reasoning\ncapabilities from Large Language Models (LLMs). However, it does not always\nimprove task performance or accurately represent reasoning processes, leaving\nunresolved questions about its usage. In this paper, we diagnose the underlying\nmechanism by comparing the reasoning process of LLMs with humans, using causal\nanalysis to understand the relationships between the problem instruction,\nreasoning, and the answer in LLMs. Our empirical study reveals that LLMs often\ndeviate from the ideal causal chain, resulting in spurious correlations and\npotential consistency errors (inconsistent reasoning and answers). We also\nexamine various factors influencing the causal structure, finding that\nin-context learning with examples strengthens it, while post-training\ntechniques like supervised fine-tuning and reinforcement learning on human\nfeedback weaken it. To our surprise, the causal structure cannot be\nstrengthened by enlarging the model size only, urging research on new\ntechniques. We hope that this preliminary study will shed light on\nunderstanding and improving the reasoning process in LLM.\n","authors":["Guangsheng Bao","Hongbo Zhang","Cunxiang Wang","Linyi Yang","Yue Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.16048v3.pdf","comment":"COLING 2025 Camera Version (8 pages, 3 figures, 18 tables)"},{"id":"http://arxiv.org/abs/2412.09203v1","updated":"2024-12-12T11:57:59Z","published":"2024-12-12T11:57:59Z","title":"CleanComedy: Creating Friendly Humor through Generative Techniques","summary":"  Humor generation is a challenging task in natural language processing due to\nlimited resources and the quality of existing datasets. Available humor\nlanguage resources often suffer from toxicity and duplication, limiting their\neffectiveness for training robust models. This paper proposes CleanComedy, a\nspecialized, partially annotated toxicity-filtered corpus of English and\nRussian jokes collected from various sources. We study the effectiveness of our\ndata filtering approach through a survey on humor and toxicity levels in\nvarious joke groups. In addition, we study advances in computer humor\ngeneration by comparing jokes written by humans with various groups of\ngenerative jokes, including our baseline models trained on the CleanComedy\ndatasets.\n","authors":["Dmitry Vikhorev","Daria Galimzianova","Svetlana Gorovaia","Elizaveta Zhemchuzhina","Ivan P. Yamshchikov"],"pdf_url":"https://arxiv.org/pdf/2412.09203v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08163v2","updated":"2024-12-12T11:42:11Z","published":"2024-12-11T07:37:26Z","title":"NLPineers@ NLU of Devanagari Script Languages 2025: Hate Speech\n  Detection using Ensembling of BERT-based models","summary":"  This paper explores hate speech detection in Devanagari-scripted languages,\nfocusing on Hindi and Nepali, for Subtask B of the CHIPSAL@COLING 2025 Shared\nTask. Using a range of transformer-based models such as XLM-RoBERTa, MURIL, and\nIndicBERT, we examine their effectiveness in navigating the nuanced boundary\nbetween hate speech and free expression. Our best performing model, implemented\nas ensemble of multilingual BERT models achieve Recall of 0.7762 (Rank 3/31 in\nterms of recall) and F1 score of 0.6914 (Rank 17/31). To address class\nimbalance, we used backtranslation for data augmentation, and cosine similarity\nto preserve label consistency after augmentation. This work emphasizes the need\nfor hate speech detection in Devanagari-scripted languages and presents a\nfoundation for further research.\n","authors":["Anmol Guragain","Nadika Poudel","Rajesh Piryani","Bishesh Khanal"],"pdf_url":"https://arxiv.org/pdf/2412.08163v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.13516v5","updated":"2024-12-12T11:29:32Z","published":"2024-02-21T03:58:49Z","title":"ProSparse: Introducing and Enhancing Intrinsic Activation Sparsity\n  within Large Language Models","summary":"  Activation sparsity refers to the existence of considerable\nweakly-contributed elements among activation outputs. As a prevalent property\nof the models using the ReLU activation function, activation sparsity has been\nproven a promising paradigm to boost model inference efficiency. Nevertheless,\nmost large language models (LLMs) adopt activation functions without intrinsic\nactivation sparsity (e.g., GELU and Swish). Some recent efforts have explored\nintroducing ReLU or its variants as the substitutive activation function to\nhelp LLMs achieve activation sparsity and inference acceleration, but few can\nsimultaneously obtain high sparsity and comparable model performance. This\npaper introduces a simple and effective sparsification method named \"ProSparse\"\nto push LLMs for higher activation sparsity while maintaining comparable\nperformance. Specifically, after substituting the activation function of LLMs\nwith ReLU, ProSparse adopts progressive sparsity regularization with a factor\nsmoothly increasing along the multi-stage sine curves. This can enhance\nactivation sparsity and mitigate performance degradation by avoiding radical\nshifts in activation distributions. With ProSparse, we obtain high sparsity of\n89.32% for LLaMA2-7B, 88.80% for LLaMA2-13B, and 87.89% for end-size\nMiniCPM-1B, respectively, achieving comparable performance to their original\nSwish-activated versions. These present the most sparsely activated models\namong open-source LLaMA versions and competitive end-size models, considerably\nsurpassing ReluLLaMA-7B (66.98%) and ReluLLaMA-13B (71.56%). Our inference\nacceleration experiments further demonstrate the significant practical\nacceleration potential of LLMs with higher activation sparsity, obtaining up to\n4.52$\\times$ inference speedup.\n","authors":["Chenyang Song","Xu Han","Zhengyan Zhang","Shengding Hu","Xiyu Shi","Kuai Li","Chen Chen","Zhiyuan Liu","Guangli Li","Tao Yang","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2402.13516v5.pdf","comment":"19 pages, 4 figures, 9 tables"},{"id":"http://arxiv.org/abs/2412.04100v2","updated":"2024-12-12T11:12:03Z","published":"2024-12-05T12:10:42Z","title":"Missing Melodies: AI Music Generation and its \"Nearly\" Complete Omission\n  of the Global South","summary":"  Recent advances in generative AI have sparked renewed interest and expanded\npossibilities for music generation. However, the performance and versatility of\nthese systems across musical genres are heavily influenced by the availability\nof training data. We conducted an extensive analysis of over one million hours\nof audio datasets used in AI music generation research and manually reviewed\nmore than 200 papers from eleven prominent AI and music conferences and\norganizations (AAAI, ACM, EUSIPCO, EURASIP, ICASSP, ICML, IJCAI, ISMIR,\nNeurIPS, NIME, SMC) to identify a critical gap in the fair representation and\ninclusion of the musical genres of the Global South in AI research. Our\nfindings reveal a stark imbalance: approximately 86% of the total dataset hours\nand over 93% of researchers focus primarily on music from the Global North.\nHowever, around 40% of these datasets include some form of non-Western music,\ngenres from the Global South account for only 14.6% of the data. Furthermore,\napproximately 51% of the papers surveyed concentrate on symbolic music\ngeneration, a method that often fails to capture the cultural nuances inherent\nin music from regions such as South Asia, the Middle East, and Africa. As AI\nincreasingly shapes the creation and dissemination of music, the significant\nunderrepresentation of music genres in datasets and research presents a serious\nthreat to global musical diversity. We also propose some important steps to\nmitigate these risks and foster a more inclusive future for AI-driven music\ngeneration.\n","authors":["Atharva Mehta","Shivam Chauhan","Monojit Choudhury"],"pdf_url":"https://arxiv.org/pdf/2412.04100v2.pdf","comment":"Submitted to CACM, 12 pages, 2 figures"},{"id":"http://arxiv.org/abs/2412.09173v1","updated":"2024-12-12T11:03:25Z","published":"2024-12-12T11:03:25Z","title":"ReFF: Reinforcing Format Faithfulness in Language Models across Varied\n  Tasks","summary":"  Following formatting instructions to generate well-structured content is a\nfundamental yet often unmet capability for large language models (LLMs). To\nstudy this capability, which we refer to as format faithfulness, we present\nFormatBench, a comprehensive format-related benchmark. Compared to previous\nformat-related benchmarks, FormatBench involves a greater variety of tasks in\nterms of application scenes (traditional NLP tasks, creative works, autonomous\nagency tasks), human-LLM interaction styles (single-turn instruction,\nmulti-turn chat), and format types (inclusion, wrapping, length, coding).\nMoreover, each task in FormatBench is attached with a format checker program.\nExtensive experiments on the benchmark reveal that state-of-the-art open- and\nclosed-source LLMs still suffer from severe deficiency in format faithfulness.\nBy virtue of the decidable nature of formats, we propose to Reinforce Format\nFaithfulness (ReFF) to help LLMs generate formatted output as instructed\nwithout compromising general quality. Without any annotated data, ReFF can\nsubstantially improve the format faithfulness rate (e.g., from 21.6% in\noriginal LLaMA3 to 95.0% on caption segmentation task), while keep the general\nquality comparable (e.g., from 47.3 to 46.4 in F1 scores). Combined with\nlabeled training data, ReFF can simultaneously improve both format faithfulness\n(e.g., from 21.6% in original LLaMA3 to 75.5%) and general quality (e.g., from\n47.3 to 61.6 in F1 scores). We further offer an interpretability analysis to\nexplain how ReFF improves both format faithfulness and general quality.\n","authors":["Jiashu Yao","Heyan Huang","Zeming Liu","Haoyu Wen","Wei Su","Boao Qian","Yuhang Guo"],"pdf_url":"https://arxiv.org/pdf/2412.09173v1.pdf","comment":"Accepted to AAAI 2025"},{"id":"http://arxiv.org/abs/2404.04108v2","updated":"2024-12-12T10:56:35Z","published":"2024-04-05T14:04:07Z","title":"Large language models as oracles for instantiating ontologies with\n  domain-specific knowledge","summary":"  Background. Endowing intelligent systems with semantic data commonly requires\ndesigning and instantiating ontologies with domain-specific knowledge.\nEspecially in the early phases, those activities are typically performed\nmanually by human experts possibly leveraging on their own experience. The\nresulting process is therefore time-consuming, error-prone, and often biased by\nthe personal background of the ontology designer. Objective. To mitigate that\nissue, we propose a novel domain-independent approach to automatically\ninstantiate ontologies with domain-specific knowledge, by leveraging on large\nlanguage models (LLMs) as oracles. Method. Starting from (i) an initial schema\ncomposed by inter-related classes and properties and (ii) a set of query\ntemplates, our method queries the LLM multiple times, and generates instances\nfor both classes and properties from its replies. Thus, the ontology is\nautomatically filled with domain-specific knowledge, compliant to the initial\nschema. As a result, the ontology is quickly and automatically enriched with\nmanifold instances, which experts may consider to keep, adjust, discard, or\ncomplement according to their own needs and expertise. Contribution. We\nformalise our method in general way and instantiate it over various LLMs, as\nwell as on a concrete case study. We report experiments rooted in the\nnutritional domain where an ontology of food meals and their ingredients is\nautomatically instantiated from scratch, starting from a categorisation of\nmeals and their relationships. There, we analyse the quality of the generated\nontologies and compare ontologies attained by exploiting different LLMs.\nExperimentally, our approach achieves a quality metric that is up to five times\nhigher than the state-of-the-art, while reducing erroneous entities and\nrelations by up to ten times. Finally, we provide a SWOT analysis of the\nproposed method.\n","authors":["Giovanni Ciatto","Andrea Agiollo","Matteo Magnini","Andrea Omicini"],"pdf_url":"https://arxiv.org/pdf/2404.04108v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09165v1","updated":"2024-12-12T10:50:26Z","published":"2024-12-12T10:50:26Z","title":"When Text Embedding Meets Large Language Model: A Comprehensive Survey","summary":"  Text embedding has become a foundational technology in natural language\nprocessing (NLP) during the deep learning era, driving advancements across a\nwide array of downstream tasks. While many natural language understanding\nchallenges can now be modeled using generative paradigms and leverage the\nrobust generative and comprehension capabilities of large language models\n(LLMs), numerous practical applications, such as semantic matching, clustering,\nand information retrieval, continue to rely on text embeddings for their\nefficiency and effectiveness. In this survey, we categorize the interplay\nbetween LLMs and text embeddings into three overarching themes: (1)\nLLM-augmented text embedding, enhancing traditional embedding methods with\nLLMs; (2) LLMs as text embedders, utilizing their innate capabilities for\nembedding generation; and (3) Text embedding understanding with LLMs,\nleveraging LLMs to analyze and interpret embeddings. By organizing these\nefforts based on interaction patterns rather than specific downstream\napplications, we offer a novel and systematic overview of contributions from\nvarious research and application domains in the era of LLMs. Furthermore, we\nhighlight the unresolved challenges that persisted in the pre-LLM era with\npre-trained language models (PLMs) and explore the emerging obstacles brought\nforth by LLMs. Building on this analysis, we outline prospective directions for\nthe evolution of text embedding, addressing both theoretical and practical\nopportunities in the rapidly advancing landscape of NLP.\n","authors":["Zhijie Nie","Zhangchi Feng","Mingxin Li","Cunwang Zhang","Yanzhao Zhang","Dingkun Long","Richong Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.09165v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2405.20612v2","updated":"2024-12-12T10:46:44Z","published":"2024-05-31T03:59:15Z","title":"UniBias: Unveiling and Mitigating LLM Bias through Internal Attention\n  and FFN Manipulation","summary":"  Large language models (LLMs) have demonstrated impressive capabilities in\nvarious tasks using the in-context learning (ICL) paradigm. However, their\neffectiveness is often compromised by inherent bias, leading to prompt\nbrittleness, i.e., sensitivity to design settings such as example selection,\norder, and prompt formatting. Previous studies have addressed LLM bias through\nexternal adjustment of model outputs, but the internal mechanisms that lead to\nsuch bias remain unexplored. Our work delves into these mechanisms,\nparticularly investigating how feedforward neural networks (FFNs) and attention\nheads result in the bias of LLMs. By Interpreting the contribution of\nindividual FFN vectors and attention heads, we identify the biased LLM\ncomponents that skew LLMs' prediction toward specific labels. To mitigate these\nbiases, we introduce UniBias, an inference-only method that effectively\nidentifies and eliminates biased FFN vectors and attention heads. Extensive\nexperiments across 12 NLP datasets demonstrate that UniBias significantly\nenhances ICL performance and alleviates prompt brittleness of LLMs.\n","authors":["Hanzhang Zhou","Zijian Feng","Zixiao Zhu","Junlang Qian","Kezhi Mao"],"pdf_url":"https://arxiv.org/pdf/2405.20612v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2407.10510v2","updated":"2024-12-12T10:40:22Z","published":"2024-07-15T08:06:37Z","title":"TCM-FTP: Fine-Tuning Large Language Models for Herbal Prescription\n  Prediction","summary":"  Traditional Chinese medicine (TCM) has relied on specific combinations of\nherbs in prescriptions to treat various symptoms and signs for thousands of\nyears. Predicting TCM prescriptions poses a fascinating technical challenge\nwith significant practical implications. However, this task faces limitations\ndue to the scarcity of high-quality clinical datasets and the complex\nrelationship between symptoms and herbs. To address these issues, we introduce\n\\textit{DigestDS}, a novel dataset comprising practical medical records from\nexperienced experts in digestive system diseases. We also propose a method,\nTCM-FTP (TCM Fine-Tuning Pre-trained), to leverage pre-trained large language\nmodels (LLMs) via supervised fine-tuning on \\textit{DigestDS}. Additionally, we\nenhance computational efficiency using a low-rank adaptation technique.\nMoreover, TCM-FTP incorporates data augmentation by permuting herbs within\nprescriptions, exploiting their order-agnostic nature. Impressively, TCM-FTP\nachieves an F1-score of 0.8031, significantly outperforming previous methods.\nFurthermore, it demonstrates remarkable accuracy in dosage prediction,\nachieving a normalized mean square error of 0.0604. In contrast, LLMs without\nfine-tuning exhibit poor performance. Although LLMs have demonstrated\nwide-ranging capabilities, our work underscores the necessity of fine-tuning\nfor TCM prescription prediction and presents an effective way to accomplish\nthis.\n","authors":["Xingzhi Zhou","Xin Dong","Chunhao Li","Yuning Bai","Yulong Xu","Ka Chun Cheung","Simon See","Xinpeng Song","Runshun Zhang","Xuezhong Zhou","Nevin L. Zhang"],"pdf_url":"https://arxiv.org/pdf/2407.10510v2.pdf","comment":"Camera-ready version to be published in BIBM 2024"},{"id":"http://arxiv.org/abs/2412.08237v2","updated":"2024-12-12T10:01:11Z","published":"2024-12-11T09:38:50Z","title":"TouchTTS: An Embarrassingly Simple TTS Framework that Everyone Can Touch","summary":"  It is well known that LLM-based systems are data-hungry. Recent LLM-based TTS\nworks typically employ complex data processing pipelines to obtain high-quality\ntraining data. These sophisticated pipelines require excellent models at each\nstage (e.g., speech denoising, speech enhancement, speaker diarization, and\npunctuation models), which themselves demand high-quality training data and are\nrarely open-sourced. Even with state-of-the-art models, issues persist, such as\nincomplete background noise removal and misalignment between punctuation and\nactual speech pauses. Moreover, the stringent filtering strategies often retain\nonly 10-30\\% of the original data, significantly impeding data scaling efforts.\nIn this work, we leverage a noise-robust audio tokenizer (S3Tokenizer) to\ndesign a simplified yet effective TTS data processing pipeline that maintains\ndata quality while substantially reducing data acquisition costs, achieving a\ndata retention rate of over 50\\%. Beyond data scaling challenges, LLM-based TTS\nsystems also incur higher deployment costs compared to conventional approaches.\nCurrent systems typically use LLMs solely for text-to-token generation, while\nrequiring separate models (e.g., flow matching models) for token-to-waveform\ngeneration, which cannot be directly executed by LLM inference engines, further\ncomplicating deployment. To address these challenges, we eliminate redundant\nmodules in both LLM and flow components, replacing the flow model backbone with\nan LLM architecture. Building upon this simplified flow backbone, we propose a\nunified architecture for both streaming and non-streaming inference,\nsignificantly reducing deployment costs. Finally, we explore the feasibility of\nunifying TTS and ASR tasks using the same data for training, thanks to the\nsimplified pipeline and the S3Tokenizer that reduces the quality requirements\nfor TTS training data.\n","authors":["Xingchen Song","Mengtao Xing","Changwei Ma","Shengqiang Li","Di Wu","Binbin Zhang","Fuping Pan","Dinghao Zhou","Yuekai Zhang","Shun Lei","Zhendong Peng","Zhiyong Wu"],"pdf_url":"https://arxiv.org/pdf/2412.08237v2.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2412.09102v1","updated":"2024-12-12T09:29:59Z","published":"2024-12-12T09:29:59Z","title":"PolyIPA -- Multilingual Phoneme-to-Grapheme Conversion Model","summary":"  This paper presents PolyIPA, a novel multilingual phoneme-to-grapheme\nconversion model designed for multilingual name transliteration, onomastic\nresearch, and information retrieval. The model leverages two helper models\ndeveloped for data augmentation: IPA2vec for finding soundalikes across\nlanguages, and similarIPA for handling phonetic notation variations. Evaluated\non a test set that spans multiple languages and writing systems, the model\nachieves a mean Character Error Rate of 0.055 and a character-level BLEU score\nof 0.914, with particularly strong performance on languages with shallow\northographies. The implementation of beam search further improves practical\nutility, with top-3 candidates reducing the effective error rate by 52.7\\% (to\nCER: 0.026), demonstrating the model's effectiveness for cross-linguistic\napplications.\n","authors":["Davor Lauc"],"pdf_url":"https://arxiv.org/pdf/2412.09102v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2404.04264v5","updated":"2024-12-12T23:17:01Z","published":"2024-03-17T17:01:45Z","title":"Logic Query of Thoughts: Guiding Large Language Models to Answer Complex\n  Logic Queries with Knowledge Graphs","summary":"  Despite the superb performance in many tasks, large language models (LLMs)\nbear the risk of generating hallucination or even wrong answers when confronted\nwith tasks that demand the accuracy of knowledge. The issue becomes even more\nnoticeable when addressing logic queries that require multiple logic reasoning\nsteps. On the other hand, knowledge graph (KG) based question answering methods\nare capable of accurately identifying the correct answers with the help of\nknowledge graph, yet its accuracy could quickly deteriorate when the knowledge\ngraph itself is sparse and incomplete. It remains a critical challenge on how\nto integrate knowledge graph reasoning with LLMs in a mutually beneficial way\nso as to mitigate both the hallucination problem of LLMs as well as the\nincompleteness issue of knowledge graphs. In this paper, we propose\n'Logic-Query-of-Thoughts' (LGOT) which is the first of its kind to combine LLMs\nwith knowledge graph based logic query reasoning. LGOT seamlessly combines\nknowledge graph reasoning and LLMs, effectively breaking down complex logic\nqueries into easy to answer subquestions. Through the utilization of both\nknowledge graph reasoning and LLMs, it successfully derives answers for each\nsubquestion. By aggregating these results and selecting the highest quality\ncandidate answers for each step, LGOT achieves accurate results to complex\nquestions. Our experimental findings demonstrate substantial performance\nenhancements, with up to 20% improvement over ChatGPT.\n","authors":["Lihui Liu","Zihao Wang","Ruizhong Qiu","Yikun Ban","Eunice Chan","Yangqiu Song","Jingrui He","Hanghang Tong"],"pdf_url":"https://arxiv.org/pdf/2404.04264v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09560v1","updated":"2024-12-12T18:46:38Z","published":"2024-12-12T18:46:38Z","title":"Foundational Large Language Models for Materials Research","summary":"  Materials discovery and development are critical for addressing global\nchallenges. Yet, the exponential growth in materials science literature\ncomprising vast amounts of textual data has created significant bottlenecks in\nknowledge extraction, synthesis, and scientific reasoning. Large Language\nModels (LLMs) offer unprecedented opportunities to accelerate materials\nresearch through automated analysis and prediction. Still, their effective\ndeployment requires domain-specific adaptation for understanding and solving\ndomain-relevant tasks. Here, we present LLaMat, a family of foundational models\nfor materials science developed through continued pretraining of LLaMA models\non an extensive corpus of materials literature and crystallographic data.\nThrough systematic evaluation, we demonstrate that LLaMat excels in\nmaterials-specific NLP and structured information extraction while maintaining\ngeneral linguistic capabilities. The specialized LLaMat-CIF variant\ndemonstrates unprecedented capabilities in crystal structure generation,\npredicting stable crystals with high coverage across the periodic table.\nIntriguingly, despite LLaMA-3's superior performance in comparison to LLaMA-2,\nwe observe that LLaMat-2 demonstrates unexpectedly enhanced domain-specific\nperformance across diverse materials science tasks, including structured\ninformation extraction from text and tables, more particularly in crystal\nstructure generation, a potential adaptation rigidity in overtrained LLMs.\nAltogether, the present work demonstrates the effectiveness of domain\nadaptation towards developing practically deployable LLM copilots for materials\nresearch. Beyond materials science, our findings reveal important\nconsiderations for domain adaptation of LLMs, such as model selection, training\nmethodology, and domain-specific performance, which may influence the\ndevelopment of specialized scientific AI systems.\n","authors":["Vaibhav Mishra","Somaditya Singh","Dhruv Ahlawat","Mohd Zaki","Vaibhav Bihani","Hargun Singh Grover","Biswajit Mishra","Santiago Miret"," Mausam","N. M. Anoop Krishnan"],"pdf_url":"https://arxiv.org/pdf/2412.09560v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.02961v2","updated":"2024-12-12T15:21:44Z","published":"2023-04-06T09:38:54Z","title":"HGCH: A Hyperbolic Graph Convolution Network Model for Heterogeneous\n  Collaborative Graph Recommendation","summary":"  User-item interaction data in collaborative filtering and graph modeling\ntasks often exhibit power-law characteristics, which suggest the suitability of\nhyperbolic space modeling. Hyperbolic Graph Convolution Neural Networks (HGCNs)\nare a novel technique that leverages the advantages of GCN and hyperbolic\nspace, and then achieves remarkable results. However, existing HGCN methods\nhave several drawbacks: they fail to fully leverage hyperbolic space properties\ndue to arbitrary embedding initialization and imprecise tangent space\naggregation; they overlook auxiliary information that could enrich the\ncollaborative graph; and their training convergence is slow due to margin\nranking loss and random negative sampling. To overcome these challenges, we\npropose Hyperbolic Graph Collaborative for Heterogeneous Recommendation (HGCH),\nan enhanced HGCN-based model for collaborative filtering that integrates\ndiverse side information into a heterogeneous collaborative graph and improves\ntraining convergence speed. HGCH first preserves the long-tailed nature of the\ngraph by initializing node embeddings with power law prior; then it aggregates\nneighbors in hyperbolic space using the gyromidpoint method for accurate\ncomputation; finally, it fuses multiple embeddings from different hyperbolic\nspaces by the gate fusion with prior. Moreover, HGCH employs a hyperbolic\nuser-specific negative sampling to speed up convergence. We evaluate HGCH on\nfour real datasets, and the results show that HGCH achieves competitive results\nand outperforms leading baselines, including HGCNs. Extensive ablation studies\nfurther confirm its effectiveness.\n","authors":["Lu Zhang","Ning Wu"],"pdf_url":"https://arxiv.org/pdf/2304.02961v2.pdf","comment":"Proceedings of the 33rd ACM International Conference on Information\n  and Knowledge Management (CIKM '24)"},{"id":"http://arxiv.org/abs/2412.09243v1","updated":"2024-12-12T12:53:30Z","published":"2024-12-12T12:53:30Z","title":"SPRec: Leveraging Self-Play to Debias Preference Alignment for Large\n  Language Model-based Recommendations","summary":"  Large language models (LLMs) have attracted significant attention in\nrecommendation systems. Current LLM-based recommender systems primarily rely on\nsupervised fine-tuning (SFT) to train the model for recommendation tasks.\nHowever, relying solely on positive samples limits the model's ability to align\nwith user satisfaction and expectations. To address this, researchers have\nintroduced Direct Preference Optimization (DPO), which explicitly aligns\nrecommendations with user preferences using offline preference ranking data.\nDespite its advantages, our theoretical analysis reveals that DPO inherently\nbiases the model towards a few items, exacerbating the filter bubble issue and\nultimately degrading user experience. In this paper, we propose SPRec, a novel\nself-play recommendation framework designed to mitigate over-recommendation and\nimprove fairness without requiring additional data or manual intervention. In\neach self-play iteration, the model undergoes an SFT step followed by a DPO\nstep, treating offline interaction data as positive samples and the predicted\noutputs from the previous iteration as negative samples. This effectively\nre-weights the DPO loss function using the model's logits, adaptively\nsuppressing biased items. Extensive experiments on multiple real-world datasets\ndemonstrate SPRec's effectiveness in enhancing recommendation accuracy and\naddressing fairness concerns.\n","authors":["Chongming Gao","Ruijun Chen","Shuai Yuan","Kexin Huang","Yuanqing Yu","Xiangnan He"],"pdf_url":"https://arxiv.org/pdf/2412.09243v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.04108v2","updated":"2024-12-12T10:56:35Z","published":"2024-04-05T14:04:07Z","title":"Large language models as oracles for instantiating ontologies with\n  domain-specific knowledge","summary":"  Background. Endowing intelligent systems with semantic data commonly requires\ndesigning and instantiating ontologies with domain-specific knowledge.\nEspecially in the early phases, those activities are typically performed\nmanually by human experts possibly leveraging on their own experience. The\nresulting process is therefore time-consuming, error-prone, and often biased by\nthe personal background of the ontology designer. Objective. To mitigate that\nissue, we propose a novel domain-independent approach to automatically\ninstantiate ontologies with domain-specific knowledge, by leveraging on large\nlanguage models (LLMs) as oracles. Method. Starting from (i) an initial schema\ncomposed by inter-related classes and properties and (ii) a set of query\ntemplates, our method queries the LLM multiple times, and generates instances\nfor both classes and properties from its replies. Thus, the ontology is\nautomatically filled with domain-specific knowledge, compliant to the initial\nschema. As a result, the ontology is quickly and automatically enriched with\nmanifold instances, which experts may consider to keep, adjust, discard, or\ncomplement according to their own needs and expertise. Contribution. We\nformalise our method in general way and instantiate it over various LLMs, as\nwell as on a concrete case study. We report experiments rooted in the\nnutritional domain where an ontology of food meals and their ingredients is\nautomatically instantiated from scratch, starting from a categorisation of\nmeals and their relationships. There, we analyse the quality of the generated\nontologies and compare ontologies attained by exploiting different LLMs.\nExperimentally, our approach achieves a quality metric that is up to five times\nhigher than the state-of-the-art, while reducing erroneous entities and\nrelations by up to ten times. Finally, we provide a SWOT analysis of the\nproposed method.\n","authors":["Giovanni Ciatto","Andrea Agiollo","Matteo Magnini","Andrea Omicini"],"pdf_url":"https://arxiv.org/pdf/2404.04108v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09165v1","updated":"2024-12-12T10:50:26Z","published":"2024-12-12T10:50:26Z","title":"When Text Embedding Meets Large Language Model: A Comprehensive Survey","summary":"  Text embedding has become a foundational technology in natural language\nprocessing (NLP) during the deep learning era, driving advancements across a\nwide array of downstream tasks. While many natural language understanding\nchallenges can now be modeled using generative paradigms and leverage the\nrobust generative and comprehension capabilities of large language models\n(LLMs), numerous practical applications, such as semantic matching, clustering,\nand information retrieval, continue to rely on text embeddings for their\nefficiency and effectiveness. In this survey, we categorize the interplay\nbetween LLMs and text embeddings into three overarching themes: (1)\nLLM-augmented text embedding, enhancing traditional embedding methods with\nLLMs; (2) LLMs as text embedders, utilizing their innate capabilities for\nembedding generation; and (3) Text embedding understanding with LLMs,\nleveraging LLMs to analyze and interpret embeddings. By organizing these\nefforts based on interaction patterns rather than specific downstream\napplications, we offer a novel and systematic overview of contributions from\nvarious research and application domains in the era of LLMs. Furthermore, we\nhighlight the unresolved challenges that persisted in the pre-LLM era with\npre-trained language models (PLMs) and explore the emerging obstacles brought\nforth by LLMs. Building on this analysis, we outline prospective directions for\nthe evolution of text embedding, addressing both theoretical and practical\nopportunities in the rapidly advancing landscape of NLP.\n","authors":["Zhijie Nie","Zhangchi Feng","Mingxin Li","Cunwang Zhang","Yanzhao Zhang","Dingkun Long","Richong Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.09165v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2411.13173v2","updated":"2024-12-12T10:22:37Z","published":"2024-11-20T10:17:09Z","title":"Writing Style Matters: An Examination of Bias and Fairness in\n  Information Retrieval Systems","summary":"  The rapid advancement of Language Model technologies has opened new\nopportunities, but also introduced new challenges related to bias and fairness.\nThis paper explores the uncharted territory of potential biases in\nstate-of-the-art universal text embedding models towards specific document and\nquery writing styles within Information Retrieval (IR) systems. Our\ninvestigation reveals that different embedding models exhibit different\npreferences of document writing style, while more informal and emotive styles\nare less favored by most embedding models. In terms of query writing styles,\nmany embedding models tend to match the style of the query with the style of\nthe retrieved documents, but some show a consistent preference for specific\nstyles. Text embedding models fine-tuned on synthetic data generated by LLMs\ndisplay a consistent preference for certain style of generated data. These\nbiases in text embedding based IR systems can inadvertently silence or\nmarginalize certain communication styles, thereby posing a significant threat\nto fairness in information retrieval. Finally, we also compare the answer\nstyles of Retrieval Augmented Generation (RAG) systems based on different LLMs\nand find out that most text embedding models are biased towards LLM's answer\nstyles when used as evaluation metrics for answer correctness. This study sheds\nlight on the critical issue of writing style based bias in IR systems, offering\nvaluable insights for the development of more fair and robust models.\n","authors":["Hongliu Cao"],"pdf_url":"https://arxiv.org/pdf/2411.13173v2.pdf","comment":"In Proceedings of the Eighteenth ACM International Conference on Web\n  Search and Data Mining (WSDM 25)"},{"id":"http://arxiv.org/abs/2408.09671v2","updated":"2024-12-12T08:48:27Z","published":"2024-08-19T03:13:20Z","title":"GANPrompt: Enhancing Robustness in LLM-Based Recommendations with\n  GAN-Enhanced Diversity Prompts","summary":"  In recent years, Large Language Models (LLMs) have demonstrated remarkable\nproficiency in comprehending and generating natural language, with a growing\nprevalence in the domain of recommendation systems. However, LLMs still face a\nsignificant challenge called prompt sensitivity, which refers to that it is\nhighly susceptible to the influence of prompt words. This inconsistency in\nresponse to minor alterations in prompt input may compromise the accuracy and\nresilience of recommendation models. To address this issue, this paper proposes\nGANPrompt, a multi-dimensional LLMs prompt diversity framework based on\nGenerative Adversarial Networks (GANs). The framework enhances the model's\nadaptability and stability to diverse prompts by integrating GANs generation\ntechniques with the deep semantic understanding capabilities of LLMs. GANPrompt\nfirst trains a generator capable of producing diverse prompts by analysing\nmultidimensional user behavioural data. These diverse prompts are then used to\ntrain the LLMs to improve its performance in the face of unseen prompts.\nFurthermore, to ensure a high degree of diversity and relevance of the prompts,\nthis study introduces a mathematical theory-based diversity constraint\nmechanism that optimises the generated prompts to ensure that they are not only\nsuperficially distinct, but also semantically cover a wide range of user\nintentions. Through extensive experiments on multiple datasets, we demonstrate\nthe effectiveness of the proposed framework, especially in improving the\nadaptability and robustness of recommendation systems in complex and dynamic\nenvironments. The experimental results demonstrate that GANPrompt yields\nsubstantial enhancements in accuracy and robustness relative to existing\nstate-of-the-art methodologies.\n","authors":["Xinyu Li","Chuang Zhao","Hongke Zhao","Likang Wu","Ming HE"],"pdf_url":"https://arxiv.org/pdf/2408.09671v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08950v1","updated":"2024-12-12T05:28:34Z","published":"2024-12-12T05:28:34Z","title":"Predicting Quality of Video Gaming Experience Using Global-Scale\n  Telemetry Data and Federated Learning","summary":"  Frames Per Second (FPS) significantly affects the gaming experience.\nProviding players with accurate FPS estimates prior to purchase benefits both\nplayers and game developers. However, we have a limited understanding of how to\npredict a game's FPS performance on a specific device. In this paper, we first\nconduct a comprehensive analysis of a wide range of factors that may affect\ngame FPS on a global-scale dataset to identify the determinants of FPS. This\nincludes player-side and game-side characteristics, as well as country-level\nsocio-economic statistics. Furthermore, recognizing that accurate FPS\npredictions require extensive user data, which raises privacy concerns, we\npropose a federated learning-based model to ensure user privacy. Each player\nand game is assigned a unique learnable knowledge kernel that gradually\nextracts latent features for improved accuracy. We also introduce a novel\ntraining and prediction scheme that allows these kernels to be dynamically\nplug-and-play, effectively addressing cold start issues. To train this model\nwith minimal bias, we collected a large telemetry dataset from 224 countries\nand regions, 100,000 users, and 835 games. Our model achieved a mean\nWasserstein distance of 0.469 between predicted and ground truth FPS\ndistributions, outperforming all baseline methods.\n","authors":["Zhongyang Zhang","Jinhe Wen","Zixi Chen","Dara Arbab","Sruti Sahani","Bijan Arbab","Haojian Jin","Tauhidur Rahman"],"pdf_url":"https://arxiv.org/pdf/2412.08950v1.pdf","comment":"22 pages, 11 figures, 6 tables"},{"id":"http://arxiv.org/abs/2412.08922v1","updated":"2024-12-12T04:13:09Z","published":"2024-12-12T04:13:09Z","title":"A Flexible Plug-and-Play Module for Generating Variable-Length","summary":"  Deep supervised hashing has become a pivotal technique in large-scale image\nretrieval, offering significant benefits in terms of storage and search\nefficiency. However, existing deep supervised hashing models predominantly\nfocus on generating fixed-length hash codes. This approach fails to address the\ninherent trade-off between efficiency and effectiveness when using hash codes\nof varying lengths. To determine the optimal hash code length for a specific\ntask, multiple models must be trained for different lengths, leading to\nincreased training time and computational overhead. Furthermore, the current\nparadigm overlooks the potential relationships between hash codes of different\nlengths, limiting the overall effectiveness of the models. To address these\nchallenges, we propose the Nested Hash Layer (NHL), a plug-and-play module\ndesigned for existing deep supervised hashing models. The NHL framework\nintroduces a novel mechanism to simultaneously generate hash codes of varying\nlengths in a nested manner. To tackle the optimization conflicts arising from\nthe multiple learning objectives associated with different code lengths, we\nfurther propose an adaptive weights strategy that dynamically monitors and\nadjusts gradients during training. Additionally, recognizing that the\nstructural information in longer hash codes can provide valuable guidance for\nshorter hash codes, we develop a long-short cascade self-distillation method\nwithin the NHL to enhance the overall quality of the generated hash codes.\nExtensive experiments demonstrate that NHL not only accelerates the training\nprocess but also achieves superior retrieval performance across various deep\nhashing models. Our code is publicly available at\nhttps://github.com/hly1998/NHL.\n","authors":["Liyang He","Yuren Zhang","Rui Li","Zhenya Huang","Runze Wu","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2412.08922v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08911v1","updated":"2024-12-12T03:47:40Z","published":"2024-12-12T03:47:40Z","title":"Goal-Conditioned Supervised Learning for Multi-Objective Recommendation","summary":"  Multi-objective learning endeavors to concurrently optimize multiple\nobjectives using a single model, aiming to achieve high and balanced\nperformance across these diverse objectives. However, it often involves a more\ncomplex optimization problem, particularly when navigating potential conflicts\nbetween objectives, leading to solutions with higher memory requirements and\ncomputational complexity. This paper introduces a Multi-Objective\nGoal-Conditioned Supervised Learning (MOGCSL) framework for automatically\nlearning to achieve multiple objectives from offline sequential data. MOGCSL\nextends the conventional Goal-Conditioned Supervised Learning (GCSL) method to\nmulti-objective scenarios by redefining goals from one-dimensional scalars to\nmulti-dimensional vectors. The need for complex architectures and optimization\nconstraints can be naturally eliminated. MOGCSL benefits from filtering out\nuninformative or noisy instances that do not achieve desirable long-term\nrewards. It also incorporates a novel goal-choosing algorithm to model and\nselect \"high\" achievable goals for inference.\n  While MOGCSL is quite general, we focus on its application to the next action\nprediction problem in commercial-grade recommender systems. In this context,\nany viable solution needs to be reasonably scalable and also be robust to large\namounts of noisy data that is characteristic of this application space. We show\nthat MOGCSL performs admirably on both counts. Specifically, extensive\nexperiments conducted on real-world recommendation datasets validate its\nefficacy and efficiency. Also, analysis and experiments are included to explain\nits strength in discounting the noisier portions of training data in\nrecommender systems.\n","authors":["Shijun Li","Hilaf Hasson","Jing Hu","Joydeep Ghosh"],"pdf_url":"https://arxiv.org/pdf/2412.08911v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.10613v2","updated":"2024-12-12T03:24:29Z","published":"2024-08-20T07:48:19Z","title":"Task-level Distributionally Robust Optimization for Large Language\n  Model-based Dense Retrieval","summary":"  Large Language Model-based Dense Retrieval (LLM-DR) optimizes over numerous\nheterogeneous fine-tuning collections from different domains. However, the\ndiscussion about its training data distribution is still minimal. Previous\nstudies rely on empirically assigned dataset choices or sampling ratios, which\ninevitably lead to sub-optimal retrieval performances. In this paper, we\npropose a new task-level Distributionally Robust Optimization (tDRO) algorithm\nfor LLM-DR fine-tuning, targeted at improving the universal domain\ngeneralization ability by end-to-end reweighting the data distribution of each\ntask. The tDRO parameterizes the domain weights and updates them with scaled\ndomain gradients. The optimized weights are then transferred to the LLM-DR\nfine-tuning to train more robust retrievers. Experiments show optimal\nimprovements in large-scale retrieval benchmarks and reduce up to 30% dataset\nusage after applying our optimization algorithm with a series of\ndifferent-sized LLM-DR models.\n","authors":["Guangyuan Ma","Yongliang Ma","Xing Wu","Zhenpeng Su","Ming Zhou","Songlin Hu"],"pdf_url":"https://arxiv.org/pdf/2408.10613v2.pdf","comment":"Accepted by AAAI25. Source code is available at\n  https://github.com/tdro-llm/tdro"},{"id":"http://arxiv.org/abs/2211.14219v2","updated":"2024-12-12T01:11:06Z","published":"2022-11-25T16:31:10Z","title":"The Informational Role of Online Recommendations: Evidence from a Field\n  Experiment","summary":"  We conduct a field experiment on a movie-recommendation platform to\ninvestigate whether and how online recommendations influence consumption\nchoices. Using a within-subjects design, our experiment measures the causal\neffect of recommendations on consumption and decomposes the relative importance\nof two economic mechanisms: expanding consumers' consideration sets and\nproviding information about their idiosyncratic match value. We find that the\ninformational component exerts a stronger influence - recommendations shape\nconsumer beliefs, which in turn drive consumption, particularly among less\nexperienced consumers. Our findings and experimental design provide valuable\ninsights for the economic evaluation and optimisation of online recommendation\nsystems.\n","authors":["Guy Aridor","Duarte Goncalves","Daniel Kluver","Ruoyan Kong","Joseph Konstan"],"pdf_url":"https://arxiv.org/pdf/2211.14219v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08847v1","updated":"2024-12-12T01:02:09Z","published":"2024-12-12T01:02:09Z","title":"MOPI-HFRS: A Multi-objective Personalized Health-aware Food\n  Recommendation System with LLM-enhanced Interpretation","summary":"  The prevalence of unhealthy eating habits has become an increasingly\nconcerning issue in the United States. However, major food recommendation\nplatforms (e.g., Yelp) continue to prioritize users' dietary preferences over\nthe healthiness of their choices. Although efforts have been made to develop\nhealth-aware food recommendation systems, the personalization of such systems\nbased on users' specific health conditions remains under-explored. In addition,\nfew research focus on the interpretability of these systems, which hinders\nusers from assessing the reliability of recommendations and impedes the\npractical deployment of these systems. In response to this gap, we first\nestablish two large-scale personalized health-aware food recommendation\nbenchmarks at the first attempt. We then develop a novel framework,\nMulti-Objective Personalized Interpretable Health-aware Food Recommendation\nSystem (MOPI-HFRS), which provides food recommendations by jointly optimizing\nthe three objectives: user preference, personalized healthiness and nutritional\ndiversity, along with an large language model (LLM)-enhanced reasoning module\nto promote healthy dietary knowledge through the interpretation of recommended\nresults. Specifically, this holistic graph learning framework first utilizes\ntwo structure learning and a structure pooling modules to leverage both\ndescriptive features and health data. Then it employs Pareto optimization to\nachieve designed multi-facet objectives. Finally, to further promote the\nhealthy dietary knowledge and awareness, we exploit an LLM by utilizing\nknowledge-infusion, prompting the LLMs with knowledge obtained from the\nrecommendation model for interpretation.\n","authors":["Zheyuan Zhang","Zehong Wang","Tianyi Ma","Varun Sameer Taneja","Sofia Nelson","Nhi Ha Lan Le","Keerthiram Murugesan","Mingxuan Ju","Nitesh V Chawla","Chuxu Zhang","Yanfang Ye"],"pdf_url":"https://arxiv.org/pdf/2412.08847v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2407.04065v3","updated":"2024-12-12T23:59:23Z","published":"2024-07-04T17:12:00Z","title":"On the Workflows and Smells of Leaderboard Operations (LBOps): An\n  Exploratory Study of Foundation Model Leaderboards","summary":"  Foundation models (FM), such as large language models (LLMs), which are\nlarge-scale machine learning (ML) models, have demonstrated remarkable\nadaptability in various downstream software engineering (SE) tasks, such as\ncode completion, code understanding, and software development. As a result, FM\nleaderboards have become essential tools for SE teams to compare and select the\nbest third-party FMs for their specific products and purposes. However, the\nlack of standardized guidelines for FM evaluation and comparison threatens the\ntransparency of FM leaderboards and limits stakeholders' ability to perform\neffective FM selection. As a first step towards addressing this challenge, our\nresearch focuses on understanding how these FM leaderboards operate in\nreal-world scenarios (\"leaderboard operations\") and identifying potential\npitfalls and areas for improvement (\"leaderboard smells\"). In this regard, we\ncollect up to 1,045 FM leaderboards from five different sources: GitHub,\nHugging Face Spaces, Papers With Code, spreadsheet and independent platform, to\nexamine their documentation and engage in direct communication with leaderboard\noperators to understand their workflows. Through card sorting and negotiated\nagreement, we identify five distinct workflow patterns and develop a domain\nmodel that captures the key components and their interactions within these\nworkflows. We then identify eight unique types of leaderboard smells in LBOps.\nBy mitigating these smells, SE teams can improve transparency, accountability,\nand collaboration in current LBOps practices, fostering a more robust and\nresponsible ecosystem for FM comparison and selection.\n","authors":["Zhimin Zhao","Abdul Ali Bangash","Filipe Roseiro Côgo","Bram Adams","Ahmed E. Hassan"],"pdf_url":"https://arxiv.org/pdf/2407.04065v3.pdf","comment":"awesome foundation model leaderboard list:\n  https://github.com/SAILResearch/awesome-foundation-model-leaderboards"},{"id":"http://arxiv.org/abs/2412.09758v1","updated":"2024-12-12T23:35:18Z","published":"2024-12-12T23:35:18Z","title":"Toward Foundation Model for Multivariate Wearable Sensing of\n  Physiological Signals","summary":"  Time-series foundation models have the ability to run inference, mainly\nforecasting, on any type of time series data, thanks to the informative\nrepresentations comprising waveform features. Wearable sensing data, on the\nother hand, contain more variability in both patterns and frequency bands of\ninterest and generally emphasize more on the ability to infer\nhealthcare-related outcomes. The main challenge of crafting a foundation model\nfor wearable sensing physiological signals is to learn generalizable\nrepresentations that support efficient adaptation across heterogeneous sensing\nconfigurations and applications. In this work, we propose NormWear, a step\ntoward such a foundation model, aiming to extract generalized and informative\nwearable sensing representations. NormWear has been pretrained on a large set\nof physiological signals, including PPG, ECG, EEG, GSR, and IMU, from various\npublic resources. For a holistic assessment, we perform downstream evaluation\non 11 public wearable sensing datasets, spanning 18 applications in the areas\nof mental health, body state inference, biomarker estimations, and disease risk\nevaluations. We demonstrate that NormWear achieves a better performance\nimprovement over competitive baselines in general time series foundation\nmodeling. In addition, leveraging a novel representation-alignment-match-based\nmethod, we align physiological signals embeddings with text embeddings. This\nalignment enables our proposed foundation model to perform zero-shot inference,\nallowing it to generalize to previously unseen wearable signal-based health\napplications. Finally, we perform nonlinear dynamic analysis on the waveform\nfeatures extracted by the model at each intermediate layer. This analysis\nquantifies the model's internal processes, offering clear insights into its\nbehavior and fostering greater trust in its inferences among end users.\n","authors":["Yunfei Luo","Yuliang Chen","Asif Salekin","Tauhidur Rahman"],"pdf_url":"https://arxiv.org/pdf/2412.09758v1.pdf","comment":"The code is available at:\n  http://github.com/Mobile-Sensing-and-UbiComp-Laboratory/NormWear"},{"id":"http://arxiv.org/abs/2412.09753v1","updated":"2024-12-12T23:05:40Z","published":"2024-12-12T23:05:40Z","title":"Towards joint graph and sampling set selection from data","summary":"  We explore the problem of sampling graph signals in scenarios where the graph\nstructure is not predefined and must be inferred from data. In this scenario,\nexisting approaches rely on a two-step process, where a graph is learned first,\nfollowed by sampling. More generally, graph learning and graph signal sampling\nhave been studied as two independent problems in the literature. This work\nprovides a foundational step towards jointly optimizing the graph structure and\nsampling set. Our main contribution, Vertex Importance Sampling (VIS), is to\nshow that the sampling set can be effectively determined from the vertex\nimportance (node weights) obtained from graph learning. We further propose\nVertex Importance Sampling with Repulsion (VISR), a greedy algorithm where\nspatially -separated \"important\" nodes are selected to ensure better\nreconstruction. Empirical results on simulated data show that sampling using\nVIS and VISR leads to competitive reconstruction performance and lower\ncomplexity than the conventional two-step approach of graph learning followed\nby graph sampling.\n","authors":["Shashank N. Sridhara","Eduardo Pavez","Antonio Ortega"],"pdf_url":"https://arxiv.org/pdf/2412.09753v1.pdf","comment":"5 pages, 7 figures, IEEE Asilomar Conference on Signals, Systems, and\n  Computers-2024"},{"id":"http://arxiv.org/abs/2404.03626v3","updated":"2024-12-12T23:03:54Z","published":"2024-04-04T17:48:28Z","title":"Training LLMs over Neurally Compressed Text","summary":"  In this paper, we explore the idea of training large language models (LLMs)\nover highly compressed text. While standard subword tokenizers compress text by\na small factor, neural text compressors can achieve much higher rates of\ncompression. If it were possible to train LLMs directly over neurally\ncompressed text, this would confer advantages in training and serving\nefficiency, as well as easier handling of long text spans. The main obstacle to\nthis goal is that strong compression tends to produce opaque outputs that are\nnot well-suited for learning. In particular, we find that text na\\\"ively\ncompressed via Arithmetic Coding is not readily learnable by LLMs. To overcome\nthis, we propose Equal-Info Windows, a novel compression technique whereby text\nis segmented into blocks that each compress to the same bit length. Using this\nmethod, we demonstrate effective learning over neurally compressed text that\nimproves with scale, and outperforms byte-level baselines by a wide margin on\nperplexity and inference speed benchmarks. While our method delivers worse\nperplexity than subword tokenizers for models trained with the same parameter\ncount, it has the benefit of shorter sequence lengths. Shorter sequence lengths\nrequire fewer autoregressive generation steps, and reduce latency. Finally, we\nprovide extensive analysis of the properties that contribute to learnability,\nand offer concrete suggestions for how to further improve the performance of\nhigh-compression tokenizers.\n","authors":["Brian Lester","Jaehoon Lee","Alex Alemi","Jeffrey Pennington","Adam Roberts","Jascha Sohl-Dickstein","Noah Constant"],"pdf_url":"https://arxiv.org/pdf/2404.03626v3.pdf","comment":"Accepted in TMLR https://openreview.net/forum?id=pRvhMSV48t"},{"id":"http://arxiv.org/abs/2408.16457v3","updated":"2024-12-12T23:02:18Z","published":"2024-08-29T11:45:01Z","title":"HYGENE: A Diffusion-based Hypergraph Generation Method","summary":"  Hypergraphs are powerful mathematical structures that can model complex,\nhigh-order relationships in various domains, including social networks,\nbioinformatics, and recommender systems. However, generating realistic and\ndiverse hypergraphs remains challenging due to their inherent complexity and\nlack of effective generative models. In this paper, we introduce a\ndiffusion-based Hypergraph Generation (HYGENE) method that addresses these\nchallenges through a progressive local expansion approach. HYGENE works on the\nbipartite representation of hypergraphs, starting with a single pair of\nconnected nodes and iteratively expanding it to form the target hypergraph. At\neach step, nodes and hyperedges are added in a localized manner using a\ndenoising diffusion process, which allows for the construction of the global\nstructure before refining local details. Our experiments demonstrated the\neffectiveness of HYGENE, proving its ability to closely mimic a variety of\nproperties in hypergraphs. To the best of our knowledge, this is the first\nattempt to employ deep learning models for hypergraph generation, and our work\naims to lay the groundwork for future research in this area.\n","authors":["Dorian Gailhard","Enzo Tartaglione","Lirida Naviner","Jhony H. Giraldo"],"pdf_url":"https://arxiv.org/pdf/2408.16457v3.pdf","comment":"arXiv admin note: text overlap with arXiv:2312.11529 by other authors"},{"id":"http://arxiv.org/abs/2412.09752v1","updated":"2024-12-12T22:57:28Z","published":"2024-12-12T22:57:28Z","title":"A Quasilinear Algorithm for Computing Higher-Order Derivatives of Deep\n  Feed-Forward Neural Networks","summary":"  The use of neural networks for solving differential equations is practically\ndifficult due to the exponentially increasing runtime of autodifferentiation\nwhen computing high-order derivatives. We propose $n$-TangentProp, the natural\nextension of the TangentProp formalism \\cite{simard1991tangent} to arbitrarily\nmany derivatives. $n$-TangentProp computes the exact derivative $d^n/dx^n f(x)$\nin quasilinear, instead of exponential time, for a densely connected,\nfeed-forward neural network $f$ with a smooth, parameter-free activation\nfunction. We validate our algorithm empirically across a range of depths,\nwidths, and number of derivatives. We demonstrate that our method is\nparticularly beneficial in the context of physics-informed neural networks\nwhere \\ntp allows for significantly faster training times than previous methods\nand has favorable scaling with respect to both model size and loss-function\ncomplexity as measured by the number of required derivatives. The code for this\npaper can be found at https://github.com/kyrochi/n\\_tangentprop.\n","authors":["Kyle R. Chickering"],"pdf_url":"https://arxiv.org/pdf/2412.09752v1.pdf","comment":"11 pages, 10 figures"},{"id":"http://arxiv.org/abs/2410.10829v2","updated":"2024-12-12T22:56:26Z","published":"2024-09-28T03:13:40Z","title":"Test Case-Informed Knowledge Tracing for Open-ended Coding Tasks","summary":"  Open-ended coding tasks, which ask students to construct programs according\nto certain specifications, are common in computer science education. Student\nmodeling can be challenging since their open-ended nature means that student\ncode can be diverse. Traditional knowledge tracing (KT) models that only\nanalyze response correctness may not fully capture nuances in student knowledge\nfrom student code. In this paper, we introduce Test case-Informed Knowledge\nTracing for Open-ended Coding (TIKTOC), a framework to simultaneously analyze\nand predict both open-ended student code and whether the code passes each test\ncase. We augment the existing CodeWorkout dataset with the test cases used for\na subset of the open-ended coding questions, and propose a multi-task learning\nKT method to simultaneously analyze and predict 1) whether a student's code\nsubmission passes each test case and 2) the student's open-ended code, using a\nlarge language model as the backbone. We quantitatively show that these methods\noutperform existing KT methods for coding that only use the overall score a\ncode submission receives. We also qualitatively demonstrate how test case\ninformation, combined with open-ended code, helps us gain fine-grained insights\ninto student knowledge.\n","authors":["Zhangqi Duan","Nigel Fernandez","Alexander Hicks","Andrew Lan"],"pdf_url":"https://arxiv.org/pdf/2410.10829v2.pdf","comment":"Published in LAK 2025: The 15th International Learning Analytics and\n  Knowledge Conference"},{"id":"http://arxiv.org/abs/2412.09748v1","updated":"2024-12-12T22:37:33Z","published":"2024-12-12T22:37:33Z","title":"New Approach to Clustering Random Attributes","summary":"  This paper proposes a new method for similarity analysis and, consequently, a\nnew algorithm for clustering different types of random attributes, both\nnumerical and nominal. However, in order for nominal attributes to be\nclustered, their values must be properly encoded. In the encoding process,\nnominal attributes obtain a new representation in numerical form. Only the\nnumeric attributes can be subjected to factor analysis, which allows them to be\nclustered in terms of their similarity to factors. The proposed method was\ntested for several sample datasets. It was found that the proposed method is\nuniversal. On the one hand, the method allows clustering of numerical\nattributes. On the other hand, it provides the ability to cluster nominal\nattributes. It also allows simultaneous clustering of numerical attributes and\nnumerically encoded nominal attributes.\n","authors":["Zenon Gniazdowski"],"pdf_url":"https://arxiv.org/pdf/2412.09748v1.pdf","comment":"50 pages, 15 figures, 25 tables"},{"id":"http://arxiv.org/abs/2412.02646v2","updated":"2024-12-12T22:15:24Z","published":"2024-12-03T18:21:20Z","title":"Interpretable Generalized Additive Models for Datasets with Missing\n  Values","summary":"  Many important datasets contain samples that are missing one or more feature\nvalues. Maintaining the interpretability of machine learning models in the\npresence of such missing data is challenging. Singly or multiply imputing\nmissing values complicates the model's mapping from features to labels. On the\nother hand, reasoning on indicator variables that represent missingness\nintroduces a potentially large number of additional terms, sacrificing\nsparsity. We solve these problems with M-GAM, a sparse, generalized, additive\nmodeling approach that incorporates missingness indicators and their\ninteraction terms while maintaining sparsity through l0 regularization. We show\nthat M-GAM provides similar or superior accuracy to prior methods while\nsignificantly improving sparsity relative to either imputation or naive\ninclusion of indicator variables.\n","authors":["Hayden McTavish","Jon Donnelly","Margo Seltzer","Cynthia Rudin"],"pdf_url":"https://arxiv.org/pdf/2412.02646v2.pdf","comment":"Published in NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.22870v3","updated":"2024-12-12T22:09:25Z","published":"2024-10-30T10:08:03Z","title":"Conditioned quantum-assisted deep generative surrogate for\n  particle-calorimeter interactions","summary":"  Particle collisions at accelerators such as the Large Hadron Collider,\nrecorded and analyzed by experiments such as ATLAS and CMS, enable exquisite\nmeasurements of the Standard Model and searches for new phenomena. Simulations\nof collision events at these detectors have played a pivotal role in shaping\nthe design of future experiments and analyzing ongoing ones. However, the quest\nfor accuracy in Large Hadron Collider (LHC) collisions comes at an imposing\ncomputational cost, with projections estimating the need for millions of\nCPU-years annually during the High Luminosity LHC (HL-LHC) run\n\\cite{collaboration2022atlas}. Simulating a single LHC event with\n\\textsc{Geant4} currently devours around 1000 CPU seconds, with simulations of\nthe calorimeter subdetectors in particular imposing substantial computational\ndemands \\cite{rousseau2023experimental}. To address this challenge, we propose\na conditioned quantum-assisted deep generative model. Our model integrates a\nconditioned variational autoencoder (VAE) on the exterior with a conditioned\nRestricted Boltzmann Machine (RBM) in the latent space, providing enhanced\nexpressiveness compared to conventional VAEs. The RBM nodes and connections are\nmeticulously engineered to enable the use of qubits and couplers on D-Wave's\nPegasus-structured \\textit{Advantage} quantum annealer (QA) for sampling. We\nintroduce a novel method for conditioning the quantum-assisted RBM using\n\\textit{flux biases}. We further propose a novel adaptive mapping to estimate\nthe effective inverse temperature in quantum annealers. The effectiveness of\nour framework is illustrated using Dataset 2 of the CaloChallenge\n\\cite{calochallenge}.\n","authors":["J. Quetzalcoatl Toledo-Marin","Sebastian Gonzalez","Hao Jia","Ian Lu","Deniz Sogutlu","Abhishek Abhishek","Colin Gay","Eric Paquet","Roger Melko","Geoffrey C. Fox","Maximilian Swiatlowski","Wojciech Fedorko"],"pdf_url":"https://arxiv.org/pdf/2410.22870v3.pdf","comment":"27 pages, 10 figures, 8 appendices"},{"id":"http://arxiv.org/abs/2412.09740v1","updated":"2024-12-12T22:07:17Z","published":"2024-12-12T22:07:17Z","title":"TelApart: Differentiating Network Faults from Customer-Premise Faults in\n  Cable Broadband Networks","summary":"  Two types of radio frequency (RF) impairments frequently occur in a cable\nbroadband network: impairments that occur inside a cable network and\nimpairments occur at the edge of the broadband network, i.e., in a subscriber's\npremise. Differentiating these two types of faults is important, as different\nfaults require different types of technical personnel to repair them.\nPresently, the cable industry lacks publicly available tools to automatically\ndiagnose the type of fault. In this work, we present TelApart, a fault\ndiagnosis system for cable broadband networks. TelApart uses telemetry data\ncollected by the Proactive Network Maintenance (PNM) infrastructure in cable\nnetworks to effectively differentiate the type of fault. Integral to TelApart's\ndesign is an unsupervised machine learning model that groups cable devices\nsharing similar anomalous patterns together. We use metrics derived from an\nISP's customer trouble tickets to programmatically tune the model's\nhyper-parameters so that an ISP can deploy TelApart in various conditions\nwithout hand-tuning its hyper-parameters. We also address the data challenge\nthat the telemetry data collected by the PNM system contain numerous missing,\nduplicated, and unaligned data points. Using real-world data contributed by a\ncable ISP, we show that TelApart can effectively identify different types of\nfaults.\n","authors":["Jiyao Hu","Zhenyu Zhou","Xiaowei Yang"],"pdf_url":"https://arxiv.org/pdf/2412.09740v1.pdf","comment":"14 pages. arXiv admin note: text overlap with arXiv:2412.09564"}]," Artificial Intelligence":[{"id":"http://arxiv.org/abs/2412.09764v1","updated":"2024-12-12T23:56:57Z","published":"2024-12-12T23:56:57Z","title":"Memory Layers at Scale","summary":"  Memory layers use a trainable key-value lookup mechanism to add extra\nparameters to a model without increasing FLOPs. Conceptually, sparsely\nactivated memory layers complement compute-heavy dense feed-forward layers,\nproviding dedicated capacity to store and retrieve information cheaply. This\nwork takes memory layers beyond proof-of-concept, proving their utility at\ncontemporary scale. On downstream tasks, language models augmented with our\nimproved memory layer outperform dense models with more than twice the\ncomputation budget, as well as mixture-of-expert models when matched for both\ncompute and parameters. We find gains are especially pronounced for factual\ntasks. We provide a fully parallelizable memory layer implementation,\ndemonstrating scaling laws with up to 128B memory parameters, pretrained to 1\ntrillion tokens, comparing to base models with up to 8B parameters.\n","authors":["Vincent-Pierre Berges","Barlas Oğuz","Daniel Haziza","Wen-tau Yih","Luke Zettlemoyer","Gargi Gosh"],"pdf_url":"https://arxiv.org/pdf/2412.09764v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.10945v2","updated":"2024-12-12T23:51:26Z","published":"2024-08-20T15:34:27Z","title":"HiRED: Attention-Guided Token Dropping for Efficient Inference of\n  High-Resolution Vision-Language Models in Resource-Constrained Environments","summary":"  High-resolution Vision-Language Models (VLMs) have been widely used in\nmultimodal tasks to enhance accuracy by preserving detailed image information.\nHowever, these models often generate excessive visual tokens due to encoding\nmultiple partitions of the input image. Processing these excessive visual\ntokens is computationally challenging, especially in resource-constrained\nenvironments with commodity GPUs. To support high-resolution images while\nmeeting resource constraints, we propose High-Resolution Early Dropping\n(HiRED), a token-dropping scheme that operates within a fixed token budget\nbefore the Large Language Model (LLM) stage. HiRED can be integrated with\nexisting high-resolution VLMs in a plug-and-play manner, as it requires no\nadditional training while still maintaining superior accuracy. We strategically\nuse the vision encoder's attention in the initial layers to assess the visual\ncontent of each image partition and allocate the token budget accordingly.\nThen, using the attention in the final layer, we select the most important\nvisual tokens from each partition within the allocated budget, dropping the\nrest. Empirically, when applied to LLaVA-Next-7B on NVIDIA TESLA P40 GPU, HiRED\nwith a 20% token budget increases token generation throughput by 4.7, reduces\nfirst-token generation latency by 15 seconds, and saves 2.3 GB of GPU memory\nfor a single inference. The code is available at\nhttps://github.com/hasanar1f/HiRED.\n","authors":["Kazi Hasan Ibn Arif","JinYi Yoon","Dimitrios S. Nikolopoulos","Hans Vandierendonck","Deepu John","Bo Ji"],"pdf_url":"https://arxiv.org/pdf/2408.10945v2.pdf","comment":"Accepted in AAAI 2025"},{"id":"http://arxiv.org/abs/2412.09760v1","updated":"2024-12-12T23:38:58Z","published":"2024-12-12T23:38:58Z","title":"Congruence-based Learning of Probabilistic Deterministic Finite Automata","summary":"  This work studies the question of learning probabilistic deterministic\nautomata from language models. For this purpose, it focuses on analyzing the\nrelations defined on algebraic structures over strings by equivalences and\nsimilarities on probability distributions. We introduce a congruence that\nextends the classical Myhill-Nerode congruence for formal languages. This new\ncongruence is the basis for defining regularity over language models. We\npresent an active learning algorithm that computes the quotient with respect to\nthis congruence whenever the language model is regular. The paper also defines\nthe notion of recognizability for language models and shows that it coincides\nwith regularity for congruences. For relations which are not congruences, it\nshows that this is not the case. Finally, it discusses the impact of this\nresult on learning in the context of language models.\n","authors":["Matías Carrasco","Franz Mayr","Sergio Yovine"],"pdf_url":"https://arxiv.org/pdf/2412.09760v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.04264v5","updated":"2024-12-12T23:17:01Z","published":"2024-03-17T17:01:45Z","title":"Logic Query of Thoughts: Guiding Large Language Models to Answer Complex\n  Logic Queries with Knowledge Graphs","summary":"  Despite the superb performance in many tasks, large language models (LLMs)\nbear the risk of generating hallucination or even wrong answers when confronted\nwith tasks that demand the accuracy of knowledge. The issue becomes even more\nnoticeable when addressing logic queries that require multiple logic reasoning\nsteps. On the other hand, knowledge graph (KG) based question answering methods\nare capable of accurately identifying the correct answers with the help of\nknowledge graph, yet its accuracy could quickly deteriorate when the knowledge\ngraph itself is sparse and incomplete. It remains a critical challenge on how\nto integrate knowledge graph reasoning with LLMs in a mutually beneficial way\nso as to mitigate both the hallucination problem of LLMs as well as the\nincompleteness issue of knowledge graphs. In this paper, we propose\n'Logic-Query-of-Thoughts' (LGOT) which is the first of its kind to combine LLMs\nwith knowledge graph based logic query reasoning. LGOT seamlessly combines\nknowledge graph reasoning and LLMs, effectively breaking down complex logic\nqueries into easy to answer subquestions. Through the utilization of both\nknowledge graph reasoning and LLMs, it successfully derives answers for each\nsubquestion. By aggregating these results and selecting the highest quality\ncandidate answers for each step, LGOT achieves accurate results to complex\nquestions. Our experimental findings demonstrate substantial performance\nenhancements, with up to 20% improvement over ChatGPT.\n","authors":["Lihui Liu","Zihao Wang","Ruizhong Qiu","Yikun Ban","Eunice Chan","Yangqiu Song","Jingrui He","Hanghang Tong"],"pdf_url":"https://arxiv.org/pdf/2404.04264v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09751v1","updated":"2024-12-12T22:48:19Z","published":"2024-12-12T22:48:19Z","title":"AI Red-Teaming is a Sociotechnical System. Now What?","summary":"  As generative AI technologies find more and more real-world applications, the\nimportance of testing their performance and safety seems paramount.\n``Red-teaming'' has quickly become the primary approach to test AI\nmodels--prioritized by AI companies, and enshrined in AI policy and regulation.\nMembers of red teams act as adversaries, probing AI systems to test their\nsafety mechanisms and uncover vulnerabilities. Yet we know too little about\nthis work and its implications. This essay calls for collaboration between\ncomputer scientists and social scientists to study the sociotechnical systems\nsurrounding AI technologies, including the work of red-teaming, to avoid\nrepeating the mistakes of the recent past. We highlight the importance of\nunderstanding the values and assumptions behind red-teaming, the labor\ninvolved, and the psychological impacts on red-teamers.\n","authors":["Tarleton Gillespie","Ryland Shaw","Mary L. Gray","Jina Suh"],"pdf_url":"https://arxiv.org/pdf/2412.09751v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2410.22870v3","updated":"2024-12-12T22:09:25Z","published":"2024-10-30T10:08:03Z","title":"Conditioned quantum-assisted deep generative surrogate for\n  particle-calorimeter interactions","summary":"  Particle collisions at accelerators such as the Large Hadron Collider,\nrecorded and analyzed by experiments such as ATLAS and CMS, enable exquisite\nmeasurements of the Standard Model and searches for new phenomena. Simulations\nof collision events at these detectors have played a pivotal role in shaping\nthe design of future experiments and analyzing ongoing ones. However, the quest\nfor accuracy in Large Hadron Collider (LHC) collisions comes at an imposing\ncomputational cost, with projections estimating the need for millions of\nCPU-years annually during the High Luminosity LHC (HL-LHC) run\n\\cite{collaboration2022atlas}. Simulating a single LHC event with\n\\textsc{Geant4} currently devours around 1000 CPU seconds, with simulations of\nthe calorimeter subdetectors in particular imposing substantial computational\ndemands \\cite{rousseau2023experimental}. To address this challenge, we propose\na conditioned quantum-assisted deep generative model. Our model integrates a\nconditioned variational autoencoder (VAE) on the exterior with a conditioned\nRestricted Boltzmann Machine (RBM) in the latent space, providing enhanced\nexpressiveness compared to conventional VAEs. The RBM nodes and connections are\nmeticulously engineered to enable the use of qubits and couplers on D-Wave's\nPegasus-structured \\textit{Advantage} quantum annealer (QA) for sampling. We\nintroduce a novel method for conditioning the quantum-assisted RBM using\n\\textit{flux biases}. We further propose a novel adaptive mapping to estimate\nthe effective inverse temperature in quantum annealers. The effectiveness of\nour framework is illustrated using Dataset 2 of the CaloChallenge\n\\cite{calochallenge}.\n","authors":["J. Quetzalcoatl Toledo-Marin","Sebastian Gonzalez","Hao Jia","Ian Lu","Deniz Sogutlu","Abhishek Abhishek","Colin Gay","Eric Paquet","Roger Melko","Geoffrey C. Fox","Maximilian Swiatlowski","Wojciech Fedorko"],"pdf_url":"https://arxiv.org/pdf/2410.22870v3.pdf","comment":"27 pages, 10 figures, 8 appendices"},{"id":"http://arxiv.org/abs/2412.09741v1","updated":"2024-12-12T22:08:53Z","published":"2024-12-12T22:08:53Z","title":"On Round-Off Errors and Gaussian Blur in Superresolution and in Image\n  Registration","summary":"  Superresolution theory and techniques seek to recover signals from samples in\nthe presence of blur and noise. Discrete image registration can be an approach\nto fuse information from different sets of samples of the same signal.\nQuantization errors in the spatial domain are inherent to digital images. We\nconsider superresolution and discrete image registration for one-dimensional\nspatially-limited piecewise constant functions which are subject to blur which\nis Gaussian or a mixture of Gaussians as well as to round-off errors. We\ndescribe a signal-dependent measurement matrix which captures both types of\neffects. For this setting we show that the difficulties in determining the\ndiscontinuity points from two sets of samples even in the absence of other\ntypes of noise. If the samples are also subject to statistical noise, then it\nis necessary to align and segment the data sequences to make the most effective\ninferences about the amplitudes and discontinuity points. Under some conditions\non the blur, the noise, and the distance between discontinuity points, we prove\nthat we can correctly align and determine the first samples following each\ndiscontinuity point in two data sequences with an approach based on dynamic\nprogramming.\n","authors":["Serap A. Savari"],"pdf_url":"https://arxiv.org/pdf/2412.09741v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09727v1","updated":"2024-12-12T21:35:13Z","published":"2024-12-12T21:35:13Z","title":"Let Curves Speak: A Continuous Glucose Monitor based Large Sensor\n  Foundation Model for Diabetes Management","summary":"  While previous studies of AI in diabetes management focus on long-term risk,\nresearch on near-future glucose prediction remains limited but important as it\nenables timely diabetes self-management. Integrating AI with continuous glucose\nmonitoring (CGM) holds promise for near-future glucose prediction. However,\nexisting models have limitations in capturing patterns of blood glucose\nfluctuations and demonstrate poor generalizability. A robust approach is needed\nto leverage massive CGM data for near-future glucose prediction. We propose\nlarge sensor models (LSMs) to capture knowledge in CGM data by modeling\npatients as sequences of glucose. CGM-LSM is pretrained on 15.96 million\nglucose records from 592 diabetes patients for near-future glucose prediction.\nWe evaluated CGM-LSM against state-of-the-art methods using the OhioT1DM\ndataset across various metrics, prediction horizons, and unseen patients.\nAdditionally, we assessed its generalizability across factors like diabetes\ntype, age, gender, and hour of day. CGM-LSM achieved exceptional performance,\nwith an rMSE of 29.81 mg/dL for type 1 diabetes patients and 23.49 mg/dL for\ntype 2 diabetes patients in a two-hour prediction horizon. For the OhioT1DM\ndataset, CGM-LSM achieved a one-hour rMSE of 15.64 mg/dL, halving the previous\nbest of 31.97 mg/dL. Robustness analyses revealed consistent performance not\nonly for unseen patients and future periods, but also across diabetes type,\nage, and gender. The model demonstrated adaptability to different hours of day,\nmaintaining accuracy across periods of various activity intensity levels.\nCGM-LSM represents a transformative step in diabetes management by leveraging\npretraining to uncover latent glucose generation patterns in sensor data. Our\nfindings also underscore the broader potential of LSMs to drive innovation\nacross domains involving complex sensor data.\n","authors":["Junjie Luo","Abhimanyu Kumbara","Mansur Shomali","Rui Han","Anand Iyer","Ritu Agarwal","Gordon Gao"],"pdf_url":"https://arxiv.org/pdf/2412.09727v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09726v1","updated":"2024-12-12T21:31:27Z","published":"2024-12-12T21:31:27Z","title":"The Unreasonable Effectiveness of Gaussian Score Approximation for\n  Diffusion Models and its Applications","summary":"  By learning the gradient of smoothed data distributions, diffusion models can\niteratively generate samples from complex distributions. The learned score\nfunction enables their generalization capabilities, but how the learned score\nrelates to the score of the underlying data manifold remains largely unclear.\nHere, we aim to elucidate this relationship by comparing learned neural scores\nto the scores of two kinds of analytically tractable distributions: Gaussians\nand Gaussian mixtures. The simplicity of the Gaussian model makes it\ntheoretically attractive, and we show that it admits a closed-form solution and\npredicts many qualitative aspects of sample generation dynamics. We claim that\nthe learned neural score is dominated by its linear (Gaussian) approximation\nfor moderate to high noise scales, and supply both theoretical and empirical\narguments to support this claim. Moreover, the Gaussian approximation\nempirically works for a larger range of noise scales than naive theory suggests\nit should, and is preferentially learned early in training. At smaller noise\nscales, we observe that learned scores are better described by a coarse-grained\n(Gaussian mixture) approximation of training data than by the score of the\ntraining distribution, a finding consistent with generalization. Our findings\nenable us to precisely predict the initial phase of trained models' sampling\ntrajectories through their Gaussian approximations. We show that this allows\nthe skipping of the first 15-30% of sampling steps while maintaining high\nsample quality (with a near state-of-the-art FID score of 1.93 on CIFAR-10\nunconditional generation). This forms the foundation of a novel hybrid sampling\nmethod, termed analytical teleportation, which can seamlessly integrate with\nand accelerate existing samplers, including DPM-Solver-v3 and UniPC. Our\nfindings suggest ways to improve the design and training of diffusion models.\n","authors":["Binxu Wang","John J. Vastola"],"pdf_url":"https://arxiv.org/pdf/2412.09726v1.pdf","comment":"69 pages, 34 figures. Published in TMLR. Previous shorter versions at\n  arxiv.org/abs/2303.02490 and arxiv.org/abs/2311.10892"},{"id":"http://arxiv.org/abs/2411.08027v2","updated":"2024-12-12T21:29:57Z","published":"2024-11-12T18:56:58Z","title":"LLMPhy: Complex Physical Reasoning Using Large Language Models and World\n  Models","summary":"  Physical reasoning is an important skill needed for robotic agents when\noperating in the real world. However, solving such reasoning problems often\ninvolves hypothesizing and reflecting over complex multi-body interactions\nunder the effect of a multitude of physical forces and thus learning all such\ninteractions poses a significant hurdle for state-of-the-art machine learning\nframeworks, including large language models (LLMs). To study this problem, we\npropose a new physical reasoning task and a dataset, dubbed TraySim. Our task\ninvolves predicting the dynamics of several objects on a tray that is given an\nexternal impact -- the domino effect of the ensued object interactions and\ntheir dynamics thus offering a challenging yet controlled setup, with the goal\nof reasoning being to infer the stability of the objects after the impact. To\nsolve this complex physical reasoning task, we present LLMPhy, a zero-shot\nblack-box optimization framework that leverages the physics knowledge and\nprogram synthesis abilities of LLMs, and synergizes these abilities with the\nworld models built into modern physics engines. Specifically, LLMPhy uses an\nLLM to generate code to iteratively estimate the physical hyperparameters of\nthe system (friction, damping, layout, etc.) via an implicit\nanalysis-by-synthesis approach using a (non-differentiable) simulator in the\nloop and uses the inferred parameters to imagine the dynamics of the scene\ntowards solving the reasoning task. To show the effectiveness of LLMPhy, we\npresent experiments on our TraySim dataset to predict the steady-state poses of\nthe objects. Our results show that the combination of the LLM and the physics\nengine leads to state-of-the-art zero-shot physical reasoning performance,\nwhile demonstrating superior convergence against standard black-box\noptimization methods and better estimation of the physical parameters.\n","authors":["Anoop Cherian","Radu Corcodel","Siddarth Jain","Diego Romeres"],"pdf_url":"https://arxiv.org/pdf/2411.08027v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.03646v2","updated":"2024-12-12T21:15:25Z","published":"2024-09-05T16:04:57Z","title":"Limited but consistent gains in adversarial robustness by co-training\n  object recognition models with human EEG","summary":"  In contrast to human vision, artificial neural networks (ANNs) remain\nrelatively susceptible to adversarial attacks. To address this vulnerability,\nefforts have been made to transfer inductive bias from human brains to ANNs,\noften by training the ANN representations to match their biological\ncounterparts. Previous works relied on brain data acquired in rodents or\nprimates using invasive techniques, from specific regions of the brain, under\nnon-natural conditions (anesthetized animals), and with stimulus datasets\nlacking diversity and naturalness. In this work, we explored whether aligning\nmodel representations to human EEG responses to a rich set of real-world images\nincreases robustness to ANNs. Specifically, we trained ResNet50-backbone models\non a dual task of classification and EEG prediction; and evaluated their EEG\nprediction accuracy and robustness to adversarial attacks. We observed\nsignificant correlation between the networks' EEG prediction accuracy, often\nhighest around 100 ms post stimulus onset, and their gains in adversarial\nrobustness. Although effect size was limited, effects were consistent across\ndifferent random initializations and robust for architectural variants. We\nfurther teased apart the data from individual EEG channels and observed\nstrongest contribution from electrodes in the parieto-occipital regions. The\ndemonstrated utility of human EEG for such tasks opens up avenues for future\nefforts that scale to larger datasets under diverse stimuli conditions with the\npromise of stronger effects.\n","authors":["Manshan Guo","Bhavin Choksi","Sari Sadiya","Alessandro T. Gifford","Martina G. Vilas","Radoslaw M. Cichy","Gemma Roig"],"pdf_url":"https://arxiv.org/pdf/2409.03646v2.pdf","comment":"accepted as ECCV HCV workshop 2024 oral presentation"},{"id":"http://arxiv.org/abs/2408.11816v2","updated":"2024-12-12T21:05:33Z","published":"2024-08-21T17:59:31Z","title":"Efficient Exploration and Discriminative World Model Learning with an\n  Object-Centric Abstraction","summary":"  In the face of difficult exploration problems in reinforcement learning, we\nstudy whether giving an agent an object-centric mapping (describing a set of\nitems and their attributes) allow for more efficient learning. We found this\nproblem is best solved hierarchically by modelling items at a higher level of\nstate abstraction to pixels, and attribute change at a higher level of temporal\nabstraction to primitive actions. This abstraction simplifies the transition\ndynamic by making specific future states easier to predict. We make use of this\nto propose a fully model-based algorithm that learns a discriminative world\nmodel, plans to explore efficiently with only a count-based intrinsic reward,\nand can subsequently plan to reach any discovered (abstract) states.\n  We demonstrate the model's ability to (i) efficiently solve single tasks,\n(ii) transfer zero-shot and few-shot across item types and environments, and\n(iii) plan across long horizons. Across a suite of 2D crafting and MiniHack\nenvironments, we empirically show our model significantly out-performs\nstate-of-the-art low-level methods (without abstraction), as well as performant\nmodel-free and model-based methods using the same abstraction. Finally, we show\nhow to learn low level object-perturbing policies via reinforcement learning,\nand the object mapping itself by supervised learning.\n","authors":["Anthony GX-Chen","Kenneth Marino","Rob Fergus"],"pdf_url":"https://arxiv.org/pdf/2408.11816v2.pdf","comment":"Preprint. Additional results"},{"id":"http://arxiv.org/abs/2407.12980v2","updated":"2024-12-12T21:05:20Z","published":"2024-07-17T19:52:53Z","title":"A Framework for testing Federated Learning algorithms using an edge-like\n  environment","summary":"  Federated Learning (FL) is a machine learning paradigm in which many clients\ncooperatively train a single centralized model while keeping their data private\nand decentralized. FL is commonly used in edge computing, which involves\nplacing computer workloads (both hardware and software) as close as possible to\nthe edge, where the data is being created and where actions are occurring,\nenabling faster response times, greater data privacy, and reduced data transfer\ncosts. However, due to the heterogeneous data distributions/contents of\nclients, it is non-trivial to accurately evaluate the contributions of local\nmodels in global centralized model aggregation. This is an example of a major\nchallenge in FL, commonly known as data imbalance or class imbalance. In\ngeneral, testing and assessing FL algorithms can be a very difficult and\ncomplex task due to the distributed nature of the systems. In this work, a\nframework is proposed and implemented to assess FL algorithms in a more easy\nand scalable way. This framework is evaluated over a distributed edge-like\nenvironment managed by a container orchestration platform (i.e. Kubernetes).\n","authors":["Felipe Machado Schwanck","Marcos Tomazzoli Leipnitz","Joel Luís Carbonera","Juliano Araujo Wickboldt"],"pdf_url":"https://arxiv.org/pdf/2407.12980v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09719v1","updated":"2024-12-12T20:52:12Z","published":"2024-12-12T20:52:12Z","title":"TransferLight: Zero-Shot Traffic Signal Control on any Road-Network","summary":"  Traffic signal control plays a crucial role in urban mobility. However,\nexisting methods often struggle to generalize beyond their training\nenvironments to unseen scenarios with varying traffic dynamics. We present\nTransferLight, a novel framework designed for robust generalization across\nroad-networks, diverse traffic conditions and intersection geometries. At its\ncore, we propose a log-distance reward function, offering spatially-aware\nsignal prioritization while remaining adaptable to varied lane configurations -\novercoming the limitations of traditional pressure-based rewards. Our\nhierarchical, heterogeneous, and directed graph neural network architecture\neffectively captures granular traffic dynamics, enabling transferability to\narbitrary intersection layouts. Using a decentralized multi-agent approach,\nglobal rewards, and novel state transition priors, we develop a single,\nweight-tied policy that scales zero-shot to any road network without\nre-training. Through domain randomization during training, we additionally\nenhance generalization capabilities. Experimental results validate\nTransferLight's superior performance in unseen scenarios, advancing practical,\ngeneralizable intelligent transportation systems to meet evolving urban traffic\ndemands.\n","authors":["Johann Schmidt","Frank Dreyer","Sayed Abid Hashimi","Sebastian Stober"],"pdf_url":"https://arxiv.org/pdf/2412.09719v1.pdf","comment":"AAAI Workshop Paper (MALTA)"},{"id":"http://arxiv.org/abs/2402.01662v4","updated":"2024-12-12T20:17:54Z","published":"2024-01-14T08:57:45Z","title":"Generative Ghosts: Anticipating Benefits and Risks of AI Afterlives","summary":"  As AI systems quickly improve in both breadth and depth of performance, they\nlend themselves to creating increasingly powerful and realistic agents,\nincluding the possibility of agents modeled on specific people. We anticipate\nthat within our lifetimes it may become common practice for people to create\ncustom AI agents to interact with loved ones and/or the broader world after\ndeath; indeed, the past year has seen a boom in startups purporting to offer\nsuch services. We call these generative ghosts, since such agents will be\ncapable of generating novel content rather than merely parroting content\nproduced by their creator while living. In this paper, we reflect on the\nhistory of technologies for AI afterlives, including current early attempts by\nindividual enthusiasts and startup companies to create generative ghosts. We\nthen introduce a novel design space detailing potential implementations of\ngenerative ghosts, and use this analytic framework to ground discussion of the\npractical and ethical implications of various approaches to designing\ngenerative ghosts, including potential positive and negative impacts on\nindividuals and society. Based on these considerations, we lay out a research\nagenda for the AI and HCI research communities to better understand the\nrisk/benefit landscape of this novel technology so as to ultimately empower\npeople who wish to create and interact with AI afterlives to do so in a\nbeneficial manner.\n","authors":["Meredith Ringel Morris","Jed R. Brubaker"],"pdf_url":"https://arxiv.org/pdf/2402.01662v4.pdf","comment":"version 4, updated to include new references and examples"},{"id":"http://arxiv.org/abs/2405.17412v2","updated":"2024-12-12T20:07:57Z","published":"2024-05-27T17:57:12Z","title":"Towards One Model for Classical Dimensionality Reduction: A\n  Probabilistic Perspective on UMAP and t-SNE","summary":"  This paper shows that dimensionality reduction methods such as UMAP and\nt-SNE, can be approximately recast as MAP inference methods corresponding to a\nmodel introduced in ProbDR, that describes the graph Laplacian (an estimate for\nthe precision/inverse covariance) matrix using a Wishart distribution, with a\nmean given by a non-linear covariance function evaluated on the latents. This\ninterpretation offers deeper theoretical and semantic insights into such\nalgorithms, by showing that variances corresponding to these covariances are\nlow (and misspecified), and forging a connection to Gaussian process latent\nvariable models by showing that well-known kernels can be used to describe\ncovariances implied by graph Laplacians. We also introduce tools with which\nsimilar dimensionality reduction methods can be studied, and pose two areas of\nresearch arising from these interpretations.\n","authors":["Aditya Ravuri","Neil D. Lawrence"],"pdf_url":"https://arxiv.org/pdf/2405.17412v2.pdf","comment":"Updated preprint"},{"id":"http://arxiv.org/abs/2412.09701v1","updated":"2024-12-12T19:49:09Z","published":"2024-12-12T19:49:09Z","title":"CUAL: Continual Uncertainty-aware Active Learner","summary":"  AI deployed in many real-world use cases should be capable of adapting to\nnovelties encountered after deployment. Here, we consider a challenging,\nunder-explored and realistic continual adaptation problem: a deployed AI agent\nis continuously provided with unlabeled data that may contain not only unseen\nsamples of known classes but also samples from novel (unknown) classes. In such\na challenging setting, it has only a tiny labeling budget to query the most\ninformative samples to help it continuously learn. We present a comprehensive\nsolution to this complex problem with our model \"CUAL\" (Continual\nUncertainty-aware Active Learner). CUAL leverages an uncertainty estimation\nalgorithm to prioritize active labeling of ambiguous (uncertain) predicted\nnovel class samples while also simultaneously pseudo-labeling the most certain\npredictions of each class. Evaluations across multiple datasets, ablations,\nsettings and backbones (e.g. ViT foundation model) demonstrate our method's\neffectiveness. We will release our code upon acceptance.\n","authors":["Amanda Rios","Ibrahima Ndiour","Parual Datta","Jerry Sydir","Omesh Tickoo","Nilesh Ahuja"],"pdf_url":"https://arxiv.org/pdf/2412.09701v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09547v2","updated":"2024-12-12T19:23:28Z","published":"2024-11-14T16:01:33Z","title":"Piecing It All Together: Verifying Multi-Hop Multimodal Claims","summary":"  Existing claim verification datasets often do not require systems to perform\ncomplex reasoning or effectively interpret multimodal evidence. To address\nthis, we introduce a new task: multi-hop multimodal claim verification. This\ntask challenges models to reason over multiple pieces of evidence from diverse\nsources, including text, images, and tables, and determine whether the combined\nmultimodal evidence supports or refutes a given claim. To study this task, we\nconstruct MMCV, a large-scale dataset comprising 15k multi-hop claims paired\nwith multimodal evidence, generated and refined using large language models,\nwith additional input from human feedback. We show that MMCV is challenging\neven for the latest state-of-the-art multimodal large language models,\nespecially as the number of reasoning hops increases. Additionally, we\nestablish a human performance benchmark on a subset of MMCV. We hope this\ndataset and its evaluation task will encourage future research in multimodal\nmulti-hop claim verification.\n","authors":["Haoran Wang","Aman Rangapur","Xiongxiao Xu","Yueqing Liang","Haroon Gharwi","Carl Yang","Kai Shu"],"pdf_url":"https://arxiv.org/pdf/2411.09547v2.pdf","comment":"COLING 2025"},{"id":"http://arxiv.org/abs/2412.09627v1","updated":"2024-12-12T18:59:59Z","published":"2024-12-12T18:59:59Z","title":"Doe-1: Closed-Loop Autonomous Driving with Large World Model","summary":"  End-to-end autonomous driving has received increasing attention due to its\npotential to learn from large amounts of data. However, most existing methods\nare still open-loop and suffer from weak scalability, lack of high-order\ninteractions, and inefficient decision-making. In this paper, we explore a\nclosed-loop framework for autonomous driving and propose a large Driving wOrld\nmodEl (Doe-1) for unified perception, prediction, and planning. We formulate\nautonomous driving as a next-token generation problem and use multi-modal\ntokens to accomplish different tasks. Specifically, we use free-form texts\n(i.e., scene descriptions) for perception and generate future predictions\ndirectly in the RGB space with image tokens. For planning, we employ a\nposition-aware tokenizer to effectively encode action into discrete tokens. We\ntrain a multi-modal transformer to autoregressively generate perception,\nprediction, and planning tokens in an end-to-end and unified manner.\nExperiments on the widely used nuScenes dataset demonstrate the effectiveness\nof Doe-1 in various tasks including visual question-answering,\naction-conditioned video generation, and motion planning. Code:\nhttps://github.com/wzzheng/Doe.\n","authors":["Wenzhao Zheng","Zetian Xia","Yuanhui Huang","Sicheng Zuo","Jie Zhou","Jiwen Lu"],"pdf_url":"https://arxiv.org/pdf/2412.09627v1.pdf","comment":"Code is available at: https://github.com/wzzheng/Doe"},{"id":"http://arxiv.org/abs/2412.09601v1","updated":"2024-12-12T18:59:11Z","published":"2024-12-12T18:59:11Z","title":"TimeRefine: Temporal Grounding with Time Refining Video LLM","summary":"  Video temporal grounding aims to localize relevant temporal boundaries in a\nvideo given a textual prompt. Recent work has focused on enabling Video LLMs to\nperform video temporal grounding via next-token prediction of temporal\ntimestamps. However, accurately localizing timestamps in videos remains\nchallenging for Video LLMs when relying solely on temporal token prediction.\nOur proposed TimeRefine addresses this challenge in two ways. First, instead of\ndirectly predicting the start and end timestamps, we reformulate the temporal\ngrounding task as a temporal refining task: the model first makes rough\npredictions and then refines them by predicting offsets to the target segment.\nThis refining process is repeated multiple times, through which the model\nprogressively self-improves its temporal localization accuracy. Second, to\nenhance the model's temporal perception capabilities, we incorporate an\nauxiliary prediction head that penalizes the model more if a predicted segment\ndeviates further from the ground truth, thus encouraging the model to make\ncloser and more accurate predictions. Our plug-and-play method can be\nintegrated into most LLM-based temporal grounding approaches. The experimental\nresults demonstrate that TimeRefine achieves 3.6% and 5.0% mIoU improvements on\nthe ActivityNet and Charades-STA datasets, respectively. Code and pretrained\nmodels will be released.\n","authors":["Xizi Wang","Feng Cheng","Ziyang Wang","Huiyu Wang","Md Mohaiminul Islam","Lorenzo Torresani","Mohit Bansal","Gedas Bertasius","David Crandall"],"pdf_url":"https://arxiv.org/pdf/2412.09601v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09600v1","updated":"2024-12-12T18:59:01Z","published":"2024-12-12T18:59:01Z","title":"Owl-1: Omni World Model for Consistent Long Video Generation","summary":"  Video generation models (VGMs) have received extensive attention recently and\nserve as promising candidates for general-purpose large vision models. While\nthey can only generate short videos each time, existing methods achieve long\nvideo generation by iteratively calling the VGMs, using the last-frame output\nas the condition for the next-round generation. However, the last frame only\ncontains short-term fine-grained information about the scene, resulting in\ninconsistency in the long horizon. To address this, we propose an Omni World\nmodeL (Owl-1) to produce long-term coherent and comprehensive conditions for\nconsistent long video generation. As videos are observations of the underlying\nevolving world, we propose to model the long-term developments in a latent\nspace and use VGMs to film them into videos. Specifically, we represent the\nworld with a latent state variable which can be decoded into explicit video\nobservations. These observations serve as a basis for anticipating temporal\ndynamics which in turn update the state variable. The interaction between\nevolving dynamics and persistent state enhances the diversity and consistency\nof the long videos. Extensive experiments show that Owl-1 achieves comparable\nperformance with SOTA methods on VBench-I2V and VBench-Long, validating its\nability to generate high-quality video observations. Code:\nhttps://github.com/huang-yh/Owl.\n","authors":["Yuanhui Huang","Wenzhao Zheng","Yuan Gao","Xin Tao","Pengfei Wan","Di Zhang","Jie Zhou","Jiwen Lu"],"pdf_url":"https://arxiv.org/pdf/2412.09600v1.pdf","comment":"Code is available at: https://github.com/huang-yh/Owl"},{"id":"http://arxiv.org/abs/2412.09596v1","updated":"2024-12-12T18:58:30Z","published":"2024-12-12T18:58:30Z","title":"InternLM-XComposer2.5-OmniLive: A Comprehensive Multimodal System for\n  Long-term Streaming Video and Audio Interactions","summary":"  Creating AI systems that can interact with environments over long periods,\nsimilar to human cognition, has been a longstanding research goal. Recent\nadvancements in multimodal large language models (MLLMs) have made significant\nstrides in open-world understanding. However, the challenge of continuous and\nsimultaneous streaming perception, memory, and reasoning remains largely\nunexplored. Current MLLMs are constrained by their sequence-to-sequence\narchitecture, which limits their ability to process inputs and generate\nresponses simultaneously, akin to being unable to think while perceiving.\nFurthermore, relying on long contexts to store historical data is impractical\nfor long-term interactions, as retaining all information becomes costly and\ninefficient. Therefore, rather than relying on a single foundation model to\nperform all functions, this project draws inspiration from the concept of the\nSpecialized Generalist AI and introduces disentangled streaming perception,\nreasoning, and memory mechanisms, enabling real-time interaction with streaming\nvideo and audio input. The proposed framework InternLM-XComposer2.5-OmniLive\n(IXC2.5-OL) consists of three key modules: (1) Streaming Perception Module:\nProcesses multimodal information in real-time, storing key details in memory\nand triggering reasoning in response to user queries. (2) Multi-modal Long\nMemory Module: Integrates short-term and long-term memory, compressing\nshort-term memories into long-term ones for efficient retrieval and improved\naccuracy. (3) Reasoning Module: Responds to queries and executes reasoning\ntasks, coordinating with the perception and memory modules. This project\nsimulates human-like cognition, enabling multimodal large language models to\nprovide continuous and adaptive service over time.\n","authors":["Pan Zhang","Xiaoyi Dong","Yuhang Cao","Yuhang Zang","Rui Qian","Xilin Wei","Lin Chen","Yifei Li","Junbo Niu","Shuangrui Ding","Qipeng Guo","Haodong Duan","Xin Chen","Han Lv","Zheng Nie","Min Zhang","Bin Wang","Wenwei Zhang","Xinyue Zhang","Jiaye Ge","Wei Li","Jingwen Li","Zhongying Tu","Conghui He","Xingcheng Zhang","Kai Chen","Yu Qiao","Dahua Lin","Jiaqi Wang"],"pdf_url":"https://arxiv.org/pdf/2412.09596v1.pdf","comment":"Github Repo:\n  https://github.com/InternLM/InternLM-XComposer/tree/main/InternLM-XComposer-2.5-OmniLive"},{"id":"http://arxiv.org/abs/2412.09582v1","updated":"2024-12-12T18:54:48Z","published":"2024-12-12T18:54:48Z","title":"Neptune: The Long Orbit to Benchmarking Long Video Understanding","summary":"  This paper describes a semi-automatic pipeline to generate challenging\nquestion-answer-decoy sets for understanding long videos. Many existing video\ndatasets and models are focused on short clips (10s-30s). While some long video\ndatasets do exist, they can often be solved by powerful image models applied\nper frame (and often to very few frames) in a video, and are usually manually\nannotated at high cost. In order to mitigate both these problems, we propose a\nscalable dataset creation pipeline which leverages large models (VLMs and\nLLMs), to automatically generate dense, time-aligned video captions, as well as\ntough question answer decoy sets for video segments (up to 15 minutes in\nlength). Our dataset Neptune covers a broad range of long video reasoning\nabilities and consists of a subset that emphasizes multimodal reasoning. Since\nexisting metrics for open-ended question answering are either rule-based or may\nrely on proprietary models, we provide a new open source model-based metric GEM\nto score open-ended responses on Neptune. Benchmark evaluations reveal that\nmost current open-source long video models perform poorly on Neptune,\nparticularly on questions testing temporal ordering, counting and state\nchanges. Through Neptune, we aim to spur the development of more advanced\nmodels capable of understanding long videos. The dataset is available at\nhttps://github.com/google-deepmind/neptune\n","authors":["Arsha Nagrani","Mingda Zhang","Ramin Mehran","Rachel Hornung","Nitesh Bharadwaj Gundavarapu","Nilpa Jha","Austin Myers","Xingyi Zhou","Boqing Gong","Cordelia Schmid","Mikhail Sirotenko","Yukun Zhu","Tobias Weyand"],"pdf_url":"https://arxiv.org/pdf/2412.09582v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09579v1","updated":"2024-12-12T18:54:07Z","published":"2024-12-12T18:54:07Z","title":"A Theoretical Analysis of Soft-Label vs Hard-Label Training in Neural\n  Networks","summary":"  Knowledge distillation, where a small student model learns from a pre-trained\nlarge teacher model, has achieved substantial empirical success since the\nseminal work of \\citep{hinton2015distilling}. Despite prior theoretical studies\nexploring the benefits of knowledge distillation, an important question remains\nunanswered: why does soft-label training from the teacher require significantly\nfewer neurons than directly training a small neural network with hard labels?\nTo address this, we first present motivating experimental results using simple\nneural network models on a binary classification problem. These results\ndemonstrate that soft-label training consistently outperforms hard-label\ntraining in accuracy, with the performance gap becoming more pronounced as the\ndataset becomes increasingly difficult to classify. We then substantiate these\nobservations with a theoretical contribution based on two-layer neural network\nmodels. Specifically, we show that soft-label training using gradient descent\nrequires only $O\\left(\\frac{1}{\\gamma^2 \\epsilon}\\right)$ neurons to achieve a\nclassification loss averaged over epochs smaller than some $\\epsilon > 0$,\nwhere $\\gamma$ is the separation margin of the limiting kernel. In contrast,\nhard-label training requires $O\\left(\\frac{1}{\\gamma^4} \\cdot\n\\ln\\left(\\frac{1}{\\epsilon}\\right)\\right)$ neurons, as derived from an adapted\nversion of the gradient descent analysis in \\citep{ji2020polylogarithmic}. This\nimplies that when $\\gamma \\leq \\epsilon$, i.e., when the dataset is challenging\nto classify, the neuron requirement for soft-label training can be\nsignificantly lower than that for hard-label training. Finally, we present\nexperimental results on deep neural networks, further validating these\ntheoretical findings.\n","authors":["Saptarshi Mandal","Xiaojun Lin","R. Srikant"],"pdf_url":"https://arxiv.org/pdf/2412.09579v1.pdf","comment":"Main Body of the Paper is under Review at L4DC 2025"},{"id":"http://arxiv.org/abs/2412.09578v1","updated":"2024-12-12T18:53:46Z","published":"2024-12-12T18:53:46Z","title":"DISHONEST: Dissecting misInformation Spread using Homogeneous sOcial\n  NEtworks and Semantic Topic classification","summary":"  The emergence of the COVID-19 pandemic resulted in a significant rise in the\nspread of misinformation on online platforms such as Twitter. Oftentimes this\ngrowth is blamed on the idea of the \"echo chamber.\" However, the behavior said\nto characterize these echo chambers exists in two dimensions. The first is in a\nuser's social interactions, where they are said to stick with the same clique\nof like-minded users. The second is in the content of their posts, where they\nare said to repeatedly espouse homogeneous ideas. In this study, we link the\ntwo by using Twitter's network of retweets to study social interactions and\ntopic modeling to study tweet content. In order to measure the diversity of a\nuser's interactions over time, we develop a novel metric to track the speed at\nwhich they travel through the social network. The application of these analysis\nmethods to misinformation-focused data from the pandemic demonstrates\ncorrelation between social behavior and tweet content. We believe this\ncorrelation supports the common intuition about how antisocial users behave,\nand further suggests that it holds even in subcommunities already rife with\nmisinformation.\n","authors":["Caleb Stam","Emily Saldanha","Mahantesh Halappanavar","Anurag Acharya"],"pdf_url":"https://arxiv.org/pdf/2412.09578v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09569v1","updated":"2024-12-12T18:51:13Z","published":"2024-12-12T18:51:13Z","title":"JuStRank: Benchmarking LLM Judges for System Ranking","summary":"  Given the rapid progress of generative AI, there is a pressing need to\nsystematically compare and choose between the numerous models and\nconfigurations available. The scale and versatility of such evaluations make\nthe use of LLM-based judges a compelling solution for this challenge.\nCrucially, this approach requires first to validate the quality of the LLM\njudge itself. Previous work has focused on instance-based assessment of LLM\njudges, where a judge is evaluated over a set of responses, or response pairs,\nwhile being agnostic to their source systems. We argue that this setting\noverlooks critical factors affecting system-level ranking, such as a judge's\npositive or negative bias towards certain systems. To address this gap, we\nconduct the first large-scale study of LLM judges as system rankers. System\nscores are generated by aggregating judgment scores over multiple system\noutputs, and the judge's quality is assessed by comparing the resulting system\nranking to a human-based ranking. Beyond overall judge assessment, our analysis\nprovides a fine-grained characterization of judge behavior, including their\ndecisiveness and bias.\n","authors":["Ariel Gera","Odellia Boni","Yotam Perlitz","Roy Bar-Haim","Lilach Eden","Asaf Yehudai"],"pdf_url":"https://arxiv.org/pdf/2412.09569v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.20535v2","updated":"2024-12-12T18:45:33Z","published":"2024-05-30T23:20:25Z","title":"Unveiling the Impact of Coding Data Instruction Fine-Tuning on Large\n  Language Models Reasoning","summary":"  Instruction Fine-Tuning (IFT) significantly enhances the zero-shot\ncapabilities of pretrained Large Language Models (LLMs). While coding data is\nknown to boost LLM reasoning abilities during pretraining, its role in\nactivating internal reasoning capacities during IFT remains understudied. This\npaper investigates a key question: How does coding data impact LLMs' reasoning\ncapacities during IFT stage? To explore this, we thoroughly examine the impact\nof coding data across different coding data proportions, model families, sizes,\nand reasoning domains, from various perspectives. Specifically, we create three\nIFT datasets with increasing coding data proportions, fine-tune six LLM\nbackbones across different families and scales on these datasets, evaluate the\ntuned models' performance across twelve tasks in three reasoning domains, and\nanalyze the outcomes from three broad-to-granular perspectives: overall,\ndomain-level, and task-specific. Our holistic analysis provides valuable\ninsights into each perspective. First, coding data tuning enhances the overall\nreasoning capabilities of LLMs across different model families and scales.\nMoreover, while the impact of coding data varies by domain, it shows consistent\ntrends within each domain across different model families and scales.\nAdditionally, coding data generally provides comparable task-specific benefits\nacross model families, with optimal proportions in IFT datasets being\ntask-dependent.\n","authors":["Xinlu Zhang","Zhiyu Zoey Chen","Xi Ye","Xianjun Yang","Lichang Chen","William Yang Wang","Linda Ruth Petzold"],"pdf_url":"https://arxiv.org/pdf/2405.20535v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09544v1","updated":"2024-12-12T18:34:47Z","published":"2024-12-12T18:34:47Z","title":"Sail into the Headwind: Alignment via Robust Rewards and Dynamic Labels\n  against Reward Hacking","summary":"  Aligning AI systems with human preferences typically suffers from the\ninfamous reward hacking problem, where optimization of an imperfect reward\nmodel leads to undesired behaviors. In this paper, we investigate reward\nhacking in offline preference optimization, which aims to improve an initial\nmodel using a preference dataset. We identify two types of reward hacking\nstemming from statistical fluctuations in the dataset: Type I Reward Hacking\ndue to subpar choices appearing more favorable, and Type II Reward Hacking due\nto decent choices appearing less favorable. We prove that many (mainstream or\ntheoretical) preference optimization methods suffer from both types of reward\nhacking. To mitigate Type I Reward Hacking, we propose POWER, a new preference\noptimization method that combines Guiasu's weighted entropy with a robust\nreward maximization objective. POWER enjoys finite-sample guarantees under\ngeneral function approximation, competing with the best covered policy in the\ndata. To mitigate Type II Reward Hacking, we analyze the learning dynamics of\npreference optimization and develop a novel technique that dynamically updates\npreference labels toward certain \"stationary labels\", resulting in diminishing\ngradients for untrustworthy samples. Empirically, POWER with dynamic labels\n(POWER-DL) consistently outperforms state-of-the-art methods on alignment\nbenchmarks, achieving improvements of up to 13.0 points on AlpacaEval 2.0 and\n11.5 points on Arena-Hard over DPO, while also improving or maintaining\nperformance on downstream tasks such as mathematical reasoning. Strong\ntheoretical guarantees and empirical results demonstrate the promise of\nPOWER-DL in mitigating reward hacking.\n","authors":["Paria Rashidinejad","Yuandong Tian"],"pdf_url":"https://arxiv.org/pdf/2412.09544v1.pdf","comment":"46 pages, 3 figures"},{"id":"http://arxiv.org/abs/2412.09666v1","updated":"2024-12-12T18:16:46Z","published":"2024-12-12T18:16:46Z","title":"Systematic Analysis of LLM Contributions to Planning: Solver, Verifier,\n  Heuristic","summary":"  In this work, we provide a systematic analysis of how large language models\n(LLMs) contribute to solving planning problems. In particular, we examine how\nLLMs perform when they are used as problem solver, solution verifier, and\nheuristic guidance to improve intermediate solutions. Our analysis reveals that\nalthough it is difficult for LLMs to generate correct plans out-of-the-box,\nLLMs are much better at providing feedback signals to intermediate/incomplete\nsolutions in the form of comparative heuristic functions. This evaluation\nframework provides insights into how future work may design better LLM-based\ntree-search algorithms to solve diverse planning and reasoning problems. We\nalso propose a novel benchmark to evaluate LLM's ability to learn user\npreferences on the fly, which has wide applications in practical settings.\n","authors":["Haoming Li","Zhaoliang Chen","Songyuan Liu","Yiming Lu","Fei Liu"],"pdf_url":"https://arxiv.org/pdf/2412.09666v1.pdf","comment":null}]}}